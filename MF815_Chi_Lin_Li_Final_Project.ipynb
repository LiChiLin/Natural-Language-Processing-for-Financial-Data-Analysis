{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHt0tbUAS4l4",
        "outputId": "61df31ca-33fa-47ae-8943-e1f2869340e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Import the libraries\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from math import ceil\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import collections\n",
        "import random\n",
        "import time\n",
        "import string\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, Convolution1D, MaxPooling1D, GlobalMaxPooling1D, Flatten, Dropout, LSTM, Bidirectional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26pnjlfVOXg5",
        "outputId": "e812298f-4a43-4749-94ff-af1fcf16738e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Uncomment if you aare using colab. Now we connect the colab notebook to our drive to access the data.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "# Run the cell and follow the instructions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzGOcqIbS9aa",
        "outputId": "d01f025c-0c80-4390-cf49-654dbbb3f4e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n"
          ]
        }
      ],
      "source": [
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LaLI_lZqTBKE"
      },
      "outputs": [],
      "source": [
        "\n",
        "DIRECTORY = '/content/gdrive/MyDrive/Colab Notebooks/MF815/NLP/NLP_app'\n",
        "\n",
        "SUMMARY_PATH = '/content/gdrive/MyDrive/Colab Notebooks/MF815/NLP/NLP_app/MutualFundSummary'\n",
        "SUMMARY_LABELS_PATH = '/content/gdrive/MyDrive/Colab Notebooks/MF815/NLP/NLP_app/MutualFundLabels.csv'\n",
        "\n",
        "HEALTHY_ARTICLES_PATH = os.path.join(DIRECTORY, \"Data\", \"FundArticlesHealthy.csv\")\n",
        "UNHEALTHY_ARTICLES_PATH = os.path.join(DIRECTORY, \"Data\", \"FundArticlesUnhealthy.csv\")\n",
        "\n",
        "glove_word2vec = 'glove.6B.50d.txt'\n",
        "our_word2vec = 'word2vec_perso.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArnUQvMhw4xZ"
      },
      "outputs": [],
      "source": [
        "# DIRECTORY = 'NLP_app'\n",
        "\n",
        "# SUMMARY_PATH = 'NLP_app/MutualFundSummary'\n",
        "# SUMMARY_LABELS_PATH = 'NLP_app/MutualFundLabels.csv'\n",
        "\n",
        "# HEALTHY_ARTICLES_PATH = os.path.join(DIRECTORY, \"Data\", \"FundArticlesHealthy.csv\")\n",
        "# UNHEALTHY_ARTICLES_PATH = os.path.join(DIRECTORY, \"Data\", \"FundArticlesUnhealthy.csv\")\n",
        "\n",
        "# glove_word2vec = 'glove.6B.50d.txt'\n",
        "# our_word2vec = 'word2vec_perso.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_C4x_FBTC4k"
      },
      "outputs": [],
      "source": [
        "# Progress bar\n",
        "def progress(value, max=100):\n",
        "    return HTML(\"\"\"\n",
        "        <progress\n",
        "            value='{value}'\n",
        "            max='{max}',\n",
        "            style='width: 100%'\n",
        "        >\n",
        "            {value}\n",
        "        </progress>\n",
        "    \"\"\".format(value=value, max=max))\n",
        "\n",
        "# Save a word2vec dictionary.\n",
        "def save_word2vec(filename):\n",
        "    #with open(os.path.join('/Users/haoxing/Documents/Work/Teaching/Machine learning for Finance/Codes/NLP/NLP_app', filename),'a' , encoding='utf-8') as f :\n",
        "    with open(os.path.join('/content/gdrive/MyDrive/Colab Notebooks/MF815/NLP/NLP_app/', filename),'a' , encoding='utf-8') as f :\n",
        "        for k, v in word2vec.items():\n",
        "            line = k+' '+str(list(v)).strip('[]').replace(',','')+'\\n'\n",
        "            f.write(line)\n",
        "\n",
        "# Load a word2vec dictionary.\n",
        "def load_word2vec(filename):\n",
        "    word2vec = {}\n",
        "    #with open(os.path.join('/Users/haoxing/Documents/Work/Teaching/Machine learning for Finance/Codes/NLP/NLP_app', filename), encoding='utf8') as f:\n",
        "    with open(os.path.join('/content/gdrive/MyDrive/Colab Notebooks/MF815/NLP/NLP_app/', filename), encoding='utf8') as f:\n",
        "        for line in f:\n",
        "            try :\n",
        "                values = line.split()\n",
        "                word = values[0]\n",
        "                vec = np.asarray(values[1:], dtype='float32')\n",
        "                word2vec[word] = vec\n",
        "            except :\n",
        "                None\n",
        "    return word2vec\n",
        "\n",
        "# read the repo in PATH and append the texts in a list\n",
        "def get_data(PATH):\n",
        "    list_dir = os.listdir(PATH)\n",
        "    texts = []\n",
        "    fund_names = []\n",
        "    out = display(progress(0, len(list_dir)-1), display_id=True)\n",
        "    for ii, filename in enumerate(list_dir) :\n",
        "        with open(PATH+'/'+filename, 'r', encoding=\"utf8\") as f :\n",
        "            txt = f.read()\n",
        "            try :\n",
        "                txt_split = txt.split('<head_breaker>')\n",
        "                summary = txt_split[1].strip()\n",
        "                fund_name = txt_split[0].strip()\n",
        "            except :\n",
        "                summary = txt\n",
        "                fund_name = ''\n",
        "        texts.append(summary)\n",
        "        fund_names.append(fund_name)\n",
        "        out.update(progress(ii, len(list_dir)-1))\n",
        "    return fund_names, texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "MqrqAYODTL6o",
        "outputId": "14b26062-00b6-4933-ee4d-70baad5adfbc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       id                                          fund_name  \\\n",
              "0    0000051931-18-000151                   American Funds College 2018 Fund   \n",
              "1    0000051931-18-000151                   American Funds College 2021 Fund   \n",
              "2    0000051931-18-000151                   American Funds College 2024 Fund   \n",
              "3    0000051931-18-000151                   American Funds College 2027 Fund   \n",
              "4    0000051931-18-000151                   American Funds College 2030 Fund   \n",
              "..                    ...                                                ...   \n",
              "462  0001710607-18-000172    American Century Diversified Corporate Bond ETF   \n",
              "463  0001710607-18-000172    American Century Diversified Municipal Bond ETF   \n",
              "464  0001710607-18-000172  American Century Quality Diversified Internati...   \n",
              "465  0001710607-18-000172     American Century STOXX U.S. Quality Growth ETF   \n",
              "466  0001710607-18-000172      American Century STOXX U.S. Quality Value ETF   \n",
              "\n",
              "    Performance fee?                 Ivestment Strategy Leverage?  \\\n",
              "0                NaN           Balanced Fund (Low Risk)       Yes   \n",
              "1                NaN           Balanced Fund (Low Risk)       Yes   \n",
              "2                NaN           Balanced Fund (Low Risk)       Yes   \n",
              "3                NaN           Balanced Fund (Low Risk)       Yes   \n",
              "4                NaN           Balanced Fund (Low Risk)       Yes   \n",
              "..               ...                                ...       ...   \n",
              "462              NaN  Fixed Income Long Only (Low Risk)       Yes   \n",
              "463              NaN  Fixed Income Long Only (Low Risk)        No   \n",
              "464              NaN        Equity Long Only (Low Risk)       Yes   \n",
              "465              NaN        Equity Long Only (Low Risk)       Yes   \n",
              "466              NaN        Equity Long Only (Low Risk)       Yes   \n",
              "\n",
              "                                 Portfolio composition  Concentration  \n",
              "0                          Investment grade securities    Diversified  \n",
              "1                          Investment grade securities    Diversified  \n",
              "2                          Investment grade securities    Diversified  \n",
              "3                          Investment grade securities    Diversified  \n",
              "4                          Investment grade securities    Diversified  \n",
              "..                                                 ...            ...  \n",
              "462                        Investment grade securities    Diversified  \n",
              "463                        Investment grade securities    Diversified  \n",
              "464  Sub-investment grade securities or emerging ma...    Diversified  \n",
              "465                                    Listed Equities    Diversified  \n",
              "466                                    Listed Equities    Diversified  \n",
              "\n",
              "[467 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b91a704c-9f71-4dbd-9ee3-416f4f8cd68c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>fund_name</th>\n",
              "      <th>Performance fee?</th>\n",
              "      <th>Ivestment Strategy</th>\n",
              "      <th>Leverage?</th>\n",
              "      <th>Portfolio composition</th>\n",
              "      <th>Concentration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000051931-18-000151</td>\n",
              "      <td>American Funds College 2018 Fund</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Balanced Fund (Low Risk)</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Investment grade securities</td>\n",
              "      <td>Diversified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000051931-18-000151</td>\n",
              "      <td>American Funds College 2021 Fund</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Balanced Fund (Low Risk)</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Investment grade securities</td>\n",
              "      <td>Diversified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000051931-18-000151</td>\n",
              "      <td>American Funds College 2024 Fund</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Balanced Fund (Low Risk)</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Investment grade securities</td>\n",
              "      <td>Diversified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0000051931-18-000151</td>\n",
              "      <td>American Funds College 2027 Fund</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Balanced Fund (Low Risk)</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Investment grade securities</td>\n",
              "      <td>Diversified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0000051931-18-000151</td>\n",
              "      <td>American Funds College 2030 Fund</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Balanced Fund (Low Risk)</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Investment grade securities</td>\n",
              "      <td>Diversified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>462</th>\n",
              "      <td>0001710607-18-000172</td>\n",
              "      <td>American Century Diversified Corporate Bond ETF</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Fixed Income Long Only (Low Risk)</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Investment grade securities</td>\n",
              "      <td>Diversified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>463</th>\n",
              "      <td>0001710607-18-000172</td>\n",
              "      <td>American Century Diversified Municipal Bond ETF</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Fixed Income Long Only (Low Risk)</td>\n",
              "      <td>No</td>\n",
              "      <td>Investment grade securities</td>\n",
              "      <td>Diversified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>464</th>\n",
              "      <td>0001710607-18-000172</td>\n",
              "      <td>American Century Quality Diversified Internati...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Equity Long Only (Low Risk)</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Sub-investment grade securities or emerging ma...</td>\n",
              "      <td>Diversified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>465</th>\n",
              "      <td>0001710607-18-000172</td>\n",
              "      <td>American Century STOXX U.S. Quality Growth ETF</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Equity Long Only (Low Risk)</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Listed Equities</td>\n",
              "      <td>Diversified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>466</th>\n",
              "      <td>0001710607-18-000172</td>\n",
              "      <td>American Century STOXX U.S. Quality Value ETF</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Equity Long Only (Low Risk)</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Listed Equities</td>\n",
              "      <td>Diversified</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>467 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b91a704c-9f71-4dbd-9ee3-416f4f8cd68c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b91a704c-9f71-4dbd-9ee3-416f4f8cd68c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b91a704c-9f71-4dbd-9ee3-416f4f8cd68c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0f7cd9ea-a635-4246-a306-fc70ab44d60a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0f7cd9ea-a635-4246-a306-fc70ab44d60a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0f7cd9ea-a635-4246-a306-fc70ab44d60a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_MutualFundLabels",
              "summary": "{\n  \"name\": \"df_MutualFundLabels\",\n  \"rows\": 467,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 58,\n        \"samples\": [\n          \"0000051931-18-000151\",\n          \"0000051931-18-001409\",\n          \"0001193125-18-286983\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fund_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 467,\n        \"samples\": [\n          \"American Funds 2055 Target Date Retirement Fund\",\n          \"GROWTH FUND\",\n          \"Portfolio Series - American Funds Managed Risk Global Allocation Portfolio\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Performance fee?\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Some performance Fees\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ivestment Strategy\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Fixed Income Long Only (Low Risk)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Leverage?\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Portfolio composition\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Investment grade securities\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" Concentration\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Concentrated by issuer / sector / jurisdiction\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df_MutualFundLabels = pd.read_csv(SUMMARY_LABELS_PATH)\n",
        "df_MutualFundLabels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pj6znaguZTYn"
      },
      "source": [
        "# 1. Split the data into training, validation, and testing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVQu4fVSw4xa"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEdwjzvlw4xa",
        "outputId": "195f6d37-f10c-4d22-cffb-91c92297d826"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values per column:\n",
            "id                         0\n",
            "fund_name                  0\n",
            "Performance fee?         447\n",
            "Ivestment Strategy         0\n",
            "Leverage?                  0\n",
            "Portfolio composition      0\n",
            " Concentration             0\n",
            "dtype: int64\n",
            "\n",
            "Distribution of 'Investment Strategy':\n",
            "Ivestment Strategy\n",
            "Equity Long Only (Low Risk)          248\n",
            "Fixed Income Long Only (Low Risk)    130\n",
            "Balanced Fund (Low Risk)              84\n",
            "Long Short Funds (High Risk)           4\n",
            "Commodities Fund (Low Risk)            1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Distribution of 'Performance fee?':\n",
            "Performance fee?\n",
            "Some performance Fees    20\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Distribution of 'Leverage?':\n",
            "Leverage?\n",
            "No     275\n",
            "Yes    192\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Distribution of 'Portfolio composition?':\n",
            "Portfolio composition\n",
            "Investment grade securities                            183\n",
            "Listed Equities                                        177\n",
            "Sub-investment grade securities or emerging markets    107\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Distribution of 'Concentration?':\n",
            " Concentration\n",
            "Diversified                                       375\n",
            "Concentrated by issuer / sector / jurisdiction     92\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "nan_counts = df_MutualFundLabels.isna().sum()\n",
        "print(\"Missing values per column:\")\n",
        "print(nan_counts)\n",
        "\n",
        "# Distribution and imbalance check for categorical data\n",
        "print(\"\\nDistribution of 'Investment Strategy':\")\n",
        "print(df_MutualFundLabels['Ivestment Strategy'].value_counts())\n",
        "\n",
        "print(\"\\nDistribution of 'Performance fee?':\")\n",
        "print(df_MutualFundLabels['Performance fee?'].value_counts())\n",
        "\n",
        "print(\"\\nDistribution of 'Leverage?':\")\n",
        "print(df_MutualFundLabels['Leverage?'].value_counts())\n",
        "\n",
        "print(\"\\nDistribution of 'Portfolio composition?':\")\n",
        "print(df_MutualFundLabels['Portfolio composition'].value_counts())\n",
        "\n",
        "print(\"\\nDistribution of 'Concentration?':\")\n",
        "print(df_MutualFundLabels[' Concentration'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "PxZdPf5TZn35",
        "outputId": "f0fa11eb-71a3-4abd-eb3d-7e77f8d8d67f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       id                               fund_name  \\\n",
              "26   0000051931-18-000465                Managed Risk Growth Fund   \n",
              "7    0000051931-18-000151  American Funds College Enrollment Fund   \n",
              "426  0001591556-18-000016    Dreyfus Global Emerging Markets Fund   \n",
              "108  0000940394-18-000852                 Eaton Vance Growth Fund   \n",
              "423  0001580642-18-006021  Anchor Tactical Equity Strategies Fund   \n",
              "..                    ...                                     ...   \n",
              "106  0000940394-18-000852       Eaton Vance Dividend Builder Fund   \n",
              "270  0001193125-18-227777           Ivy Global Equity Income Fund   \n",
              "348  0001379491-18-003799             Franklin FTSE Australia ETF   \n",
              "435  0001683863-18-000108                      S&P 500 Index Fund   \n",
              "102  0000932471-18-008471  Vanguard Russell 2000 Value Index Fund   \n",
              "\n",
              "    Performance fee? Leverage?  \\\n",
              "26               NaN       Yes   \n",
              "7                NaN       Yes   \n",
              "426              NaN       Yes   \n",
              "108              NaN        No   \n",
              "423              NaN       Yes   \n",
              "..               ...       ...   \n",
              "106              NaN       Yes   \n",
              "270              NaN        No   \n",
              "348              NaN        No   \n",
              "435              NaN        No   \n",
              "102              NaN        No   \n",
              "\n",
              "                                 Portfolio composition  \\\n",
              "26                         Investment grade securities   \n",
              "7                          Investment grade securities   \n",
              "426  Sub-investment grade securities or emerging ma...   \n",
              "108                                    Listed Equities   \n",
              "423                        Investment grade securities   \n",
              "..                                                 ...   \n",
              "106                                    Listed Equities   \n",
              "270                                    Listed Equities   \n",
              "348                                    Listed Equities   \n",
              "435                                    Listed Equities   \n",
              "102                        Investment grade securities   \n",
              "\n",
              "                                      Concentration  \n",
              "26                                      Diversified  \n",
              "7                                       Diversified  \n",
              "426                                     Diversified  \n",
              "108                                     Diversified  \n",
              "423                                     Diversified  \n",
              "..                                              ...  \n",
              "106                                     Diversified  \n",
              "270                                     Diversified  \n",
              "348  Concentrated by issuer / sector / jurisdiction  \n",
              "435                                     Diversified  \n",
              "102                                     Diversified  \n",
              "\n",
              "[326 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7725d41f-c9cf-48b1-8b90-684dcae0a959\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>fund_name</th>\n",
              "      <th>Performance fee?</th>\n",
              "      <th>Leverage?</th>\n",
              "      <th>Portfolio composition</th>\n",
              "      <th>Concentration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0000051931-18-000465</td>\n",
              "      <td>Managed Risk Growth Fund</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Investment grade securities</td>\n",
              "      <td>Diversified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0000051931-18-000151</td>\n",
              "      <td>American Funds College Enrollment Fund</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Investment grade securities</td>\n",
              "      <td>Diversified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>426</th>\n",
              "      <td>0001591556-18-000016</td>\n",
              "      <td>Dreyfus Global Emerging Markets Fund</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Sub-investment grade securities or emerging ma...</td>\n",
              "      <td>Diversified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>0000940394-18-000852</td>\n",
              "      <td>Eaton Vance Growth Fund</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>Listed Equities</td>\n",
              "      <td>Diversified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>423</th>\n",
              "      <td>0001580642-18-006021</td>\n",
              "      <td>Anchor Tactical Equity Strategies Fund</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Investment grade securities</td>\n",
              "      <td>Diversified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>0000940394-18-000852</td>\n",
              "      <td>Eaton Vance Dividend Builder Fund</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Listed Equities</td>\n",
              "      <td>Diversified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>0001193125-18-227777</td>\n",
              "      <td>Ivy Global Equity Income Fund</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>Listed Equities</td>\n",
              "      <td>Diversified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>348</th>\n",
              "      <td>0001379491-18-003799</td>\n",
              "      <td>Franklin FTSE Australia ETF</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>Listed Equities</td>\n",
              "      <td>Concentrated by issuer / sector / jurisdiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>0001683863-18-000108</td>\n",
              "      <td>S&amp;P 500 Index Fund</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>Listed Equities</td>\n",
              "      <td>Diversified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>0000932471-18-008471</td>\n",
              "      <td>Vanguard Russell 2000 Value Index Fund</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>Investment grade securities</td>\n",
              "      <td>Diversified</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>326 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7725d41f-c9cf-48b1-8b90-684dcae0a959')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7725d41f-c9cf-48b1-8b90-684dcae0a959 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7725d41f-c9cf-48b1-8b90-684dcae0a959');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bd867348-8328-42a4-8654-dd5b5c178cbb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bd867348-8328-42a4-8654-dd5b5c178cbb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bd867348-8328-42a4-8654-dd5b5c178cbb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_train",
              "summary": "{\n  \"name\": \"X_train\",\n  \"rows\": 326,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 55,\n        \"samples\": [\n          \"0001193125-18-091654\",\n          \"0001683863-18-000339\",\n          \"0000932471-18-008471\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fund_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 326,\n        \"samples\": [\n          \"Variable Portfolio - BlackRock Global Inflation-Protected Securities Fund\",\n          \"AllianzGI Global Small-Cap Fund\",\n          \"JPMorgan New York Tax Free Bond Fund\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Performance fee?\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Some performance Fees\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Leverage?\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Portfolio composition\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Investment grade securities\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" Concentration\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Concentrated by issuer / sector / jurisdiction\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "y = df_MutualFundLabels['Ivestment Strategy']\n",
        "X = df_MutualFundLabels.drop(columns =\"Ivestment Strategy\")\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Split the temp into validation (2/3 of temp, which is 20% of the total data) and test (1/3 of temp, 10% of the total data)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=1/3, random_state=42)\n",
        "\n",
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yoNQd7Uw4xa",
        "outputId": "e5206072-acf8-4bc4-d034-972c5f2e03e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(326, 6)\n",
            "(94, 6)\n",
            "(47, 6)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(X_val.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sk6QQf9gaN2f"
      },
      "source": [
        "# 2. Following the NLP application in class,use the skip-gram model to build a word embedding dictionary from the mutual fund summaries in the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "egHLsusjPYun",
        "outputId": "e2c9b68a-d0d6-42f4-c7fb-60f285a7ef1a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <progress\n",
              "            value='544'\n",
              "            max='544',\n",
              "            style='width: 100%'\n",
              "        >\n",
              "            544\n",
              "        </progress>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Managed Risk Growth Fund', 'American Funds College Enrollment Fund', 'Dreyfus Global Emerging Markets Fund', 'Eaton Vance Growth Fund', 'Anchor Tactical Equity Strategies Fund', 'Cornerstone Moderately Aggressive Fund', 'Eaton Vance Arizona Municipal Income Fund', 'Eaton Vance TABS 10-to-20 Year Laddered Municipal Bond Fund', 'Fidelity Simplicity RMD 2015 Fund', 'MainStay VP Janus Henderson Balanced Portfolio', 'Columbia Overseas Value Fund', 'Fidelity Advisor Utilities Fund', 'Franklin FTSE Hong Kong ETF', 'Fidelity International Discovery Fund', 'PIMCO California Municipal Bond Fund', 'Janus Henderson Mid Cap Value Portfolio', 'Swan Defined Risk Emerging Markets Fund', 'MFS Tennessee Municipal Bond Fund', 'Fidelity Advisor Health Care Fund', 'Columbia Small Cap Value Fund II', 'Janus Henderson Research Fund', 'Franklin FTSE Europe ETF', 'Columbia Small Cap Index Fund', 'Variable Portfolio - Oppenheimer International Growth Fund', 'Eaton Vance Large-Cap Value Fund', 'PIMCO REALPATH 2050 Fund', 'MainStay VP Common Stock Portfolio', 'PIMCO California Intermediate Municipal Bond Fund', 'MainStay VP Income Builder Portfolio', 'American Century Growth ETF', 'Franklin FTSE Mexico ETF', 'Vanguard Long-Term Treasury Fund', 'Variable Portfolio - Morgan Stanley Advantage Fund', 'Janus Henderson Enterprise Fund', 'Fidelity Managed Retirement Income Fund', 'Columbia Variable Portfolio - Government Money Market Fund', 'T. Rowe Price Emerging Markets Stock Fund', 'Anchor Tactical Credit Strategies Fund', 'AllianzGI Emerging Markets Opportunities Fund', 'Fidelity Flex U.S. Bond Index Fund', 'Eaton Vance Connecticut Municipal Income Fund', 'AllianzGI NFJ Small-Cap Value Fund', 'Ivy Micro Cap Growth Fund', 'AllianzGI Small-Cap Fund', 'Fidelity Advisor Freedom 2030 Fund', 'Columbia Variable Portfolio - Dividend Opportunity Fund', 'Janus Henderson Forty Portfolio', 'Columbia Select Large Cap Equity Fund', 'Franklin Payout 2018 Fund', 'Franklin Liberty International Opportunities ETF', 'U.S. Government/AAA-Rated Securities Fund', 'MFS Pennsylvania Municipal Bond Fund', 'Fidelity Advisor Financial Services Fund', 'Variable Portfolio - MFS Value Fund', 'Fidelity Diversified International Fund', 'Ivy Balanced Fund', 'ADAPTIVE EQUITY FUND', 'Eaton Vance Small-Cap Fund', 'Janus Henderson Global Research Portfolio', 'American Century STOXX U.S. Quality Growth ETF', 'American Funds College 2036 Fund', 'Franklin LibertyQ Global Dividend ETF', 'Fidelity Flex Opportunistic Insights Fund', 'MainStay VP S&P 500 Index Portfolio', 'MainStay VP Epoch U.S. Small Cap Portfolio', 'Janus Henderson International Small Cap Fund', 'Western Asset Intermediate Maturity California Municipals Fund', 'Blue Chip Income and Growth Fund', 'Franklin FTSE India ETF', 'Vanguard Russell 3000 Index Fund', 'Vanguard Intermediate-Term Treasury Fund', 'American Funds Conservative Growth and Income Portfolio', 'Precious Metals and Minerals Fund', 'Janus Henderson Forty Fund', 'Emerging Markets Fund', 'Ivy Global Income Allocation Fund', 'Columbia Variable Portfolio - Income Opportunities Fund', 'Government Securities Fund', 'Fidelity Advisor Freedom 2040 Fund', 'Fidelity ZERO Extended Market Index Fund', 'Columbia Variable Portfolio - Emerging Markets Fund', 'Vanguard Energy Fund', 'MainStay VP Convertible Portfolio', 'Janus Henderson Contrarian Fund', 'PIMCO REALPATH 2020 Fund', 'MainStay VP Eagle Small Growth Portfolio', 'American Funds College 2024 Fund', 'Vanguard Real Estate Index Fund', 'Franklin LibertyQ International Equity Hedged ETF', 'SUSTAINABLE EQUITY FUND', 'Ivy Core Equity Fund', 'Eaton Vance Pennsylvania Municipal Income Fund', 'Fidelity Series Short-Term Credit Fund', 'Vanguard Long-Term Treasury Index Fund', 'MFS West Virginia Municipal Bond Fund', 'Franklin FTSE France ETF', 'Fidelity Advisor Freedom 2050 Fund', 'Total Return Strategy Fund', 'Vanguard Russell 1000 Growth Index Fund', 'Ivy Small Cap Core Fund', 'SMALL CAP GROWTH FUND', 'International Growth and Income Fund', 'Ultra-Short Bond Fund', 'MainStay VP Balanced Portfolio', 'Eaton Vance New Jersey Municipal Income Fund', 'Janus Henderson Venture Fund', 'Columbia Variable Portfolio - Mid Cap Growth Fund', 'Janus Henderson U.S. Growth Opportunities Fund', 'SELECT FUND', 'Columbia Select International Equity Fund', 'AllianzGI Global Small-Cap Fund', 'Ivy Science and Technology Fund', 'Ivy Managed International Opportunities Fund', 'Fidelity International Growth Fund', 'Franklin Liberty Municipal Bond ETF', 'Franklin Liberty U.S. Low Volatility ETF', 'Franklin Payout 2023 Fund', 'MFS Strategic Income Fund', 'Ivy Municipal Bond Fund', 'Janus Henderson Global Technology Portfolio', 'Fidelity Simplicity RMD 2010 Fund', 'Janus Henderson Flexible Bond Portfolio', 'MFS Alabama Municipal Bond Fund', 'Fidelity Simplicity RMD 2020 Fund', 'Ivy Energy Fund', 'JPMorgan Europe Dynamic Fund', 'Franklin FTSE Europe Hedged ETF', 'Fidelity Municipal Income 2023 Fund', 'Fidelity Advisor Freedom 2035 Fund', 'Fidelity International Capital Appreciation Fund', 'Franklin FTSE Italy ETF', 'Delaware International Small Cap Fund', 'Eaton Vance Special Equities Fund', 'Janus Henderson Overseas Fund', 'Ivy Securian Real Estate Securities Fund', 'DELAWARE INTERNATIONAL VALUE EQUITY FUND', 'Capital Growth Fund', 'Income Stock Fund', 'Fidelity Advisor Freedom 2055 Fund', 'PIMCO REALPATH 2030 Fund', 'Ivy Value Fund', 'Janus Henderson Emerging Markets Fund', 'MFS Municipal Income Fund', 'Columbia Variable Portfolio - High Yield Bond Fund', 'AllianzGI NFJ International Value Fund', 'PIMCO REALPATH 2025 Fund', 'Eaton Vance TABS 5-to-15 Year Laddered Municipal Bond Fund', 'Eaton Vance Minnesota Municipal Income Fund', 'Franklin FTSE Japan Hedged ETF', 'Janus Henderson Global Unconstrained Bond Portfolio', 'Franklin LibertyQ U.S. Small Cap Equity ETF', 'Fidelity Emerging Markets Discovery Fund', 'MFS Global Total Return Fund', 'Ivy Securian Core Bond Fund', 'Fidelity Simplicity RMD Income Fund', 'Eaton Vance Global Small-Cap Fund', 'Franklin FTSE Asia ex Japan ETF', 'Multi-Manager Value Strategies Fund', 'MFS Maryland Municipal Bond Fund', 'Fidelity Advisor Energy Fund', 'American Funds Retirement Income Portfolio - Enhanced', 'Federated MDT Large Cap Growth Fund', 'NT GROWTH FUND', 'Ivy Natural Resources Fund', 'Vanguard Short-Term Federal Fund', 'Columbia Mid Cap Index Fund', 'Western Asset Massachusetts Municipals Fund', 'MainStay VP Small Cap Core Portfolio', 'Capital Income Builder', 'Portfolio Series - American Funds Managed Risk Growth and Income Portfolio', 'Managed Risk International Fund', 'Janus Henderson Global Real Estate Fund', 'MFS Virginia Municipal Bond Fund', 'Franklin LibertyQ Global Equity ETF', 'Fidelity Advisor Series Opportunistic Insights Fund', 'Janus Henderson Global Bond Portfolio', 'Vanguard Long-Term Corporate Bond Index Fund', 'American Funds 2035 Target Date Retirement Fund', 'Columbia Large Cap Growth Fund III', 'Franklin FTSE Brazil ETF', 'Franklin FTSE Germany ETF', 'Janus Henderson International Value Fund', 'American Funds Tax-Advantaged Growth and Income Portfolio', 'Franklin FTSE Switzerland ETF', 'Columbia Variable Portfolio - U.S. Government Mortgage Fund', 'Ivy Municipal High Income Fund', 'AllianzGI Health Sciences Fund', 'Fidelity Managed Retirement 2015 Fund', 'American Funds College 2030 Fund', 'AllianzGI Mid-Cap Fund', 'Swan Defined Risk U.S. Small Cap Fund', 'Vanguard Russell 2000 Growth Index Fund', 'Janus Henderson Overseas Portfolio', 'Franklin Payout 2022 Fund', 'Variable Portfolio - T. Rowe Price Large Cap Value Fund', 'Janus Henderson Global Research Fund', 'Vanguard Russell 1000 Index Fund', 'NORTHERN MONEY MARKET FUND', 'Variable Portfolio - Victory Sycamore Established Value Fund', 'BALANCED FUND', 'American Funds 2015 Target Date Retirement Fund', 'Portfolio Series - American Funds Growth and Income Portfolio', 'Ivy Emerging Markets Equity Fund', 'Fidelity Advisor Freedom 2010 Fund', 'Columbia Variable Portfolio - Large Cap Growth Fund', 'Swan Defined Risk Foreign Developed Fund', 'Managed Risk Growth-Income Fund', 'Science & Technology Fund', 'PIMCO California Short Duration Municipal Income Fund', 'AllianzGI NFJ Mid-Cap Value Fund', 'Ivy Small Cap Growth Fund', 'Janus Henderson Balanced Fund', 'Franklin Payout 2020 Fund', 'MFS North Carolina Municipal Bond Fund', 'CAPITAL VALUE FUND', 'MFS Mississippi Municipal Bond Fund', 'MFS Utilities Fund', 'World Growth Fund', 'American Funds U.S. Government Money Market Fund', 'Fidelity Advisor Freedom 2005 Fund', 'Nasdaq-100 Index Fund', 'HERITAGE FUND', 'Columbia Large Cap Value Fund', 'Global Balanced Fund', 'MainStay VP MFS Utilities Portfolio', 'American Funds Preservation Portfolio', 'Federated MDT Balanced Fund', 'Fidelity Municipal Income 2019 Fund', 'Variable Portfolio - Wells Fargo Short Duration Government Fund', 'Ivy Mid Cap Growth Fund', 'Fidelity Series Corporate Bond Fund', 'Fidelity Flex Conservative Income Bond Fund', 'Fidelity Advisor Freedom 2060 Fund', 'PIMCO REALPATH 2045 Fund', 'Variable Portfolio - BlackRock Global Inflation-Protected Securities Fund', 'Variable Portfolio - Partners Small Cap Value Fund', 'NORTHERN U.S. GOVERNMENT SELECT MONEY MARKET FUND', 'Dreyfus Yield Enhancement Strategy Fund', 'AllianzGI Focused Growth Fund', 'USAA MSCI Emerging Markets Value Momentum Blend Index ETF', 'Federated MDT All Cap Core Fund', 'Columbia Small/Mid Cap Value Fund', 'Franklin FTSE Canada ETF', 'Ivy European Opportunities Fund', 'Columbia Variable Portfolio - Large Cap Index Fund', 'Janus Henderson Asia Equity Fund', 'American Funds Retirement Income Portfolio - Conservative', 'Janus Henderson Balanced Portfolio', 'Thrivent Partner Healthcare Portfolio', 'JPMorgan New York Tax Free Bond Fund', 'AllianzGI NFJ Large-Cap Value Fund', 'Vanguard Short-Term Treasury Index Fund', 'American Funds 2045 Target Date Retirement Fund', 'Fidelity Managed Retirement 2020 Fund', 'American Funds College 2021 Fund', 'Fidelity Global Equity Income Fund', 'Intermediate-Term Bond Fund', 'American Funds 2025 Target Date Retirement Fund', 'Vanguard Intermediate-Term Investment-Grade Fund', 'Columbia Variable Portfolio - Select Smaller-Cap Value Fund', 'Portfolio Series - American Funds Managed Risk Growth Portfolio', 'AllianzGI Technology Fund', 'Franklin FTSE United Kingdom ETF', 'Vanguard Precious Metals and Mining Fund', 'Fidelity Advisor Consumer Discretionary Fund', 'Managed Allocation Fund', 'American Funds 2040 Target Date Retirement Fund', 'Fidelity Advisor Technology Fund', 'Ivy Asset Strategy Fund', 'Columbia Large Cap Index Fund', 'Corporate Bond Fund', 'DELAWARE EMERGING MARKETS FUND', 'Vanguard Ultra-Short-Term Bond Fund', 'Fidelity Managed Retirement 2010 Fund', 'Ivy High Income Fund', 'Janus Henderson European Focus Fund', 'Fidelity Advisor Freedom 2015 Fund', 'USAA MSCI USA Value Momentum Blend Index ETF', 'MFS Massachusetts Municipal Bond Fund', 'JPMorgan Equity Focus Fund', 'High Income Fund', 'Fidelity Advisor New Insights Fund', 'Columbia Mid Cap Value Fund', 'American Funds 2050 Target Date Retirement Fund', 'Franklin FTSE South Korea ETF', 'American Funds 2030 Target Date Retirement Fund', 'Janus Henderson Global Value Fund', 'Schwab New York Municipal Money Fund', 'American Century Diversified Municipal Bond ETF', 'ClearBridge Global Health Care Innovations Fund', 'Janus Henderson Global Life Sciences Fund', 'Dreyfus International Bond Fund', 'American Funds 2020 Target Date Retirement Fund', 'Fidelity Advisor Semiconductors Fund', 'PIMCO REALPATH 2040 Fund', 'AllianzGI Global Natural Resources Fund', 'High-Income Bond Fund', 'PIMCO Gurtin National Municipal Intermediate Value Fund', 'MainStay VP T. Rowe Price Equity Income Portfolio', 'Ivy Limited-Term Bond Fund', 'Columbia Variable Portfolio - Balanced Fund', 'Fidelity GNMA Fund', 'NORTHERN MUNICIPAL MONEY MARKET FUND', 'Fidelity Emerging Markets Fund', 'Fidelity Advisor Industrials Fund', 'AllianzGI NFJ Dividend Value Fund', 'JPMorgan Global Allocation Fund', 'MainStay VP Epoch U.S. Equity Yield Portfolio', 'MFS Arkansas Municipal Bond Fund', 'MainStay VP Growth Allocation Portfolio', 'Franklin FTSE Japan ETF', 'Vanguard Russell 1000 Value Index Fund', 'Franklin LibertyQ Emerging Markets ETF', 'Vanguard Short-Term Treasury Fund', 'Fidelity Advisor Freedom 2025 Fund', 'Variable Portfolio - TCW Core Plus Bond Fund', 'Eaton Vance Municipal Opportunities Fund', 'American Century STOXX U.S. Quality Value ETF', 'Growth-Income Fund', 'Schwab California Municipal Money Fund', 'T. Rowe Price Africa & Middle East Fund', 'Eaton Vance Dividend Builder Fund', 'Ivy Global Equity Income Fund', 'Franklin FTSE Australia ETF', 'S&P 500 Index Fund', 'Vanguard Russell 2000 Value Index Fund']\n",
            "326\n",
            "326\n"
          ]
        }
      ],
      "source": [
        "fund_names, summaries = get_data(SUMMARY_PATH)\n",
        "fund_names_in_x_train = X_train['fund_name'].tolist()\n",
        "\n",
        "print(fund_names_in_x_train)\n",
        "# Filter summaries where the fund name is in X_train\n",
        "selected_summaries = [summary for fund_name, summary in zip(fund_names, summaries) if fund_name in fund_names_in_x_train]\n",
        "\n",
        "print(len(fund_names_in_x_train))\n",
        "print(len(selected_summaries))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijVx-1GCDbpV"
      },
      "outputs": [],
      "source": [
        "# clean and tokenize the text -> we don't want to lemmatize\n",
        "def tokenizer(txt):\n",
        "    txt = txt.replace('\\n', ' ').replace('\\t', ' ').lower()\n",
        "    word_tokens = word_tokenize(txt)\n",
        "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
        "    filtered_sentence = [w for w in filtered_sentence if re.sub(\"[^A-Za-z ]+\",'',w) != '']\n",
        "    return filtered_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ez6d80vDpdU"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "text_words = np.concatenate([tokenizer(summary) for summary in selected_summaries])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AgiOFDlDsXZ",
        "outputId": "8024be9d-2d9d-424d-ea37-8f19b8be9fac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fund' 'summary' 'investment' 'objective' 'fund' 'seeks' 'long-term'\n",
            " 'capital' 'growth' 'fees' 'expenses' 'following' 'table' 'describes'\n",
            " 'fees' 'expenses' 'may' 'pay' 'buy' 'hold']\n"
          ]
        }
      ],
      "source": [
        "print(text_words[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVhS2ksPaa0b"
      },
      "outputs": [],
      "source": [
        "# Training Parameters\n",
        "batch_size = 128 # The model will be trained batch per batch and one batch contains 128 rows\n",
        "num_epochs = 2 # The model will go through all the data twice\n",
        "\n",
        "# Word2Vec Parameters\n",
        "embedding_size = 50 # Dimension of the embedding vector\n",
        "max_vocabulary_size = 5000 # Total number of different words in the vocabulary\n",
        "min_occurrence = 10 # Remove all words that does not appears at least n times\n",
        "skip_window = 3 # How many words to consider left and right\n",
        "num_skips = 4 # How many times to reuse an input to generate a label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Myo8cJCxDGNM"
      },
      "outputs": [],
      "source": [
        "# Build the dictionary and replace rare words with UNK token\n",
        "count = [('UNK', -1)]\n",
        "# Retrieve the most common words\n",
        "count.extend(collections.Counter(text_words).most_common(max_vocabulary_size - 1))\n",
        "# Remove samples with less than 'min_occurrence' occurrences\n",
        "for i in range(len(count) - 1, -1, -1):\n",
        "    if count[i][1] < min_occurrence:\n",
        "        count.pop(i)\n",
        "    else:\n",
        "        # The collection is ordered, so stop when 'min_occurrence' is reached\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBvTPLCpD5c5"
      },
      "outputs": [],
      "source": [
        "word2id = dict()\n",
        "for i, (word, _)in enumerate(count):\n",
        "    word2id[word] = i\n",
        "id2word = dict(zip(word2id.values(), word2id.keys()))\n",
        "vocab_size = len(id2word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CRsTXoCD6Q2",
        "outputId": "7aded09a-2381-4737-df2c-b6514e6cab1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of the vocabulary : 2917\n"
          ]
        }
      ],
      "source": [
        "print ('size of the vocabulary : '+str(vocab_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ccAu5cpD9o4"
      },
      "outputs": [],
      "source": [
        "# create data\n",
        "data = list()\n",
        "unk_count = 0\n",
        "for word in text_words:\n",
        "    # Retrieve a word id, or assign it index 0 ('UNK') if not in dictionary\n",
        "    index = word2id.get(word, 0)\n",
        "    if index == 0:\n",
        "        unk_count += 1\n",
        "    data.append(index)\n",
        "count[0] = ('UNK', unk_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wGX6cK2D_Bc",
        "outputId": "54e6bb5f-c49e-49cb-f81e-2d5ce44db573"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 321, 3, 125, 1, 233, 272, 70, 94, 13, 9, 165, 53, 359, 13, 9, 2, 66, 179, 182]\n"
          ]
        }
      ],
      "source": [
        "print(data[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5SQMZEYQxAy"
      },
      "outputs": [],
      "source": [
        "# build OneHot vector from index\n",
        "def to_one_hot(data_point_index, vocab_size):\n",
        "    temp = np.zeros(vocab_size)\n",
        "    temp[data_point_index] = 1\n",
        "    return temp\n",
        "\n",
        "# Generate training batch for the skip-gram model\n",
        "def batch_generator(batch_size, num_skips, skip_window, vocab_size):\n",
        "    data_index = 0\n",
        "    while True :\n",
        "        assert batch_size % num_skips == 0\n",
        "        assert num_skips <= 2 * skip_window\n",
        "        # batch is filled with 128 inputs\n",
        "        batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
        "        # labels is filled with 128 outputs\n",
        "        labels = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
        "        span = 2 * skip_window + 1\n",
        "        # buffer keep track of the visited indexes visited\n",
        "        buffer = collections.deque(maxlen=span)\n",
        "        if data_index + span > len(data):\n",
        "            data_index = 0\n",
        "            # We stop the loop when we went through all the corpus\n",
        "            break\n",
        "        buffer.extend(data[data_index:data_index + span])\n",
        "        data_index += span\n",
        "        for i in range(batch_size // num_skips):\n",
        "            # Take the context current word\n",
        "            context_words = [w for w in range(span) if w != skip_window]\n",
        "            # Randomly select num_skips words in the context\n",
        "            words_to_use = random.sample(context_words, num_skips)\n",
        "            for j, context_word in enumerate(words_to_use):\n",
        "                # Creates one raw data\n",
        "                batch[i * num_skips + j] = buffer[skip_window]\n",
        "                labels[i * num_skips + j] = buffer[context_word]\n",
        "            if data_index == len(data):\n",
        "                buffer.extend(data[0:span])\n",
        "                data_index = span\n",
        "            else:\n",
        "                buffer.append(data[data_index])\n",
        "                data_index += 1\n",
        "        # Backtrack a little bit to avoid skipping words in the end of a batch\n",
        "        data_index = (data_index + len(data) - span) % len(data)\n",
        "\n",
        "        # translate word index to on-hot representation\n",
        "        batch_one_hot = np.array([to_one_hot(b, vocab_size) for b in batch])\n",
        "        labels_one_hot = np.array([to_one_hot(l, vocab_size) for l in labels])\n",
        "\n",
        "        # output one batch\n",
        "        yield batch_one_hot, labels_one_hot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-A-yayoQ06Q"
      },
      "source": [
        "### Train the skip-gram model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9V62WRUQ0O2",
        "outputId": "9fa91e74-7222-4d9b-c3d5-a70d24a641e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 2917)]            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 50)                145900    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2917)              148767    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 294667 (1.12 MB)\n",
            "Trainable params: 294667 (1.12 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Create en compile the Autoencoder\n",
        "def creat_word2vec_model():\n",
        "    input_word = Input(shape=(vocab_size,))\n",
        "\n",
        "    encoded = Dense(embedding_size, activation='linear')(input_word)\n",
        "    decoded = Dense(vocab_size, activation='softmax')(encoded)\n",
        "\n",
        "    # The autoencoder is the whole model with hidden layer contected to the output layer.\n",
        "    autoencoder = Model(input_word, decoded)\n",
        "    # The encoder is just the input layer connected to the hidden layer. One the Autoencoder will be trained we will use\n",
        "    # the encoder to create our word vectors\n",
        "    encoder = Model(input_word, encoded)\n",
        "\n",
        "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "    return encoder, autoencoder\n",
        "\n",
        "# We create the model\n",
        "encoder, autoencoder = creat_word2vec_model()\n",
        "\n",
        "autoencoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvcVSw4cRFr6",
        "outputId": "148c7435-1033-4aff-d1d1-3aa1d7932e21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-872bc948d3d9>:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  autoencoder.fit_generator(batch_generator(batch_size, num_skips, skip_window, vocab_size), steps_per_epoch=ceil(len(data) / batch_size), epochs=num_epochs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "4588/4588 [==============================] - 138s 30ms/step - loss: 0.0191\n",
            "Epoch 2/2\n",
            "4588/4588 [==============================] - 115s 25ms/step - loss: 0.0025\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f78792e9240>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Finally we can train the model by feeding it with our batch generator !\n",
        "autoencoder.fit_generator(batch_generator(batch_size, num_skips, skip_window, vocab_size), steps_per_epoch=ceil(len(data) / batch_size), epochs=num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCowx44WRfbS",
        "outputId": "ad291387-adb8-4797-de5b-f83e4dce935b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 107ms/step\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 119ms/step\n",
            "1/1 [==============================] - 0s 142ms/step\n",
            "1/1 [==============================] - 0s 107ms/step\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 214ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "1/1 [==============================] - 0s 101ms/step\n",
            "1/1 [==============================] - 0s 134ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 99ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 106ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        }
      ],
      "source": [
        "# Create the Vectorizer function (prediciton of the encoder)\n",
        "def vecotrize(word):\n",
        "    word_one_hot = to_one_hot(word2id[word], vocab_size)\n",
        "    return encoder.predict(np.array([word_one_hot]))[0]\n",
        "\n",
        "# Create the word2vec dictionary\n",
        "word2vec = {w : vecotrize(w) for w in word2id.keys()}\n",
        "\n",
        "save_word2vec(our_word2vec) # if rerun"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Swc5M3PFI9l5"
      },
      "source": [
        "# 3. Design a strategy to build knowledge bases associated to aforementioned three main mutual fund types."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afrNaarfYLA0"
      },
      "source": [
        "Here we use clustering to build knowledge bases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMCNs4gBI7bY"
      },
      "outputs": [],
      "source": [
        "key_words = [\n",
        "    'Investment', 'Objective', 'Fees', 'Expenses', 'Shareholder', 'Annual',\n",
        "    'Operating', 'Fee', 'Waiver', 'Expense', 'Reimbursement', 'Portfolio',\n",
        "    'Turnover', 'Principal', 'Strategies', 'Equity', 'Securities',\n",
        "    'High-Yield', 'Debt', 'Dynamic', 'Asset', 'Allocation', 'Derivatives',\n",
        "    'Currency', 'Risk', 'Credit', 'Interest', 'Rate', 'Inflation', 'Foreign',\n",
        "    'Non-U.S.', 'Emerging', 'Market', 'Derivatives', 'Short', 'Sale',\n",
        "    'Leverage', 'Market', 'Liquidity', 'Management', 'Performance',\n",
        "    'Information', 'Average', 'Annual', 'Total', 'Returns', 'Investment',\n",
        "    'Adviser', 'Portfolio', 'Managers', 'Additional', 'Information'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5f3CLdCWTeu-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "class CustomWord2Vec:\n",
        "    def __init__(self, word2vec_vec):\n",
        "        # Initialize with your pre-loaded vectors\n",
        "        self.vectors = word2vec_vec\n",
        "\n",
        "    def most_similar(self, word, top_n=5):\n",
        "        if word not in self.vectors:\n",
        "            return []\n",
        "        similarities = {}\n",
        "        word_vec = self.vectors[word].reshape(1, -1)\n",
        "        for other_word, vec in self.vectors.items():\n",
        "            if other_word != word:\n",
        "                sim = cosine_similarity(word_vec, vec.reshape(1, -1))\n",
        "                similarities[other_word] = sim[0][0]\n",
        "        sorted_similarities = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
        "        return sorted_similarities[:top_n]\n",
        "\n",
        "# Instantiate the model\n",
        "word2vec_model = CustomWord2Vec(word2vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bz1c-MzUZCW",
        "outputId": "561f9254-e86e-41b7-cc55-e63c241471c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Investment': [],\n",
              " 'Objective': [],\n",
              " 'Fees': [],\n",
              " 'Expenses': [],\n",
              " 'Shareholder': [],\n",
              " 'Annual': [],\n",
              " 'Operating': [],\n",
              " 'Fee': [],\n",
              " 'Waiver': [],\n",
              " 'Expense': [],\n",
              " 'Reimbursement': [],\n",
              " 'Portfolio': [],\n",
              " 'Turnover': [],\n",
              " 'Principal': [],\n",
              " 'Strategies': [],\n",
              " 'Equity': [],\n",
              " 'Securities': [],\n",
              " 'High-Yield': [],\n",
              " 'Debt': [],\n",
              " 'Dynamic': [],\n",
              " 'Asset': [],\n",
              " 'Allocation': [],\n",
              " 'Derivatives': [],\n",
              " 'Currency': [],\n",
              " 'Risk': [],\n",
              " 'Credit': [],\n",
              " 'Interest': [],\n",
              " 'Rate': [],\n",
              " 'Inflation': [],\n",
              " 'Foreign': [],\n",
              " 'Non-U.S.': [],\n",
              " 'Emerging': [],\n",
              " 'Market': [],\n",
              " 'Short': [],\n",
              " 'Sale': [],\n",
              " 'Leverage': [],\n",
              " 'Liquidity': [],\n",
              " 'Management': [],\n",
              " 'Performance': [],\n",
              " 'Information': [],\n",
              " 'Average': [],\n",
              " 'Total': [],\n",
              " 'Returns': [],\n",
              " 'Adviser': [],\n",
              " 'Managers': [],\n",
              " 'Additional': []}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "knowledge_base = {keyword: word2vec_model.most_similar(keyword, top_n=5) for keyword in key_words}\n",
        "knowledge_base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "JVjXpqtXaUeo",
        "outputId": "c77feeba-dd96-40c9-9c9a-7c7a3ec71892"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import networkx as nx\n",
        "\n",
        "G = nx.DiGraph()\n",
        "\n",
        "for keyword, related_terms in knowledge_base.items():\n",
        "    G.add_node(keyword, type='keyword')\n",
        "    for term, similarity in related_terms:\n",
        "        G.add_node(term, type='related_term')\n",
        "        G.add_edge(keyword, term, weight=similarity)\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pos = nx.spring_layout(G, k=0.5)  # k regulates the distance between nodes\n",
        "nx.draw(G, pos, with_labels=True, node_size=800, node_color='lightblue', edge_color='gray', font_size=8, font_weight='bold')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHCzeAfrw4xc"
      },
      "outputs": [],
      "source": [
        "knowledge_base = list(knowledge_base)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfkB-MsZUcrW"
      },
      "source": [
        "# 4. Measure distance of each summary to each knowledge base. Design a classification algorithm to predict the investment strategy of each fund."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mN2df1setvtF"
      },
      "source": [
        "## Measure distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PengOTVfbHx_",
        "outputId": "5a939417-4c01-42ce-c2b8-071d1613b3e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Similarity between Summary 218 and KB Entry 15: 0.00\n",
            "Similarity between Summary 218 and KB Entry 16: 0.02\n",
            "Similarity between Summary 218 and KB Entry 17: 0.07\n",
            "Similarity between Summary 218 and KB Entry 18: 0.00\n",
            "Similarity between Summary 218 and KB Entry 19: 0.02\n",
            "Similarity between Summary 218 and KB Entry 20: 0.00\n",
            "Similarity between Summary 218 and KB Entry 21: 0.02\n",
            "Similarity between Summary 218 and KB Entry 22: 0.00\n",
            "Similarity between Summary 218 and KB Entry 23: 0.03\n",
            "Similarity between Summary 218 and KB Entry 24: 0.01\n",
            "Similarity between Summary 218 and KB Entry 25: 0.08\n",
            "Similarity between Summary 218 and KB Entry 26: 0.01\n",
            "Similarity between Summary 218 and KB Entry 27: 0.04\n",
            "Similarity between Summary 218 and KB Entry 28: 0.01\n",
            "Similarity between Summary 218 and KB Entry 29: 0.00\n",
            "Similarity between Summary 218 and KB Entry 30: 0.07\n",
            "Similarity between Summary 218 and KB Entry 31: 0.01\n",
            "Similarity between Summary 218 and KB Entry 32: 0.03\n",
            "Similarity between Summary 218 and KB Entry 33: 0.06\n",
            "Similarity between Summary 218 and KB Entry 34: 0.01\n",
            "Similarity between Summary 218 and KB Entry 35: 0.01\n",
            "Similarity between Summary 218 and KB Entry 36: 0.01\n",
            "Similarity between Summary 218 and KB Entry 37: 0.01\n",
            "Similarity between Summary 218 and KB Entry 38: 0.01\n",
            "Similarity between Summary 218 and KB Entry 39: 0.05\n",
            "Similarity between Summary 218 and KB Entry 40: 0.02\n",
            "Similarity between Summary 218 and KB Entry 41: 0.01\n",
            "Similarity between Summary 218 and KB Entry 42: 0.01\n",
            "Similarity between Summary 218 and KB Entry 43: 0.03\n",
            "Similarity between Summary 218 and KB Entry 44: 0.01\n",
            "Similarity between Summary 218 and KB Entry 45: 0.02\n",
            "Similarity between Summary 218 and KB Entry 46: 0.01\n",
            "Similarity between Summary 219 and KB Entry 1: 0.07\n",
            "Similarity between Summary 219 and KB Entry 2: 0.01\n",
            "Similarity between Summary 219 and KB Entry 3: 0.04\n",
            "Similarity between Summary 219 and KB Entry 4: 0.08\n",
            "Similarity between Summary 219 and KB Entry 5: 0.01\n",
            "Similarity between Summary 219 and KB Entry 6: 0.03\n",
            "Similarity between Summary 219 and KB Entry 7: 0.02\n",
            "Similarity between Summary 219 and KB Entry 8: 0.02\n",
            "Similarity between Summary 219 and KB Entry 9: 0.00\n",
            "Similarity between Summary 219 and KB Entry 10: 0.01\n",
            "Similarity between Summary 219 and KB Entry 11: 0.00\n",
            "Similarity between Summary 219 and KB Entry 12: 0.04\n",
            "Similarity between Summary 219 and KB Entry 13: 0.01\n",
            "Similarity between Summary 219 and KB Entry 14: 0.00\n",
            "Similarity between Summary 219 and KB Entry 15: 0.01\n",
            "Similarity between Summary 219 and KB Entry 16: 0.05\n",
            "Similarity between Summary 219 and KB Entry 17: 0.10\n",
            "Similarity between Summary 219 and KB Entry 18: 0.00\n",
            "Similarity between Summary 219 and KB Entry 19: 0.00\n",
            "Similarity between Summary 219 and KB Entry 20: 0.00\n",
            "Similarity between Summary 219 and KB Entry 21: 0.01\n",
            "Similarity between Summary 219 and KB Entry 22: 0.00\n",
            "Similarity between Summary 219 and KB Entry 23: 0.05\n",
            "Similarity between Summary 219 and KB Entry 24: 0.01\n",
            "Similarity between Summary 219 and KB Entry 25: 0.05\n",
            "Similarity between Summary 219 and KB Entry 26: 0.01\n",
            "Similarity between Summary 219 and KB Entry 27: 0.01\n",
            "Similarity between Summary 219 and KB Entry 28: 0.01\n",
            "Similarity between Summary 219 and KB Entry 29: 0.01\n",
            "Similarity between Summary 219 and KB Entry 30: 0.03\n",
            "Similarity between Summary 219 and KB Entry 31: 0.02\n",
            "Similarity between Summary 219 and KB Entry 32: 0.00\n",
            "Similarity between Summary 219 and KB Entry 33: 0.05\n",
            "Similarity between Summary 219 and KB Entry 34: 0.01\n",
            "Similarity between Summary 219 and KB Entry 35: 0.01\n",
            "Similarity between Summary 219 and KB Entry 36: 0.00\n",
            "Similarity between Summary 219 and KB Entry 37: 0.00\n",
            "Similarity between Summary 219 and KB Entry 38: 0.02\n",
            "Similarity between Summary 219 and KB Entry 39: 0.03\n",
            "Similarity between Summary 219 and KB Entry 40: 0.01\n",
            "Similarity between Summary 219 and KB Entry 41: 0.02\n",
            "Similarity between Summary 219 and KB Entry 42: 0.03\n",
            "Similarity between Summary 219 and KB Entry 43: 0.03\n",
            "Similarity between Summary 219 and KB Entry 44: 0.06\n",
            "Similarity between Summary 219 and KB Entry 45: 0.01\n",
            "Similarity between Summary 219 and KB Entry 46: 0.00\n",
            "Similarity between Summary 220 and KB Entry 1: 0.06\n",
            "Similarity between Summary 220 and KB Entry 2: 0.00\n",
            "Similarity between Summary 220 and KB Entry 3: 0.05\n",
            "Similarity between Summary 220 and KB Entry 4: 0.06\n",
            "Similarity between Summary 220 and KB Entry 5: 0.00\n",
            "Similarity between Summary 220 and KB Entry 6: 0.01\n",
            "Similarity between Summary 220 and KB Entry 7: 0.01\n",
            "Similarity between Summary 220 and KB Entry 8: 0.02\n",
            "Similarity between Summary 220 and KB Entry 9: 0.00\n",
            "Similarity between Summary 220 and KB Entry 10: 0.02\n",
            "Similarity between Summary 220 and KB Entry 11: 0.00\n",
            "Similarity between Summary 220 and KB Entry 12: 0.05\n",
            "Similarity between Summary 220 and KB Entry 13: 0.01\n",
            "Similarity between Summary 220 and KB Entry 14: 0.01\n",
            "Similarity between Summary 220 and KB Entry 15: 0.00\n",
            "Similarity between Summary 220 and KB Entry 16: 0.02\n",
            "Similarity between Summary 220 and KB Entry 17: 0.08\n",
            "Similarity between Summary 220 and KB Entry 18: 0.00\n",
            "Similarity between Summary 220 and KB Entry 19: 0.01\n",
            "Similarity between Summary 220 and KB Entry 20: 0.00\n",
            "Similarity between Summary 220 and KB Entry 21: 0.01\n",
            "Similarity between Summary 220 and KB Entry 22: 0.00\n",
            "Similarity between Summary 220 and KB Entry 23: 0.04\n",
            "Similarity between Summary 220 and KB Entry 24: 0.02\n",
            "Similarity between Summary 220 and KB Entry 25: 0.04\n",
            "Similarity between Summary 220 and KB Entry 26: 0.00\n",
            "Similarity between Summary 220 and KB Entry 27: 0.02\n",
            "Similarity between Summary 220 and KB Entry 28: 0.00\n",
            "Similarity between Summary 220 and KB Entry 29: 0.00\n",
            "Similarity between Summary 220 and KB Entry 30: 0.08\n",
            "Similarity between Summary 220 and KB Entry 31: 0.01\n",
            "Similarity between Summary 220 and KB Entry 32: 0.04\n",
            "Similarity between Summary 220 and KB Entry 33: 0.05\n",
            "Similarity between Summary 220 and KB Entry 34: 0.01\n",
            "Similarity between Summary 220 and KB Entry 35: 0.01\n",
            "Similarity between Summary 220 and KB Entry 36: 0.01\n",
            "Similarity between Summary 220 and KB Entry 37: 0.00\n",
            "Similarity between Summary 220 and KB Entry 38: 0.01\n",
            "Similarity between Summary 220 and KB Entry 39: 0.05\n",
            "Similarity between Summary 220 and KB Entry 40: 0.02\n",
            "Similarity between Summary 220 and KB Entry 41: 0.01\n",
            "Similarity between Summary 220 and KB Entry 42: 0.01\n",
            "Similarity between Summary 220 and KB Entry 43: 0.03\n",
            "Similarity between Summary 220 and KB Entry 44: 0.01\n",
            "Similarity between Summary 220 and KB Entry 45: 0.02\n",
            "Similarity between Summary 220 and KB Entry 46: 0.01\n",
            "Similarity between Summary 221 and KB Entry 1: 0.06\n",
            "Similarity between Summary 221 and KB Entry 2: 0.01\n",
            "Similarity between Summary 221 and KB Entry 3: 0.07\n",
            "Similarity between Summary 221 and KB Entry 4: 0.07\n",
            "Similarity between Summary 221 and KB Entry 5: 0.00\n",
            "Similarity between Summary 221 and KB Entry 6: 0.02\n",
            "Similarity between Summary 221 and KB Entry 7: 0.01\n",
            "Similarity between Summary 221 and KB Entry 8: 0.02\n",
            "Similarity between Summary 221 and KB Entry 9: 0.00\n",
            "Similarity between Summary 221 and KB Entry 10: 0.03\n",
            "Similarity between Summary 221 and KB Entry 11: 0.00\n",
            "Similarity between Summary 221 and KB Entry 12: 0.06\n",
            "Similarity between Summary 221 and KB Entry 13: 0.01\n",
            "Similarity between Summary 221 and KB Entry 14: 0.01\n",
            "Similarity between Summary 221 and KB Entry 15: 0.01\n",
            "Similarity between Summary 221 and KB Entry 16: 0.01\n",
            "Similarity between Summary 221 and KB Entry 17: 0.06\n",
            "Similarity between Summary 221 and KB Entry 18: 0.00\n",
            "Similarity between Summary 221 and KB Entry 19: 0.00\n",
            "Similarity between Summary 221 and KB Entry 20: 0.00\n",
            "Similarity between Summary 221 and KB Entry 21: 0.01\n",
            "Similarity between Summary 221 and KB Entry 22: 0.00\n",
            "Similarity between Summary 221 and KB Entry 23: 0.00\n",
            "Similarity between Summary 221 and KB Entry 24: 0.00\n",
            "Similarity between Summary 221 and KB Entry 25: 0.04\n",
            "Similarity between Summary 221 and KB Entry 26: 0.00\n",
            "Similarity between Summary 221 and KB Entry 27: 0.01\n",
            "Similarity between Summary 221 and KB Entry 28: 0.01\n",
            "Similarity between Summary 221 and KB Entry 29: 0.00\n",
            "Similarity between Summary 221 and KB Entry 30: 0.03\n",
            "Similarity between Summary 221 and KB Entry 31: 0.01\n",
            "Similarity between Summary 221 and KB Entry 32: 0.02\n",
            "Similarity between Summary 221 and KB Entry 33: 0.04\n",
            "Similarity between Summary 221 and KB Entry 34: 0.00\n",
            "Similarity between Summary 221 and KB Entry 35: 0.01\n",
            "Similarity between Summary 221 and KB Entry 36: 0.00\n",
            "Similarity between Summary 221 and KB Entry 37: 0.00\n",
            "Similarity between Summary 221 and KB Entry 38: 0.01\n",
            "Similarity between Summary 221 and KB Entry 39: 0.07\n",
            "Similarity between Summary 221 and KB Entry 40: 0.03\n",
            "Similarity between Summary 221 and KB Entry 41: 0.01\n",
            "Similarity between Summary 221 and KB Entry 42: 0.01\n",
            "Similarity between Summary 221 and KB Entry 43: 0.04\n",
            "Similarity between Summary 221 and KB Entry 44: 0.01\n",
            "Similarity between Summary 221 and KB Entry 45: 0.03\n",
            "Similarity between Summary 221 and KB Entry 46: 0.01\n",
            "Similarity between Summary 222 and KB Entry 1: 0.07\n",
            "Similarity between Summary 222 and KB Entry 2: 0.01\n",
            "Similarity between Summary 222 and KB Entry 3: 0.02\n",
            "Similarity between Summary 222 and KB Entry 4: 0.04\n",
            "Similarity between Summary 222 and KB Entry 5: 0.00\n",
            "Similarity between Summary 222 and KB Entry 6: 0.02\n",
            "Similarity between Summary 222 and KB Entry 7: 0.01\n",
            "Similarity between Summary 222 and KB Entry 8: 0.01\n",
            "Similarity between Summary 222 and KB Entry 9: 0.00\n",
            "Similarity between Summary 222 and KB Entry 10: 0.00\n",
            "Similarity between Summary 222 and KB Entry 11: 0.00\n",
            "Similarity between Summary 222 and KB Entry 12: 0.31\n",
            "Similarity between Summary 222 and KB Entry 13: 0.01\n",
            "Similarity between Summary 222 and KB Entry 14: 0.01\n",
            "Similarity between Summary 222 and KB Entry 15: 0.01\n",
            "Similarity between Summary 222 and KB Entry 16: 0.02\n",
            "Similarity between Summary 222 and KB Entry 17: 0.12\n",
            "Similarity between Summary 222 and KB Entry 18: 0.00\n",
            "Similarity between Summary 222 and KB Entry 19: 0.01\n",
            "Similarity between Summary 222 and KB Entry 20: 0.00\n",
            "Similarity between Summary 222 and KB Entry 21: 0.01\n",
            "Similarity between Summary 222 and KB Entry 22: 0.00\n",
            "Similarity between Summary 222 and KB Entry 23: 0.05\n",
            "Similarity between Summary 222 and KB Entry 24: 0.02\n",
            "Similarity between Summary 222 and KB Entry 25: 0.07\n",
            "Similarity between Summary 222 and KB Entry 26: 0.00\n",
            "Similarity between Summary 222 and KB Entry 27: 0.02\n",
            "Similarity between Summary 222 and KB Entry 28: 0.01\n",
            "Similarity between Summary 222 and KB Entry 29: 0.00\n",
            "Similarity between Summary 222 and KB Entry 30: 0.05\n",
            "Similarity between Summary 222 and KB Entry 31: 0.00\n",
            "Similarity between Summary 222 and KB Entry 32: 0.05\n",
            "Similarity between Summary 222 and KB Entry 33: 0.05\n",
            "Similarity between Summary 222 and KB Entry 34: 0.01\n",
            "Similarity between Summary 222 and KB Entry 35: 0.00\n",
            "Similarity between Summary 222 and KB Entry 36: 0.01\n",
            "Similarity between Summary 222 and KB Entry 37: 0.00\n",
            "Similarity between Summary 222 and KB Entry 38: 0.01\n",
            "Similarity between Summary 222 and KB Entry 39: 0.04\n",
            "Similarity between Summary 222 and KB Entry 40: 0.01\n",
            "Similarity between Summary 222 and KB Entry 41: 0.01\n",
            "Similarity between Summary 222 and KB Entry 42: 0.02\n",
            "Similarity between Summary 222 and KB Entry 43: 0.02\n",
            "Similarity between Summary 222 and KB Entry 44: 0.00\n",
            "Similarity between Summary 222 and KB Entry 45: 0.03\n",
            "Similarity between Summary 222 and KB Entry 46: 0.01\n",
            "Similarity between Summary 223 and KB Entry 1: 0.08\n",
            "Similarity between Summary 223 and KB Entry 2: 0.01\n",
            "Similarity between Summary 223 and KB Entry 3: 0.07\n",
            "Similarity between Summary 223 and KB Entry 4: 0.08\n",
            "Similarity between Summary 223 and KB Entry 5: 0.00\n",
            "Similarity between Summary 223 and KB Entry 6: 0.02\n",
            "Similarity between Summary 223 and KB Entry 7: 0.01\n",
            "Similarity between Summary 223 and KB Entry 8: 0.02\n",
            "Similarity between Summary 223 and KB Entry 9: 0.00\n",
            "Similarity between Summary 223 and KB Entry 10: 0.03\n",
            "Similarity between Summary 223 and KB Entry 11: 0.00\n",
            "Similarity between Summary 223 and KB Entry 12: 0.04\n",
            "Similarity between Summary 223 and KB Entry 13: 0.01\n",
            "Similarity between Summary 223 and KB Entry 14: 0.01\n",
            "Similarity between Summary 223 and KB Entry 15: 0.01\n",
            "Similarity between Summary 223 and KB Entry 16: 0.02\n",
            "Similarity between Summary 223 and KB Entry 17: 0.05\n",
            "Similarity between Summary 223 and KB Entry 18: 0.01\n",
            "Similarity between Summary 223 and KB Entry 19: 0.00\n",
            "Similarity between Summary 223 and KB Entry 20: 0.00\n",
            "Similarity between Summary 223 and KB Entry 21: 0.01\n",
            "Similarity between Summary 223 and KB Entry 22: 0.00\n",
            "Similarity between Summary 223 and KB Entry 23: 0.04\n",
            "Similarity between Summary 223 and KB Entry 24: 0.00\n",
            "Similarity between Summary 223 and KB Entry 25: 0.04\n",
            "Similarity between Summary 223 and KB Entry 26: 0.00\n",
            "Similarity between Summary 223 and KB Entry 27: 0.01\n",
            "Similarity between Summary 223 and KB Entry 28: 0.01\n",
            "Similarity between Summary 223 and KB Entry 29: 0.00\n",
            "Similarity between Summary 223 and KB Entry 30: 0.00\n",
            "Similarity between Summary 223 and KB Entry 31: 0.01\n",
            "Similarity between Summary 223 and KB Entry 32: 0.00\n",
            "Similarity between Summary 223 and KB Entry 33: 0.04\n",
            "Similarity between Summary 223 and KB Entry 34: 0.00\n",
            "Similarity between Summary 223 and KB Entry 35: 0.01\n",
            "Similarity between Summary 223 and KB Entry 36: 0.01\n",
            "Similarity between Summary 223 and KB Entry 37: 0.00\n",
            "Similarity between Summary 223 and KB Entry 38: 0.02\n",
            "Similarity between Summary 223 and KB Entry 39: 0.06\n",
            "Similarity between Summary 223 and KB Entry 40: 0.03\n",
            "Similarity between Summary 223 and KB Entry 41: 0.01\n",
            "Similarity between Summary 223 and KB Entry 42: 0.01\n",
            "Similarity between Summary 223 and KB Entry 43: 0.03\n",
            "Similarity between Summary 223 and KB Entry 44: 0.01\n",
            "Similarity between Summary 223 and KB Entry 45: 0.00\n",
            "Similarity between Summary 223 and KB Entry 46: 0.01\n",
            "Similarity between Summary 224 and KB Entry 1: 0.06\n",
            "Similarity between Summary 224 and KB Entry 2: 0.01\n",
            "Similarity between Summary 224 and KB Entry 3: 0.06\n",
            "Similarity between Summary 224 and KB Entry 4: 0.08\n",
            "Similarity between Summary 224 and KB Entry 5: 0.01\n",
            "Similarity between Summary 224 and KB Entry 6: 0.02\n",
            "Similarity between Summary 224 and KB Entry 7: 0.02\n",
            "Similarity between Summary 224 and KB Entry 8: 0.03\n",
            "Similarity between Summary 224 and KB Entry 9: 0.01\n",
            "Similarity between Summary 224 and KB Entry 10: 0.03\n",
            "Similarity between Summary 224 and KB Entry 11: 0.00\n",
            "Similarity between Summary 224 and KB Entry 12: 0.06\n",
            "Similarity between Summary 224 and KB Entry 13: 0.01\n",
            "Similarity between Summary 224 and KB Entry 14: 0.00\n",
            "Similarity between Summary 224 and KB Entry 15: 0.01\n",
            "Similarity between Summary 224 and KB Entry 16: 0.01\n",
            "Similarity between Summary 224 and KB Entry 17: 0.04\n",
            "Similarity between Summary 224 and KB Entry 18: 0.00\n",
            "Similarity between Summary 224 and KB Entry 19: 0.00\n",
            "Similarity between Summary 224 and KB Entry 20: 0.00\n",
            "Similarity between Summary 224 and KB Entry 21: 0.01\n",
            "Similarity between Summary 224 and KB Entry 22: 0.00\n",
            "Similarity between Summary 224 and KB Entry 23: 0.00\n",
            "Similarity between Summary 224 and KB Entry 24: 0.00\n",
            "Similarity between Summary 224 and KB Entry 25: 0.03\n",
            "Similarity between Summary 224 and KB Entry 26: 0.00\n",
            "Similarity between Summary 224 and KB Entry 27: 0.01\n",
            "Similarity between Summary 224 and KB Entry 28: 0.01\n",
            "Similarity between Summary 224 and KB Entry 29: 0.00\n",
            "Similarity between Summary 224 and KB Entry 30: 0.00\n",
            "Similarity between Summary 224 and KB Entry 31: 0.01\n",
            "Similarity between Summary 224 and KB Entry 32: 0.00\n",
            "Similarity between Summary 224 and KB Entry 33: 0.04\n",
            "Similarity between Summary 224 and KB Entry 34: 0.00\n",
            "Similarity between Summary 224 and KB Entry 35: 0.01\n",
            "Similarity between Summary 224 and KB Entry 36: 0.00\n",
            "Similarity between Summary 224 and KB Entry 37: 0.00\n",
            "Similarity between Summary 224 and KB Entry 38: 0.03\n",
            "Similarity between Summary 224 and KB Entry 39: 0.06\n",
            "Similarity between Summary 224 and KB Entry 40: 0.02\n",
            "Similarity between Summary 224 and KB Entry 41: 0.01\n",
            "Similarity between Summary 224 and KB Entry 42: 0.01\n",
            "Similarity between Summary 224 and KB Entry 43: 0.04\n",
            "Similarity between Summary 224 and KB Entry 44: 0.01\n",
            "Similarity between Summary 224 and KB Entry 45: 0.02\n",
            "Similarity between Summary 224 and KB Entry 46: 0.01\n",
            "Similarity between Summary 225 and KB Entry 1: 0.06\n",
            "Similarity between Summary 225 and KB Entry 2: 0.01\n",
            "Similarity between Summary 225 and KB Entry 3: 0.04\n",
            "Similarity between Summary 225 and KB Entry 4: 0.05\n",
            "Similarity between Summary 225 and KB Entry 5: 0.00\n",
            "Similarity between Summary 225 and KB Entry 6: 0.02\n",
            "Similarity between Summary 225 and KB Entry 7: 0.01\n",
            "Similarity between Summary 225 and KB Entry 8: 0.00\n",
            "Similarity between Summary 225 and KB Entry 9: 0.00\n",
            "Similarity between Summary 225 and KB Entry 10: 0.00\n",
            "Similarity between Summary 225 and KB Entry 11: 0.00\n",
            "Similarity between Summary 225 and KB Entry 12: 0.03\n",
            "Similarity between Summary 225 and KB Entry 13: 0.01\n",
            "Similarity between Summary 225 and KB Entry 14: 0.00\n",
            "Similarity between Summary 225 and KB Entry 15: 0.01\n",
            "Similarity between Summary 225 and KB Entry 16: 0.04\n",
            "Similarity between Summary 225 and KB Entry 17: 0.08\n",
            "Similarity between Summary 225 and KB Entry 18: 0.00\n",
            "Similarity between Summary 225 and KB Entry 19: 0.01\n",
            "Similarity between Summary 225 and KB Entry 20: 0.04\n",
            "Similarity between Summary 225 and KB Entry 21: 0.01\n",
            "Similarity between Summary 225 and KB Entry 22: 0.00\n",
            "Similarity between Summary 225 and KB Entry 23: 0.04\n",
            "Similarity between Summary 225 and KB Entry 24: 0.08\n",
            "Similarity between Summary 225 and KB Entry 25: 0.06\n",
            "Similarity between Summary 225 and KB Entry 26: 0.01\n",
            "Similarity between Summary 225 and KB Entry 27: 0.01\n",
            "Similarity between Summary 225 and KB Entry 28: 0.01\n",
            "Similarity between Summary 225 and KB Entry 29: 0.02\n",
            "Similarity between Summary 225 and KB Entry 30: 0.04\n",
            "Similarity between Summary 225 and KB Entry 31: 0.00\n",
            "Similarity between Summary 225 and KB Entry 32: 0.02\n",
            "Similarity between Summary 225 and KB Entry 33: 0.05\n",
            "Similarity between Summary 225 and KB Entry 34: 0.01\n",
            "Similarity between Summary 225 and KB Entry 35: 0.01\n",
            "Similarity between Summary 225 and KB Entry 36: 0.01\n",
            "Similarity between Summary 225 and KB Entry 37: 0.00\n",
            "Similarity between Summary 225 and KB Entry 38: 0.02\n",
            "Similarity between Summary 225 and KB Entry 39: 0.03\n",
            "Similarity between Summary 225 and KB Entry 40: 0.01\n",
            "Similarity between Summary 225 and KB Entry 41: 0.01\n",
            "Similarity between Summary 225 and KB Entry 42: 0.03\n",
            "Similarity between Summary 225 and KB Entry 43: 0.03\n",
            "Similarity between Summary 225 and KB Entry 44: 0.02\n",
            "Similarity between Summary 225 and KB Entry 45: 0.00\n",
            "Similarity between Summary 225 and KB Entry 46: 0.00\n",
            "Similarity between Summary 226 and KB Entry 1: 0.07\n",
            "Similarity between Summary 226 and KB Entry 2: 0.01\n",
            "Similarity between Summary 226 and KB Entry 3: 0.04\n",
            "Similarity between Summary 226 and KB Entry 4: 0.05\n",
            "Similarity between Summary 226 and KB Entry 5: 0.00\n",
            "Similarity between Summary 226 and KB Entry 6: 0.01\n",
            "Similarity between Summary 226 and KB Entry 7: 0.01\n",
            "Similarity between Summary 226 and KB Entry 8: 0.01\n",
            "Similarity between Summary 226 and KB Entry 9: 0.00\n",
            "Similarity between Summary 226 and KB Entry 10: 0.01\n",
            "Similarity between Summary 226 and KB Entry 11: 0.00\n",
            "Similarity between Summary 226 and KB Entry 12: 0.03\n",
            "Similarity between Summary 226 and KB Entry 13: 0.01\n",
            "Similarity between Summary 226 and KB Entry 14: 0.01\n",
            "Similarity between Summary 226 and KB Entry 15: 0.02\n",
            "Similarity between Summary 226 and KB Entry 16: 0.02\n",
            "Similarity between Summary 226 and KB Entry 17: 0.13\n",
            "Similarity between Summary 226 and KB Entry 18: 0.02\n",
            "Similarity between Summary 226 and KB Entry 19: 0.00\n",
            "Similarity between Summary 226 and KB Entry 20: 0.00\n",
            "Similarity between Summary 226 and KB Entry 21: 0.03\n",
            "Similarity between Summary 226 and KB Entry 22: 0.03\n",
            "Similarity between Summary 226 and KB Entry 23: 0.03\n",
            "Similarity between Summary 226 and KB Entry 24: 0.01\n",
            "Similarity between Summary 226 and KB Entry 25: 0.07\n",
            "Similarity between Summary 226 and KB Entry 26: 0.04\n",
            "Similarity between Summary 226 and KB Entry 27: 0.04\n",
            "Similarity between Summary 226 and KB Entry 28: 0.03\n",
            "Similarity between Summary 226 and KB Entry 29: 0.05\n",
            "Similarity between Summary 226 and KB Entry 30: 0.03\n",
            "Similarity between Summary 226 and KB Entry 31: 0.01\n",
            "Similarity between Summary 226 and KB Entry 32: 0.01\n",
            "Similarity between Summary 226 and KB Entry 33: 0.06\n",
            "Similarity between Summary 226 and KB Entry 34: 0.04\n",
            "Similarity between Summary 226 and KB Entry 35: 0.01\n",
            "Similarity between Summary 226 and KB Entry 36: 0.01\n",
            "Similarity between Summary 226 and KB Entry 37: 0.01\n",
            "Similarity between Summary 226 and KB Entry 38: 0.02\n",
            "Similarity between Summary 226 and KB Entry 39: 0.02\n",
            "Similarity between Summary 226 and KB Entry 40: 0.01\n",
            "Similarity between Summary 226 and KB Entry 41: 0.01\n",
            "Similarity between Summary 226 and KB Entry 42: 0.02\n",
            "Similarity between Summary 226 and KB Entry 43: 0.02\n",
            "Similarity between Summary 226 and KB Entry 44: 0.03\n",
            "Similarity between Summary 226 and KB Entry 45: 0.00\n",
            "Similarity between Summary 226 and KB Entry 46: 0.01\n",
            "Similarity between Summary 227 and KB Entry 1: 0.10\n",
            "Similarity between Summary 227 and KB Entry 2: 0.01\n",
            "Similarity between Summary 227 and KB Entry 3: 0.04\n",
            "Similarity between Summary 227 and KB Entry 4: 0.03\n",
            "Similarity between Summary 227 and KB Entry 5: 0.01\n",
            "Similarity between Summary 227 and KB Entry 6: 0.03\n",
            "Similarity between Summary 227 and KB Entry 7: 0.02\n",
            "Similarity between Summary 227 and KB Entry 8: 0.01\n",
            "Similarity between Summary 227 and KB Entry 9: 0.01\n",
            "Similarity between Summary 227 and KB Entry 10: 0.01\n",
            "Similarity between Summary 227 and KB Entry 11: 0.01\n",
            "Similarity between Summary 227 and KB Entry 12: 0.26\n",
            "Similarity between Summary 227 and KB Entry 13: 0.01\n",
            "Similarity between Summary 227 and KB Entry 14: 0.02\n",
            "Similarity between Summary 227 and KB Entry 15: 0.01\n",
            "Similarity between Summary 227 and KB Entry 16: 0.03\n",
            "Similarity between Summary 227 and KB Entry 17: 0.10\n",
            "Similarity between Summary 227 and KB Entry 18: 0.01\n",
            "Similarity between Summary 227 and KB Entry 19: 0.01\n",
            "Similarity between Summary 227 and KB Entry 20: 0.00\n",
            "Similarity between Summary 227 and KB Entry 21: 0.02\n",
            "Similarity between Summary 227 and KB Entry 22: 0.03\n",
            "Similarity between Summary 227 and KB Entry 23: 0.00\n",
            "Similarity between Summary 227 and KB Entry 24: 0.00\n",
            "Similarity between Summary 227 and KB Entry 25: 0.06\n",
            "Similarity between Summary 227 and KB Entry 26: 0.01\n",
            "Similarity between Summary 227 and KB Entry 27: 0.02\n",
            "Similarity between Summary 227 and KB Entry 28: 0.01\n",
            "Similarity between Summary 227 and KB Entry 29: 0.00\n",
            "Similarity between Summary 227 and KB Entry 30: 0.00\n",
            "Similarity between Summary 227 and KB Entry 31: 0.00\n",
            "Similarity between Summary 227 and KB Entry 32: 0.00\n",
            "Similarity between Summary 227 and KB Entry 33: 0.07\n",
            "Similarity between Summary 227 and KB Entry 34: 0.00\n",
            "Similarity between Summary 227 and KB Entry 35: 0.00\n",
            "Similarity between Summary 227 and KB Entry 36: 0.00\n",
            "Similarity between Summary 227 and KB Entry 37: 0.01\n",
            "Similarity between Summary 227 and KB Entry 38: 0.03\n",
            "Similarity between Summary 227 and KB Entry 39: 0.04\n",
            "Similarity between Summary 227 and KB Entry 40: 0.02\n",
            "Similarity between Summary 227 and KB Entry 41: 0.02\n",
            "Similarity between Summary 227 and KB Entry 42: 0.02\n",
            "Similarity between Summary 227 and KB Entry 43: 0.02\n",
            "Similarity between Summary 227 and KB Entry 44: 0.00\n",
            "Similarity between Summary 227 and KB Entry 45: 0.01\n",
            "Similarity between Summary 227 and KB Entry 46: 0.00\n",
            "Similarity between Summary 228 and KB Entry 1: 0.05\n",
            "Similarity between Summary 228 and KB Entry 2: 0.01\n",
            "Similarity between Summary 228 and KB Entry 3: 0.03\n",
            "Similarity between Summary 228 and KB Entry 4: 0.05\n",
            "Similarity between Summary 228 and KB Entry 5: 0.00\n",
            "Similarity between Summary 228 and KB Entry 6: 0.02\n",
            "Similarity between Summary 228 and KB Entry 7: 0.02\n",
            "Similarity between Summary 228 and KB Entry 8: 0.01\n",
            "Similarity between Summary 228 and KB Entry 9: 0.00\n",
            "Similarity between Summary 228 and KB Entry 10: 0.01\n",
            "Similarity between Summary 228 and KB Entry 11: 0.00\n",
            "Similarity between Summary 228 and KB Entry 12: 0.02\n",
            "Similarity between Summary 228 and KB Entry 13: 0.01\n",
            "Similarity between Summary 228 and KB Entry 14: 0.01\n",
            "Similarity between Summary 228 and KB Entry 15: 0.00\n",
            "Similarity between Summary 228 and KB Entry 16: 0.00\n",
            "Similarity between Summary 228 and KB Entry 17: 0.14\n",
            "Similarity between Summary 228 and KB Entry 18: 0.02\n",
            "Similarity between Summary 228 and KB Entry 19: 0.02\n",
            "Similarity between Summary 228 and KB Entry 20: 0.00\n",
            "Similarity between Summary 228 and KB Entry 21: 0.02\n",
            "Similarity between Summary 228 and KB Entry 22: 0.00\n",
            "Similarity between Summary 228 and KB Entry 23: 0.00\n",
            "Similarity between Summary 228 and KB Entry 24: 0.00\n",
            "Similarity between Summary 228 and KB Entry 25: 0.09\n",
            "Similarity between Summary 228 and KB Entry 26: 0.05\n",
            "Similarity between Summary 228 and KB Entry 27: 0.08\n",
            "Similarity between Summary 228 and KB Entry 28: 0.02\n",
            "Similarity between Summary 228 and KB Entry 29: 0.01\n",
            "Similarity between Summary 228 and KB Entry 30: 0.00\n",
            "Similarity between Summary 228 and KB Entry 31: 0.00\n",
            "Similarity between Summary 228 and KB Entry 32: 0.00\n",
            "Similarity between Summary 228 and KB Entry 33: 0.05\n",
            "Similarity between Summary 228 and KB Entry 34: 0.01\n",
            "Similarity between Summary 228 and KB Entry 35: 0.01\n",
            "Similarity between Summary 228 and KB Entry 36: 0.00\n",
            "Similarity between Summary 228 and KB Entry 37: 0.01\n",
            "Similarity between Summary 228 and KB Entry 38: 0.01\n",
            "Similarity between Summary 228 and KB Entry 39: 0.02\n",
            "Similarity between Summary 228 and KB Entry 40: 0.01\n",
            "Similarity between Summary 228 and KB Entry 41: 0.02\n",
            "Similarity between Summary 228 and KB Entry 42: 0.02\n",
            "Similarity between Summary 228 and KB Entry 43: 0.02\n",
            "Similarity between Summary 228 and KB Entry 44: 0.03\n",
            "Similarity between Summary 228 and KB Entry 45: 0.00\n",
            "Similarity between Summary 228 and KB Entry 46: 0.01\n",
            "Similarity between Summary 229 and KB Entry 1: 0.08\n",
            "Similarity between Summary 229 and KB Entry 2: 0.02\n",
            "Similarity between Summary 229 and KB Entry 3: 0.04\n",
            "Similarity between Summary 229 and KB Entry 4: 0.03\n",
            "Similarity between Summary 229 and KB Entry 5: 0.00\n",
            "Similarity between Summary 229 and KB Entry 6: 0.03\n",
            "Similarity between Summary 229 and KB Entry 7: 0.01\n",
            "Similarity between Summary 229 and KB Entry 8: 0.01\n",
            "Similarity between Summary 229 and KB Entry 9: 0.01\n",
            "Similarity between Summary 229 and KB Entry 10: 0.01\n",
            "Similarity between Summary 229 and KB Entry 11: 0.01\n",
            "Similarity between Summary 229 and KB Entry 12: 0.25\n",
            "Similarity between Summary 229 and KB Entry 13: 0.01\n",
            "Similarity between Summary 229 and KB Entry 14: 0.01\n",
            "Similarity between Summary 229 and KB Entry 15: 0.01\n",
            "Similarity between Summary 229 and KB Entry 16: 0.02\n",
            "Similarity between Summary 229 and KB Entry 17: 0.06\n",
            "Similarity between Summary 229 and KB Entry 18: 0.01\n",
            "Similarity between Summary 229 and KB Entry 19: 0.00\n",
            "Similarity between Summary 229 and KB Entry 20: 0.00\n",
            "Similarity between Summary 229 and KB Entry 21: 0.02\n",
            "Similarity between Summary 229 and KB Entry 22: 0.03\n",
            "Similarity between Summary 229 and KB Entry 23: 0.00\n",
            "Similarity between Summary 229 and KB Entry 24: 0.00\n",
            "Similarity between Summary 229 and KB Entry 25: 0.05\n",
            "Similarity between Summary 229 and KB Entry 26: 0.00\n",
            "Similarity between Summary 229 and KB Entry 27: 0.00\n",
            "Similarity between Summary 229 and KB Entry 28: 0.01\n",
            "Similarity between Summary 229 and KB Entry 29: 0.00\n",
            "Similarity between Summary 229 and KB Entry 30: 0.00\n",
            "Similarity between Summary 229 and KB Entry 31: 0.00\n",
            "Similarity between Summary 229 and KB Entry 32: 0.00\n",
            "Similarity between Summary 229 and KB Entry 33: 0.08\n",
            "Similarity between Summary 229 and KB Entry 34: 0.00\n",
            "Similarity between Summary 229 and KB Entry 35: 0.00\n",
            "Similarity between Summary 229 and KB Entry 36: 0.00\n",
            "Similarity between Summary 229 and KB Entry 37: 0.01\n",
            "Similarity between Summary 229 and KB Entry 38: 0.03\n",
            "Similarity between Summary 229 and KB Entry 39: 0.04\n",
            "Similarity between Summary 229 and KB Entry 40: 0.03\n",
            "Similarity between Summary 229 and KB Entry 41: 0.02\n",
            "Similarity between Summary 229 and KB Entry 42: 0.01\n",
            "Similarity between Summary 229 and KB Entry 43: 0.02\n",
            "Similarity between Summary 229 and KB Entry 44: 0.00\n",
            "Similarity between Summary 229 and KB Entry 45: 0.01\n",
            "Similarity between Summary 229 and KB Entry 46: 0.00\n",
            "Similarity between Summary 230 and KB Entry 1: 0.08\n",
            "Similarity between Summary 230 and KB Entry 2: 0.01\n",
            "Similarity between Summary 230 and KB Entry 3: 0.03\n",
            "Similarity between Summary 230 and KB Entry 4: 0.03\n",
            "Similarity between Summary 230 and KB Entry 5: 0.00\n",
            "Similarity between Summary 230 and KB Entry 6: 0.02\n",
            "Similarity between Summary 230 and KB Entry 7: 0.01\n",
            "Similarity between Summary 230 and KB Entry 8: 0.01\n",
            "Similarity between Summary 230 and KB Entry 9: 0.00\n",
            "Similarity between Summary 230 and KB Entry 10: 0.01\n",
            "Similarity between Summary 230 and KB Entry 11: 0.00\n",
            "Similarity between Summary 230 and KB Entry 12: 0.25\n",
            "Similarity between Summary 230 and KB Entry 13: 0.01\n",
            "Similarity between Summary 230 and KB Entry 14: 0.01\n",
            "Similarity between Summary 230 and KB Entry 15: 0.01\n",
            "Similarity between Summary 230 and KB Entry 16: 0.02\n",
            "Similarity between Summary 230 and KB Entry 17: 0.13\n",
            "Similarity between Summary 230 and KB Entry 18: 0.01\n",
            "Similarity between Summary 230 and KB Entry 19: 0.05\n",
            "Similarity between Summary 230 and KB Entry 20: 0.00\n",
            "Similarity between Summary 230 and KB Entry 21: 0.03\n",
            "Similarity between Summary 230 and KB Entry 22: 0.02\n",
            "Similarity between Summary 230 and KB Entry 23: 0.02\n",
            "Similarity between Summary 230 and KB Entry 24: 0.00\n",
            "Similarity between Summary 230 and KB Entry 25: 0.08\n",
            "Similarity between Summary 230 and KB Entry 26: 0.02\n",
            "Similarity between Summary 230 and KB Entry 27: 0.05\n",
            "Similarity between Summary 230 and KB Entry 28: 0.03\n",
            "Similarity between Summary 230 and KB Entry 29: 0.00\n",
            "Similarity between Summary 230 and KB Entry 30: 0.02\n",
            "Similarity between Summary 230 and KB Entry 31: 0.00\n",
            "Similarity between Summary 230 and KB Entry 32: 0.01\n",
            "Similarity between Summary 230 and KB Entry 33: 0.07\n",
            "Similarity between Summary 230 and KB Entry 34: 0.01\n",
            "Similarity between Summary 230 and KB Entry 35: 0.00\n",
            "Similarity between Summary 230 and KB Entry 36: 0.00\n",
            "Similarity between Summary 230 and KB Entry 37: 0.02\n",
            "Similarity between Summary 230 and KB Entry 38: 0.03\n",
            "Similarity between Summary 230 and KB Entry 39: 0.03\n",
            "Similarity between Summary 230 and KB Entry 40: 0.01\n",
            "Similarity between Summary 230 and KB Entry 41: 0.01\n",
            "Similarity between Summary 230 and KB Entry 42: 0.01\n",
            "Similarity between Summary 230 and KB Entry 43: 0.01\n",
            "Similarity between Summary 230 and KB Entry 44: 0.00\n",
            "Similarity between Summary 230 and KB Entry 45: 0.01\n",
            "Similarity between Summary 230 and KB Entry 46: 0.00\n",
            "Similarity between Summary 231 and KB Entry 1: 0.09\n",
            "Similarity between Summary 231 and KB Entry 2: 0.01\n",
            "Similarity between Summary 231 and KB Entry 3: 0.02\n",
            "Similarity between Summary 231 and KB Entry 4: 0.02\n",
            "Similarity between Summary 231 and KB Entry 5: 0.00\n",
            "Similarity between Summary 231 and KB Entry 6: 0.02\n",
            "Similarity between Summary 231 and KB Entry 7: 0.01\n",
            "Similarity between Summary 231 and KB Entry 8: 0.01\n",
            "Similarity between Summary 231 and KB Entry 9: 0.01\n",
            "Similarity between Summary 231 and KB Entry 10: 0.01\n",
            "Similarity between Summary 231 and KB Entry 11: 0.01\n",
            "Similarity between Summary 231 and KB Entry 12: 0.24\n",
            "Similarity between Summary 231 and KB Entry 13: 0.01\n",
            "Similarity between Summary 231 and KB Entry 14: 0.02\n",
            "Similarity between Summary 231 and KB Entry 15: 0.01\n",
            "Similarity between Summary 231 and KB Entry 16: 0.02\n",
            "Similarity between Summary 231 and KB Entry 17: 0.17\n",
            "Similarity between Summary 231 and KB Entry 18: 0.03\n",
            "Similarity between Summary 231 and KB Entry 19: 0.07\n",
            "Similarity between Summary 231 and KB Entry 20: 0.00\n",
            "Similarity between Summary 231 and KB Entry 21: 0.01\n",
            "Similarity between Summary 231 and KB Entry 22: 0.02\n",
            "Similarity between Summary 231 and KB Entry 23: 0.00\n",
            "Similarity between Summary 231 and KB Entry 24: 0.00\n",
            "Similarity between Summary 231 and KB Entry 25: 0.08\n",
            "Similarity between Summary 231 and KB Entry 26: 0.02\n",
            "Similarity between Summary 231 and KB Entry 27: 0.05\n",
            "Similarity between Summary 231 and KB Entry 28: 0.02\n",
            "Similarity between Summary 231 and KB Entry 29: 0.00\n",
            "Similarity between Summary 231 and KB Entry 30: 0.04\n",
            "Similarity between Summary 231 and KB Entry 31: 0.01\n",
            "Similarity between Summary 231 and KB Entry 32: 0.01\n",
            "Similarity between Summary 231 and KB Entry 33: 0.06\n",
            "Similarity between Summary 231 and KB Entry 34: 0.01\n",
            "Similarity between Summary 231 and KB Entry 35: 0.01\n",
            "Similarity between Summary 231 and KB Entry 36: 0.00\n",
            "Similarity between Summary 231 and KB Entry 37: 0.02\n",
            "Similarity between Summary 231 and KB Entry 38: 0.02\n",
            "Similarity between Summary 231 and KB Entry 39: 0.03\n",
            "Similarity between Summary 231 and KB Entry 40: 0.02\n",
            "Similarity between Summary 231 and KB Entry 41: 0.01\n",
            "Similarity between Summary 231 and KB Entry 42: 0.01\n",
            "Similarity between Summary 231 and KB Entry 43: 0.01\n",
            "Similarity between Summary 231 and KB Entry 44: 0.00\n",
            "Similarity between Summary 231 and KB Entry 45: 0.00\n",
            "Similarity between Summary 231 and KB Entry 46: 0.00\n",
            "Similarity between Summary 232 and KB Entry 1: 0.09\n",
            "Similarity between Summary 232 and KB Entry 2: 0.01\n",
            "Similarity between Summary 232 and KB Entry 3: 0.03\n",
            "Similarity between Summary 232 and KB Entry 4: 0.03\n",
            "Similarity between Summary 232 and KB Entry 5: 0.00\n",
            "Similarity between Summary 232 and KB Entry 6: 0.03\n",
            "Similarity between Summary 232 and KB Entry 7: 0.01\n",
            "Similarity between Summary 232 and KB Entry 8: 0.01\n",
            "Similarity between Summary 232 and KB Entry 9: 0.01\n",
            "Similarity between Summary 232 and KB Entry 10: 0.01\n",
            "Similarity between Summary 232 and KB Entry 11: 0.01\n",
            "Similarity between Summary 232 and KB Entry 12: 0.28\n",
            "Similarity between Summary 232 and KB Entry 13: 0.01\n",
            "Similarity between Summary 232 and KB Entry 14: 0.01\n",
            "Similarity between Summary 232 and KB Entry 15: 0.01\n",
            "Similarity between Summary 232 and KB Entry 16: 0.02\n",
            "Similarity between Summary 232 and KB Entry 17: 0.10\n",
            "Similarity between Summary 232 and KB Entry 18: 0.01\n",
            "Similarity between Summary 232 and KB Entry 19: 0.00\n",
            "Similarity between Summary 232 and KB Entry 20: 0.00\n",
            "Similarity between Summary 232 and KB Entry 21: 0.03\n",
            "Similarity between Summary 232 and KB Entry 22: 0.03\n",
            "Similarity between Summary 232 and KB Entry 23: 0.00\n",
            "Similarity between Summary 232 and KB Entry 24: 0.01\n",
            "Similarity between Summary 232 and KB Entry 25: 0.05\n",
            "Similarity between Summary 232 and KB Entry 26: 0.00\n",
            "Similarity between Summary 232 and KB Entry 27: 0.00\n",
            "Similarity between Summary 232 and KB Entry 28: 0.01\n",
            "Similarity between Summary 232 and KB Entry 29: 0.00\n",
            "Similarity between Summary 232 and KB Entry 30: 0.04\n",
            "Similarity between Summary 232 and KB Entry 31: 0.00\n",
            "Similarity between Summary 232 and KB Entry 32: 0.01\n",
            "Similarity between Summary 232 and KB Entry 33: 0.08\n",
            "Similarity between Summary 232 and KB Entry 34: 0.00\n",
            "Similarity between Summary 232 and KB Entry 35: 0.01\n",
            "Similarity between Summary 232 and KB Entry 36: 0.00\n",
            "Similarity between Summary 232 and KB Entry 37: 0.02\n",
            "Similarity between Summary 232 and KB Entry 38: 0.03\n",
            "Similarity between Summary 232 and KB Entry 39: 0.03\n",
            "Similarity between Summary 232 and KB Entry 40: 0.02\n",
            "Similarity between Summary 232 and KB Entry 41: 0.02\n",
            "Similarity between Summary 232 and KB Entry 42: 0.01\n",
            "Similarity between Summary 232 and KB Entry 43: 0.02\n",
            "Similarity between Summary 232 and KB Entry 44: 0.00\n",
            "Similarity between Summary 232 and KB Entry 45: 0.01\n",
            "Similarity between Summary 232 and KB Entry 46: 0.00\n",
            "Similarity between Summary 233 and KB Entry 1: 0.10\n",
            "Similarity between Summary 233 and KB Entry 2: 0.01\n",
            "Similarity between Summary 233 and KB Entry 3: 0.04\n",
            "Similarity between Summary 233 and KB Entry 4: 0.05\n",
            "Similarity between Summary 233 and KB Entry 5: 0.01\n",
            "Similarity between Summary 233 and KB Entry 6: 0.03\n",
            "Similarity between Summary 233 and KB Entry 7: 0.02\n",
            "Similarity between Summary 233 and KB Entry 8: 0.02\n",
            "Similarity between Summary 233 and KB Entry 9: 0.02\n",
            "Similarity between Summary 233 and KB Entry 10: 0.01\n",
            "Similarity between Summary 233 and KB Entry 11: 0.01\n",
            "Similarity between Summary 233 and KB Entry 12: 0.26\n",
            "Similarity between Summary 233 and KB Entry 13: 0.01\n",
            "Similarity between Summary 233 and KB Entry 14: 0.02\n",
            "Similarity between Summary 233 and KB Entry 15: 0.02\n",
            "Similarity between Summary 233 and KB Entry 16: 0.07\n",
            "Similarity between Summary 233 and KB Entry 17: 0.09\n",
            "Similarity between Summary 233 and KB Entry 18: 0.05\n",
            "Similarity between Summary 233 and KB Entry 19: 0.01\n",
            "Similarity between Summary 233 and KB Entry 20: 0.00\n",
            "Similarity between Summary 233 and KB Entry 21: 0.01\n",
            "Similarity between Summary 233 and KB Entry 22: 0.02\n",
            "Similarity between Summary 233 and KB Entry 23: 0.00\n",
            "Similarity between Summary 233 and KB Entry 24: 0.00\n",
            "Similarity between Summary 233 and KB Entry 25: 0.05\n",
            "Similarity between Summary 233 and KB Entry 26: 0.00\n",
            "Similarity between Summary 233 and KB Entry 27: 0.01\n",
            "Similarity between Summary 233 and KB Entry 28: 0.01\n",
            "Similarity between Summary 233 and KB Entry 29: 0.00\n",
            "Similarity between Summary 233 and KB Entry 30: 0.04\n",
            "Similarity between Summary 233 and KB Entry 31: 0.00\n",
            "Similarity between Summary 233 and KB Entry 32: 0.01\n",
            "Similarity between Summary 233 and KB Entry 33: 0.06\n",
            "Similarity between Summary 233 and KB Entry 34: 0.00\n",
            "Similarity between Summary 233 and KB Entry 35: 0.01\n",
            "Similarity between Summary 233 and KB Entry 36: 0.00\n",
            "Similarity between Summary 233 and KB Entry 37: 0.00\n",
            "Similarity between Summary 233 and KB Entry 38: 0.03\n",
            "Similarity between Summary 233 and KB Entry 39: 0.04\n",
            "Similarity between Summary 233 and KB Entry 40: 0.02\n",
            "Similarity between Summary 233 and KB Entry 41: 0.02\n",
            "Similarity between Summary 233 and KB Entry 42: 0.02\n",
            "Similarity between Summary 233 and KB Entry 43: 0.02\n",
            "Similarity between Summary 233 and KB Entry 44: 0.00\n",
            "Similarity between Summary 233 and KB Entry 45: 0.01\n",
            "Similarity between Summary 233 and KB Entry 46: 0.00\n",
            "Similarity between Summary 234 and KB Entry 1: 0.06\n",
            "Similarity between Summary 234 and KB Entry 2: 0.01\n",
            "Similarity between Summary 234 and KB Entry 3: 0.02\n",
            "Similarity between Summary 234 and KB Entry 4: 0.02\n",
            "Similarity between Summary 234 and KB Entry 5: 0.00\n",
            "Similarity between Summary 234 and KB Entry 6: 0.01\n",
            "Similarity between Summary 234 and KB Entry 7: 0.01\n",
            "Similarity between Summary 234 and KB Entry 8: 0.00\n",
            "Similarity between Summary 234 and KB Entry 9: 0.00\n",
            "Similarity between Summary 234 and KB Entry 10: 0.00\n",
            "Similarity between Summary 234 and KB Entry 11: 0.00\n",
            "Similarity between Summary 234 and KB Entry 12: 0.27\n",
            "Similarity between Summary 234 and KB Entry 13: 0.00\n",
            "Similarity between Summary 234 and KB Entry 14: 0.01\n",
            "Similarity between Summary 234 and KB Entry 15: 0.02\n",
            "Similarity between Summary 234 and KB Entry 16: 0.03\n",
            "Similarity between Summary 234 and KB Entry 17: 0.10\n",
            "Similarity between Summary 234 and KB Entry 18: 0.01\n",
            "Similarity between Summary 234 and KB Entry 19: 0.03\n",
            "Similarity between Summary 234 and KB Entry 20: 0.00\n",
            "Similarity between Summary 234 and KB Entry 21: 0.05\n",
            "Similarity between Summary 234 and KB Entry 22: 0.06\n",
            "Similarity between Summary 234 and KB Entry 23: 0.02\n",
            "Similarity between Summary 234 and KB Entry 24: 0.01\n",
            "Similarity between Summary 234 and KB Entry 25: 0.09\n",
            "Similarity between Summary 234 and KB Entry 26: 0.02\n",
            "Similarity between Summary 234 and KB Entry 27: 0.04\n",
            "Similarity between Summary 234 and KB Entry 28: 0.02\n",
            "Similarity between Summary 234 and KB Entry 29: 0.00\n",
            "Similarity between Summary 234 and KB Entry 30: 0.02\n",
            "Similarity between Summary 234 and KB Entry 31: 0.01\n",
            "Similarity between Summary 234 and KB Entry 32: 0.00\n",
            "Similarity between Summary 234 and KB Entry 33: 0.06\n",
            "Similarity between Summary 234 and KB Entry 34: 0.04\n",
            "Similarity between Summary 234 and KB Entry 35: 0.01\n",
            "Similarity between Summary 234 and KB Entry 36: 0.01\n",
            "Similarity between Summary 234 and KB Entry 37: 0.02\n",
            "Similarity between Summary 234 and KB Entry 38: 0.02\n",
            "Similarity between Summary 234 and KB Entry 39: 0.02\n",
            "Similarity between Summary 234 and KB Entry 40: 0.01\n",
            "Similarity between Summary 234 and KB Entry 41: 0.01\n",
            "Similarity between Summary 234 and KB Entry 42: 0.01\n",
            "Similarity between Summary 234 and KB Entry 43: 0.01\n",
            "Similarity between Summary 234 and KB Entry 44: 0.00\n",
            "Similarity between Summary 234 and KB Entry 45: 0.01\n",
            "Similarity between Summary 234 and KB Entry 46: 0.01\n",
            "Similarity between Summary 235 and KB Entry 1: 0.09\n",
            "Similarity between Summary 235 and KB Entry 2: 0.01\n",
            "Similarity between Summary 235 and KB Entry 3: 0.02\n",
            "Similarity between Summary 235 and KB Entry 4: 0.02\n",
            "Similarity between Summary 235 and KB Entry 5: 0.00\n",
            "Similarity between Summary 235 and KB Entry 6: 0.01\n",
            "Similarity between Summary 235 and KB Entry 7: 0.01\n",
            "Similarity between Summary 235 and KB Entry 8: 0.01\n",
            "Similarity between Summary 235 and KB Entry 9: 0.00\n",
            "Similarity between Summary 235 and KB Entry 10: 0.01\n",
            "Similarity between Summary 235 and KB Entry 11: 0.00\n",
            "Similarity between Summary 235 and KB Entry 12: 0.25\n",
            "Similarity between Summary 235 and KB Entry 13: 0.01\n",
            "Similarity between Summary 235 and KB Entry 14: 0.02\n",
            "Similarity between Summary 235 and KB Entry 15: 0.01\n",
            "Similarity between Summary 235 and KB Entry 16: 0.03\n",
            "Similarity between Summary 235 and KB Entry 17: 0.14\n",
            "Similarity between Summary 235 and KB Entry 18: 0.02\n",
            "Similarity between Summary 235 and KB Entry 19: 0.06\n",
            "Similarity between Summary 235 and KB Entry 20: 0.00\n",
            "Similarity between Summary 235 and KB Entry 21: 0.03\n",
            "Similarity between Summary 235 and KB Entry 22: 0.03\n",
            "Similarity between Summary 235 and KB Entry 23: 0.02\n",
            "Similarity between Summary 235 and KB Entry 24: 0.01\n",
            "Similarity between Summary 235 and KB Entry 25: 0.09\n",
            "Similarity between Summary 235 and KB Entry 26: 0.03\n",
            "Similarity between Summary 235 and KB Entry 27: 0.05\n",
            "Similarity between Summary 235 and KB Entry 28: 0.04\n",
            "Similarity between Summary 235 and KB Entry 29: 0.00\n",
            "Similarity between Summary 235 and KB Entry 30: 0.02\n",
            "Similarity between Summary 235 and KB Entry 31: 0.01\n",
            "Similarity between Summary 235 and KB Entry 32: 0.01\n",
            "Similarity between Summary 235 and KB Entry 33: 0.06\n",
            "Similarity between Summary 235 and KB Entry 34: 0.01\n",
            "Similarity between Summary 235 and KB Entry 35: 0.01\n",
            "Similarity between Summary 235 and KB Entry 36: 0.01\n",
            "Similarity between Summary 235 and KB Entry 37: 0.02\n",
            "Similarity between Summary 235 and KB Entry 38: 0.02\n",
            "Similarity between Summary 235 and KB Entry 39: 0.03\n",
            "Similarity between Summary 235 and KB Entry 40: 0.01\n",
            "Similarity between Summary 235 and KB Entry 41: 0.01\n",
            "Similarity between Summary 235 and KB Entry 42: 0.01\n",
            "Similarity between Summary 235 and KB Entry 43: 0.01\n",
            "Similarity between Summary 235 and KB Entry 44: 0.00\n",
            "Similarity between Summary 235 and KB Entry 45: 0.01\n",
            "Similarity between Summary 235 and KB Entry 46: 0.00\n",
            "Similarity between Summary 236 and KB Entry 1: 0.07\n",
            "Similarity between Summary 236 and KB Entry 2: 0.01\n",
            "Similarity between Summary 236 and KB Entry 3: 0.03\n",
            "Similarity between Summary 236 and KB Entry 4: 0.03\n",
            "Similarity between Summary 236 and KB Entry 5: 0.00\n",
            "Similarity between Summary 236 and KB Entry 6: 0.02\n",
            "Similarity between Summary 236 and KB Entry 7: 0.01\n",
            "Similarity between Summary 236 and KB Entry 8: 0.01\n",
            "Similarity between Summary 236 and KB Entry 9: 0.01\n",
            "Similarity between Summary 236 and KB Entry 10: 0.01\n",
            "Similarity between Summary 236 and KB Entry 11: 0.01\n",
            "Similarity between Summary 236 and KB Entry 12: 0.28\n",
            "Similarity between Summary 236 and KB Entry 13: 0.01\n",
            "Similarity between Summary 236 and KB Entry 14: 0.01\n",
            "Similarity between Summary 236 and KB Entry 15: 0.01\n",
            "Similarity between Summary 236 and KB Entry 16: 0.02\n",
            "Similarity between Summary 236 and KB Entry 17: 0.16\n",
            "Similarity between Summary 236 and KB Entry 18: 0.04\n",
            "Similarity between Summary 236 and KB Entry 19: 0.07\n",
            "Similarity between Summary 236 and KB Entry 20: 0.00\n",
            "Similarity between Summary 236 and KB Entry 21: 0.02\n",
            "Similarity between Summary 236 and KB Entry 22: 0.02\n",
            "Similarity between Summary 236 and KB Entry 23: 0.00\n",
            "Similarity between Summary 236 and KB Entry 24: 0.00\n",
            "Similarity between Summary 236 and KB Entry 25: 0.10\n",
            "Similarity between Summary 236 and KB Entry 26: 0.01\n",
            "Similarity between Summary 236 and KB Entry 27: 0.06\n",
            "Similarity between Summary 236 and KB Entry 28: 0.04\n",
            "Similarity between Summary 236 and KB Entry 29: 0.00\n",
            "Similarity between Summary 236 and KB Entry 30: 0.04\n",
            "Similarity between Summary 236 and KB Entry 31: 0.01\n",
            "Similarity between Summary 236 and KB Entry 32: 0.02\n",
            "Similarity between Summary 236 and KB Entry 33: 0.07\n",
            "Similarity between Summary 236 and KB Entry 34: 0.02\n",
            "Similarity between Summary 236 and KB Entry 35: 0.01\n",
            "Similarity between Summary 236 and KB Entry 36: 0.00\n",
            "Similarity between Summary 236 and KB Entry 37: 0.02\n",
            "Similarity between Summary 236 and KB Entry 38: 0.03\n",
            "Similarity between Summary 236 and KB Entry 39: 0.02\n",
            "Similarity between Summary 236 and KB Entry 40: 0.02\n",
            "Similarity between Summary 236 and KB Entry 41: 0.01\n",
            "Similarity between Summary 236 and KB Entry 42: 0.01\n",
            "Similarity between Summary 236 and KB Entry 43: 0.01\n",
            "Similarity between Summary 236 and KB Entry 44: 0.00\n",
            "Similarity between Summary 236 and KB Entry 45: 0.03\n",
            "Similarity between Summary 236 and KB Entry 46: 0.01\n",
            "Similarity between Summary 237 and KB Entry 1: 0.07\n",
            "Similarity between Summary 237 and KB Entry 2: 0.01\n",
            "Similarity between Summary 237 and KB Entry 3: 0.02\n",
            "Similarity between Summary 237 and KB Entry 4: 0.02\n",
            "Similarity between Summary 237 and KB Entry 5: 0.00\n",
            "Similarity between Summary 237 and KB Entry 6: 0.02\n",
            "Similarity between Summary 237 and KB Entry 7: 0.01\n",
            "Similarity between Summary 237 and KB Entry 8: 0.01\n",
            "Similarity between Summary 237 and KB Entry 9: 0.00\n",
            "Similarity between Summary 237 and KB Entry 10: 0.01\n",
            "Similarity between Summary 237 and KB Entry 11: 0.00\n",
            "Similarity between Summary 237 and KB Entry 12: 0.23\n",
            "Similarity between Summary 237 and KB Entry 13: 0.01\n",
            "Similarity between Summary 237 and KB Entry 14: 0.01\n",
            "Similarity between Summary 237 and KB Entry 15: 0.01\n",
            "Similarity between Summary 237 and KB Entry 16: 0.02\n",
            "Similarity between Summary 237 and KB Entry 17: 0.13\n",
            "Similarity between Summary 237 and KB Entry 18: 0.02\n",
            "Similarity between Summary 237 and KB Entry 19: 0.06\n",
            "Similarity between Summary 237 and KB Entry 20: 0.00\n",
            "Similarity between Summary 237 and KB Entry 21: 0.01\n",
            "Similarity between Summary 237 and KB Entry 22: 0.02\n",
            "Similarity between Summary 237 and KB Entry 23: 0.04\n",
            "Similarity between Summary 237 and KB Entry 24: 0.03\n",
            "Similarity between Summary 237 and KB Entry 25: 0.10\n",
            "Similarity between Summary 237 and KB Entry 26: 0.02\n",
            "Similarity between Summary 237 and KB Entry 27: 0.04\n",
            "Similarity between Summary 237 and KB Entry 28: 0.02\n",
            "Similarity between Summary 237 and KB Entry 29: 0.00\n",
            "Similarity between Summary 237 and KB Entry 30: 0.04\n",
            "Similarity between Summary 237 and KB Entry 31: 0.00\n",
            "Similarity between Summary 237 and KB Entry 32: 0.02\n",
            "Similarity between Summary 237 and KB Entry 33: 0.07\n",
            "Similarity between Summary 237 and KB Entry 34: 0.00\n",
            "Similarity between Summary 237 and KB Entry 35: 0.01\n",
            "Similarity between Summary 237 and KB Entry 36: 0.01\n",
            "Similarity between Summary 237 and KB Entry 37: 0.02\n",
            "Similarity between Summary 237 and KB Entry 38: 0.02\n",
            "Similarity between Summary 237 and KB Entry 39: 0.03\n",
            "Similarity between Summary 237 and KB Entry 40: 0.01\n",
            "Similarity between Summary 237 and KB Entry 41: 0.01\n",
            "Similarity between Summary 237 and KB Entry 42: 0.02\n",
            "Similarity between Summary 237 and KB Entry 43: 0.01\n",
            "Similarity between Summary 237 and KB Entry 44: 0.00\n",
            "Similarity between Summary 237 and KB Entry 45: 0.01\n",
            "Similarity between Summary 237 and KB Entry 46: 0.00\n",
            "Similarity between Summary 238 and KB Entry 1: 0.10\n",
            "Similarity between Summary 238 and KB Entry 2: 0.01\n",
            "Similarity between Summary 238 and KB Entry 3: 0.05\n",
            "Similarity between Summary 238 and KB Entry 4: 0.09\n",
            "Similarity between Summary 238 and KB Entry 5: 0.01\n",
            "Similarity between Summary 238 and KB Entry 6: 0.03\n",
            "Similarity between Summary 238 and KB Entry 7: 0.03\n",
            "Similarity between Summary 238 and KB Entry 8: 0.01\n",
            "Similarity between Summary 238 and KB Entry 9: 0.00\n",
            "Similarity between Summary 238 and KB Entry 10: 0.01\n",
            "Similarity between Summary 238 and KB Entry 11: 0.00\n",
            "Similarity between Summary 238 and KB Entry 12: 0.04\n",
            "Similarity between Summary 238 and KB Entry 13: 0.02\n",
            "Similarity between Summary 238 and KB Entry 14: 0.01\n",
            "Similarity between Summary 238 and KB Entry 15: 0.00\n",
            "Similarity between Summary 238 and KB Entry 16: 0.01\n",
            "Similarity between Summary 238 and KB Entry 17: 0.08\n",
            "Similarity between Summary 238 and KB Entry 18: 0.01\n",
            "Similarity between Summary 238 and KB Entry 19: 0.00\n",
            "Similarity between Summary 238 and KB Entry 20: 0.00\n",
            "Similarity between Summary 238 and KB Entry 21: 0.01\n",
            "Similarity between Summary 238 and KB Entry 22: 0.04\n",
            "Similarity between Summary 238 and KB Entry 23: 0.03\n",
            "Similarity between Summary 238 and KB Entry 24: 0.01\n",
            "Similarity between Summary 238 and KB Entry 25: 0.08\n",
            "Similarity between Summary 238 and KB Entry 26: 0.02\n",
            "Similarity between Summary 238 and KB Entry 27: 0.05\n",
            "Similarity between Summary 238 and KB Entry 28: 0.02\n",
            "Similarity between Summary 238 and KB Entry 29: 0.00\n",
            "Similarity between Summary 238 and KB Entry 30: 0.03\n",
            "Similarity between Summary 238 and KB Entry 31: 0.00\n",
            "Similarity between Summary 238 and KB Entry 32: 0.01\n",
            "Similarity between Summary 238 and KB Entry 33: 0.04\n",
            "Similarity between Summary 238 and KB Entry 34: 0.00\n",
            "Similarity between Summary 238 and KB Entry 35: 0.02\n",
            "Similarity between Summary 238 and KB Entry 36: 0.01\n",
            "Similarity between Summary 238 and KB Entry 37: 0.02\n",
            "Similarity between Summary 238 and KB Entry 38: 0.02\n",
            "Similarity between Summary 238 and KB Entry 39: 0.03\n",
            "Similarity between Summary 238 and KB Entry 40: 0.01\n",
            "Similarity between Summary 238 and KB Entry 41: 0.02\n",
            "Similarity between Summary 238 and KB Entry 42: 0.02\n",
            "Similarity between Summary 238 and KB Entry 43: 0.03\n",
            "Similarity between Summary 238 and KB Entry 44: 0.03\n",
            "Similarity between Summary 238 and KB Entry 45: 0.01\n",
            "Similarity between Summary 238 and KB Entry 46: 0.00\n",
            "Similarity between Summary 239 and KB Entry 1: 0.08\n",
            "Similarity between Summary 239 and KB Entry 2: 0.01\n",
            "Similarity between Summary 239 and KB Entry 3: 0.05\n",
            "Similarity between Summary 239 and KB Entry 4: 0.05\n",
            "Similarity between Summary 239 and KB Entry 5: 0.00\n",
            "Similarity between Summary 239 and KB Entry 6: 0.04\n",
            "Similarity between Summary 239 and KB Entry 7: 0.02\n",
            "Similarity between Summary 239 and KB Entry 8: 0.01\n",
            "Similarity between Summary 239 and KB Entry 9: 0.02\n",
            "Similarity between Summary 239 and KB Entry 10: 0.01\n",
            "Similarity between Summary 239 and KB Entry 11: 0.01\n",
            "Similarity between Summary 239 and KB Entry 12: 0.28\n",
            "Similarity between Summary 239 and KB Entry 13: 0.01\n",
            "Similarity between Summary 239 and KB Entry 14: 0.01\n",
            "Similarity between Summary 239 and KB Entry 15: 0.01\n",
            "Similarity between Summary 239 and KB Entry 16: 0.01\n",
            "Similarity between Summary 239 and KB Entry 17: 0.04\n",
            "Similarity between Summary 239 and KB Entry 18: 0.00\n",
            "Similarity between Summary 239 and KB Entry 19: 0.00\n",
            "Similarity between Summary 239 and KB Entry 20: 0.00\n",
            "Similarity between Summary 239 and KB Entry 21: 0.03\n",
            "Similarity between Summary 239 and KB Entry 22: 0.02\n",
            "Similarity between Summary 239 and KB Entry 23: 0.05\n",
            "Similarity between Summary 239 and KB Entry 24: 0.00\n",
            "Similarity between Summary 239 and KB Entry 25: 0.06\n",
            "Similarity between Summary 239 and KB Entry 26: 0.00\n",
            "Similarity between Summary 239 and KB Entry 27: 0.01\n",
            "Similarity between Summary 239 and KB Entry 28: 0.01\n",
            "Similarity between Summary 239 and KB Entry 29: 0.00\n",
            "Similarity between Summary 239 and KB Entry 30: 0.00\n",
            "Similarity between Summary 239 and KB Entry 31: 0.00\n",
            "Similarity between Summary 239 and KB Entry 32: 0.00\n",
            "Similarity between Summary 239 and KB Entry 33: 0.04\n",
            "Similarity between Summary 239 and KB Entry 34: 0.00\n",
            "Similarity between Summary 239 and KB Entry 35: 0.01\n",
            "Similarity between Summary 239 and KB Entry 36: 0.01\n",
            "Similarity between Summary 239 and KB Entry 37: 0.00\n",
            "Similarity between Summary 239 and KB Entry 38: 0.03\n",
            "Similarity between Summary 239 and KB Entry 39: 0.04\n",
            "Similarity between Summary 239 and KB Entry 40: 0.02\n",
            "Similarity between Summary 239 and KB Entry 41: 0.02\n",
            "Similarity between Summary 239 and KB Entry 42: 0.03\n",
            "Similarity between Summary 239 and KB Entry 43: 0.02\n",
            "Similarity between Summary 239 and KB Entry 44: 0.00\n",
            "Similarity between Summary 239 and KB Entry 45: 0.01\n",
            "Similarity between Summary 239 and KB Entry 46: 0.00\n",
            "Similarity between Summary 240 and KB Entry 1: 0.07\n",
            "Similarity between Summary 240 and KB Entry 2: 0.01\n",
            "Similarity between Summary 240 and KB Entry 3: 0.03\n",
            "Similarity between Summary 240 and KB Entry 4: 0.03\n",
            "Similarity between Summary 240 and KB Entry 5: 0.00\n",
            "Similarity between Summary 240 and KB Entry 6: 0.02\n",
            "Similarity between Summary 240 and KB Entry 7: 0.01\n",
            "Similarity between Summary 240 and KB Entry 8: 0.01\n",
            "Similarity between Summary 240 and KB Entry 9: 0.01\n",
            "Similarity between Summary 240 and KB Entry 10: 0.01\n",
            "Similarity between Summary 240 and KB Entry 11: 0.01\n",
            "Similarity between Summary 240 and KB Entry 12: 0.26\n",
            "Similarity between Summary 240 and KB Entry 13: 0.01\n",
            "Similarity between Summary 240 and KB Entry 14: 0.01\n",
            "Similarity between Summary 240 and KB Entry 15: 0.01\n",
            "Similarity between Summary 240 and KB Entry 16: 0.04\n",
            "Similarity between Summary 240 and KB Entry 17: 0.12\n",
            "Similarity between Summary 240 and KB Entry 18: 0.04\n",
            "Similarity between Summary 240 and KB Entry 19: 0.06\n",
            "Similarity between Summary 240 and KB Entry 20: 0.00\n",
            "Similarity between Summary 240 and KB Entry 21: 0.02\n",
            "Similarity between Summary 240 and KB Entry 22: 0.02\n",
            "Similarity between Summary 240 and KB Entry 23: 0.03\n",
            "Similarity between Summary 240 and KB Entry 24: 0.00\n",
            "Similarity between Summary 240 and KB Entry 25: 0.09\n",
            "Similarity between Summary 240 and KB Entry 26: 0.01\n",
            "Similarity between Summary 240 and KB Entry 27: 0.04\n",
            "Similarity between Summary 240 and KB Entry 28: 0.02\n",
            "Similarity between Summary 240 and KB Entry 29: 0.00\n",
            "Similarity between Summary 240 and KB Entry 30: 0.03\n",
            "Similarity between Summary 240 and KB Entry 31: 0.00\n",
            "Similarity between Summary 240 and KB Entry 32: 0.01\n",
            "Similarity between Summary 240 and KB Entry 33: 0.06\n",
            "Similarity between Summary 240 and KB Entry 34: 0.01\n",
            "Similarity between Summary 240 and KB Entry 35: 0.00\n",
            "Similarity between Summary 240 and KB Entry 36: 0.01\n",
            "Similarity between Summary 240 and KB Entry 37: 0.02\n",
            "Similarity between Summary 240 and KB Entry 38: 0.02\n",
            "Similarity between Summary 240 and KB Entry 39: 0.03\n",
            "Similarity between Summary 240 and KB Entry 40: 0.02\n",
            "Similarity between Summary 240 and KB Entry 41: 0.02\n",
            "Similarity between Summary 240 and KB Entry 42: 0.02\n",
            "Similarity between Summary 240 and KB Entry 43: 0.01\n",
            "Similarity between Summary 240 and KB Entry 44: 0.00\n",
            "Similarity between Summary 240 and KB Entry 45: 0.00\n",
            "Similarity between Summary 240 and KB Entry 46: 0.00\n",
            "Similarity between Summary 241 and KB Entry 1: 0.08\n",
            "Similarity between Summary 241 and KB Entry 2: 0.02\n",
            "Similarity between Summary 241 and KB Entry 3: 0.03\n",
            "Similarity between Summary 241 and KB Entry 4: 0.03\n",
            "Similarity between Summary 241 and KB Entry 5: 0.00\n",
            "Similarity between Summary 241 and KB Entry 6: 0.03\n",
            "Similarity between Summary 241 and KB Entry 7: 0.01\n",
            "Similarity between Summary 241 and KB Entry 8: 0.01\n",
            "Similarity between Summary 241 and KB Entry 9: 0.01\n",
            "Similarity between Summary 241 and KB Entry 10: 0.01\n",
            "Similarity between Summary 241 and KB Entry 11: 0.01\n",
            "Similarity between Summary 241 and KB Entry 12: 0.26\n",
            "Similarity between Summary 241 and KB Entry 13: 0.01\n",
            "Similarity between Summary 241 and KB Entry 14: 0.01\n",
            "Similarity between Summary 241 and KB Entry 15: 0.01\n",
            "Similarity between Summary 241 and KB Entry 16: 0.02\n",
            "Similarity between Summary 241 and KB Entry 17: 0.06\n",
            "Similarity between Summary 241 and KB Entry 18: 0.01\n",
            "Similarity between Summary 241 and KB Entry 19: 0.00\n",
            "Similarity between Summary 241 and KB Entry 20: 0.00\n",
            "Similarity between Summary 241 and KB Entry 21: 0.02\n",
            "Similarity between Summary 241 and KB Entry 22: 0.03\n",
            "Similarity between Summary 241 and KB Entry 23: 0.00\n",
            "Similarity between Summary 241 and KB Entry 24: 0.00\n",
            "Similarity between Summary 241 and KB Entry 25: 0.05\n",
            "Similarity between Summary 241 and KB Entry 26: 0.00\n",
            "Similarity between Summary 241 and KB Entry 27: 0.00\n",
            "Similarity between Summary 241 and KB Entry 28: 0.01\n",
            "Similarity between Summary 241 and KB Entry 29: 0.00\n",
            "Similarity between Summary 241 and KB Entry 30: 0.00\n",
            "Similarity between Summary 241 and KB Entry 31: 0.00\n",
            "Similarity between Summary 241 and KB Entry 32: 0.00\n",
            "Similarity between Summary 241 and KB Entry 33: 0.09\n",
            "Similarity between Summary 241 and KB Entry 34: 0.00\n",
            "Similarity between Summary 241 and KB Entry 35: 0.00\n",
            "Similarity between Summary 241 and KB Entry 36: 0.00\n",
            "Similarity between Summary 241 and KB Entry 37: 0.01\n",
            "Similarity between Summary 241 and KB Entry 38: 0.03\n",
            "Similarity between Summary 241 and KB Entry 39: 0.04\n",
            "Similarity between Summary 241 and KB Entry 40: 0.03\n",
            "Similarity between Summary 241 and KB Entry 41: 0.02\n",
            "Similarity between Summary 241 and KB Entry 42: 0.01\n",
            "Similarity between Summary 241 and KB Entry 43: 0.02\n",
            "Similarity between Summary 241 and KB Entry 44: 0.00\n",
            "Similarity between Summary 241 and KB Entry 45: 0.01\n",
            "Similarity between Summary 241 and KB Entry 46: 0.00\n",
            "Similarity between Summary 242 and KB Entry 1: 0.10\n",
            "Similarity between Summary 242 and KB Entry 2: 0.02\n",
            "Similarity between Summary 242 and KB Entry 3: 0.03\n",
            "Similarity between Summary 242 and KB Entry 4: 0.06\n",
            "Similarity between Summary 242 and KB Entry 5: 0.00\n",
            "Similarity between Summary 242 and KB Entry 6: 0.01\n",
            "Similarity between Summary 242 and KB Entry 7: 0.01\n",
            "Similarity between Summary 242 and KB Entry 8: 0.01\n",
            "Similarity between Summary 242 and KB Entry 9: 0.02\n",
            "Similarity between Summary 242 and KB Entry 10: 0.01\n",
            "Similarity between Summary 242 and KB Entry 11: 0.03\n",
            "Similarity between Summary 242 and KB Entry 12: 0.04\n",
            "Similarity between Summary 242 and KB Entry 13: 0.01\n",
            "Similarity between Summary 242 and KB Entry 14: 0.01\n",
            "Similarity between Summary 242 and KB Entry 15: 0.01\n",
            "Similarity between Summary 242 and KB Entry 16: 0.02\n",
            "Similarity between Summary 242 and KB Entry 17: 0.07\n",
            "Similarity between Summary 242 and KB Entry 18: 0.00\n",
            "Similarity between Summary 242 and KB Entry 19: 0.04\n",
            "Similarity between Summary 242 and KB Entry 20: 0.00\n",
            "Similarity between Summary 242 and KB Entry 21: 0.01\n",
            "Similarity between Summary 242 and KB Entry 22: 0.00\n",
            "Similarity between Summary 242 and KB Entry 23: 0.02\n",
            "Similarity between Summary 242 and KB Entry 24: 0.01\n",
            "Similarity between Summary 242 and KB Entry 25: 0.06\n",
            "Similarity between Summary 242 and KB Entry 26: 0.02\n",
            "Similarity between Summary 242 and KB Entry 27: 0.03\n",
            "Similarity between Summary 242 and KB Entry 28: 0.01\n",
            "Similarity between Summary 242 and KB Entry 29: 0.00\n",
            "Similarity between Summary 242 and KB Entry 30: 0.01\n",
            "Similarity between Summary 242 and KB Entry 31: 0.00\n",
            "Similarity between Summary 242 and KB Entry 32: 0.00\n",
            "Similarity between Summary 242 and KB Entry 33: 0.04\n",
            "Similarity between Summary 242 and KB Entry 34: 0.02\n",
            "Similarity between Summary 242 and KB Entry 35: 0.00\n",
            "Similarity between Summary 242 and KB Entry 36: 0.00\n",
            "Similarity between Summary 242 and KB Entry 37: 0.00\n",
            "Similarity between Summary 242 and KB Entry 38: 0.03\n",
            "Similarity between Summary 242 and KB Entry 39: 0.00\n",
            "Similarity between Summary 242 and KB Entry 40: 0.01\n",
            "Similarity between Summary 242 and KB Entry 41: 0.01\n",
            "Similarity between Summary 242 and KB Entry 42: 0.01\n",
            "Similarity between Summary 242 and KB Entry 43: 0.01\n",
            "Similarity between Summary 242 and KB Entry 44: 0.05\n",
            "Similarity between Summary 242 and KB Entry 45: 0.01\n",
            "Similarity between Summary 242 and KB Entry 46: 0.00\n",
            "Similarity between Summary 243 and KB Entry 1: 0.09\n",
            "Similarity between Summary 243 and KB Entry 2: 0.01\n",
            "Similarity between Summary 243 and KB Entry 3: 0.03\n",
            "Similarity between Summary 243 and KB Entry 4: 0.05\n",
            "Similarity between Summary 243 and KB Entry 5: 0.00\n",
            "Similarity between Summary 243 and KB Entry 6: 0.01\n",
            "Similarity between Summary 243 and KB Entry 7: 0.01\n",
            "Similarity between Summary 243 and KB Entry 8: 0.01\n",
            "Similarity between Summary 243 and KB Entry 9: 0.02\n",
            "Similarity between Summary 243 and KB Entry 10: 0.01\n",
            "Similarity between Summary 243 and KB Entry 11: 0.03\n",
            "Similarity between Summary 243 and KB Entry 12: 0.04\n",
            "Similarity between Summary 243 and KB Entry 13: 0.01\n",
            "Similarity between Summary 243 and KB Entry 14: 0.01\n",
            "Similarity between Summary 243 and KB Entry 15: 0.01\n",
            "Similarity between Summary 243 and KB Entry 16: 0.02\n",
            "Similarity between Summary 243 and KB Entry 17: 0.07\n",
            "Similarity between Summary 243 and KB Entry 18: 0.00\n",
            "Similarity between Summary 243 and KB Entry 19: 0.04\n",
            "Similarity between Summary 243 and KB Entry 20: 0.00\n",
            "Similarity between Summary 243 and KB Entry 21: 0.01\n",
            "Similarity between Summary 243 and KB Entry 22: 0.00\n",
            "Similarity between Summary 243 and KB Entry 23: 0.02\n",
            "Similarity between Summary 243 and KB Entry 24: 0.01\n",
            "Similarity between Summary 243 and KB Entry 25: 0.06\n",
            "Similarity between Summary 243 and KB Entry 26: 0.02\n",
            "Similarity between Summary 243 and KB Entry 27: 0.03\n",
            "Similarity between Summary 243 and KB Entry 28: 0.01\n",
            "Similarity between Summary 243 and KB Entry 29: 0.00\n",
            "Similarity between Summary 243 and KB Entry 30: 0.01\n",
            "Similarity between Summary 243 and KB Entry 31: 0.00\n",
            "Similarity between Summary 243 and KB Entry 32: 0.00\n",
            "Similarity between Summary 243 and KB Entry 33: 0.04\n",
            "Similarity between Summary 243 and KB Entry 34: 0.02\n",
            "Similarity between Summary 243 and KB Entry 35: 0.00\n",
            "Similarity between Summary 243 and KB Entry 36: 0.00\n",
            "Similarity between Summary 243 and KB Entry 37: 0.00\n",
            "Similarity between Summary 243 and KB Entry 38: 0.03\n",
            "Similarity between Summary 243 and KB Entry 39: 0.00\n",
            "Similarity between Summary 243 and KB Entry 40: 0.01\n",
            "Similarity between Summary 243 and KB Entry 41: 0.01\n",
            "Similarity between Summary 243 and KB Entry 42: 0.01\n",
            "Similarity between Summary 243 and KB Entry 43: 0.01\n",
            "Similarity between Summary 243 and KB Entry 44: 0.05\n",
            "Similarity between Summary 243 and KB Entry 45: 0.01\n",
            "Similarity between Summary 243 and KB Entry 46: 0.00\n",
            "Similarity between Summary 244 and KB Entry 1: 0.09\n",
            "Similarity between Summary 244 and KB Entry 2: 0.02\n",
            "Similarity between Summary 244 and KB Entry 3: 0.03\n",
            "Similarity between Summary 244 and KB Entry 4: 0.05\n",
            "Similarity between Summary 244 and KB Entry 5: 0.00\n",
            "Similarity between Summary 244 and KB Entry 6: 0.01\n",
            "Similarity between Summary 244 and KB Entry 7: 0.01\n",
            "Similarity between Summary 244 and KB Entry 8: 0.01\n",
            "Similarity between Summary 244 and KB Entry 9: 0.02\n",
            "Similarity between Summary 244 and KB Entry 10: 0.01\n",
            "Similarity between Summary 244 and KB Entry 11: 0.03\n",
            "Similarity between Summary 244 and KB Entry 12: 0.04\n",
            "Similarity between Summary 244 and KB Entry 13: 0.01\n",
            "Similarity between Summary 244 and KB Entry 14: 0.01\n",
            "Similarity between Summary 244 and KB Entry 15: 0.01\n",
            "Similarity between Summary 244 and KB Entry 16: 0.02\n",
            "Similarity between Summary 244 and KB Entry 17: 0.08\n",
            "Similarity between Summary 244 and KB Entry 18: 0.00\n",
            "Similarity between Summary 244 and KB Entry 19: 0.04\n",
            "Similarity between Summary 244 and KB Entry 20: 0.00\n",
            "Similarity between Summary 244 and KB Entry 21: 0.01\n",
            "Similarity between Summary 244 and KB Entry 22: 0.00\n",
            "Similarity between Summary 244 and KB Entry 23: 0.02\n",
            "Similarity between Summary 244 and KB Entry 24: 0.01\n",
            "Similarity between Summary 244 and KB Entry 25: 0.06\n",
            "Similarity between Summary 244 and KB Entry 26: 0.02\n",
            "Similarity between Summary 244 and KB Entry 27: 0.03\n",
            "Similarity between Summary 244 and KB Entry 28: 0.01\n",
            "Similarity between Summary 244 and KB Entry 29: 0.00\n",
            "Similarity between Summary 244 and KB Entry 30: 0.01\n",
            "Similarity between Summary 244 and KB Entry 31: 0.00\n",
            "Similarity between Summary 244 and KB Entry 32: 0.01\n",
            "Similarity between Summary 244 and KB Entry 33: 0.04\n",
            "Similarity between Summary 244 and KB Entry 34: 0.02\n",
            "Similarity between Summary 244 and KB Entry 35: 0.00\n",
            "Similarity between Summary 244 and KB Entry 36: 0.00\n",
            "Similarity between Summary 244 and KB Entry 37: 0.00\n",
            "Similarity between Summary 244 and KB Entry 38: 0.03\n",
            "Similarity between Summary 244 and KB Entry 39: 0.00\n",
            "Similarity between Summary 244 and KB Entry 40: 0.01\n",
            "Similarity between Summary 244 and KB Entry 41: 0.01\n",
            "Similarity between Summary 244 and KB Entry 42: 0.01\n",
            "Similarity between Summary 244 and KB Entry 43: 0.01\n",
            "Similarity between Summary 244 and KB Entry 44: 0.05\n",
            "Similarity between Summary 244 and KB Entry 45: 0.01\n",
            "Similarity between Summary 244 and KB Entry 46: 0.00\n",
            "Similarity between Summary 245 and KB Entry 1: 0.10\n",
            "Similarity between Summary 245 and KB Entry 2: 0.01\n",
            "Similarity between Summary 245 and KB Entry 3: 0.02\n",
            "Similarity between Summary 245 and KB Entry 4: 0.03\n",
            "Similarity between Summary 245 and KB Entry 5: 0.01\n",
            "Similarity between Summary 245 and KB Entry 6: 0.02\n",
            "Similarity between Summary 245 and KB Entry 7: 0.02\n",
            "Similarity between Summary 245 and KB Entry 8: 0.02\n",
            "Similarity between Summary 245 and KB Entry 9: 0.00\n",
            "Similarity between Summary 245 and KB Entry 10: 0.01\n",
            "Similarity between Summary 245 and KB Entry 11: 0.00\n",
            "Similarity between Summary 245 and KB Entry 12: 0.02\n",
            "Similarity between Summary 245 and KB Entry 13: 0.01\n",
            "Similarity between Summary 245 and KB Entry 14: 0.01\n",
            "Similarity between Summary 245 and KB Entry 15: 0.01\n",
            "Similarity between Summary 245 and KB Entry 16: 0.00\n",
            "Similarity between Summary 245 and KB Entry 17: 0.01\n",
            "Similarity between Summary 245 and KB Entry 18: 0.01\n",
            "Similarity between Summary 245 and KB Entry 19: 0.07\n",
            "Similarity between Summary 245 and KB Entry 20: 0.00\n",
            "Similarity between Summary 245 and KB Entry 21: 0.01\n",
            "Similarity between Summary 245 and KB Entry 22: 0.00\n",
            "Similarity between Summary 245 and KB Entry 23: 0.05\n",
            "Similarity between Summary 245 and KB Entry 24: 0.00\n",
            "Similarity between Summary 245 and KB Entry 25: 0.05\n",
            "Similarity between Summary 245 and KB Entry 26: 0.04\n",
            "Similarity between Summary 245 and KB Entry 27: 0.04\n",
            "Similarity between Summary 245 and KB Entry 28: 0.02\n",
            "Similarity between Summary 245 and KB Entry 29: 0.00\n",
            "Similarity between Summary 245 and KB Entry 30: 0.00\n",
            "Similarity between Summary 245 and KB Entry 31: 0.00\n",
            "Similarity between Summary 245 and KB Entry 32: 0.00\n",
            "Similarity between Summary 245 and KB Entry 33: 0.04\n",
            "Similarity between Summary 245 and KB Entry 34: 0.00\n",
            "Similarity between Summary 245 and KB Entry 35: 0.01\n",
            "Similarity between Summary 245 and KB Entry 36: 0.02\n",
            "Similarity between Summary 245 and KB Entry 37: 0.01\n",
            "Similarity between Summary 245 and KB Entry 38: 0.00\n",
            "Similarity between Summary 245 and KB Entry 39: 0.04\n",
            "Similarity between Summary 245 and KB Entry 40: 0.01\n",
            "Similarity between Summary 245 and KB Entry 41: 0.01\n",
            "Similarity between Summary 245 and KB Entry 42: 0.02\n",
            "Similarity between Summary 245 and KB Entry 43: 0.04\n",
            "Similarity between Summary 245 and KB Entry 44: 0.01\n",
            "Similarity between Summary 245 and KB Entry 45: 0.00\n",
            "Similarity between Summary 245 and KB Entry 46: 0.00\n",
            "Similarity between Summary 246 and KB Entry 1: 0.10\n",
            "Similarity between Summary 246 and KB Entry 2: 0.01\n",
            "Similarity between Summary 246 and KB Entry 3: 0.02\n",
            "Similarity between Summary 246 and KB Entry 4: 0.05\n",
            "Similarity between Summary 246 and KB Entry 5: 0.01\n",
            "Similarity between Summary 246 and KB Entry 6: 0.02\n",
            "Similarity between Summary 246 and KB Entry 7: 0.02\n",
            "Similarity between Summary 246 and KB Entry 8: 0.02\n",
            "Similarity between Summary 246 and KB Entry 9: 0.00\n",
            "Similarity between Summary 246 and KB Entry 10: 0.01\n",
            "Similarity between Summary 246 and KB Entry 11: 0.00\n",
            "Similarity between Summary 246 and KB Entry 12: 0.02\n",
            "Similarity between Summary 246 and KB Entry 13: 0.01\n",
            "Similarity between Summary 246 and KB Entry 14: 0.01\n",
            "Similarity between Summary 246 and KB Entry 15: 0.01\n",
            "Similarity between Summary 246 and KB Entry 16: 0.00\n",
            "Similarity between Summary 246 and KB Entry 17: 0.01\n",
            "Similarity between Summary 246 and KB Entry 18: 0.01\n",
            "Similarity between Summary 246 and KB Entry 19: 0.07\n",
            "Similarity between Summary 246 and KB Entry 20: 0.00\n",
            "Similarity between Summary 246 and KB Entry 21: 0.01\n",
            "Similarity between Summary 246 and KB Entry 22: 0.00\n",
            "Similarity between Summary 246 and KB Entry 23: 0.05\n",
            "Similarity between Summary 246 and KB Entry 24: 0.00\n",
            "Similarity between Summary 246 and KB Entry 25: 0.05\n",
            "Similarity between Summary 246 and KB Entry 26: 0.04\n",
            "Similarity between Summary 246 and KB Entry 27: 0.04\n",
            "Similarity between Summary 246 and KB Entry 28: 0.02\n",
            "Similarity between Summary 246 and KB Entry 29: 0.00\n",
            "Similarity between Summary 246 and KB Entry 30: 0.00\n",
            "Similarity between Summary 246 and KB Entry 31: 0.00\n",
            "Similarity between Summary 246 and KB Entry 32: 0.00\n",
            "Similarity between Summary 246 and KB Entry 33: 0.04\n",
            "Similarity between Summary 246 and KB Entry 34: 0.00\n",
            "Similarity between Summary 246 and KB Entry 35: 0.01\n",
            "Similarity between Summary 246 and KB Entry 36: 0.02\n",
            "Similarity between Summary 246 and KB Entry 37: 0.01\n",
            "Similarity between Summary 246 and KB Entry 38: 0.00\n",
            "Similarity between Summary 246 and KB Entry 39: 0.04\n",
            "Similarity between Summary 246 and KB Entry 40: 0.01\n",
            "Similarity between Summary 246 and KB Entry 41: 0.02\n",
            "Similarity between Summary 246 and KB Entry 42: 0.02\n",
            "Similarity between Summary 246 and KB Entry 43: 0.04\n",
            "Similarity between Summary 246 and KB Entry 44: 0.01\n",
            "Similarity between Summary 246 and KB Entry 45: 0.00\n",
            "Similarity between Summary 246 and KB Entry 46: 0.00\n",
            "Similarity between Summary 247 and KB Entry 1: 0.10\n",
            "Similarity between Summary 247 and KB Entry 2: 0.01\n",
            "Similarity between Summary 247 and KB Entry 3: 0.02\n",
            "Similarity between Summary 247 and KB Entry 4: 0.03\n",
            "Similarity between Summary 247 and KB Entry 5: 0.01\n",
            "Similarity between Summary 247 and KB Entry 6: 0.01\n",
            "Similarity between Summary 247 and KB Entry 7: 0.01\n",
            "Similarity between Summary 247 and KB Entry 8: 0.01\n",
            "Similarity between Summary 247 and KB Entry 9: 0.00\n",
            "Similarity between Summary 247 and KB Entry 10: 0.00\n",
            "Similarity between Summary 247 and KB Entry 11: 0.00\n",
            "Similarity between Summary 247 and KB Entry 12: 0.02\n",
            "Similarity between Summary 247 and KB Entry 13: 0.01\n",
            "Similarity between Summary 247 and KB Entry 14: 0.01\n",
            "Similarity between Summary 247 and KB Entry 15: 0.01\n",
            "Similarity between Summary 247 and KB Entry 16: 0.00\n",
            "Similarity between Summary 247 and KB Entry 17: 0.01\n",
            "Similarity between Summary 247 and KB Entry 18: 0.01\n",
            "Similarity between Summary 247 and KB Entry 19: 0.07\n",
            "Similarity between Summary 247 and KB Entry 20: 0.00\n",
            "Similarity between Summary 247 and KB Entry 21: 0.01\n",
            "Similarity between Summary 247 and KB Entry 22: 0.00\n",
            "Similarity between Summary 247 and KB Entry 23: 0.05\n",
            "Similarity between Summary 247 and KB Entry 24: 0.00\n",
            "Similarity between Summary 247 and KB Entry 25: 0.05\n",
            "Similarity between Summary 247 and KB Entry 26: 0.04\n",
            "Similarity between Summary 247 and KB Entry 27: 0.04\n",
            "Similarity between Summary 247 and KB Entry 28: 0.02\n",
            "Similarity between Summary 247 and KB Entry 29: 0.00\n",
            "Similarity between Summary 247 and KB Entry 30: 0.00\n",
            "Similarity between Summary 247 and KB Entry 31: 0.01\n",
            "Similarity between Summary 247 and KB Entry 32: 0.00\n",
            "Similarity between Summary 247 and KB Entry 33: 0.04\n",
            "Similarity between Summary 247 and KB Entry 34: 0.00\n",
            "Similarity between Summary 247 and KB Entry 35: 0.01\n",
            "Similarity between Summary 247 and KB Entry 36: 0.02\n",
            "Similarity between Summary 247 and KB Entry 37: 0.01\n",
            "Similarity between Summary 247 and KB Entry 38: 0.00\n",
            "Similarity between Summary 247 and KB Entry 39: 0.04\n",
            "Similarity between Summary 247 and KB Entry 40: 0.01\n",
            "Similarity between Summary 247 and KB Entry 41: 0.01\n",
            "Similarity between Summary 247 and KB Entry 42: 0.01\n",
            "Similarity between Summary 247 and KB Entry 43: 0.04\n",
            "Similarity between Summary 247 and KB Entry 44: 0.01\n",
            "Similarity between Summary 247 and KB Entry 45: 0.00\n",
            "Similarity between Summary 247 and KB Entry 46: 0.00\n",
            "Similarity between Summary 248 and KB Entry 1: 0.10\n",
            "Similarity between Summary 248 and KB Entry 2: 0.01\n",
            "Similarity between Summary 248 and KB Entry 3: 0.02\n",
            "Similarity between Summary 248 and KB Entry 4: 0.05\n",
            "Similarity between Summary 248 and KB Entry 5: 0.01\n",
            "Similarity between Summary 248 and KB Entry 6: 0.02\n",
            "Similarity between Summary 248 and KB Entry 7: 0.02\n",
            "Similarity between Summary 248 and KB Entry 8: 0.02\n",
            "Similarity between Summary 248 and KB Entry 9: 0.00\n",
            "Similarity between Summary 248 and KB Entry 10: 0.01\n",
            "Similarity between Summary 248 and KB Entry 11: 0.00\n",
            "Similarity between Summary 248 and KB Entry 12: 0.02\n",
            "Similarity between Summary 248 and KB Entry 13: 0.01\n",
            "Similarity between Summary 248 and KB Entry 14: 0.01\n",
            "Similarity between Summary 248 and KB Entry 15: 0.01\n",
            "Similarity between Summary 248 and KB Entry 16: 0.00\n",
            "Similarity between Summary 248 and KB Entry 17: 0.01\n",
            "Similarity between Summary 248 and KB Entry 18: 0.01\n",
            "Similarity between Summary 248 and KB Entry 19: 0.07\n",
            "Similarity between Summary 248 and KB Entry 20: 0.00\n",
            "Similarity between Summary 248 and KB Entry 21: 0.01\n",
            "Similarity between Summary 248 and KB Entry 22: 0.00\n",
            "Similarity between Summary 248 and KB Entry 23: 0.05\n",
            "Similarity between Summary 248 and KB Entry 24: 0.00\n",
            "Similarity between Summary 248 and KB Entry 25: 0.05\n",
            "Similarity between Summary 248 and KB Entry 26: 0.04\n",
            "Similarity between Summary 248 and KB Entry 27: 0.04\n",
            "Similarity between Summary 248 and KB Entry 28: 0.02\n",
            "Similarity between Summary 248 and KB Entry 29: 0.00\n",
            "Similarity between Summary 248 and KB Entry 30: 0.00\n",
            "Similarity between Summary 248 and KB Entry 31: 0.00\n",
            "Similarity between Summary 248 and KB Entry 32: 0.00\n",
            "Similarity between Summary 248 and KB Entry 33: 0.04\n",
            "Similarity between Summary 248 and KB Entry 34: 0.00\n",
            "Similarity between Summary 248 and KB Entry 35: 0.01\n",
            "Similarity between Summary 248 and KB Entry 36: 0.02\n",
            "Similarity between Summary 248 and KB Entry 37: 0.01\n",
            "Similarity between Summary 248 and KB Entry 38: 0.00\n",
            "Similarity between Summary 248 and KB Entry 39: 0.04\n",
            "Similarity between Summary 248 and KB Entry 40: 0.01\n",
            "Similarity between Summary 248 and KB Entry 41: 0.02\n",
            "Similarity between Summary 248 and KB Entry 42: 0.02\n",
            "Similarity between Summary 248 and KB Entry 43: 0.04\n",
            "Similarity between Summary 248 and KB Entry 44: 0.01\n",
            "Similarity between Summary 248 and KB Entry 45: 0.00\n",
            "Similarity between Summary 248 and KB Entry 46: 0.00\n",
            "Similarity between Summary 249 and KB Entry 1: 0.10\n",
            "Similarity between Summary 249 and KB Entry 2: 0.01\n",
            "Similarity between Summary 249 and KB Entry 3: 0.02\n",
            "Similarity between Summary 249 and KB Entry 4: 0.05\n",
            "Similarity between Summary 249 and KB Entry 5: 0.01\n",
            "Similarity between Summary 249 and KB Entry 6: 0.02\n",
            "Similarity between Summary 249 and KB Entry 7: 0.02\n",
            "Similarity between Summary 249 and KB Entry 8: 0.02\n",
            "Similarity between Summary 249 and KB Entry 9: 0.00\n",
            "Similarity between Summary 249 and KB Entry 10: 0.01\n",
            "Similarity between Summary 249 and KB Entry 11: 0.00\n",
            "Similarity between Summary 249 and KB Entry 12: 0.03\n",
            "Similarity between Summary 249 and KB Entry 13: 0.01\n",
            "Similarity between Summary 249 and KB Entry 14: 0.01\n",
            "Similarity between Summary 249 and KB Entry 15: 0.01\n",
            "Similarity between Summary 249 and KB Entry 16: 0.05\n",
            "Similarity between Summary 249 and KB Entry 17: 0.05\n",
            "Similarity between Summary 249 and KB Entry 18: 0.00\n",
            "Similarity between Summary 249 and KB Entry 19: 0.06\n",
            "Similarity between Summary 249 and KB Entry 20: 0.00\n",
            "Similarity between Summary 249 and KB Entry 21: 0.01\n",
            "Similarity between Summary 249 and KB Entry 22: 0.00\n",
            "Similarity between Summary 249 and KB Entry 23: 0.04\n",
            "Similarity between Summary 249 and KB Entry 24: 0.02\n",
            "Similarity between Summary 249 and KB Entry 25: 0.05\n",
            "Similarity between Summary 249 and KB Entry 26: 0.01\n",
            "Similarity between Summary 249 and KB Entry 27: 0.03\n",
            "Similarity between Summary 249 and KB Entry 28: 0.01\n",
            "Similarity between Summary 249 and KB Entry 29: 0.00\n",
            "Similarity between Summary 249 and KB Entry 30: 0.04\n",
            "Similarity between Summary 249 and KB Entry 31: 0.00\n",
            "Similarity between Summary 249 and KB Entry 32: 0.02\n",
            "Similarity between Summary 249 and KB Entry 33: 0.06\n",
            "Similarity between Summary 249 and KB Entry 34: 0.00\n",
            "Similarity between Summary 249 and KB Entry 35: 0.01\n",
            "Similarity between Summary 249 and KB Entry 36: 0.02\n",
            "Similarity between Summary 249 and KB Entry 37: 0.01\n",
            "Similarity between Summary 249 and KB Entry 38: 0.00\n",
            "Similarity between Summary 249 and KB Entry 39: 0.03\n",
            "Similarity between Summary 249 and KB Entry 40: 0.01\n",
            "Similarity between Summary 249 and KB Entry 41: 0.02\n",
            "Similarity between Summary 249 and KB Entry 42: 0.03\n",
            "Similarity between Summary 249 and KB Entry 43: 0.03\n",
            "Similarity between Summary 249 and KB Entry 44: 0.01\n",
            "Similarity between Summary 249 and KB Entry 45: 0.01\n",
            "Similarity between Summary 249 and KB Entry 46: 0.01\n",
            "Similarity between Summary 250 and KB Entry 1: 0.09\n",
            "Similarity between Summary 250 and KB Entry 2: 0.01\n",
            "Similarity between Summary 250 and KB Entry 3: 0.02\n",
            "Similarity between Summary 250 and KB Entry 4: 0.03\n",
            "Similarity between Summary 250 and KB Entry 5: 0.01\n",
            "Similarity between Summary 250 and KB Entry 6: 0.02\n",
            "Similarity between Summary 250 and KB Entry 7: 0.02\n",
            "Similarity between Summary 250 and KB Entry 8: 0.02\n",
            "Similarity between Summary 250 and KB Entry 9: 0.00\n",
            "Similarity between Summary 250 and KB Entry 10: 0.01\n",
            "Similarity between Summary 250 and KB Entry 11: 0.00\n",
            "Similarity between Summary 250 and KB Entry 12: 0.02\n",
            "Similarity between Summary 250 and KB Entry 13: 0.01\n",
            "Similarity between Summary 250 and KB Entry 14: 0.01\n",
            "Similarity between Summary 250 and KB Entry 15: 0.01\n",
            "Similarity between Summary 250 and KB Entry 16: 0.00\n",
            "Similarity between Summary 250 and KB Entry 17: 0.01\n",
            "Similarity between Summary 250 and KB Entry 18: 0.01\n",
            "Similarity between Summary 250 and KB Entry 19: 0.07\n",
            "Similarity between Summary 250 and KB Entry 20: 0.00\n",
            "Similarity between Summary 250 and KB Entry 21: 0.01\n",
            "Similarity between Summary 250 and KB Entry 22: 0.00\n",
            "Similarity between Summary 250 and KB Entry 23: 0.05\n",
            "Similarity between Summary 250 and KB Entry 24: 0.00\n",
            "Similarity between Summary 250 and KB Entry 25: 0.05\n",
            "Similarity between Summary 250 and KB Entry 26: 0.04\n",
            "Similarity between Summary 250 and KB Entry 27: 0.04\n",
            "Similarity between Summary 250 and KB Entry 28: 0.02\n",
            "Similarity between Summary 250 and KB Entry 29: 0.00\n",
            "Similarity between Summary 250 and KB Entry 30: 0.00\n",
            "Similarity between Summary 250 and KB Entry 31: 0.01\n",
            "Similarity between Summary 250 and KB Entry 32: 0.00\n",
            "Similarity between Summary 250 and KB Entry 33: 0.04\n",
            "Similarity between Summary 250 and KB Entry 34: 0.00\n",
            "Similarity between Summary 250 and KB Entry 35: 0.01\n",
            "Similarity between Summary 250 and KB Entry 36: 0.02\n",
            "Similarity between Summary 250 and KB Entry 37: 0.01\n",
            "Similarity between Summary 250 and KB Entry 38: 0.00\n",
            "Similarity between Summary 250 and KB Entry 39: 0.04\n",
            "Similarity between Summary 250 and KB Entry 40: 0.01\n",
            "Similarity between Summary 250 and KB Entry 41: 0.01\n",
            "Similarity between Summary 250 and KB Entry 42: 0.02\n",
            "Similarity between Summary 250 and KB Entry 43: 0.04\n",
            "Similarity between Summary 250 and KB Entry 44: 0.01\n",
            "Similarity between Summary 250 and KB Entry 45: 0.00\n",
            "Similarity between Summary 250 and KB Entry 46: 0.00\n",
            "Similarity between Summary 251 and KB Entry 1: 0.11\n",
            "Similarity between Summary 251 and KB Entry 2: 0.01\n",
            "Similarity between Summary 251 and KB Entry 3: 0.02\n",
            "Similarity between Summary 251 and KB Entry 4: 0.05\n",
            "Similarity between Summary 251 and KB Entry 5: 0.01\n",
            "Similarity between Summary 251 and KB Entry 6: 0.02\n",
            "Similarity between Summary 251 and KB Entry 7: 0.02\n",
            "Similarity between Summary 251 and KB Entry 8: 0.02\n",
            "Similarity between Summary 251 and KB Entry 9: 0.00\n",
            "Similarity between Summary 251 and KB Entry 10: 0.01\n",
            "Similarity between Summary 251 and KB Entry 11: 0.00\n",
            "Similarity between Summary 251 and KB Entry 12: 0.02\n",
            "Similarity between Summary 251 and KB Entry 13: 0.01\n",
            "Similarity between Summary 251 and KB Entry 14: 0.01\n",
            "Similarity between Summary 251 and KB Entry 15: 0.01\n",
            "Similarity between Summary 251 and KB Entry 16: 0.00\n",
            "Similarity between Summary 251 and KB Entry 17: 0.01\n",
            "Similarity between Summary 251 and KB Entry 18: 0.01\n",
            "Similarity between Summary 251 and KB Entry 19: 0.07\n",
            "Similarity between Summary 251 and KB Entry 20: 0.00\n",
            "Similarity between Summary 251 and KB Entry 21: 0.01\n",
            "Similarity between Summary 251 and KB Entry 22: 0.00\n",
            "Similarity between Summary 251 and KB Entry 23: 0.05\n",
            "Similarity between Summary 251 and KB Entry 24: 0.00\n",
            "Similarity between Summary 251 and KB Entry 25: 0.05\n",
            "Similarity between Summary 251 and KB Entry 26: 0.04\n",
            "Similarity between Summary 251 and KB Entry 27: 0.04\n",
            "Similarity between Summary 251 and KB Entry 28: 0.02\n",
            "Similarity between Summary 251 and KB Entry 29: 0.00\n",
            "Similarity between Summary 251 and KB Entry 30: 0.00\n",
            "Similarity between Summary 251 and KB Entry 31: 0.00\n",
            "Similarity between Summary 251 and KB Entry 32: 0.00\n",
            "Similarity between Summary 251 and KB Entry 33: 0.05\n",
            "Similarity between Summary 251 and KB Entry 34: 0.00\n",
            "Similarity between Summary 251 and KB Entry 35: 0.01\n",
            "Similarity between Summary 251 and KB Entry 36: 0.02\n",
            "Similarity between Summary 251 and KB Entry 37: 0.01\n",
            "Similarity between Summary 251 and KB Entry 38: 0.00\n",
            "Similarity between Summary 251 and KB Entry 39: 0.04\n",
            "Similarity between Summary 251 and KB Entry 40: 0.01\n",
            "Similarity between Summary 251 and KB Entry 41: 0.02\n",
            "Similarity between Summary 251 and KB Entry 42: 0.02\n",
            "Similarity between Summary 251 and KB Entry 43: 0.04\n",
            "Similarity between Summary 251 and KB Entry 44: 0.01\n",
            "Similarity between Summary 251 and KB Entry 45: 0.00\n",
            "Similarity between Summary 251 and KB Entry 46: 0.00\n",
            "Similarity between Summary 252 and KB Entry 1: 0.13\n",
            "Similarity between Summary 252 and KB Entry 2: 0.01\n",
            "Similarity between Summary 252 and KB Entry 3: 0.03\n",
            "Similarity between Summary 252 and KB Entry 4: 0.05\n",
            "Similarity between Summary 252 and KB Entry 5: 0.01\n",
            "Similarity between Summary 252 and KB Entry 6: 0.02\n",
            "Similarity between Summary 252 and KB Entry 7: 0.02\n",
            "Similarity between Summary 252 and KB Entry 8: 0.02\n",
            "Similarity between Summary 252 and KB Entry 9: 0.00\n",
            "Similarity between Summary 252 and KB Entry 10: 0.01\n",
            "Similarity between Summary 252 and KB Entry 11: 0.00\n",
            "Similarity between Summary 252 and KB Entry 12: 0.03\n",
            "Similarity between Summary 252 and KB Entry 13: 0.01\n",
            "Similarity between Summary 252 and KB Entry 14: 0.01\n",
            "Similarity between Summary 252 and KB Entry 15: 0.01\n",
            "Similarity between Summary 252 and KB Entry 16: 0.04\n",
            "Similarity between Summary 252 and KB Entry 17: 0.03\n",
            "Similarity between Summary 252 and KB Entry 18: 0.01\n",
            "Similarity between Summary 252 and KB Entry 19: 0.08\n",
            "Similarity between Summary 252 and KB Entry 20: 0.00\n",
            "Similarity between Summary 252 and KB Entry 21: 0.01\n",
            "Similarity between Summary 252 and KB Entry 22: 0.00\n",
            "Similarity between Summary 252 and KB Entry 23: 0.05\n",
            "Similarity between Summary 252 and KB Entry 24: 0.02\n",
            "Similarity between Summary 252 and KB Entry 25: 0.06\n",
            "Similarity between Summary 252 and KB Entry 26: 0.01\n",
            "Similarity between Summary 252 and KB Entry 27: 0.04\n",
            "Similarity between Summary 252 and KB Entry 28: 0.02\n",
            "Similarity between Summary 252 and KB Entry 29: 0.00\n",
            "Similarity between Summary 252 and KB Entry 30: 0.03\n",
            "Similarity between Summary 252 and KB Entry 31: 0.00\n",
            "Similarity between Summary 252 and KB Entry 32: 0.03\n",
            "Similarity between Summary 252 and KB Entry 33: 0.07\n",
            "Similarity between Summary 252 and KB Entry 34: 0.00\n",
            "Similarity between Summary 252 and KB Entry 35: 0.02\n",
            "Similarity between Summary 252 and KB Entry 36: 0.02\n",
            "Similarity between Summary 252 and KB Entry 37: 0.01\n",
            "Similarity between Summary 252 and KB Entry 38: 0.00\n",
            "Similarity between Summary 252 and KB Entry 39: 0.03\n",
            "Similarity between Summary 252 and KB Entry 40: 0.01\n",
            "Similarity between Summary 252 and KB Entry 41: 0.02\n",
            "Similarity between Summary 252 and KB Entry 42: 0.02\n",
            "Similarity between Summary 252 and KB Entry 43: 0.04\n",
            "Similarity between Summary 252 and KB Entry 44: 0.01\n",
            "Similarity between Summary 252 and KB Entry 45: 0.00\n",
            "Similarity between Summary 252 and KB Entry 46: 0.01\n",
            "Similarity between Summary 253 and KB Entry 1: 0.10\n",
            "Similarity between Summary 253 and KB Entry 2: 0.01\n",
            "Similarity between Summary 253 and KB Entry 3: 0.02\n",
            "Similarity between Summary 253 and KB Entry 4: 0.03\n",
            "Similarity between Summary 253 and KB Entry 5: 0.01\n",
            "Similarity between Summary 253 and KB Entry 6: 0.01\n",
            "Similarity between Summary 253 and KB Entry 7: 0.01\n",
            "Similarity between Summary 253 and KB Entry 8: 0.01\n",
            "Similarity between Summary 253 and KB Entry 9: 0.00\n",
            "Similarity between Summary 253 and KB Entry 10: 0.00\n",
            "Similarity between Summary 253 and KB Entry 11: 0.00\n",
            "Similarity between Summary 253 and KB Entry 12: 0.02\n",
            "Similarity between Summary 253 and KB Entry 13: 0.01\n",
            "Similarity between Summary 253 and KB Entry 14: 0.01\n",
            "Similarity between Summary 253 and KB Entry 15: 0.01\n",
            "Similarity between Summary 253 and KB Entry 16: 0.04\n",
            "Similarity between Summary 253 and KB Entry 17: 0.03\n",
            "Similarity between Summary 253 and KB Entry 18: 0.01\n",
            "Similarity between Summary 253 and KB Entry 19: 0.08\n",
            "Similarity between Summary 253 and KB Entry 20: 0.00\n",
            "Similarity between Summary 253 and KB Entry 21: 0.01\n",
            "Similarity between Summary 253 and KB Entry 22: 0.00\n",
            "Similarity between Summary 253 and KB Entry 23: 0.05\n",
            "Similarity between Summary 253 and KB Entry 24: 0.02\n",
            "Similarity between Summary 253 and KB Entry 25: 0.06\n",
            "Similarity between Summary 253 and KB Entry 26: 0.01\n",
            "Similarity between Summary 253 and KB Entry 27: 0.03\n",
            "Similarity between Summary 253 and KB Entry 28: 0.01\n",
            "Similarity between Summary 253 and KB Entry 29: 0.00\n",
            "Similarity between Summary 253 and KB Entry 30: 0.03\n",
            "Similarity between Summary 253 and KB Entry 31: 0.00\n",
            "Similarity between Summary 253 and KB Entry 32: 0.03\n",
            "Similarity between Summary 253 and KB Entry 33: 0.06\n",
            "Similarity between Summary 253 and KB Entry 34: 0.00\n",
            "Similarity between Summary 253 and KB Entry 35: 0.02\n",
            "Similarity between Summary 253 and KB Entry 36: 0.02\n",
            "Similarity between Summary 253 and KB Entry 37: 0.01\n",
            "Similarity between Summary 253 and KB Entry 38: 0.00\n",
            "Similarity between Summary 253 and KB Entry 39: 0.05\n",
            "Similarity between Summary 253 and KB Entry 40: 0.01\n",
            "Similarity between Summary 253 and KB Entry 41: 0.01\n",
            "Similarity between Summary 253 and KB Entry 42: 0.01\n",
            "Similarity between Summary 253 and KB Entry 43: 0.04\n",
            "Similarity between Summary 253 and KB Entry 44: 0.01\n",
            "Similarity between Summary 253 and KB Entry 45: 0.00\n",
            "Similarity between Summary 253 and KB Entry 46: 0.01\n",
            "Similarity between Summary 254 and KB Entry 1: 0.10\n",
            "Similarity between Summary 254 and KB Entry 2: 0.01\n",
            "Similarity between Summary 254 and KB Entry 3: 0.02\n",
            "Similarity between Summary 254 and KB Entry 4: 0.05\n",
            "Similarity between Summary 254 and KB Entry 5: 0.01\n",
            "Similarity between Summary 254 and KB Entry 6: 0.02\n",
            "Similarity between Summary 254 and KB Entry 7: 0.02\n",
            "Similarity between Summary 254 and KB Entry 8: 0.02\n",
            "Similarity between Summary 254 and KB Entry 9: 0.00\n",
            "Similarity between Summary 254 and KB Entry 10: 0.01\n",
            "Similarity between Summary 254 and KB Entry 11: 0.00\n",
            "Similarity between Summary 254 and KB Entry 12: 0.02\n",
            "Similarity between Summary 254 and KB Entry 13: 0.01\n",
            "Similarity between Summary 254 and KB Entry 14: 0.01\n",
            "Similarity between Summary 254 and KB Entry 15: 0.01\n",
            "Similarity between Summary 254 and KB Entry 16: 0.00\n",
            "Similarity between Summary 254 and KB Entry 17: 0.01\n",
            "Similarity between Summary 254 and KB Entry 18: 0.01\n",
            "Similarity between Summary 254 and KB Entry 19: 0.07\n",
            "Similarity between Summary 254 and KB Entry 20: 0.00\n",
            "Similarity between Summary 254 and KB Entry 21: 0.01\n",
            "Similarity between Summary 254 and KB Entry 22: 0.00\n",
            "Similarity between Summary 254 and KB Entry 23: 0.05\n",
            "Similarity between Summary 254 and KB Entry 24: 0.00\n",
            "Similarity between Summary 254 and KB Entry 25: 0.05\n",
            "Similarity between Summary 254 and KB Entry 26: 0.04\n",
            "Similarity between Summary 254 and KB Entry 27: 0.04\n",
            "Similarity between Summary 254 and KB Entry 28: 0.02\n",
            "Similarity between Summary 254 and KB Entry 29: 0.00\n",
            "Similarity between Summary 254 and KB Entry 30: 0.00\n",
            "Similarity between Summary 254 and KB Entry 31: 0.00\n",
            "Similarity between Summary 254 and KB Entry 32: 0.00\n",
            "Similarity between Summary 254 and KB Entry 33: 0.04\n",
            "Similarity between Summary 254 and KB Entry 34: 0.00\n",
            "Similarity between Summary 254 and KB Entry 35: 0.01\n",
            "Similarity between Summary 254 and KB Entry 36: 0.02\n",
            "Similarity between Summary 254 and KB Entry 37: 0.01\n",
            "Similarity between Summary 254 and KB Entry 38: 0.00\n",
            "Similarity between Summary 254 and KB Entry 39: 0.04\n",
            "Similarity between Summary 254 and KB Entry 40: 0.01\n",
            "Similarity between Summary 254 and KB Entry 41: 0.02\n",
            "Similarity between Summary 254 and KB Entry 42: 0.02\n",
            "Similarity between Summary 254 and KB Entry 43: 0.04\n",
            "Similarity between Summary 254 and KB Entry 44: 0.01\n",
            "Similarity between Summary 254 and KB Entry 45: 0.00\n",
            "Similarity between Summary 254 and KB Entry 46: 0.00\n",
            "Similarity between Summary 255 and KB Entry 1: 0.10\n",
            "Similarity between Summary 255 and KB Entry 2: 0.01\n",
            "Similarity between Summary 255 and KB Entry 3: 0.02\n",
            "Similarity between Summary 255 and KB Entry 4: 0.03\n",
            "Similarity between Summary 255 and KB Entry 5: 0.01\n",
            "Similarity between Summary 255 and KB Entry 6: 0.01\n",
            "Similarity between Summary 255 and KB Entry 7: 0.01\n",
            "Similarity between Summary 255 and KB Entry 8: 0.01\n",
            "Similarity between Summary 255 and KB Entry 9: 0.00\n",
            "Similarity between Summary 255 and KB Entry 10: 0.00\n",
            "Similarity between Summary 255 and KB Entry 11: 0.00\n",
            "Similarity between Summary 255 and KB Entry 12: 0.02\n",
            "Similarity between Summary 255 and KB Entry 13: 0.01\n",
            "Similarity between Summary 255 and KB Entry 14: 0.01\n",
            "Similarity between Summary 255 and KB Entry 15: 0.01\n",
            "Similarity between Summary 255 and KB Entry 16: 0.00\n",
            "Similarity between Summary 255 and KB Entry 17: 0.01\n",
            "Similarity between Summary 255 and KB Entry 18: 0.01\n",
            "Similarity between Summary 255 and KB Entry 19: 0.07\n",
            "Similarity between Summary 255 and KB Entry 20: 0.00\n",
            "Similarity between Summary 255 and KB Entry 21: 0.01\n",
            "Similarity between Summary 255 and KB Entry 22: 0.00\n",
            "Similarity between Summary 255 and KB Entry 23: 0.05\n",
            "Similarity between Summary 255 and KB Entry 24: 0.00\n",
            "Similarity between Summary 255 and KB Entry 25: 0.05\n",
            "Similarity between Summary 255 and KB Entry 26: 0.04\n",
            "Similarity between Summary 255 and KB Entry 27: 0.04\n",
            "Similarity between Summary 255 and KB Entry 28: 0.02\n",
            "Similarity between Summary 255 and KB Entry 29: 0.00\n",
            "Similarity between Summary 255 and KB Entry 30: 0.00\n",
            "Similarity between Summary 255 and KB Entry 31: 0.00\n",
            "Similarity between Summary 255 and KB Entry 32: 0.00\n",
            "Similarity between Summary 255 and KB Entry 33: 0.04\n",
            "Similarity between Summary 255 and KB Entry 34: 0.00\n",
            "Similarity between Summary 255 and KB Entry 35: 0.01\n",
            "Similarity between Summary 255 and KB Entry 36: 0.02\n",
            "Similarity between Summary 255 and KB Entry 37: 0.01\n",
            "Similarity between Summary 255 and KB Entry 38: 0.00\n",
            "Similarity between Summary 255 and KB Entry 39: 0.04\n",
            "Similarity between Summary 255 and KB Entry 40: 0.01\n",
            "Similarity between Summary 255 and KB Entry 41: 0.01\n",
            "Similarity between Summary 255 and KB Entry 42: 0.01\n",
            "Similarity between Summary 255 and KB Entry 43: 0.04\n",
            "Similarity between Summary 255 and KB Entry 44: 0.01\n",
            "Similarity between Summary 255 and KB Entry 45: 0.00\n",
            "Similarity between Summary 255 and KB Entry 46: 0.00\n",
            "Similarity between Summary 256 and KB Entry 1: 0.10\n",
            "Similarity between Summary 256 and KB Entry 2: 0.01\n",
            "Similarity between Summary 256 and KB Entry 3: 0.02\n",
            "Similarity between Summary 256 and KB Entry 4: 0.05\n",
            "Similarity between Summary 256 and KB Entry 5: 0.01\n",
            "Similarity between Summary 256 and KB Entry 6: 0.02\n",
            "Similarity between Summary 256 and KB Entry 7: 0.02\n",
            "Similarity between Summary 256 and KB Entry 8: 0.02\n",
            "Similarity between Summary 256 and KB Entry 9: 0.00\n",
            "Similarity between Summary 256 and KB Entry 10: 0.01\n",
            "Similarity between Summary 256 and KB Entry 11: 0.00\n",
            "Similarity between Summary 256 and KB Entry 12: 0.02\n",
            "Similarity between Summary 256 and KB Entry 13: 0.01\n",
            "Similarity between Summary 256 and KB Entry 14: 0.01\n",
            "Similarity between Summary 256 and KB Entry 15: 0.01\n",
            "Similarity between Summary 256 and KB Entry 16: 0.00\n",
            "Similarity between Summary 256 and KB Entry 17: 0.01\n",
            "Similarity between Summary 256 and KB Entry 18: 0.01\n",
            "Similarity between Summary 256 and KB Entry 19: 0.07\n",
            "Similarity between Summary 256 and KB Entry 20: 0.00\n",
            "Similarity between Summary 256 and KB Entry 21: 0.01\n",
            "Similarity between Summary 256 and KB Entry 22: 0.00\n",
            "Similarity between Summary 256 and KB Entry 23: 0.05\n",
            "Similarity between Summary 256 and KB Entry 24: 0.00\n",
            "Similarity between Summary 256 and KB Entry 25: 0.05\n",
            "Similarity between Summary 256 and KB Entry 26: 0.04\n",
            "Similarity between Summary 256 and KB Entry 27: 0.04\n",
            "Similarity between Summary 256 and KB Entry 28: 0.02\n",
            "Similarity between Summary 256 and KB Entry 29: 0.00\n",
            "Similarity between Summary 256 and KB Entry 30: 0.00\n",
            "Similarity between Summary 256 and KB Entry 31: 0.00\n",
            "Similarity between Summary 256 and KB Entry 32: 0.00\n",
            "Similarity between Summary 256 and KB Entry 33: 0.04\n",
            "Similarity between Summary 256 and KB Entry 34: 0.00\n",
            "Similarity between Summary 256 and KB Entry 35: 0.01\n",
            "Similarity between Summary 256 and KB Entry 36: 0.02\n",
            "Similarity between Summary 256 and KB Entry 37: 0.01\n",
            "Similarity between Summary 256 and KB Entry 38: 0.00\n",
            "Similarity between Summary 256 and KB Entry 39: 0.04\n",
            "Similarity between Summary 256 and KB Entry 40: 0.01\n",
            "Similarity between Summary 256 and KB Entry 41: 0.02\n",
            "Similarity between Summary 256 and KB Entry 42: 0.02\n",
            "Similarity between Summary 256 and KB Entry 43: 0.04\n",
            "Similarity between Summary 256 and KB Entry 44: 0.01\n",
            "Similarity between Summary 256 and KB Entry 45: 0.00\n",
            "Similarity between Summary 256 and KB Entry 46: 0.00\n",
            "Similarity between Summary 257 and KB Entry 1: 0.10\n",
            "Similarity between Summary 257 and KB Entry 2: 0.01\n",
            "Similarity between Summary 257 and KB Entry 3: 0.02\n",
            "Similarity between Summary 257 and KB Entry 4: 0.03\n",
            "Similarity between Summary 257 and KB Entry 5: 0.01\n",
            "Similarity between Summary 257 and KB Entry 6: 0.02\n",
            "Similarity between Summary 257 and KB Entry 7: 0.02\n",
            "Similarity between Summary 257 and KB Entry 8: 0.02\n",
            "Similarity between Summary 257 and KB Entry 9: 0.00\n",
            "Similarity between Summary 257 and KB Entry 10: 0.01\n",
            "Similarity between Summary 257 and KB Entry 11: 0.00\n",
            "Similarity between Summary 257 and KB Entry 12: 0.02\n",
            "Similarity between Summary 257 and KB Entry 13: 0.01\n",
            "Similarity between Summary 257 and KB Entry 14: 0.01\n",
            "Similarity between Summary 257 and KB Entry 15: 0.01\n",
            "Similarity between Summary 257 and KB Entry 16: 0.00\n",
            "Similarity between Summary 257 and KB Entry 17: 0.01\n",
            "Similarity between Summary 257 and KB Entry 18: 0.01\n",
            "Similarity between Summary 257 and KB Entry 19: 0.07\n",
            "Similarity between Summary 257 and KB Entry 20: 0.00\n",
            "Similarity between Summary 257 and KB Entry 21: 0.01\n",
            "Similarity between Summary 257 and KB Entry 22: 0.00\n",
            "Similarity between Summary 257 and KB Entry 23: 0.05\n",
            "Similarity between Summary 257 and KB Entry 24: 0.00\n",
            "Similarity between Summary 257 and KB Entry 25: 0.05\n",
            "Similarity between Summary 257 and KB Entry 26: 0.04\n",
            "Similarity between Summary 257 and KB Entry 27: 0.04\n",
            "Similarity between Summary 257 and KB Entry 28: 0.02\n",
            "Similarity between Summary 257 and KB Entry 29: 0.00\n",
            "Similarity between Summary 257 and KB Entry 30: 0.00\n",
            "Similarity between Summary 257 and KB Entry 31: 0.00\n",
            "Similarity between Summary 257 and KB Entry 32: 0.00\n",
            "Similarity between Summary 257 and KB Entry 33: 0.04\n",
            "Similarity between Summary 257 and KB Entry 34: 0.00\n",
            "Similarity between Summary 257 and KB Entry 35: 0.01\n",
            "Similarity between Summary 257 and KB Entry 36: 0.02\n",
            "Similarity between Summary 257 and KB Entry 37: 0.01\n",
            "Similarity between Summary 257 and KB Entry 38: 0.00\n",
            "Similarity between Summary 257 and KB Entry 39: 0.04\n",
            "Similarity between Summary 257 and KB Entry 40: 0.01\n",
            "Similarity between Summary 257 and KB Entry 41: 0.01\n",
            "Similarity between Summary 257 and KB Entry 42: 0.02\n",
            "Similarity between Summary 257 and KB Entry 43: 0.04\n",
            "Similarity between Summary 257 and KB Entry 44: 0.01\n",
            "Similarity between Summary 257 and KB Entry 45: 0.00\n",
            "Similarity between Summary 257 and KB Entry 46: 0.00\n",
            "Similarity between Summary 258 and KB Entry 1: 0.10\n",
            "Similarity between Summary 258 and KB Entry 2: 0.01\n",
            "Similarity between Summary 258 and KB Entry 3: 0.02\n",
            "Similarity between Summary 258 and KB Entry 4: 0.05\n",
            "Similarity between Summary 258 and KB Entry 5: 0.01\n",
            "Similarity between Summary 258 and KB Entry 6: 0.02\n",
            "Similarity between Summary 258 and KB Entry 7: 0.02\n",
            "Similarity between Summary 258 and KB Entry 8: 0.02\n",
            "Similarity between Summary 258 and KB Entry 9: 0.00\n",
            "Similarity between Summary 258 and KB Entry 10: 0.01\n",
            "Similarity between Summary 258 and KB Entry 11: 0.00\n",
            "Similarity between Summary 258 and KB Entry 12: 0.02\n",
            "Similarity between Summary 258 and KB Entry 13: 0.01\n",
            "Similarity between Summary 258 and KB Entry 14: 0.01\n",
            "Similarity between Summary 258 and KB Entry 15: 0.01\n",
            "Similarity between Summary 258 and KB Entry 16: 0.00\n",
            "Similarity between Summary 258 and KB Entry 17: 0.01\n",
            "Similarity between Summary 258 and KB Entry 18: 0.01\n",
            "Similarity between Summary 258 and KB Entry 19: 0.07\n",
            "Similarity between Summary 258 and KB Entry 20: 0.00\n",
            "Similarity between Summary 258 and KB Entry 21: 0.01\n",
            "Similarity between Summary 258 and KB Entry 22: 0.00\n",
            "Similarity between Summary 258 and KB Entry 23: 0.05\n",
            "Similarity between Summary 258 and KB Entry 24: 0.00\n",
            "Similarity between Summary 258 and KB Entry 25: 0.05\n",
            "Similarity between Summary 258 and KB Entry 26: 0.04\n",
            "Similarity between Summary 258 and KB Entry 27: 0.04\n",
            "Similarity between Summary 258 and KB Entry 28: 0.02\n",
            "Similarity between Summary 258 and KB Entry 29: 0.00\n",
            "Similarity between Summary 258 and KB Entry 30: 0.00\n",
            "Similarity between Summary 258 and KB Entry 31: 0.01\n",
            "Similarity between Summary 258 and KB Entry 32: 0.00\n",
            "Similarity between Summary 258 and KB Entry 33: 0.04\n",
            "Similarity between Summary 258 and KB Entry 34: 0.00\n",
            "Similarity between Summary 258 and KB Entry 35: 0.01\n",
            "Similarity between Summary 258 and KB Entry 36: 0.02\n",
            "Similarity between Summary 258 and KB Entry 37: 0.01\n",
            "Similarity between Summary 258 and KB Entry 38: 0.00\n",
            "Similarity between Summary 258 and KB Entry 39: 0.04\n",
            "Similarity between Summary 258 and KB Entry 40: 0.01\n",
            "Similarity between Summary 258 and KB Entry 41: 0.02\n",
            "Similarity between Summary 258 and KB Entry 42: 0.02\n",
            "Similarity between Summary 258 and KB Entry 43: 0.04\n",
            "Similarity between Summary 258 and KB Entry 44: 0.01\n",
            "Similarity between Summary 258 and KB Entry 45: 0.00\n",
            "Similarity between Summary 258 and KB Entry 46: 0.00\n",
            "Similarity between Summary 259 and KB Entry 1: 0.07\n",
            "Similarity between Summary 259 and KB Entry 2: 0.01\n",
            "Similarity between Summary 259 and KB Entry 3: 0.02\n",
            "Similarity between Summary 259 and KB Entry 4: 0.06\n",
            "Similarity between Summary 259 and KB Entry 5: 0.02\n",
            "Similarity between Summary 259 and KB Entry 6: 0.02\n",
            "Similarity between Summary 259 and KB Entry 7: 0.02\n",
            "Similarity between Summary 259 and KB Entry 8: 0.00\n",
            "Similarity between Summary 259 and KB Entry 9: 0.00\n",
            "Similarity between Summary 259 and KB Entry 10: 0.02\n",
            "Similarity between Summary 259 and KB Entry 11: 0.02\n",
            "Similarity between Summary 259 and KB Entry 12: 0.00\n",
            "Similarity between Summary 259 and KB Entry 13: 0.00\n",
            "Similarity between Summary 259 and KB Entry 14: 0.01\n",
            "Similarity between Summary 259 and KB Entry 15: 0.00\n",
            "Similarity between Summary 259 and KB Entry 16: 0.00\n",
            "Similarity between Summary 259 and KB Entry 17: 0.08\n",
            "Similarity between Summary 259 and KB Entry 18: 0.03\n",
            "Similarity between Summary 259 and KB Entry 19: 0.01\n",
            "Similarity between Summary 259 and KB Entry 20: 0.00\n",
            "Similarity between Summary 259 and KB Entry 21: 0.01\n",
            "Similarity between Summary 259 and KB Entry 22: 0.00\n",
            "Similarity between Summary 259 and KB Entry 23: 0.00\n",
            "Similarity between Summary 259 and KB Entry 24: 0.00\n",
            "Similarity between Summary 259 and KB Entry 25: 0.07\n",
            "Similarity between Summary 259 and KB Entry 26: 0.02\n",
            "Similarity between Summary 259 and KB Entry 27: 0.05\n",
            "Similarity between Summary 259 and KB Entry 28: 0.01\n",
            "Similarity between Summary 259 and KB Entry 29: 0.01\n",
            "Similarity between Summary 259 and KB Entry 30: 0.00\n",
            "Similarity between Summary 259 and KB Entry 31: 0.00\n",
            "Similarity between Summary 259 and KB Entry 32: 0.00\n",
            "Similarity between Summary 259 and KB Entry 33: 0.07\n",
            "Similarity between Summary 259 and KB Entry 34: 0.00\n",
            "Similarity between Summary 259 and KB Entry 35: 0.01\n",
            "Similarity between Summary 259 and KB Entry 36: 0.00\n",
            "Similarity between Summary 259 and KB Entry 37: 0.03\n",
            "Similarity between Summary 259 and KB Entry 38: 0.01\n",
            "Similarity between Summary 259 and KB Entry 39: 0.01\n",
            "Similarity between Summary 259 and KB Entry 40: 0.02\n",
            "Similarity between Summary 259 and KB Entry 41: 0.00\n",
            "Similarity between Summary 259 and KB Entry 42: 0.02\n",
            "Similarity between Summary 259 and KB Entry 43: 0.00\n",
            "Similarity between Summary 259 and KB Entry 44: 0.02\n",
            "Similarity between Summary 259 and KB Entry 45: 0.00\n",
            "Similarity between Summary 259 and KB Entry 46: 0.00\n",
            "Similarity between Summary 260 and KB Entry 1: 0.11\n",
            "Similarity between Summary 260 and KB Entry 2: 0.01\n",
            "Similarity between Summary 260 and KB Entry 3: 0.02\n",
            "Similarity between Summary 260 and KB Entry 4: 0.04\n",
            "Similarity between Summary 260 and KB Entry 5: 0.00\n",
            "Similarity between Summary 260 and KB Entry 6: 0.01\n",
            "Similarity between Summary 260 and KB Entry 7: 0.01\n",
            "Similarity between Summary 260 and KB Entry 8: 0.01\n",
            "Similarity between Summary 260 and KB Entry 9: 0.00\n",
            "Similarity between Summary 260 and KB Entry 10: 0.00\n",
            "Similarity between Summary 260 and KB Entry 11: 0.00\n",
            "Similarity between Summary 260 and KB Entry 12: 0.06\n",
            "Similarity between Summary 260 and KB Entry 13: 0.00\n",
            "Similarity between Summary 260 and KB Entry 14: 0.01\n",
            "Similarity between Summary 260 and KB Entry 15: 0.02\n",
            "Similarity between Summary 260 and KB Entry 16: 0.01\n",
            "Similarity between Summary 260 and KB Entry 17: 0.07\n",
            "Similarity between Summary 260 and KB Entry 18: 0.03\n",
            "Similarity between Summary 260 and KB Entry 19: 0.04\n",
            "Similarity between Summary 260 and KB Entry 20: 0.00\n",
            "Similarity between Summary 260 and KB Entry 21: 0.01\n",
            "Similarity between Summary 260 and KB Entry 22: 0.00\n",
            "Similarity between Summary 260 and KB Entry 23: 0.06\n",
            "Similarity between Summary 260 and KB Entry 24: 0.01\n",
            "Similarity between Summary 260 and KB Entry 25: 0.15\n",
            "Similarity between Summary 260 and KB Entry 26: 0.03\n",
            "Similarity between Summary 260 and KB Entry 27: 0.04\n",
            "Similarity between Summary 260 and KB Entry 28: 0.03\n",
            "Similarity between Summary 260 and KB Entry 29: 0.00\n",
            "Similarity between Summary 260 and KB Entry 30: 0.04\n",
            "Similarity between Summary 260 and KB Entry 31: 0.00\n",
            "Similarity between Summary 260 and KB Entry 32: 0.00\n",
            "Similarity between Summary 260 and KB Entry 33: 0.07\n",
            "Similarity between Summary 260 and KB Entry 34: 0.01\n",
            "Similarity between Summary 260 and KB Entry 35: 0.01\n",
            "Similarity between Summary 260 and KB Entry 36: 0.01\n",
            "Similarity between Summary 260 and KB Entry 37: 0.04\n",
            "Similarity between Summary 260 and KB Entry 38: 0.04\n",
            "Similarity between Summary 260 and KB Entry 39: 0.03\n",
            "Similarity between Summary 260 and KB Entry 40: 0.01\n",
            "Similarity between Summary 260 and KB Entry 41: 0.00\n",
            "Similarity between Summary 260 and KB Entry 42: 0.01\n",
            "Similarity between Summary 260 and KB Entry 43: 0.03\n",
            "Similarity between Summary 260 and KB Entry 44: 0.01\n",
            "Similarity between Summary 260 and KB Entry 45: 0.00\n",
            "Similarity between Summary 260 and KB Entry 46: 0.00\n",
            "Similarity between Summary 261 and KB Entry 1: 0.08\n",
            "Similarity between Summary 261 and KB Entry 2: 0.01\n",
            "Similarity between Summary 261 and KB Entry 3: 0.04\n",
            "Similarity between Summary 261 and KB Entry 4: 0.07\n",
            "Similarity between Summary 261 and KB Entry 5: 0.01\n",
            "Similarity between Summary 261 and KB Entry 6: 0.04\n",
            "Similarity between Summary 261 and KB Entry 7: 0.03\n",
            "Similarity between Summary 261 and KB Entry 8: 0.00\n",
            "Similarity between Summary 261 and KB Entry 9: 0.00\n",
            "Similarity between Summary 261 and KB Entry 10: 0.02\n",
            "Similarity between Summary 261 and KB Entry 11: 0.03\n",
            "Similarity between Summary 261 and KB Entry 12: 0.03\n",
            "Similarity between Summary 261 and KB Entry 13: 0.01\n",
            "Similarity between Summary 261 and KB Entry 14: 0.01\n",
            "Similarity between Summary 261 and KB Entry 15: 0.00\n",
            "Similarity between Summary 261 and KB Entry 16: 0.01\n",
            "Similarity between Summary 261 and KB Entry 17: 0.04\n",
            "Similarity between Summary 261 and KB Entry 18: 0.01\n",
            "Similarity between Summary 261 and KB Entry 19: 0.01\n",
            "Similarity between Summary 261 and KB Entry 20: 0.00\n",
            "Similarity between Summary 261 and KB Entry 21: 0.01\n",
            "Similarity between Summary 261 and KB Entry 22: 0.00\n",
            "Similarity between Summary 261 and KB Entry 23: 0.00\n",
            "Similarity between Summary 261 and KB Entry 24: 0.01\n",
            "Similarity between Summary 261 and KB Entry 25: 0.02\n",
            "Similarity between Summary 261 and KB Entry 26: 0.00\n",
            "Similarity between Summary 261 and KB Entry 27: 0.00\n",
            "Similarity between Summary 261 and KB Entry 28: 0.02\n",
            "Similarity between Summary 261 and KB Entry 29: 0.00\n",
            "Similarity between Summary 261 and KB Entry 30: 0.02\n",
            "Similarity between Summary 261 and KB Entry 31: 0.01\n",
            "Similarity between Summary 261 and KB Entry 32: 0.01\n",
            "Similarity between Summary 261 and KB Entry 33: 0.03\n",
            "Similarity between Summary 261 and KB Entry 34: 0.01\n",
            "Similarity between Summary 261 and KB Entry 35: 0.02\n",
            "Similarity between Summary 261 and KB Entry 36: 0.00\n",
            "Similarity between Summary 261 and KB Entry 37: 0.00\n",
            "Similarity between Summary 261 and KB Entry 38: 0.02\n",
            "Similarity between Summary 261 and KB Entry 39: 0.05\n",
            "Similarity between Summary 261 and KB Entry 40: 0.02\n",
            "Similarity between Summary 261 and KB Entry 41: 0.02\n",
            "Similarity between Summary 261 and KB Entry 42: 0.02\n",
            "Similarity between Summary 261 and KB Entry 43: 0.04\n",
            "Similarity between Summary 261 and KB Entry 44: 0.03\n",
            "Similarity between Summary 261 and KB Entry 45: 0.00\n",
            "Similarity between Summary 261 and KB Entry 46: 0.00\n",
            "Similarity between Summary 262 and KB Entry 1: 0.05\n",
            "Similarity between Summary 262 and KB Entry 2: 0.00\n",
            "Similarity between Summary 262 and KB Entry 3: 0.02\n",
            "Similarity between Summary 262 and KB Entry 4: 0.04\n",
            "Similarity between Summary 262 and KB Entry 5: 0.01\n",
            "Similarity between Summary 262 and KB Entry 6: 0.01\n",
            "Similarity between Summary 262 and KB Entry 7: 0.02\n",
            "Similarity between Summary 262 and KB Entry 8: 0.02\n",
            "Similarity between Summary 262 and KB Entry 9: 0.00\n",
            "Similarity between Summary 262 and KB Entry 10: 0.01\n",
            "Similarity between Summary 262 and KB Entry 11: 0.01\n",
            "Similarity between Summary 262 and KB Entry 12: 0.00\n",
            "Similarity between Summary 262 and KB Entry 13: 0.00\n",
            "Similarity between Summary 262 and KB Entry 14: 0.01\n",
            "Similarity between Summary 262 and KB Entry 15: 0.00\n",
            "Similarity between Summary 262 and KB Entry 16: 0.00\n",
            "Similarity between Summary 262 and KB Entry 17: 0.10\n",
            "Similarity between Summary 262 and KB Entry 18: 0.03\n",
            "Similarity between Summary 262 and KB Entry 19: 0.02\n",
            "Similarity between Summary 262 and KB Entry 20: 0.00\n",
            "Similarity between Summary 262 and KB Entry 21: 0.03\n",
            "Similarity between Summary 262 and KB Entry 22: 0.00\n",
            "Similarity between Summary 262 and KB Entry 23: 0.00\n",
            "Similarity between Summary 262 and KB Entry 24: 0.00\n",
            "Similarity between Summary 262 and KB Entry 25: 0.10\n",
            "Similarity between Summary 262 and KB Entry 26: 0.04\n",
            "Similarity between Summary 262 and KB Entry 27: 0.05\n",
            "Similarity between Summary 262 and KB Entry 28: 0.01\n",
            "Similarity between Summary 262 and KB Entry 29: 0.00\n",
            "Similarity between Summary 262 and KB Entry 30: 0.03\n",
            "Similarity between Summary 262 and KB Entry 31: 0.01\n",
            "Similarity between Summary 262 and KB Entry 32: 0.00\n",
            "Similarity between Summary 262 and KB Entry 33: 0.08\n",
            "Similarity between Summary 262 and KB Entry 34: 0.00\n",
            "Similarity between Summary 262 and KB Entry 35: 0.01\n",
            "Similarity between Summary 262 and KB Entry 36: 0.00\n",
            "Similarity between Summary 262 and KB Entry 37: 0.06\n",
            "Similarity between Summary 262 and KB Entry 38: 0.01\n",
            "Similarity between Summary 262 and KB Entry 39: 0.01\n",
            "Similarity between Summary 262 and KB Entry 40: 0.02\n",
            "Similarity between Summary 262 and KB Entry 41: 0.00\n",
            "Similarity between Summary 262 and KB Entry 42: 0.03\n",
            "Similarity between Summary 262 and KB Entry 43: 0.00\n",
            "Similarity between Summary 262 and KB Entry 44: 0.02\n",
            "Similarity between Summary 262 and KB Entry 45: 0.00\n",
            "Similarity between Summary 262 and KB Entry 46: 0.00\n",
            "Similarity between Summary 263 and KB Entry 1: 0.05\n",
            "Similarity between Summary 263 and KB Entry 2: 0.00\n",
            "Similarity between Summary 263 and KB Entry 3: 0.02\n",
            "Similarity between Summary 263 and KB Entry 4: 0.04\n",
            "Similarity between Summary 263 and KB Entry 5: 0.01\n",
            "Similarity between Summary 263 and KB Entry 6: 0.01\n",
            "Similarity between Summary 263 and KB Entry 7: 0.02\n",
            "Similarity between Summary 263 and KB Entry 8: 0.02\n",
            "Similarity between Summary 263 and KB Entry 9: 0.00\n",
            "Similarity between Summary 263 and KB Entry 10: 0.01\n",
            "Similarity between Summary 263 and KB Entry 11: 0.01\n",
            "Similarity between Summary 263 and KB Entry 12: 0.00\n",
            "Similarity between Summary 263 and KB Entry 13: 0.00\n",
            "Similarity between Summary 263 and KB Entry 14: 0.01\n",
            "Similarity between Summary 263 and KB Entry 15: 0.00\n",
            "Similarity between Summary 263 and KB Entry 16: 0.00\n",
            "Similarity between Summary 263 and KB Entry 17: 0.09\n",
            "Similarity between Summary 263 and KB Entry 18: 0.03\n",
            "Similarity between Summary 263 and KB Entry 19: 0.02\n",
            "Similarity between Summary 263 and KB Entry 20: 0.00\n",
            "Similarity between Summary 263 and KB Entry 21: 0.02\n",
            "Similarity between Summary 263 and KB Entry 22: 0.00\n",
            "Similarity between Summary 263 and KB Entry 23: 0.00\n",
            "Similarity between Summary 263 and KB Entry 24: 0.00\n",
            "Similarity between Summary 263 and KB Entry 25: 0.10\n",
            "Similarity between Summary 263 and KB Entry 26: 0.04\n",
            "Similarity between Summary 263 and KB Entry 27: 0.06\n",
            "Similarity between Summary 263 and KB Entry 28: 0.03\n",
            "Similarity between Summary 263 and KB Entry 29: 0.00\n",
            "Similarity between Summary 263 and KB Entry 30: 0.00\n",
            "Similarity between Summary 263 and KB Entry 31: 0.01\n",
            "Similarity between Summary 263 and KB Entry 32: 0.00\n",
            "Similarity between Summary 263 and KB Entry 33: 0.07\n",
            "Similarity between Summary 263 and KB Entry 34: 0.01\n",
            "Similarity between Summary 263 and KB Entry 35: 0.01\n",
            "Similarity between Summary 263 and KB Entry 36: 0.00\n",
            "Similarity between Summary 263 and KB Entry 37: 0.05\n",
            "Similarity between Summary 263 and KB Entry 38: 0.01\n",
            "Similarity between Summary 263 and KB Entry 39: 0.01\n",
            "Similarity between Summary 263 and KB Entry 40: 0.02\n",
            "Similarity between Summary 263 and KB Entry 41: 0.00\n",
            "Similarity between Summary 263 and KB Entry 42: 0.02\n",
            "Similarity between Summary 263 and KB Entry 43: 0.00\n",
            "Similarity between Summary 263 and KB Entry 44: 0.02\n",
            "Similarity between Summary 263 and KB Entry 45: 0.00\n",
            "Similarity between Summary 263 and KB Entry 46: 0.01\n",
            "Similarity between Summary 264 and KB Entry 1: 0.08\n",
            "Similarity between Summary 264 and KB Entry 2: 0.01\n",
            "Similarity between Summary 264 and KB Entry 3: 0.02\n",
            "Similarity between Summary 264 and KB Entry 4: 0.06\n",
            "Similarity between Summary 264 and KB Entry 5: 0.02\n",
            "Similarity between Summary 264 and KB Entry 6: 0.04\n",
            "Similarity between Summary 264 and KB Entry 7: 0.03\n",
            "Similarity between Summary 264 and KB Entry 8: 0.05\n",
            "Similarity between Summary 264 and KB Entry 9: 0.02\n",
            "Similarity between Summary 264 and KB Entry 10: 0.00\n",
            "Similarity between Summary 264 and KB Entry 11: 0.00\n",
            "Similarity between Summary 264 and KB Entry 12: 0.11\n",
            "Similarity between Summary 264 and KB Entry 13: 0.02\n",
            "Similarity between Summary 264 and KB Entry 14: 0.02\n",
            "Similarity between Summary 264 and KB Entry 15: 0.01\n",
            "Similarity between Summary 264 and KB Entry 16: 0.02\n",
            "Similarity between Summary 264 and KB Entry 17: 0.10\n",
            "Similarity between Summary 264 and KB Entry 18: 0.00\n",
            "Similarity between Summary 264 and KB Entry 19: 0.00\n",
            "Similarity between Summary 264 and KB Entry 20: 0.00\n",
            "Similarity between Summary 264 and KB Entry 21: 0.00\n",
            "Similarity between Summary 264 and KB Entry 22: 0.00\n",
            "Similarity between Summary 264 and KB Entry 23: 0.00\n",
            "Similarity between Summary 264 and KB Entry 24: 0.00\n",
            "Similarity between Summary 264 and KB Entry 25: 0.03\n",
            "Similarity between Summary 264 and KB Entry 26: 0.00\n",
            "Similarity between Summary 264 and KB Entry 27: 0.00\n",
            "Similarity between Summary 264 and KB Entry 28: 0.01\n",
            "Similarity between Summary 264 and KB Entry 29: 0.00\n",
            "Similarity between Summary 264 and KB Entry 30: 0.03\n",
            "Similarity between Summary 264 and KB Entry 31: 0.00\n",
            "Similarity between Summary 264 and KB Entry 32: 0.00\n",
            "Similarity between Summary 264 and KB Entry 33: 0.04\n",
            "Similarity between Summary 264 and KB Entry 34: 0.01\n",
            "Similarity between Summary 264 and KB Entry 35: 0.01\n",
            "Similarity between Summary 264 and KB Entry 36: 0.00\n",
            "Similarity between Summary 264 and KB Entry 37: 0.00\n",
            "Similarity between Summary 264 and KB Entry 38: 0.05\n",
            "Similarity between Summary 264 and KB Entry 39: 0.05\n",
            "Similarity between Summary 264 and KB Entry 40: 0.01\n",
            "Similarity between Summary 264 and KB Entry 41: 0.02\n",
            "Similarity between Summary 264 and KB Entry 42: 0.02\n",
            "Similarity between Summary 264 and KB Entry 43: 0.04\n",
            "Similarity between Summary 264 and KB Entry 44: 0.00\n",
            "Similarity between Summary 264 and KB Entry 45: 0.08\n",
            "Similarity between Summary 264 and KB Entry 46: 0.00\n",
            "Similarity between Summary 265 and KB Entry 1: 0.06\n",
            "Similarity between Summary 265 and KB Entry 2: 0.01\n",
            "Similarity between Summary 265 and KB Entry 3: 0.02\n",
            "Similarity between Summary 265 and KB Entry 4: 0.03\n",
            "Similarity between Summary 265 and KB Entry 5: 0.00\n",
            "Similarity between Summary 265 and KB Entry 6: 0.02\n",
            "Similarity between Summary 265 and KB Entry 7: 0.01\n",
            "Similarity between Summary 265 and KB Entry 8: 0.00\n",
            "Similarity between Summary 265 and KB Entry 9: 0.00\n",
            "Similarity between Summary 265 and KB Entry 10: 0.00\n",
            "Similarity between Summary 265 and KB Entry 11: 0.00\n",
            "Similarity between Summary 265 and KB Entry 12: 0.04\n",
            "Similarity between Summary 265 and KB Entry 13: 0.01\n",
            "Similarity between Summary 265 and KB Entry 14: 0.02\n",
            "Similarity between Summary 265 and KB Entry 15: 0.01\n",
            "Similarity between Summary 265 and KB Entry 16: 0.02\n",
            "Similarity between Summary 265 and KB Entry 17: 0.10\n",
            "Similarity between Summary 265 and KB Entry 18: 0.03\n",
            "Similarity between Summary 265 and KB Entry 19: 0.03\n",
            "Similarity between Summary 265 and KB Entry 20: 0.00\n",
            "Similarity between Summary 265 and KB Entry 21: 0.02\n",
            "Similarity between Summary 265 and KB Entry 22: 0.00\n",
            "Similarity between Summary 265 and KB Entry 23: 0.05\n",
            "Similarity between Summary 265 and KB Entry 24: 0.00\n",
            "Similarity between Summary 265 and KB Entry 25: 0.13\n",
            "Similarity between Summary 265 and KB Entry 26: 0.04\n",
            "Similarity between Summary 265 and KB Entry 27: 0.05\n",
            "Similarity between Summary 265 and KB Entry 28: 0.02\n",
            "Similarity between Summary 265 and KB Entry 29: 0.00\n",
            "Similarity between Summary 265 and KB Entry 30: 0.00\n",
            "Similarity between Summary 265 and KB Entry 31: 0.00\n",
            "Similarity between Summary 265 and KB Entry 32: 0.00\n",
            "Similarity between Summary 265 and KB Entry 33: 0.04\n",
            "Similarity between Summary 265 and KB Entry 34: 0.03\n",
            "Similarity between Summary 265 and KB Entry 35: 0.01\n",
            "Similarity between Summary 265 and KB Entry 36: 0.02\n",
            "Similarity between Summary 265 and KB Entry 37: 0.02\n",
            "Similarity between Summary 265 and KB Entry 38: 0.02\n",
            "Similarity between Summary 265 and KB Entry 39: 0.05\n",
            "Similarity between Summary 265 and KB Entry 40: 0.03\n",
            "Similarity between Summary 265 and KB Entry 41: 0.04\n",
            "Similarity between Summary 265 and KB Entry 42: 0.04\n",
            "Similarity between Summary 265 and KB Entry 43: 0.04\n",
            "Similarity between Summary 265 and KB Entry 44: 0.01\n",
            "Similarity between Summary 265 and KB Entry 45: 0.00\n",
            "Similarity between Summary 265 and KB Entry 46: 0.00\n",
            "Similarity between Summary 266 and KB Entry 1: 0.06\n",
            "Similarity between Summary 266 and KB Entry 2: 0.01\n",
            "Similarity between Summary 266 and KB Entry 3: 0.02\n",
            "Similarity between Summary 266 and KB Entry 4: 0.03\n",
            "Similarity between Summary 266 and KB Entry 5: 0.00\n",
            "Similarity between Summary 266 and KB Entry 6: 0.02\n",
            "Similarity between Summary 266 and KB Entry 7: 0.02\n",
            "Similarity between Summary 266 and KB Entry 8: 0.00\n",
            "Similarity between Summary 266 and KB Entry 9: 0.00\n",
            "Similarity between Summary 266 and KB Entry 10: 0.02\n",
            "Similarity between Summary 266 and KB Entry 11: 0.00\n",
            "Similarity between Summary 266 and KB Entry 12: 0.04\n",
            "Similarity between Summary 266 and KB Entry 13: 0.01\n",
            "Similarity between Summary 266 and KB Entry 14: 0.02\n",
            "Similarity between Summary 266 and KB Entry 15: 0.01\n",
            "Similarity between Summary 266 and KB Entry 16: 0.01\n",
            "Similarity between Summary 266 and KB Entry 17: 0.10\n",
            "Similarity between Summary 266 and KB Entry 18: 0.03\n",
            "Similarity between Summary 266 and KB Entry 19: 0.03\n",
            "Similarity between Summary 266 and KB Entry 20: 0.00\n",
            "Similarity between Summary 266 and KB Entry 21: 0.02\n",
            "Similarity between Summary 266 and KB Entry 22: 0.00\n",
            "Similarity between Summary 266 and KB Entry 23: 0.05\n",
            "Similarity between Summary 266 and KB Entry 24: 0.00\n",
            "Similarity between Summary 266 and KB Entry 25: 0.13\n",
            "Similarity between Summary 266 and KB Entry 26: 0.04\n",
            "Similarity between Summary 266 and KB Entry 27: 0.06\n",
            "Similarity between Summary 266 and KB Entry 28: 0.02\n",
            "Similarity between Summary 266 and KB Entry 29: 0.00\n",
            "Similarity between Summary 266 and KB Entry 30: 0.00\n",
            "Similarity between Summary 266 and KB Entry 31: 0.02\n",
            "Similarity between Summary 266 and KB Entry 32: 0.00\n",
            "Similarity between Summary 266 and KB Entry 33: 0.03\n",
            "Similarity between Summary 266 and KB Entry 34: 0.01\n",
            "Similarity between Summary 266 and KB Entry 35: 0.01\n",
            "Similarity between Summary 266 and KB Entry 36: 0.02\n",
            "Similarity between Summary 266 and KB Entry 37: 0.02\n",
            "Similarity between Summary 266 and KB Entry 38: 0.02\n",
            "Similarity between Summary 266 and KB Entry 39: 0.04\n",
            "Similarity between Summary 266 and KB Entry 40: 0.02\n",
            "Similarity between Summary 266 and KB Entry 41: 0.03\n",
            "Similarity between Summary 266 and KB Entry 42: 0.03\n",
            "Similarity between Summary 266 and KB Entry 43: 0.03\n",
            "Similarity between Summary 266 and KB Entry 44: 0.01\n",
            "Similarity between Summary 266 and KB Entry 45: 0.00\n",
            "Similarity between Summary 266 and KB Entry 46: 0.00\n",
            "Similarity between Summary 267 and KB Entry 1: 0.06\n",
            "Similarity between Summary 267 and KB Entry 2: 0.01\n",
            "Similarity between Summary 267 and KB Entry 3: 0.02\n",
            "Similarity between Summary 267 and KB Entry 4: 0.03\n",
            "Similarity between Summary 267 and KB Entry 5: 0.00\n",
            "Similarity between Summary 267 and KB Entry 6: 0.02\n",
            "Similarity between Summary 267 and KB Entry 7: 0.01\n",
            "Similarity between Summary 267 and KB Entry 8: 0.00\n",
            "Similarity between Summary 267 and KB Entry 9: 0.00\n",
            "Similarity between Summary 267 and KB Entry 10: 0.00\n",
            "Similarity between Summary 267 and KB Entry 11: 0.00\n",
            "Similarity between Summary 267 and KB Entry 12: 0.04\n",
            "Similarity between Summary 267 and KB Entry 13: 0.01\n",
            "Similarity between Summary 267 and KB Entry 14: 0.02\n",
            "Similarity between Summary 267 and KB Entry 15: 0.01\n",
            "Similarity between Summary 267 and KB Entry 16: 0.02\n",
            "Similarity between Summary 267 and KB Entry 17: 0.10\n",
            "Similarity between Summary 267 and KB Entry 18: 0.03\n",
            "Similarity between Summary 267 and KB Entry 19: 0.03\n",
            "Similarity between Summary 267 and KB Entry 20: 0.00\n",
            "Similarity between Summary 267 and KB Entry 21: 0.02\n",
            "Similarity between Summary 267 and KB Entry 22: 0.00\n",
            "Similarity between Summary 267 and KB Entry 23: 0.04\n",
            "Similarity between Summary 267 and KB Entry 24: 0.00\n",
            "Similarity between Summary 267 and KB Entry 25: 0.12\n",
            "Similarity between Summary 267 and KB Entry 26: 0.04\n",
            "Similarity between Summary 267 and KB Entry 27: 0.05\n",
            "Similarity between Summary 267 and KB Entry 28: 0.02\n",
            "Similarity between Summary 267 and KB Entry 29: 0.00\n",
            "Similarity between Summary 267 and KB Entry 30: 0.00\n",
            "Similarity between Summary 267 and KB Entry 31: 0.00\n",
            "Similarity between Summary 267 and KB Entry 32: 0.00\n",
            "Similarity between Summary 267 and KB Entry 33: 0.03\n",
            "Similarity between Summary 267 and KB Entry 34: 0.01\n",
            "Similarity between Summary 267 and KB Entry 35: 0.01\n",
            "Similarity between Summary 267 and KB Entry 36: 0.02\n",
            "Similarity between Summary 267 and KB Entry 37: 0.02\n",
            "Similarity between Summary 267 and KB Entry 38: 0.01\n",
            "Similarity between Summary 267 and KB Entry 39: 0.05\n",
            "Similarity between Summary 267 and KB Entry 40: 0.03\n",
            "Similarity between Summary 267 and KB Entry 41: 0.03\n",
            "Similarity between Summary 267 and KB Entry 42: 0.03\n",
            "Similarity between Summary 267 and KB Entry 43: 0.04\n",
            "Similarity between Summary 267 and KB Entry 44: 0.01\n",
            "Similarity between Summary 267 and KB Entry 45: 0.00\n",
            "Similarity between Summary 267 and KB Entry 46: 0.00\n",
            "Similarity between Summary 268 and KB Entry 1: 0.05\n",
            "Similarity between Summary 268 and KB Entry 2: 0.01\n",
            "Similarity between Summary 268 and KB Entry 3: 0.02\n",
            "Similarity between Summary 268 and KB Entry 4: 0.02\n",
            "Similarity between Summary 268 and KB Entry 5: 0.01\n",
            "Similarity between Summary 268 and KB Entry 6: 0.02\n",
            "Similarity between Summary 268 and KB Entry 7: 0.02\n",
            "Similarity between Summary 268 and KB Entry 8: 0.02\n",
            "Similarity between Summary 268 and KB Entry 9: 0.02\n",
            "Similarity between Summary 268 and KB Entry 10: 0.01\n",
            "Similarity between Summary 268 and KB Entry 11: 0.01\n",
            "Similarity between Summary 268 and KB Entry 12: 0.05\n",
            "Similarity between Summary 268 and KB Entry 13: 0.01\n",
            "Similarity between Summary 268 and KB Entry 14: 0.03\n",
            "Similarity between Summary 268 and KB Entry 15: 0.00\n",
            "Similarity between Summary 268 and KB Entry 16: 0.00\n",
            "Similarity between Summary 268 and KB Entry 17: 0.13\n",
            "Similarity between Summary 268 and KB Entry 18: 0.01\n",
            "Similarity between Summary 268 and KB Entry 19: 0.01\n",
            "Similarity between Summary 268 and KB Entry 20: 0.00\n",
            "Similarity between Summary 268 and KB Entry 21: 0.00\n",
            "Similarity between Summary 268 and KB Entry 22: 0.00\n",
            "Similarity between Summary 268 and KB Entry 23: 0.00\n",
            "Similarity between Summary 268 and KB Entry 24: 0.00\n",
            "Similarity between Summary 268 and KB Entry 25: 0.18\n",
            "Similarity between Summary 268 and KB Entry 26: 0.06\n",
            "Similarity between Summary 268 and KB Entry 27: 0.09\n",
            "Similarity between Summary 268 and KB Entry 28: 0.04\n",
            "Similarity between Summary 268 and KB Entry 29: 0.00\n",
            "Similarity between Summary 268 and KB Entry 30: 0.00\n",
            "Similarity between Summary 268 and KB Entry 31: 0.01\n",
            "Similarity between Summary 268 and KB Entry 32: 0.00\n",
            "Similarity between Summary 268 and KB Entry 33: 0.03\n",
            "Similarity between Summary 268 and KB Entry 34: 0.02\n",
            "Similarity between Summary 268 and KB Entry 35: 0.01\n",
            "Similarity between Summary 268 and KB Entry 36: 0.01\n",
            "Similarity between Summary 268 and KB Entry 37: 0.02\n",
            "Similarity between Summary 268 and KB Entry 38: 0.02\n",
            "Similarity between Summary 268 and KB Entry 39: 0.02\n",
            "Similarity between Summary 268 and KB Entry 40: 0.02\n",
            "Similarity between Summary 268 and KB Entry 41: 0.02\n",
            "Similarity between Summary 268 and KB Entry 42: 0.02\n",
            "Similarity between Summary 268 and KB Entry 43: 0.00\n",
            "Similarity between Summary 268 and KB Entry 44: 0.02\n",
            "Similarity between Summary 268 and KB Entry 45: 0.00\n",
            "Similarity between Summary 268 and KB Entry 46: 0.00\n",
            "Similarity between Summary 269 and KB Entry 1: 0.07\n",
            "Similarity between Summary 269 and KB Entry 2: 0.01\n",
            "Similarity between Summary 269 and KB Entry 3: 0.03\n",
            "Similarity between Summary 269 and KB Entry 4: 0.03\n",
            "Similarity between Summary 269 and KB Entry 5: 0.00\n",
            "Similarity between Summary 269 and KB Entry 6: 0.02\n",
            "Similarity between Summary 269 and KB Entry 7: 0.02\n",
            "Similarity between Summary 269 and KB Entry 8: 0.01\n",
            "Similarity between Summary 269 and KB Entry 9: 0.01\n",
            "Similarity between Summary 269 and KB Entry 10: 0.02\n",
            "Similarity between Summary 269 and KB Entry 11: 0.01\n",
            "Similarity between Summary 269 and KB Entry 12: 0.02\n",
            "Similarity between Summary 269 and KB Entry 13: 0.01\n",
            "Similarity between Summary 269 and KB Entry 14: 0.01\n",
            "Similarity between Summary 269 and KB Entry 15: 0.01\n",
            "Similarity between Summary 269 and KB Entry 16: 0.02\n",
            "Similarity between Summary 269 and KB Entry 17: 0.07\n",
            "Similarity between Summary 269 and KB Entry 18: 0.02\n",
            "Similarity between Summary 269 and KB Entry 19: 0.00\n",
            "Similarity between Summary 269 and KB Entry 20: 0.00\n",
            "Similarity between Summary 269 and KB Entry 21: 0.05\n",
            "Similarity between Summary 269 and KB Entry 22: 0.08\n",
            "Similarity between Summary 269 and KB Entry 23: 0.03\n",
            "Similarity between Summary 269 and KB Entry 24: 0.00\n",
            "Similarity between Summary 269 and KB Entry 25: 0.12\n",
            "Similarity between Summary 269 and KB Entry 26: 0.02\n",
            "Similarity between Summary 269 and KB Entry 27: 0.03\n",
            "Similarity between Summary 269 and KB Entry 28: 0.01\n",
            "Similarity between Summary 269 and KB Entry 29: 0.03\n",
            "Similarity between Summary 269 and KB Entry 30: 0.02\n",
            "Similarity between Summary 269 and KB Entry 31: 0.02\n",
            "Similarity between Summary 269 and KB Entry 32: 0.01\n",
            "Similarity between Summary 269 and KB Entry 33: 0.03\n",
            "Similarity between Summary 269 and KB Entry 34: 0.01\n",
            "Similarity between Summary 269 and KB Entry 35: 0.00\n",
            "Similarity between Summary 269 and KB Entry 36: 0.01\n",
            "Similarity between Summary 269 and KB Entry 37: 0.01\n",
            "Similarity between Summary 269 and KB Entry 38: 0.02\n",
            "Similarity between Summary 269 and KB Entry 39: 0.03\n",
            "Similarity between Summary 269 and KB Entry 40: 0.02\n",
            "Similarity between Summary 269 and KB Entry 41: 0.02\n",
            "Similarity between Summary 269 and KB Entry 42: 0.02\n",
            "Similarity between Summary 269 and KB Entry 43: 0.03\n",
            "Similarity between Summary 269 and KB Entry 44: 0.00\n",
            "Similarity between Summary 269 and KB Entry 45: 0.00\n",
            "Similarity between Summary 269 and KB Entry 46: 0.01\n",
            "Similarity between Summary 270 and KB Entry 1: 0.07\n",
            "Similarity between Summary 270 and KB Entry 2: 0.01\n",
            "Similarity between Summary 270 and KB Entry 3: 0.03\n",
            "Similarity between Summary 270 and KB Entry 4: 0.03\n",
            "Similarity between Summary 270 and KB Entry 5: 0.00\n",
            "Similarity between Summary 270 and KB Entry 6: 0.02\n",
            "Similarity between Summary 270 and KB Entry 7: 0.02\n",
            "Similarity between Summary 270 and KB Entry 8: 0.01\n",
            "Similarity between Summary 270 and KB Entry 9: 0.01\n",
            "Similarity between Summary 270 and KB Entry 10: 0.02\n",
            "Similarity between Summary 270 and KB Entry 11: 0.01\n",
            "Similarity between Summary 270 and KB Entry 12: 0.02\n",
            "Similarity between Summary 270 and KB Entry 13: 0.01\n",
            "Similarity between Summary 270 and KB Entry 14: 0.01\n",
            "Similarity between Summary 270 and KB Entry 15: 0.01\n",
            "Similarity between Summary 270 and KB Entry 16: 0.02\n",
            "Similarity between Summary 270 and KB Entry 17: 0.07\n",
            "Similarity between Summary 270 and KB Entry 18: 0.02\n",
            "Similarity between Summary 270 and KB Entry 19: 0.00\n",
            "Similarity between Summary 270 and KB Entry 20: 0.00\n",
            "Similarity between Summary 270 and KB Entry 21: 0.05\n",
            "Similarity between Summary 270 and KB Entry 22: 0.08\n",
            "Similarity between Summary 270 and KB Entry 23: 0.03\n",
            "Similarity between Summary 270 and KB Entry 24: 0.00\n",
            "Similarity between Summary 270 and KB Entry 25: 0.12\n",
            "Similarity between Summary 270 and KB Entry 26: 0.02\n",
            "Similarity between Summary 270 and KB Entry 27: 0.03\n",
            "Similarity between Summary 270 and KB Entry 28: 0.01\n",
            "Similarity between Summary 270 and KB Entry 29: 0.03\n",
            "Similarity between Summary 270 and KB Entry 30: 0.02\n",
            "Similarity between Summary 270 and KB Entry 31: 0.02\n",
            "Similarity between Summary 270 and KB Entry 32: 0.01\n",
            "Similarity between Summary 270 and KB Entry 33: 0.03\n",
            "Similarity between Summary 270 and KB Entry 34: 0.01\n",
            "Similarity between Summary 270 and KB Entry 35: 0.00\n",
            "Similarity between Summary 270 and KB Entry 36: 0.01\n",
            "Similarity between Summary 270 and KB Entry 37: 0.01\n",
            "Similarity between Summary 270 and KB Entry 38: 0.02\n",
            "Similarity between Summary 270 and KB Entry 39: 0.03\n",
            "Similarity between Summary 270 and KB Entry 40: 0.02\n",
            "Similarity between Summary 270 and KB Entry 41: 0.02\n",
            "Similarity between Summary 270 and KB Entry 42: 0.02\n",
            "Similarity between Summary 270 and KB Entry 43: 0.03\n",
            "Similarity between Summary 270 and KB Entry 44: 0.00\n",
            "Similarity between Summary 270 and KB Entry 45: 0.00\n",
            "Similarity between Summary 270 and KB Entry 46: 0.01\n",
            "Similarity between Summary 271 and KB Entry 1: 0.07\n",
            "Similarity between Summary 271 and KB Entry 2: 0.01\n",
            "Similarity between Summary 271 and KB Entry 3: 0.03\n",
            "Similarity between Summary 271 and KB Entry 4: 0.03\n",
            "Similarity between Summary 271 and KB Entry 5: 0.00\n",
            "Similarity between Summary 271 and KB Entry 6: 0.02\n",
            "Similarity between Summary 271 and KB Entry 7: 0.02\n",
            "Similarity between Summary 271 and KB Entry 8: 0.01\n",
            "Similarity between Summary 271 and KB Entry 9: 0.01\n",
            "Similarity between Summary 271 and KB Entry 10: 0.02\n",
            "Similarity between Summary 271 and KB Entry 11: 0.01\n",
            "Similarity between Summary 271 and KB Entry 12: 0.02\n",
            "Similarity between Summary 271 and KB Entry 13: 0.00\n",
            "Similarity between Summary 271 and KB Entry 14: 0.01\n",
            "Similarity between Summary 271 and KB Entry 15: 0.01\n",
            "Similarity between Summary 271 and KB Entry 16: 0.02\n",
            "Similarity between Summary 271 and KB Entry 17: 0.07\n",
            "Similarity between Summary 271 and KB Entry 18: 0.02\n",
            "Similarity between Summary 271 and KB Entry 19: 0.00\n",
            "Similarity between Summary 271 and KB Entry 20: 0.00\n",
            "Similarity between Summary 271 and KB Entry 21: 0.05\n",
            "Similarity between Summary 271 and KB Entry 22: 0.08\n",
            "Similarity between Summary 271 and KB Entry 23: 0.03\n",
            "Similarity between Summary 271 and KB Entry 24: 0.00\n",
            "Similarity between Summary 271 and KB Entry 25: 0.12\n",
            "Similarity between Summary 271 and KB Entry 26: 0.02\n",
            "Similarity between Summary 271 and KB Entry 27: 0.03\n",
            "Similarity between Summary 271 and KB Entry 28: 0.01\n",
            "Similarity between Summary 271 and KB Entry 29: 0.03\n",
            "Similarity between Summary 271 and KB Entry 30: 0.02\n",
            "Similarity between Summary 271 and KB Entry 31: 0.02\n",
            "Similarity between Summary 271 and KB Entry 32: 0.01\n",
            "Similarity between Summary 271 and KB Entry 33: 0.03\n",
            "Similarity between Summary 271 and KB Entry 34: 0.01\n",
            "Similarity between Summary 271 and KB Entry 35: 0.00\n",
            "Similarity between Summary 271 and KB Entry 36: 0.01\n",
            "Similarity between Summary 271 and KB Entry 37: 0.01\n",
            "Similarity between Summary 271 and KB Entry 38: 0.02\n",
            "Similarity between Summary 271 and KB Entry 39: 0.03\n",
            "Similarity between Summary 271 and KB Entry 40: 0.02\n",
            "Similarity between Summary 271 and KB Entry 41: 0.02\n",
            "Similarity between Summary 271 and KB Entry 42: 0.02\n",
            "Similarity between Summary 271 and KB Entry 43: 0.03\n",
            "Similarity between Summary 271 and KB Entry 44: 0.00\n",
            "Similarity between Summary 271 and KB Entry 45: 0.00\n",
            "Similarity between Summary 271 and KB Entry 46: 0.01\n",
            "Similarity between Summary 272 and KB Entry 1: 0.07\n",
            "Similarity between Summary 272 and KB Entry 2: 0.01\n",
            "Similarity between Summary 272 and KB Entry 3: 0.03\n",
            "Similarity between Summary 272 and KB Entry 4: 0.03\n",
            "Similarity between Summary 272 and KB Entry 5: 0.00\n",
            "Similarity between Summary 272 and KB Entry 6: 0.02\n",
            "Similarity between Summary 272 and KB Entry 7: 0.02\n",
            "Similarity between Summary 272 and KB Entry 8: 0.01\n",
            "Similarity between Summary 272 and KB Entry 9: 0.01\n",
            "Similarity between Summary 272 and KB Entry 10: 0.02\n",
            "Similarity between Summary 272 and KB Entry 11: 0.01\n",
            "Similarity between Summary 272 and KB Entry 12: 0.02\n",
            "Similarity between Summary 272 and KB Entry 13: 0.00\n",
            "Similarity between Summary 272 and KB Entry 14: 0.01\n",
            "Similarity between Summary 272 and KB Entry 15: 0.01\n",
            "Similarity between Summary 272 and KB Entry 16: 0.02\n",
            "Similarity between Summary 272 and KB Entry 17: 0.07\n",
            "Similarity between Summary 272 and KB Entry 18: 0.02\n",
            "Similarity between Summary 272 and KB Entry 19: 0.00\n",
            "Similarity between Summary 272 and KB Entry 20: 0.00\n",
            "Similarity between Summary 272 and KB Entry 21: 0.05\n",
            "Similarity between Summary 272 and KB Entry 22: 0.08\n",
            "Similarity between Summary 272 and KB Entry 23: 0.03\n",
            "Similarity between Summary 272 and KB Entry 24: 0.00\n",
            "Similarity between Summary 272 and KB Entry 25: 0.12\n",
            "Similarity between Summary 272 and KB Entry 26: 0.02\n",
            "Similarity between Summary 272 and KB Entry 27: 0.03\n",
            "Similarity between Summary 272 and KB Entry 28: 0.01\n",
            "Similarity between Summary 272 and KB Entry 29: 0.03\n",
            "Similarity between Summary 272 and KB Entry 30: 0.02\n",
            "Similarity between Summary 272 and KB Entry 31: 0.02\n",
            "Similarity between Summary 272 and KB Entry 32: 0.01\n",
            "Similarity between Summary 272 and KB Entry 33: 0.03\n",
            "Similarity between Summary 272 and KB Entry 34: 0.01\n",
            "Similarity between Summary 272 and KB Entry 35: 0.00\n",
            "Similarity between Summary 272 and KB Entry 36: 0.01\n",
            "Similarity between Summary 272 and KB Entry 37: 0.01\n",
            "Similarity between Summary 272 and KB Entry 38: 0.02\n",
            "Similarity between Summary 272 and KB Entry 39: 0.03\n",
            "Similarity between Summary 272 and KB Entry 40: 0.02\n",
            "Similarity between Summary 272 and KB Entry 41: 0.02\n",
            "Similarity between Summary 272 and KB Entry 42: 0.02\n",
            "Similarity between Summary 272 and KB Entry 43: 0.03\n",
            "Similarity between Summary 272 and KB Entry 44: 0.00\n",
            "Similarity between Summary 272 and KB Entry 45: 0.00\n",
            "Similarity between Summary 272 and KB Entry 46: 0.01\n",
            "Similarity between Summary 273 and KB Entry 1: 0.07\n",
            "Similarity between Summary 273 and KB Entry 2: 0.01\n",
            "Similarity between Summary 273 and KB Entry 3: 0.03\n",
            "Similarity between Summary 273 and KB Entry 4: 0.03\n",
            "Similarity between Summary 273 and KB Entry 5: 0.00\n",
            "Similarity between Summary 273 and KB Entry 6: 0.02\n",
            "Similarity between Summary 273 and KB Entry 7: 0.02\n",
            "Similarity between Summary 273 and KB Entry 8: 0.01\n",
            "Similarity between Summary 273 and KB Entry 9: 0.01\n",
            "Similarity between Summary 273 and KB Entry 10: 0.02\n",
            "Similarity between Summary 273 and KB Entry 11: 0.01\n",
            "Similarity between Summary 273 and KB Entry 12: 0.02\n",
            "Similarity between Summary 273 and KB Entry 13: 0.00\n",
            "Similarity between Summary 273 and KB Entry 14: 0.01\n",
            "Similarity between Summary 273 and KB Entry 15: 0.01\n",
            "Similarity between Summary 273 and KB Entry 16: 0.02\n",
            "Similarity between Summary 273 and KB Entry 17: 0.07\n",
            "Similarity between Summary 273 and KB Entry 18: 0.02\n",
            "Similarity between Summary 273 and KB Entry 19: 0.00\n",
            "Similarity between Summary 273 and KB Entry 20: 0.00\n",
            "Similarity between Summary 273 and KB Entry 21: 0.05\n",
            "Similarity between Summary 273 and KB Entry 22: 0.08\n",
            "Similarity between Summary 273 and KB Entry 23: 0.03\n",
            "Similarity between Summary 273 and KB Entry 24: 0.00\n",
            "Similarity between Summary 273 and KB Entry 25: 0.12\n",
            "Similarity between Summary 273 and KB Entry 26: 0.02\n",
            "Similarity between Summary 273 and KB Entry 27: 0.03\n",
            "Similarity between Summary 273 and KB Entry 28: 0.01\n",
            "Similarity between Summary 273 and KB Entry 29: 0.03\n",
            "Similarity between Summary 273 and KB Entry 30: 0.02\n",
            "Similarity between Summary 273 and KB Entry 31: 0.02\n",
            "Similarity between Summary 273 and KB Entry 32: 0.01\n",
            "Similarity between Summary 273 and KB Entry 33: 0.03\n",
            "Similarity between Summary 273 and KB Entry 34: 0.01\n",
            "Similarity between Summary 273 and KB Entry 35: 0.00\n",
            "Similarity between Summary 273 and KB Entry 36: 0.01\n",
            "Similarity between Summary 273 and KB Entry 37: 0.01\n",
            "Similarity between Summary 273 and KB Entry 38: 0.02\n",
            "Similarity between Summary 273 and KB Entry 39: 0.03\n",
            "Similarity between Summary 273 and KB Entry 40: 0.02\n",
            "Similarity between Summary 273 and KB Entry 41: 0.02\n",
            "Similarity between Summary 273 and KB Entry 42: 0.02\n",
            "Similarity between Summary 273 and KB Entry 43: 0.03\n",
            "Similarity between Summary 273 and KB Entry 44: 0.00\n",
            "Similarity between Summary 273 and KB Entry 45: 0.00\n",
            "Similarity between Summary 273 and KB Entry 46: 0.01\n",
            "Similarity between Summary 274 and KB Entry 1: 0.07\n",
            "Similarity between Summary 274 and KB Entry 2: 0.01\n",
            "Similarity between Summary 274 and KB Entry 3: 0.03\n",
            "Similarity between Summary 274 and KB Entry 4: 0.03\n",
            "Similarity between Summary 274 and KB Entry 5: 0.00\n",
            "Similarity between Summary 274 and KB Entry 6: 0.02\n",
            "Similarity between Summary 274 and KB Entry 7: 0.02\n",
            "Similarity between Summary 274 and KB Entry 8: 0.01\n",
            "Similarity between Summary 274 and KB Entry 9: 0.01\n",
            "Similarity between Summary 274 and KB Entry 10: 0.02\n",
            "Similarity between Summary 274 and KB Entry 11: 0.01\n",
            "Similarity between Summary 274 and KB Entry 12: 0.02\n",
            "Similarity between Summary 274 and KB Entry 13: 0.01\n",
            "Similarity between Summary 274 and KB Entry 14: 0.01\n",
            "Similarity between Summary 274 and KB Entry 15: 0.01\n",
            "Similarity between Summary 274 and KB Entry 16: 0.02\n",
            "Similarity between Summary 274 and KB Entry 17: 0.07\n",
            "Similarity between Summary 274 and KB Entry 18: 0.02\n",
            "Similarity between Summary 274 and KB Entry 19: 0.00\n",
            "Similarity between Summary 274 and KB Entry 20: 0.00\n",
            "Similarity between Summary 274 and KB Entry 21: 0.05\n",
            "Similarity between Summary 274 and KB Entry 22: 0.08\n",
            "Similarity between Summary 274 and KB Entry 23: 0.03\n",
            "Similarity between Summary 274 and KB Entry 24: 0.00\n",
            "Similarity between Summary 274 and KB Entry 25: 0.12\n",
            "Similarity between Summary 274 and KB Entry 26: 0.02\n",
            "Similarity between Summary 274 and KB Entry 27: 0.03\n",
            "Similarity between Summary 274 and KB Entry 28: 0.01\n",
            "Similarity between Summary 274 and KB Entry 29: 0.03\n",
            "Similarity between Summary 274 and KB Entry 30: 0.02\n",
            "Similarity between Summary 274 and KB Entry 31: 0.02\n",
            "Similarity between Summary 274 and KB Entry 32: 0.01\n",
            "Similarity between Summary 274 and KB Entry 33: 0.03\n",
            "Similarity between Summary 274 and KB Entry 34: 0.01\n",
            "Similarity between Summary 274 and KB Entry 35: 0.00\n",
            "Similarity between Summary 274 and KB Entry 36: 0.01\n",
            "Similarity between Summary 274 and KB Entry 37: 0.01\n",
            "Similarity between Summary 274 and KB Entry 38: 0.02\n",
            "Similarity between Summary 274 and KB Entry 39: 0.03\n",
            "Similarity between Summary 274 and KB Entry 40: 0.02\n",
            "Similarity between Summary 274 and KB Entry 41: 0.02\n",
            "Similarity between Summary 274 and KB Entry 42: 0.02\n",
            "Similarity between Summary 274 and KB Entry 43: 0.03\n",
            "Similarity between Summary 274 and KB Entry 44: 0.00\n",
            "Similarity between Summary 274 and KB Entry 45: 0.00\n",
            "Similarity between Summary 274 and KB Entry 46: 0.01\n",
            "Similarity between Summary 275 and KB Entry 1: 0.09\n",
            "Similarity between Summary 275 and KB Entry 2: 0.01\n",
            "Similarity between Summary 275 and KB Entry 3: 0.01\n",
            "Similarity between Summary 275 and KB Entry 4: 0.03\n",
            "Similarity between Summary 275 and KB Entry 5: 0.00\n",
            "Similarity between Summary 275 and KB Entry 6: 0.01\n",
            "Similarity between Summary 275 and KB Entry 7: 0.01\n",
            "Similarity between Summary 275 and KB Entry 8: 0.01\n",
            "Similarity between Summary 275 and KB Entry 9: 0.01\n",
            "Similarity between Summary 275 and KB Entry 10: 0.01\n",
            "Similarity between Summary 275 and KB Entry 11: 0.00\n",
            "Similarity between Summary 275 and KB Entry 12: 0.04\n",
            "Similarity between Summary 275 and KB Entry 13: 0.01\n",
            "Similarity between Summary 275 and KB Entry 14: 0.01\n",
            "Similarity between Summary 275 and KB Entry 15: 0.01\n",
            "Similarity between Summary 275 and KB Entry 16: 0.02\n",
            "Similarity between Summary 275 and KB Entry 17: 0.11\n",
            "Similarity between Summary 275 and KB Entry 18: 0.00\n",
            "Similarity between Summary 275 and KB Entry 19: 0.06\n",
            "Similarity between Summary 275 and KB Entry 20: 0.00\n",
            "Similarity between Summary 275 and KB Entry 21: 0.02\n",
            "Similarity between Summary 275 and KB Entry 22: 0.02\n",
            "Similarity between Summary 275 and KB Entry 23: 0.00\n",
            "Similarity between Summary 275 and KB Entry 24: 0.01\n",
            "Similarity between Summary 275 and KB Entry 25: 0.05\n",
            "Similarity between Summary 275 and KB Entry 26: 0.02\n",
            "Similarity between Summary 275 and KB Entry 27: 0.03\n",
            "Similarity between Summary 275 and KB Entry 28: 0.01\n",
            "Similarity between Summary 275 and KB Entry 29: 0.00\n",
            "Similarity between Summary 275 and KB Entry 30: 0.01\n",
            "Similarity between Summary 275 and KB Entry 31: 0.00\n",
            "Similarity between Summary 275 and KB Entry 32: 0.01\n",
            "Similarity between Summary 275 and KB Entry 33: 0.05\n",
            "Similarity between Summary 275 and KB Entry 34: 0.02\n",
            "Similarity between Summary 275 and KB Entry 35: 0.01\n",
            "Similarity between Summary 275 and KB Entry 36: 0.00\n",
            "Similarity between Summary 275 and KB Entry 37: 0.01\n",
            "Similarity between Summary 275 and KB Entry 38: 0.03\n",
            "Similarity between Summary 275 and KB Entry 39: 0.00\n",
            "Similarity between Summary 275 and KB Entry 40: 0.01\n",
            "Similarity between Summary 275 and KB Entry 41: 0.00\n",
            "Similarity between Summary 275 and KB Entry 42: 0.00\n",
            "Similarity between Summary 275 and KB Entry 43: 0.00\n",
            "Similarity between Summary 275 and KB Entry 44: 0.06\n",
            "Similarity between Summary 275 and KB Entry 45: 0.00\n",
            "Similarity between Summary 275 and KB Entry 46: 0.01\n",
            "Similarity between Summary 276 and KB Entry 1: 0.09\n",
            "Similarity between Summary 276 and KB Entry 2: 0.01\n",
            "Similarity between Summary 276 and KB Entry 3: 0.04\n",
            "Similarity between Summary 276 and KB Entry 4: 0.07\n",
            "Similarity between Summary 276 and KB Entry 5: 0.01\n",
            "Similarity between Summary 276 and KB Entry 6: 0.05\n",
            "Similarity between Summary 276 and KB Entry 7: 0.03\n",
            "Similarity between Summary 276 and KB Entry 8: 0.00\n",
            "Similarity between Summary 276 and KB Entry 9: 0.00\n",
            "Similarity between Summary 276 and KB Entry 10: 0.02\n",
            "Similarity between Summary 276 and KB Entry 11: 0.03\n",
            "Similarity between Summary 276 and KB Entry 12: 0.04\n",
            "Similarity between Summary 276 and KB Entry 13: 0.01\n",
            "Similarity between Summary 276 and KB Entry 14: 0.01\n",
            "Similarity between Summary 276 and KB Entry 15: 0.00\n",
            "Similarity between Summary 276 and KB Entry 16: 0.05\n",
            "Similarity between Summary 276 and KB Entry 17: 0.06\n",
            "Similarity between Summary 276 and KB Entry 18: 0.00\n",
            "Similarity between Summary 276 and KB Entry 19: 0.01\n",
            "Similarity between Summary 276 and KB Entry 20: 0.00\n",
            "Similarity between Summary 276 and KB Entry 21: 0.00\n",
            "Similarity between Summary 276 and KB Entry 22: 0.00\n",
            "Similarity between Summary 276 and KB Entry 23: 0.00\n",
            "Similarity between Summary 276 and KB Entry 24: 0.01\n",
            "Similarity between Summary 276 and KB Entry 25: 0.02\n",
            "Similarity between Summary 276 and KB Entry 26: 0.00\n",
            "Similarity between Summary 276 and KB Entry 27: 0.00\n",
            "Similarity between Summary 276 and KB Entry 28: 0.02\n",
            "Similarity between Summary 276 and KB Entry 29: 0.01\n",
            "Similarity between Summary 276 and KB Entry 30: 0.03\n",
            "Similarity between Summary 276 and KB Entry 31: 0.01\n",
            "Similarity between Summary 276 and KB Entry 32: 0.02\n",
            "Similarity between Summary 276 and KB Entry 33: 0.04\n",
            "Similarity between Summary 276 and KB Entry 34: 0.01\n",
            "Similarity between Summary 276 and KB Entry 35: 0.02\n",
            "Similarity between Summary 276 and KB Entry 36: 0.00\n",
            "Similarity between Summary 276 and KB Entry 37: 0.00\n",
            "Similarity between Summary 276 and KB Entry 38: 0.01\n",
            "Similarity between Summary 276 and KB Entry 39: 0.04\n",
            "Similarity between Summary 276 and KB Entry 40: 0.02\n",
            "Similarity between Summary 276 and KB Entry 41: 0.02\n",
            "Similarity between Summary 276 and KB Entry 42: 0.03\n",
            "Similarity between Summary 276 and KB Entry 43: 0.04\n",
            "Similarity between Summary 276 and KB Entry 44: 0.07\n",
            "Similarity between Summary 276 and KB Entry 45: 0.01\n",
            "Similarity between Summary 276 and KB Entry 46: 0.01\n",
            "Similarity between Summary 277 and KB Entry 1: 0.08\n",
            "Similarity between Summary 277 and KB Entry 2: 0.02\n",
            "Similarity between Summary 277 and KB Entry 3: 0.05\n",
            "Similarity between Summary 277 and KB Entry 4: 0.09\n",
            "Similarity between Summary 277 and KB Entry 5: 0.02\n",
            "Similarity between Summary 277 and KB Entry 6: 0.06\n",
            "Similarity between Summary 277 and KB Entry 7: 0.03\n",
            "Similarity between Summary 277 and KB Entry 8: 0.03\n",
            "Similarity between Summary 277 and KB Entry 9: 0.00\n",
            "Similarity between Summary 277 and KB Entry 10: 0.02\n",
            "Similarity between Summary 277 and KB Entry 11: 0.04\n",
            "Similarity between Summary 277 and KB Entry 12: 0.04\n",
            "Similarity between Summary 277 and KB Entry 13: 0.01\n",
            "Similarity between Summary 277 and KB Entry 14: 0.01\n",
            "Similarity between Summary 277 and KB Entry 15: 0.00\n",
            "Similarity between Summary 277 and KB Entry 16: 0.01\n",
            "Similarity between Summary 277 and KB Entry 17: 0.02\n",
            "Similarity between Summary 277 and KB Entry 18: 0.00\n",
            "Similarity between Summary 277 and KB Entry 19: 0.01\n",
            "Similarity between Summary 277 and KB Entry 20: 0.00\n",
            "Similarity between Summary 277 and KB Entry 21: 0.00\n",
            "Similarity between Summary 277 and KB Entry 22: 0.00\n",
            "Similarity between Summary 277 and KB Entry 23: 0.00\n",
            "Similarity between Summary 277 and KB Entry 24: 0.00\n",
            "Similarity between Summary 277 and KB Entry 25: 0.02\n",
            "Similarity between Summary 277 and KB Entry 26: 0.00\n",
            "Similarity between Summary 277 and KB Entry 27: 0.00\n",
            "Similarity between Summary 277 and KB Entry 28: 0.01\n",
            "Similarity between Summary 277 and KB Entry 29: 0.00\n",
            "Similarity between Summary 277 and KB Entry 30: 0.00\n",
            "Similarity between Summary 277 and KB Entry 31: 0.00\n",
            "Similarity between Summary 277 and KB Entry 32: 0.00\n",
            "Similarity between Summary 277 and KB Entry 33: 0.01\n",
            "Similarity between Summary 277 and KB Entry 34: 0.01\n",
            "Similarity between Summary 277 and KB Entry 35: 0.02\n",
            "Similarity between Summary 277 and KB Entry 36: 0.00\n",
            "Similarity between Summary 277 and KB Entry 37: 0.00\n",
            "Similarity between Summary 277 and KB Entry 38: 0.02\n",
            "Similarity between Summary 277 and KB Entry 39: 0.04\n",
            "Similarity between Summary 277 and KB Entry 40: 0.01\n",
            "Similarity between Summary 277 and KB Entry 41: 0.02\n",
            "Similarity between Summary 277 and KB Entry 42: 0.02\n",
            "Similarity between Summary 277 and KB Entry 43: 0.04\n",
            "Similarity between Summary 277 and KB Entry 44: 0.03\n",
            "Similarity between Summary 277 and KB Entry 45: 0.00\n",
            "Similarity between Summary 277 and KB Entry 46: 0.00\n",
            "Similarity between Summary 278 and KB Entry 1: 0.12\n",
            "Similarity between Summary 278 and KB Entry 2: 0.02\n",
            "Similarity between Summary 278 and KB Entry 3: 0.02\n",
            "Similarity between Summary 278 and KB Entry 4: 0.05\n",
            "Similarity between Summary 278 and KB Entry 5: 0.00\n",
            "Similarity between Summary 278 and KB Entry 6: 0.01\n",
            "Similarity between Summary 278 and KB Entry 7: 0.01\n",
            "Similarity between Summary 278 and KB Entry 8: 0.00\n",
            "Similarity between Summary 278 and KB Entry 9: 0.00\n",
            "Similarity between Summary 278 and KB Entry 10: 0.00\n",
            "Similarity between Summary 278 and KB Entry 11: 0.00\n",
            "Similarity between Summary 278 and KB Entry 12: 0.04\n",
            "Similarity between Summary 278 and KB Entry 13: 0.01\n",
            "Similarity between Summary 278 and KB Entry 14: 0.02\n",
            "Similarity between Summary 278 and KB Entry 15: 0.01\n",
            "Similarity between Summary 278 and KB Entry 16: 0.01\n",
            "Similarity between Summary 278 and KB Entry 17: 0.12\n",
            "Similarity between Summary 278 and KB Entry 18: 0.00\n",
            "Similarity between Summary 278 and KB Entry 19: 0.08\n",
            "Similarity between Summary 278 and KB Entry 20: 0.00\n",
            "Similarity between Summary 278 and KB Entry 21: 0.01\n",
            "Similarity between Summary 278 and KB Entry 22: 0.02\n",
            "Similarity between Summary 278 and KB Entry 23: 0.00\n",
            "Similarity between Summary 278 and KB Entry 24: 0.01\n",
            "Similarity between Summary 278 and KB Entry 25: 0.03\n",
            "Similarity between Summary 278 and KB Entry 26: 0.03\n",
            "Similarity between Summary 278 and KB Entry 27: 0.03\n",
            "Similarity between Summary 278 and KB Entry 28: 0.01\n",
            "Similarity between Summary 278 and KB Entry 29: 0.00\n",
            "Similarity between Summary 278 and KB Entry 30: 0.02\n",
            "Similarity between Summary 278 and KB Entry 31: 0.01\n",
            "Similarity between Summary 278 and KB Entry 32: 0.02\n",
            "Similarity between Summary 278 and KB Entry 33: 0.04\n",
            "Similarity between Summary 278 and KB Entry 34: 0.00\n",
            "Similarity between Summary 278 and KB Entry 35: 0.01\n",
            "Similarity between Summary 278 and KB Entry 36: 0.00\n",
            "Similarity between Summary 278 and KB Entry 37: 0.02\n",
            "Similarity between Summary 278 and KB Entry 38: 0.02\n",
            "Similarity between Summary 278 and KB Entry 39: 0.01\n",
            "Similarity between Summary 278 and KB Entry 40: 0.01\n",
            "Similarity between Summary 278 and KB Entry 41: 0.00\n",
            "Similarity between Summary 278 and KB Entry 42: 0.00\n",
            "Similarity between Summary 278 and KB Entry 43: 0.00\n",
            "Similarity between Summary 278 and KB Entry 44: 0.06\n",
            "Similarity between Summary 278 and KB Entry 45: 0.00\n",
            "Similarity between Summary 278 and KB Entry 46: 0.01\n",
            "Similarity between Summary 279 and KB Entry 1: 0.10\n",
            "Similarity between Summary 279 and KB Entry 2: 0.02\n",
            "Similarity between Summary 279 and KB Entry 3: 0.02\n",
            "Similarity between Summary 279 and KB Entry 4: 0.03\n",
            "Similarity between Summary 279 and KB Entry 5: 0.00\n",
            "Similarity between Summary 279 and KB Entry 6: 0.01\n",
            "Similarity between Summary 279 and KB Entry 7: 0.01\n",
            "Similarity between Summary 279 and KB Entry 8: 0.01\n",
            "Similarity between Summary 279 and KB Entry 9: 0.02\n",
            "Similarity between Summary 279 and KB Entry 10: 0.01\n",
            "Similarity between Summary 279 and KB Entry 11: 0.00\n",
            "Similarity between Summary 279 and KB Entry 12: 0.04\n",
            "Similarity between Summary 279 and KB Entry 13: 0.01\n",
            "Similarity between Summary 279 and KB Entry 14: 0.01\n",
            "Similarity between Summary 279 and KB Entry 15: 0.01\n",
            "Similarity between Summary 279 and KB Entry 16: 0.03\n",
            "Similarity between Summary 279 and KB Entry 17: 0.09\n",
            "Similarity between Summary 279 and KB Entry 18: 0.00\n",
            "Similarity between Summary 279 and KB Entry 19: 0.05\n",
            "Similarity between Summary 279 and KB Entry 20: 0.00\n",
            "Similarity between Summary 279 and KB Entry 21: 0.01\n",
            "Similarity between Summary 279 and KB Entry 22: 0.02\n",
            "Similarity between Summary 279 and KB Entry 23: 0.00\n",
            "Similarity between Summary 279 and KB Entry 24: 0.01\n",
            "Similarity between Summary 279 and KB Entry 25: 0.05\n",
            "Similarity between Summary 279 and KB Entry 26: 0.02\n",
            "Similarity between Summary 279 and KB Entry 27: 0.03\n",
            "Similarity between Summary 279 and KB Entry 28: 0.01\n",
            "Similarity between Summary 279 and KB Entry 29: 0.00\n",
            "Similarity between Summary 279 and KB Entry 30: 0.01\n",
            "Similarity between Summary 279 and KB Entry 31: 0.01\n",
            "Similarity between Summary 279 and KB Entry 32: 0.01\n",
            "Similarity between Summary 279 and KB Entry 33: 0.04\n",
            "Similarity between Summary 279 and KB Entry 34: 0.02\n",
            "Similarity between Summary 279 and KB Entry 35: 0.01\n",
            "Similarity between Summary 279 and KB Entry 36: 0.00\n",
            "Similarity between Summary 279 and KB Entry 37: 0.01\n",
            "Similarity between Summary 279 and KB Entry 38: 0.03\n",
            "Similarity between Summary 279 and KB Entry 39: 0.01\n",
            "Similarity between Summary 279 and KB Entry 40: 0.01\n",
            "Similarity between Summary 279 and KB Entry 41: 0.00\n",
            "Similarity between Summary 279 and KB Entry 42: 0.00\n",
            "Similarity between Summary 279 and KB Entry 43: 0.00\n",
            "Similarity between Summary 279 and KB Entry 44: 0.06\n",
            "Similarity between Summary 279 and KB Entry 45: 0.00\n",
            "Similarity between Summary 279 and KB Entry 46: 0.01\n",
            "Similarity between Summary 280 and KB Entry 1: 0.10\n",
            "Similarity between Summary 280 and KB Entry 2: 0.01\n",
            "Similarity between Summary 280 and KB Entry 3: 0.02\n",
            "Similarity between Summary 280 and KB Entry 4: 0.04\n",
            "Similarity between Summary 280 and KB Entry 5: 0.01\n",
            "Similarity between Summary 280 and KB Entry 6: 0.02\n",
            "Similarity between Summary 280 and KB Entry 7: 0.02\n",
            "Similarity between Summary 280 and KB Entry 8: 0.00\n",
            "Similarity between Summary 280 and KB Entry 9: 0.00\n",
            "Similarity between Summary 280 and KB Entry 10: 0.02\n",
            "Similarity between Summary 280 and KB Entry 11: 0.00\n",
            "Similarity between Summary 280 and KB Entry 12: 0.02\n",
            "Similarity between Summary 280 and KB Entry 13: 0.00\n",
            "Similarity between Summary 280 and KB Entry 14: 0.01\n",
            "Similarity between Summary 280 and KB Entry 15: 0.00\n",
            "Similarity between Summary 280 and KB Entry 16: 0.00\n",
            "Similarity between Summary 280 and KB Entry 17: 0.11\n",
            "Similarity between Summary 280 and KB Entry 18: 0.03\n",
            "Similarity between Summary 280 and KB Entry 19: 0.00\n",
            "Similarity between Summary 280 and KB Entry 20: 0.00\n",
            "Similarity between Summary 280 and KB Entry 21: 0.01\n",
            "Similarity between Summary 280 and KB Entry 22: 0.00\n",
            "Similarity between Summary 280 and KB Entry 23: 0.00\n",
            "Similarity between Summary 280 and KB Entry 24: 0.00\n",
            "Similarity between Summary 280 and KB Entry 25: 0.06\n",
            "Similarity between Summary 280 and KB Entry 26: 0.05\n",
            "Similarity between Summary 280 and KB Entry 27: 0.05\n",
            "Similarity between Summary 280 and KB Entry 28: 0.02\n",
            "Similarity between Summary 280 and KB Entry 29: 0.00\n",
            "Similarity between Summary 280 and KB Entry 30: 0.01\n",
            "Similarity between Summary 280 and KB Entry 31: 0.01\n",
            "Similarity between Summary 280 and KB Entry 32: 0.00\n",
            "Similarity between Summary 280 and KB Entry 33: 0.11\n",
            "Similarity between Summary 280 and KB Entry 34: 0.00\n",
            "Similarity between Summary 280 and KB Entry 35: 0.01\n",
            "Similarity between Summary 280 and KB Entry 36: 0.00\n",
            "Similarity between Summary 280 and KB Entry 37: 0.07\n",
            "Similarity between Summary 280 and KB Entry 38: 0.01\n",
            "Similarity between Summary 280 and KB Entry 39: 0.02\n",
            "Similarity between Summary 280 and KB Entry 40: 0.01\n",
            "Similarity between Summary 280 and KB Entry 41: 0.01\n",
            "Similarity between Summary 280 and KB Entry 42: 0.02\n",
            "Similarity between Summary 280 and KB Entry 43: 0.01\n",
            "Similarity between Summary 280 and KB Entry 44: 0.04\n",
            "Similarity between Summary 280 and KB Entry 45: 0.00\n",
            "Similarity between Summary 280 and KB Entry 46: 0.00\n",
            "Similarity between Summary 281 and KB Entry 1: 0.10\n",
            "Similarity between Summary 281 and KB Entry 2: 0.01\n",
            "Similarity between Summary 281 and KB Entry 3: 0.02\n",
            "Similarity between Summary 281 and KB Entry 4: 0.04\n",
            "Similarity between Summary 281 and KB Entry 5: 0.01\n",
            "Similarity between Summary 281 and KB Entry 6: 0.02\n",
            "Similarity between Summary 281 and KB Entry 7: 0.02\n",
            "Similarity between Summary 281 and KB Entry 8: 0.00\n",
            "Similarity between Summary 281 and KB Entry 9: 0.00\n",
            "Similarity between Summary 281 and KB Entry 10: 0.02\n",
            "Similarity between Summary 281 and KB Entry 11: 0.00\n",
            "Similarity between Summary 281 and KB Entry 12: 0.02\n",
            "Similarity between Summary 281 and KB Entry 13: 0.00\n",
            "Similarity between Summary 281 and KB Entry 14: 0.01\n",
            "Similarity between Summary 281 and KB Entry 15: 0.00\n",
            "Similarity between Summary 281 and KB Entry 16: 0.00\n",
            "Similarity between Summary 281 and KB Entry 17: 0.11\n",
            "Similarity between Summary 281 and KB Entry 18: 0.03\n",
            "Similarity between Summary 281 and KB Entry 19: 0.00\n",
            "Similarity between Summary 281 and KB Entry 20: 0.00\n",
            "Similarity between Summary 281 and KB Entry 21: 0.01\n",
            "Similarity between Summary 281 and KB Entry 22: 0.00\n",
            "Similarity between Summary 281 and KB Entry 23: 0.00\n",
            "Similarity between Summary 281 and KB Entry 24: 0.00\n",
            "Similarity between Summary 281 and KB Entry 25: 0.07\n",
            "Similarity between Summary 281 and KB Entry 26: 0.05\n",
            "Similarity between Summary 281 and KB Entry 27: 0.04\n",
            "Similarity between Summary 281 and KB Entry 28: 0.02\n",
            "Similarity between Summary 281 and KB Entry 29: 0.00\n",
            "Similarity between Summary 281 and KB Entry 30: 0.01\n",
            "Similarity between Summary 281 and KB Entry 31: 0.01\n",
            "Similarity between Summary 281 and KB Entry 32: 0.00\n",
            "Similarity between Summary 281 and KB Entry 33: 0.11\n",
            "Similarity between Summary 281 and KB Entry 34: 0.00\n",
            "Similarity between Summary 281 and KB Entry 35: 0.01\n",
            "Similarity between Summary 281 and KB Entry 36: 0.00\n",
            "Similarity between Summary 281 and KB Entry 37: 0.07\n",
            "Similarity between Summary 281 and KB Entry 38: 0.01\n",
            "Similarity between Summary 281 and KB Entry 39: 0.02\n",
            "Similarity between Summary 281 and KB Entry 40: 0.01\n",
            "Similarity between Summary 281 and KB Entry 41: 0.01\n",
            "Similarity between Summary 281 and KB Entry 42: 0.02\n",
            "Similarity between Summary 281 and KB Entry 43: 0.01\n",
            "Similarity between Summary 281 and KB Entry 44: 0.04\n",
            "Similarity between Summary 281 and KB Entry 45: 0.00\n",
            "Similarity between Summary 281 and KB Entry 46: 0.00\n",
            "Similarity between Summary 282 and KB Entry 1: 0.08\n",
            "Similarity between Summary 282 and KB Entry 2: 0.00\n",
            "Similarity between Summary 282 and KB Entry 3: 0.03\n",
            "Similarity between Summary 282 and KB Entry 4: 0.05\n",
            "Similarity between Summary 282 and KB Entry 5: 0.01\n",
            "Similarity between Summary 282 and KB Entry 6: 0.03\n",
            "Similarity between Summary 282 and KB Entry 7: 0.02\n",
            "Similarity between Summary 282 and KB Entry 8: 0.04\n",
            "Similarity between Summary 282 and KB Entry 9: 0.02\n",
            "Similarity between Summary 282 and KB Entry 10: 0.00\n",
            "Similarity between Summary 282 and KB Entry 11: 0.00\n",
            "Similarity between Summary 282 and KB Entry 12: 0.09\n",
            "Similarity between Summary 282 and KB Entry 13: 0.01\n",
            "Similarity between Summary 282 and KB Entry 14: 0.01\n",
            "Similarity between Summary 282 and KB Entry 15: 0.00\n",
            "Similarity between Summary 282 and KB Entry 16: 0.01\n",
            "Similarity between Summary 282 and KB Entry 17: 0.06\n",
            "Similarity between Summary 282 and KB Entry 18: 0.00\n",
            "Similarity between Summary 282 and KB Entry 19: 0.00\n",
            "Similarity between Summary 282 and KB Entry 20: 0.00\n",
            "Similarity between Summary 282 and KB Entry 21: 0.00\n",
            "Similarity between Summary 282 and KB Entry 22: 0.00\n",
            "Similarity between Summary 282 and KB Entry 23: 0.00\n",
            "Similarity between Summary 282 and KB Entry 24: 0.00\n",
            "Similarity between Summary 282 and KB Entry 25: 0.01\n",
            "Similarity between Summary 282 and KB Entry 26: 0.00\n",
            "Similarity between Summary 282 and KB Entry 27: 0.00\n",
            "Similarity between Summary 282 and KB Entry 28: 0.01\n",
            "Similarity between Summary 282 and KB Entry 29: 0.00\n",
            "Similarity between Summary 282 and KB Entry 30: 0.02\n",
            "Similarity between Summary 282 and KB Entry 31: 0.00\n",
            "Similarity between Summary 282 and KB Entry 32: 0.00\n",
            "Similarity between Summary 282 and KB Entry 33: 0.03\n",
            "Similarity between Summary 282 and KB Entry 34: 0.01\n",
            "Similarity between Summary 282 and KB Entry 35: 0.01\n",
            "Similarity between Summary 282 and KB Entry 36: 0.00\n",
            "Similarity between Summary 282 and KB Entry 37: 0.00\n",
            "Similarity between Summary 282 and KB Entry 38: 0.03\n",
            "Similarity between Summary 282 and KB Entry 39: 0.06\n",
            "Similarity between Summary 282 and KB Entry 40: 0.02\n",
            "Similarity between Summary 282 and KB Entry 41: 0.01\n",
            "Similarity between Summary 282 and KB Entry 42: 0.02\n",
            "Similarity between Summary 282 and KB Entry 43: 0.04\n",
            "Similarity between Summary 282 and KB Entry 44: 0.00\n",
            "Similarity between Summary 282 and KB Entry 45: 0.08\n",
            "Similarity between Summary 282 and KB Entry 46: 0.01\n",
            "Similarity between Summary 283 and KB Entry 1: 0.08\n",
            "Similarity between Summary 283 and KB Entry 2: 0.01\n",
            "Similarity between Summary 283 and KB Entry 3: 0.03\n",
            "Similarity between Summary 283 and KB Entry 4: 0.06\n",
            "Similarity between Summary 283 and KB Entry 5: 0.01\n",
            "Similarity between Summary 283 and KB Entry 6: 0.03\n",
            "Similarity between Summary 283 and KB Entry 7: 0.02\n",
            "Similarity between Summary 283 and KB Entry 8: 0.01\n",
            "Similarity between Summary 283 and KB Entry 9: 0.00\n",
            "Similarity between Summary 283 and KB Entry 10: 0.01\n",
            "Similarity between Summary 283 and KB Entry 11: 0.00\n",
            "Similarity between Summary 283 and KB Entry 12: 0.07\n",
            "Similarity between Summary 283 and KB Entry 13: 0.01\n",
            "Similarity between Summary 283 and KB Entry 14: 0.01\n",
            "Similarity between Summary 283 and KB Entry 15: 0.00\n",
            "Similarity between Summary 283 and KB Entry 16: 0.02\n",
            "Similarity between Summary 283 and KB Entry 17: 0.07\n",
            "Similarity between Summary 283 and KB Entry 18: 0.00\n",
            "Similarity between Summary 283 and KB Entry 19: 0.01\n",
            "Similarity between Summary 283 and KB Entry 20: 0.00\n",
            "Similarity between Summary 283 and KB Entry 21: 0.00\n",
            "Similarity between Summary 283 and KB Entry 22: 0.00\n",
            "Similarity between Summary 283 and KB Entry 23: 0.00\n",
            "Similarity between Summary 283 and KB Entry 24: 0.01\n",
            "Similarity between Summary 283 and KB Entry 25: 0.03\n",
            "Similarity between Summary 283 and KB Entry 26: 0.00\n",
            "Similarity between Summary 283 and KB Entry 27: 0.00\n",
            "Similarity between Summary 283 and KB Entry 28: 0.01\n",
            "Similarity between Summary 283 and KB Entry 29: 0.00\n",
            "Similarity between Summary 283 and KB Entry 30: 0.04\n",
            "Similarity between Summary 283 and KB Entry 31: 0.00\n",
            "Similarity between Summary 283 and KB Entry 32: 0.02\n",
            "Similarity between Summary 283 and KB Entry 33: 0.03\n",
            "Similarity between Summary 283 and KB Entry 34: 0.01\n",
            "Similarity between Summary 283 and KB Entry 35: 0.02\n",
            "Similarity between Summary 283 and KB Entry 36: 0.00\n",
            "Similarity between Summary 283 and KB Entry 37: 0.00\n",
            "Similarity between Summary 283 and KB Entry 38: 0.08\n",
            "Similarity between Summary 283 and KB Entry 39: 0.04\n",
            "Similarity between Summary 283 and KB Entry 40: 0.01\n",
            "Similarity between Summary 283 and KB Entry 41: 0.01\n",
            "Similarity between Summary 283 and KB Entry 42: 0.01\n",
            "Similarity between Summary 283 and KB Entry 43: 0.04\n",
            "Similarity between Summary 283 and KB Entry 44: 0.06\n",
            "Similarity between Summary 283 and KB Entry 45: 0.01\n",
            "Similarity between Summary 283 and KB Entry 46: 0.01\n",
            "Similarity between Summary 284 and KB Entry 1: 0.09\n",
            "Similarity between Summary 284 and KB Entry 2: 0.00\n",
            "Similarity between Summary 284 and KB Entry 3: 0.03\n",
            "Similarity between Summary 284 and KB Entry 4: 0.05\n",
            "Similarity between Summary 284 and KB Entry 5: 0.02\n",
            "Similarity between Summary 284 and KB Entry 6: 0.03\n",
            "Similarity between Summary 284 and KB Entry 7: 0.02\n",
            "Similarity between Summary 284 and KB Entry 8: 0.02\n",
            "Similarity between Summary 284 and KB Entry 9: 0.00\n",
            "Similarity between Summary 284 and KB Entry 10: 0.00\n",
            "Similarity between Summary 284 and KB Entry 11: 0.00\n",
            "Similarity between Summary 284 and KB Entry 12: 0.08\n",
            "Similarity between Summary 284 and KB Entry 13: 0.01\n",
            "Similarity between Summary 284 and KB Entry 14: 0.02\n",
            "Similarity between Summary 284 and KB Entry 15: 0.01\n",
            "Similarity between Summary 284 and KB Entry 16: 0.01\n",
            "Similarity between Summary 284 and KB Entry 17: 0.08\n",
            "Similarity between Summary 284 and KB Entry 18: 0.00\n",
            "Similarity between Summary 284 and KB Entry 19: 0.00\n",
            "Similarity between Summary 284 and KB Entry 20: 0.00\n",
            "Similarity between Summary 284 and KB Entry 21: 0.00\n",
            "Similarity between Summary 284 and KB Entry 22: 0.00\n",
            "Similarity between Summary 284 and KB Entry 23: 0.00\n",
            "Similarity between Summary 284 and KB Entry 24: 0.00\n",
            "Similarity between Summary 284 and KB Entry 25: 0.02\n",
            "Similarity between Summary 284 and KB Entry 26: 0.00\n",
            "Similarity between Summary 284 and KB Entry 27: 0.00\n",
            "Similarity between Summary 284 and KB Entry 28: 0.01\n",
            "Similarity between Summary 284 and KB Entry 29: 0.00\n",
            "Similarity between Summary 284 and KB Entry 30: 0.02\n",
            "Similarity between Summary 284 and KB Entry 31: 0.00\n",
            "Similarity between Summary 284 and KB Entry 32: 0.00\n",
            "Similarity between Summary 284 and KB Entry 33: 0.04\n",
            "Similarity between Summary 284 and KB Entry 34: 0.01\n",
            "Similarity between Summary 284 and KB Entry 35: 0.01\n",
            "Similarity between Summary 284 and KB Entry 36: 0.00\n",
            "Similarity between Summary 284 and KB Entry 37: 0.00\n",
            "Similarity between Summary 284 and KB Entry 38: 0.02\n",
            "Similarity between Summary 284 and KB Entry 39: 0.07\n",
            "Similarity between Summary 284 and KB Entry 40: 0.02\n",
            "Similarity between Summary 284 and KB Entry 41: 0.01\n",
            "Similarity between Summary 284 and KB Entry 42: 0.02\n",
            "Similarity between Summary 284 and KB Entry 43: 0.04\n",
            "Similarity between Summary 284 and KB Entry 44: 0.00\n",
            "Similarity between Summary 284 and KB Entry 45: 0.06\n",
            "Similarity between Summary 284 and KB Entry 46: 0.01\n",
            "Similarity between Summary 285 and KB Entry 1: 0.09\n",
            "Similarity between Summary 285 and KB Entry 2: 0.01\n",
            "Similarity between Summary 285 and KB Entry 3: 0.03\n",
            "Similarity between Summary 285 and KB Entry 4: 0.05\n",
            "Similarity between Summary 285 and KB Entry 5: 0.01\n",
            "Similarity between Summary 285 and KB Entry 6: 0.03\n",
            "Similarity between Summary 285 and KB Entry 7: 0.02\n",
            "Similarity between Summary 285 and KB Entry 8: 0.02\n",
            "Similarity between Summary 285 and KB Entry 9: 0.00\n",
            "Similarity between Summary 285 and KB Entry 10: 0.00\n",
            "Similarity between Summary 285 and KB Entry 11: 0.00\n",
            "Similarity between Summary 285 and KB Entry 12: 0.09\n",
            "Similarity between Summary 285 and KB Entry 13: 0.01\n",
            "Similarity between Summary 285 and KB Entry 14: 0.01\n",
            "Similarity between Summary 285 and KB Entry 15: 0.00\n",
            "Similarity between Summary 285 and KB Entry 16: 0.02\n",
            "Similarity between Summary 285 and KB Entry 17: 0.06\n",
            "Similarity between Summary 285 and KB Entry 18: 0.01\n",
            "Similarity between Summary 285 and KB Entry 19: 0.00\n",
            "Similarity between Summary 285 and KB Entry 20: 0.00\n",
            "Similarity between Summary 285 and KB Entry 21: 0.00\n",
            "Similarity between Summary 285 and KB Entry 22: 0.00\n",
            "Similarity between Summary 285 and KB Entry 23: 0.00\n",
            "Similarity between Summary 285 and KB Entry 24: 0.00\n",
            "Similarity between Summary 285 and KB Entry 25: 0.03\n",
            "Similarity between Summary 285 and KB Entry 26: 0.00\n",
            "Similarity between Summary 285 and KB Entry 27: 0.00\n",
            "Similarity between Summary 285 and KB Entry 28: 0.01\n",
            "Similarity between Summary 285 and KB Entry 29: 0.00\n",
            "Similarity between Summary 285 and KB Entry 30: 0.02\n",
            "Similarity between Summary 285 and KB Entry 31: 0.00\n",
            "Similarity between Summary 285 and KB Entry 32: 0.00\n",
            "Similarity between Summary 285 and KB Entry 33: 0.03\n",
            "Similarity between Summary 285 and KB Entry 34: 0.00\n",
            "Similarity between Summary 285 and KB Entry 35: 0.01\n",
            "Similarity between Summary 285 and KB Entry 36: 0.00\n",
            "Similarity between Summary 285 and KB Entry 37: 0.00\n",
            "Similarity between Summary 285 and KB Entry 38: 0.02\n",
            "Similarity between Summary 285 and KB Entry 39: 0.07\n",
            "Similarity between Summary 285 and KB Entry 40: 0.02\n",
            "Similarity between Summary 285 and KB Entry 41: 0.01\n",
            "Similarity between Summary 285 and KB Entry 42: 0.02\n",
            "Similarity between Summary 285 and KB Entry 43: 0.05\n",
            "Similarity between Summary 285 and KB Entry 44: 0.00\n",
            "Similarity between Summary 285 and KB Entry 45: 0.07\n",
            "Similarity between Summary 285 and KB Entry 46: 0.01\n",
            "Similarity between Summary 286 and KB Entry 1: 0.06\n",
            "Similarity between Summary 286 and KB Entry 2: 0.01\n",
            "Similarity between Summary 286 and KB Entry 3: 0.05\n",
            "Similarity between Summary 286 and KB Entry 4: 0.06\n",
            "Similarity between Summary 286 and KB Entry 5: 0.00\n",
            "Similarity between Summary 286 and KB Entry 6: 0.02\n",
            "Similarity between Summary 286 and KB Entry 7: 0.02\n",
            "Similarity between Summary 286 and KB Entry 8: 0.02\n",
            "Similarity between Summary 286 and KB Entry 9: 0.02\n",
            "Similarity between Summary 286 and KB Entry 10: 0.02\n",
            "Similarity between Summary 286 and KB Entry 11: 0.01\n",
            "Similarity between Summary 286 and KB Entry 12: 0.06\n",
            "Similarity between Summary 286 and KB Entry 13: 0.01\n",
            "Similarity between Summary 286 and KB Entry 14: 0.01\n",
            "Similarity between Summary 286 and KB Entry 15: 0.01\n",
            "Similarity between Summary 286 and KB Entry 16: 0.03\n",
            "Similarity between Summary 286 and KB Entry 17: 0.06\n",
            "Similarity between Summary 286 and KB Entry 18: 0.00\n",
            "Similarity between Summary 286 and KB Entry 19: 0.00\n",
            "Similarity between Summary 286 and KB Entry 20: 0.00\n",
            "Similarity between Summary 286 and KB Entry 21: 0.01\n",
            "Similarity between Summary 286 and KB Entry 22: 0.01\n",
            "Similarity between Summary 286 and KB Entry 23: 0.00\n",
            "Similarity between Summary 286 and KB Entry 24: 0.02\n",
            "Similarity between Summary 286 and KB Entry 25: 0.06\n",
            "Similarity between Summary 286 and KB Entry 26: 0.00\n",
            "Similarity between Summary 286 and KB Entry 27: 0.01\n",
            "Similarity between Summary 286 and KB Entry 28: 0.01\n",
            "Similarity between Summary 286 and KB Entry 29: 0.00\n",
            "Similarity between Summary 286 and KB Entry 30: 0.05\n",
            "Similarity between Summary 286 and KB Entry 31: 0.00\n",
            "Similarity between Summary 286 and KB Entry 32: 0.10\n",
            "Similarity between Summary 286 and KB Entry 33: 0.07\n",
            "Similarity between Summary 286 and KB Entry 34: 0.01\n",
            "Similarity between Summary 286 and KB Entry 35: 0.01\n",
            "Similarity between Summary 286 and KB Entry 36: 0.01\n",
            "Similarity between Summary 286 and KB Entry 37: 0.00\n",
            "Similarity between Summary 286 and KB Entry 38: 0.02\n",
            "Similarity between Summary 286 and KB Entry 39: 0.03\n",
            "Similarity between Summary 286 and KB Entry 40: 0.02\n",
            "Similarity between Summary 286 and KB Entry 41: 0.01\n",
            "Similarity between Summary 286 and KB Entry 42: 0.02\n",
            "Similarity between Summary 286 and KB Entry 43: 0.06\n",
            "Similarity between Summary 286 and KB Entry 44: 0.11\n",
            "Similarity between Summary 286 and KB Entry 45: 0.00\n",
            "Similarity between Summary 286 and KB Entry 46: 0.01\n",
            "Similarity between Summary 287 and KB Entry 1: 0.06\n",
            "Similarity between Summary 287 and KB Entry 2: 0.01\n",
            "Similarity between Summary 287 and KB Entry 3: 0.05\n",
            "Similarity between Summary 287 and KB Entry 4: 0.07\n",
            "Similarity between Summary 287 and KB Entry 5: 0.00\n",
            "Similarity between Summary 287 and KB Entry 6: 0.02\n",
            "Similarity between Summary 287 and KB Entry 7: 0.02\n",
            "Similarity between Summary 287 and KB Entry 8: 0.02\n",
            "Similarity between Summary 287 and KB Entry 9: 0.02\n",
            "Similarity between Summary 287 and KB Entry 10: 0.03\n",
            "Similarity between Summary 287 and KB Entry 11: 0.01\n",
            "Similarity between Summary 287 and KB Entry 12: 0.06\n",
            "Similarity between Summary 287 and KB Entry 13: 0.01\n",
            "Similarity between Summary 287 and KB Entry 14: 0.01\n",
            "Similarity between Summary 287 and KB Entry 15: 0.01\n",
            "Similarity between Summary 287 and KB Entry 16: 0.03\n",
            "Similarity between Summary 287 and KB Entry 17: 0.06\n",
            "Similarity between Summary 287 and KB Entry 18: 0.00\n",
            "Similarity between Summary 287 and KB Entry 19: 0.00\n",
            "Similarity between Summary 287 and KB Entry 20: 0.00\n",
            "Similarity between Summary 287 and KB Entry 21: 0.01\n",
            "Similarity between Summary 287 and KB Entry 22: 0.01\n",
            "Similarity between Summary 287 and KB Entry 23: 0.00\n",
            "Similarity between Summary 287 and KB Entry 24: 0.02\n",
            "Similarity between Summary 287 and KB Entry 25: 0.06\n",
            "Similarity between Summary 287 and KB Entry 26: 0.00\n",
            "Similarity between Summary 287 and KB Entry 27: 0.01\n",
            "Similarity between Summary 287 and KB Entry 28: 0.01\n",
            "Similarity between Summary 287 and KB Entry 29: 0.00\n",
            "Similarity between Summary 287 and KB Entry 30: 0.07\n",
            "Similarity between Summary 287 and KB Entry 31: 0.00\n",
            "Similarity between Summary 287 and KB Entry 32: 0.00\n",
            "Similarity between Summary 287 and KB Entry 33: 0.05\n",
            "Similarity between Summary 287 and KB Entry 34: 0.01\n",
            "Similarity between Summary 287 and KB Entry 35: 0.01\n",
            "Similarity between Summary 287 and KB Entry 36: 0.01\n",
            "Similarity between Summary 287 and KB Entry 37: 0.00\n",
            "Similarity between Summary 287 and KB Entry 38: 0.01\n",
            "Similarity between Summary 287 and KB Entry 39: 0.04\n",
            "Similarity between Summary 287 and KB Entry 40: 0.02\n",
            "Similarity between Summary 287 and KB Entry 41: 0.01\n",
            "Similarity between Summary 287 and KB Entry 42: 0.02\n",
            "Similarity between Summary 287 and KB Entry 43: 0.06\n",
            "Similarity between Summary 287 and KB Entry 44: 0.11\n",
            "Similarity between Summary 287 and KB Entry 45: 0.00\n",
            "Similarity between Summary 287 and KB Entry 46: 0.01\n",
            "Similarity between Summary 288 and KB Entry 1: 0.07\n",
            "Similarity between Summary 288 and KB Entry 2: 0.01\n",
            "Similarity between Summary 288 and KB Entry 3: 0.05\n",
            "Similarity between Summary 288 and KB Entry 4: 0.08\n",
            "Similarity between Summary 288 and KB Entry 5: 0.00\n",
            "Similarity between Summary 288 and KB Entry 6: 0.03\n",
            "Similarity between Summary 288 and KB Entry 7: 0.02\n",
            "Similarity between Summary 288 and KB Entry 8: 0.02\n",
            "Similarity between Summary 288 and KB Entry 9: 0.02\n",
            "Similarity between Summary 288 and KB Entry 10: 0.03\n",
            "Similarity between Summary 288 and KB Entry 11: 0.01\n",
            "Similarity between Summary 288 and KB Entry 12: 0.07\n",
            "Similarity between Summary 288 and KB Entry 13: 0.01\n",
            "Similarity between Summary 288 and KB Entry 14: 0.01\n",
            "Similarity between Summary 288 and KB Entry 15: 0.01\n",
            "Similarity between Summary 288 and KB Entry 16: 0.04\n",
            "Similarity between Summary 288 and KB Entry 17: 0.04\n",
            "Similarity between Summary 288 and KB Entry 18: 0.00\n",
            "Similarity between Summary 288 and KB Entry 19: 0.00\n",
            "Similarity between Summary 288 and KB Entry 20: 0.00\n",
            "Similarity between Summary 288 and KB Entry 21: 0.01\n",
            "Similarity between Summary 288 and KB Entry 22: 0.01\n",
            "Similarity between Summary 288 and KB Entry 23: 0.00\n",
            "Similarity between Summary 288 and KB Entry 24: 0.00\n",
            "Similarity between Summary 288 and KB Entry 25: 0.06\n",
            "Similarity between Summary 288 and KB Entry 26: 0.00\n",
            "Similarity between Summary 288 and KB Entry 27: 0.01\n",
            "Similarity between Summary 288 and KB Entry 28: 0.01\n",
            "Similarity between Summary 288 and KB Entry 29: 0.00\n",
            "Similarity between Summary 288 and KB Entry 30: 0.02\n",
            "Similarity between Summary 288 and KB Entry 31: 0.00\n",
            "Similarity between Summary 288 and KB Entry 32: 0.00\n",
            "Similarity between Summary 288 and KB Entry 33: 0.05\n",
            "Similarity between Summary 288 and KB Entry 34: 0.01\n",
            "Similarity between Summary 288 and KB Entry 35: 0.01\n",
            "Similarity between Summary 288 and KB Entry 36: 0.01\n",
            "Similarity between Summary 288 and KB Entry 37: 0.00\n",
            "Similarity between Summary 288 and KB Entry 38: 0.02\n",
            "Similarity between Summary 288 and KB Entry 39: 0.04\n",
            "Similarity between Summary 288 and KB Entry 40: 0.02\n",
            "Similarity between Summary 288 and KB Entry 41: 0.01\n",
            "Similarity between Summary 288 and KB Entry 42: 0.03\n",
            "Similarity between Summary 288 and KB Entry 43: 0.06\n",
            "Similarity between Summary 288 and KB Entry 44: 0.11\n",
            "Similarity between Summary 288 and KB Entry 45: 0.01\n",
            "Similarity between Summary 288 and KB Entry 46: 0.01\n",
            "Similarity between Summary 289 and KB Entry 1: 0.08\n",
            "Similarity between Summary 289 and KB Entry 2: 0.01\n",
            "Similarity between Summary 289 and KB Entry 3: 0.04\n",
            "Similarity between Summary 289 and KB Entry 4: 0.07\n",
            "Similarity between Summary 289 and KB Entry 5: 0.01\n",
            "Similarity between Summary 289 and KB Entry 6: 0.02\n",
            "Similarity between Summary 289 and KB Entry 7: 0.03\n",
            "Similarity between Summary 289 and KB Entry 8: 0.02\n",
            "Similarity between Summary 289 and KB Entry 9: 0.01\n",
            "Similarity between Summary 289 and KB Entry 10: 0.03\n",
            "Similarity between Summary 289 and KB Entry 11: 0.02\n",
            "Similarity between Summary 289 and KB Entry 12: 0.03\n",
            "Similarity between Summary 289 and KB Entry 13: 0.01\n",
            "Similarity between Summary 289 and KB Entry 14: 0.01\n",
            "Similarity between Summary 289 and KB Entry 15: 0.01\n",
            "Similarity between Summary 289 and KB Entry 16: 0.00\n",
            "Similarity between Summary 289 and KB Entry 17: 0.03\n",
            "Similarity between Summary 289 and KB Entry 18: 0.00\n",
            "Similarity between Summary 289 and KB Entry 19: 0.00\n",
            "Similarity between Summary 289 and KB Entry 20: 0.00\n",
            "Similarity between Summary 289 and KB Entry 21: 0.00\n",
            "Similarity between Summary 289 and KB Entry 22: 0.01\n",
            "Similarity between Summary 289 and KB Entry 23: 0.00\n",
            "Similarity between Summary 289 and KB Entry 24: 0.00\n",
            "Similarity between Summary 289 and KB Entry 25: 0.00\n",
            "Similarity between Summary 289 and KB Entry 26: 0.00\n",
            "Similarity between Summary 289 and KB Entry 27: 0.01\n",
            "Similarity between Summary 289 and KB Entry 28: 0.01\n",
            "Similarity between Summary 289 and KB Entry 29: 0.00\n",
            "Similarity between Summary 289 and KB Entry 30: 0.02\n",
            "Similarity between Summary 289 and KB Entry 31: 0.00\n",
            "Similarity between Summary 289 and KB Entry 32: 0.04\n",
            "Similarity between Summary 289 and KB Entry 33: 0.06\n",
            "Similarity between Summary 289 and KB Entry 34: 0.00\n",
            "Similarity between Summary 289 and KB Entry 35: 0.01\n",
            "Similarity between Summary 289 and KB Entry 36: 0.00\n",
            "Similarity between Summary 289 and KB Entry 37: 0.01\n",
            "Similarity between Summary 289 and KB Entry 38: 0.02\n",
            "Similarity between Summary 289 and KB Entry 39: 0.03\n",
            "Similarity between Summary 289 and KB Entry 40: 0.02\n",
            "Similarity between Summary 289 and KB Entry 41: 0.02\n",
            "Similarity between Summary 289 and KB Entry 42: 0.02\n",
            "Similarity between Summary 289 and KB Entry 43: 0.06\n",
            "Similarity between Summary 289 and KB Entry 44: 0.03\n",
            "Similarity between Summary 289 and KB Entry 45: 0.00\n",
            "Similarity between Summary 289 and KB Entry 46: 0.01\n",
            "Similarity between Summary 290 and KB Entry 1: 0.06\n",
            "Similarity between Summary 290 and KB Entry 2: 0.01\n",
            "Similarity between Summary 290 and KB Entry 3: 0.04\n",
            "Similarity between Summary 290 and KB Entry 4: 0.10\n",
            "Similarity between Summary 290 and KB Entry 5: 0.01\n",
            "Similarity between Summary 290 and KB Entry 6: 0.02\n",
            "Similarity between Summary 290 and KB Entry 7: 0.03\n",
            "Similarity between Summary 290 and KB Entry 8: 0.02\n",
            "Similarity between Summary 290 and KB Entry 9: 0.01\n",
            "Similarity between Summary 290 and KB Entry 10: 0.06\n",
            "Similarity between Summary 290 and KB Entry 11: 0.04\n",
            "Similarity between Summary 290 and KB Entry 12: 0.02\n",
            "Similarity between Summary 290 and KB Entry 13: 0.01\n",
            "Similarity between Summary 290 and KB Entry 14: 0.01\n",
            "Similarity between Summary 290 and KB Entry 15: 0.01\n",
            "Similarity between Summary 290 and KB Entry 16: 0.00\n",
            "Similarity between Summary 290 and KB Entry 17: 0.03\n",
            "Similarity between Summary 290 and KB Entry 18: 0.01\n",
            "Similarity between Summary 290 and KB Entry 19: 0.00\n",
            "Similarity between Summary 290 and KB Entry 20: 0.00\n",
            "Similarity between Summary 290 and KB Entry 21: 0.00\n",
            "Similarity between Summary 290 and KB Entry 22: 0.01\n",
            "Similarity between Summary 290 and KB Entry 23: 0.00\n",
            "Similarity between Summary 290 and KB Entry 24: 0.01\n",
            "Similarity between Summary 290 and KB Entry 25: 0.00\n",
            "Similarity between Summary 290 and KB Entry 26: 0.01\n",
            "Similarity between Summary 290 and KB Entry 27: 0.01\n",
            "Similarity between Summary 290 and KB Entry 28: 0.01\n",
            "Similarity between Summary 290 and KB Entry 29: 0.01\n",
            "Similarity between Summary 290 and KB Entry 30: 0.01\n",
            "Similarity between Summary 290 and KB Entry 31: 0.00\n",
            "Similarity between Summary 290 and KB Entry 32: 0.02\n",
            "Similarity between Summary 290 and KB Entry 33: 0.03\n",
            "Similarity between Summary 290 and KB Entry 34: 0.00\n",
            "Similarity between Summary 290 and KB Entry 35: 0.01\n",
            "Similarity between Summary 290 and KB Entry 36: 0.00\n",
            "Similarity between Summary 290 and KB Entry 37: 0.01\n",
            "Similarity between Summary 290 and KB Entry 38: 0.02\n",
            "Similarity between Summary 290 and KB Entry 39: 0.03\n",
            "Similarity between Summary 290 and KB Entry 40: 0.02\n",
            "Similarity between Summary 290 and KB Entry 41: 0.02\n",
            "Similarity between Summary 290 and KB Entry 42: 0.01\n",
            "Similarity between Summary 290 and KB Entry 43: 0.06\n",
            "Similarity between Summary 290 and KB Entry 44: 0.03\n",
            "Similarity between Summary 290 and KB Entry 45: 0.00\n",
            "Similarity between Summary 290 and KB Entry 46: 0.01\n",
            "Similarity between Summary 291 and KB Entry 1: 0.11\n",
            "Similarity between Summary 291 and KB Entry 2: 0.01\n",
            "Similarity between Summary 291 and KB Entry 3: 0.04\n",
            "Similarity between Summary 291 and KB Entry 4: 0.07\n",
            "Similarity between Summary 291 and KB Entry 5: 0.00\n",
            "Similarity between Summary 291 and KB Entry 6: 0.02\n",
            "Similarity between Summary 291 and KB Entry 7: 0.02\n",
            "Similarity between Summary 291 and KB Entry 8: 0.00\n",
            "Similarity between Summary 291 and KB Entry 9: 0.00\n",
            "Similarity between Summary 291 and KB Entry 10: 0.00\n",
            "Similarity between Summary 291 and KB Entry 11: 0.00\n",
            "Similarity between Summary 291 and KB Entry 12: 0.04\n",
            "Similarity between Summary 291 and KB Entry 13: 0.01\n",
            "Similarity between Summary 291 and KB Entry 14: 0.02\n",
            "Similarity between Summary 291 and KB Entry 15: 0.01\n",
            "Similarity between Summary 291 and KB Entry 16: 0.00\n",
            "Similarity between Summary 291 and KB Entry 17: 0.13\n",
            "Similarity between Summary 291 and KB Entry 18: 0.01\n",
            "Similarity between Summary 291 and KB Entry 19: 0.03\n",
            "Similarity between Summary 291 and KB Entry 20: 0.00\n",
            "Similarity between Summary 291 and KB Entry 21: 0.00\n",
            "Similarity between Summary 291 and KB Entry 22: 0.00\n",
            "Similarity between Summary 291 and KB Entry 23: 0.00\n",
            "Similarity between Summary 291 and KB Entry 24: 0.01\n",
            "Similarity between Summary 291 and KB Entry 25: 0.01\n",
            "Similarity between Summary 291 and KB Entry 26: 0.04\n",
            "Similarity between Summary 291 and KB Entry 27: 0.07\n",
            "Similarity between Summary 291 and KB Entry 28: 0.04\n",
            "Similarity between Summary 291 and KB Entry 29: 0.00\n",
            "Similarity between Summary 291 and KB Entry 30: 0.02\n",
            "Similarity between Summary 291 and KB Entry 31: 0.00\n",
            "Similarity between Summary 291 and KB Entry 32: 0.01\n",
            "Similarity between Summary 291 and KB Entry 33: 0.04\n",
            "Similarity between Summary 291 and KB Entry 34: 0.04\n",
            "Similarity between Summary 291 and KB Entry 35: 0.00\n",
            "Similarity between Summary 291 and KB Entry 36: 0.00\n",
            "Similarity between Summary 291 and KB Entry 37: 0.03\n",
            "Similarity between Summary 291 and KB Entry 38: 0.03\n",
            "Similarity between Summary 291 and KB Entry 39: 0.00\n",
            "Similarity between Summary 291 and KB Entry 40: 0.02\n",
            "Similarity between Summary 291 and KB Entry 41: 0.03\n",
            "Similarity between Summary 291 and KB Entry 42: 0.01\n",
            "Similarity between Summary 291 and KB Entry 43: 0.01\n",
            "Similarity between Summary 291 and KB Entry 44: 0.04\n",
            "Similarity between Summary 291 and KB Entry 45: 0.00\n",
            "Similarity between Summary 291 and KB Entry 46: 0.00\n",
            "Similarity between Summary 292 and KB Entry 1: 0.06\n",
            "Similarity between Summary 292 and KB Entry 2: 0.01\n",
            "Similarity between Summary 292 and KB Entry 3: 0.03\n",
            "Similarity between Summary 292 and KB Entry 4: 0.05\n",
            "Similarity between Summary 292 and KB Entry 5: 0.00\n",
            "Similarity between Summary 292 and KB Entry 6: 0.02\n",
            "Similarity between Summary 292 and KB Entry 7: 0.02\n",
            "Similarity between Summary 292 and KB Entry 8: 0.01\n",
            "Similarity between Summary 292 and KB Entry 9: 0.01\n",
            "Similarity between Summary 292 and KB Entry 10: 0.02\n",
            "Similarity between Summary 292 and KB Entry 11: 0.01\n",
            "Similarity between Summary 292 and KB Entry 12: 0.25\n",
            "Similarity between Summary 292 and KB Entry 13: 0.01\n",
            "Similarity between Summary 292 and KB Entry 14: 0.01\n",
            "Similarity between Summary 292 and KB Entry 15: 0.00\n",
            "Similarity between Summary 292 and KB Entry 16: 0.00\n",
            "Similarity between Summary 292 and KB Entry 17: 0.08\n",
            "Similarity between Summary 292 and KB Entry 18: 0.00\n",
            "Similarity between Summary 292 and KB Entry 19: 0.00\n",
            "Similarity between Summary 292 and KB Entry 20: 0.00\n",
            "Similarity between Summary 292 and KB Entry 21: 0.01\n",
            "Similarity between Summary 292 and KB Entry 22: 0.00\n",
            "Similarity between Summary 292 and KB Entry 23: 0.00\n",
            "Similarity between Summary 292 and KB Entry 24: 0.01\n",
            "Similarity between Summary 292 and KB Entry 25: 0.08\n",
            "Similarity between Summary 292 and KB Entry 26: 0.00\n",
            "Similarity between Summary 292 and KB Entry 27: 0.00\n",
            "Similarity between Summary 292 and KB Entry 28: 0.01\n",
            "Similarity between Summary 292 and KB Entry 29: 0.00\n",
            "Similarity between Summary 292 and KB Entry 30: 0.03\n",
            "Similarity between Summary 292 and KB Entry 31: 0.02\n",
            "Similarity between Summary 292 and KB Entry 32: 0.03\n",
            "Similarity between Summary 292 and KB Entry 33: 0.03\n",
            "Similarity between Summary 292 and KB Entry 34: 0.02\n",
            "Similarity between Summary 292 and KB Entry 35: 0.01\n",
            "Similarity between Summary 292 and KB Entry 36: 0.00\n",
            "Similarity between Summary 292 and KB Entry 37: 0.01\n",
            "Similarity between Summary 292 and KB Entry 38: 0.04\n",
            "Similarity between Summary 292 and KB Entry 39: 0.04\n",
            "Similarity between Summary 292 and KB Entry 40: 0.03\n",
            "Similarity between Summary 292 and KB Entry 41: 0.02\n",
            "Similarity between Summary 292 and KB Entry 42: 0.01\n",
            "Similarity between Summary 292 and KB Entry 43: 0.02\n",
            "Similarity between Summary 292 and KB Entry 44: 0.03\n",
            "Similarity between Summary 292 and KB Entry 45: 0.00\n",
            "Similarity between Summary 292 and KB Entry 46: 0.01\n",
            "Similarity between Summary 293 and KB Entry 1: 0.08\n",
            "Similarity between Summary 293 and KB Entry 2: 0.01\n",
            "Similarity between Summary 293 and KB Entry 3: 0.04\n",
            "Similarity between Summary 293 and KB Entry 4: 0.07\n",
            "Similarity between Summary 293 and KB Entry 5: 0.01\n",
            "Similarity between Summary 293 and KB Entry 6: 0.03\n",
            "Similarity between Summary 293 and KB Entry 7: 0.02\n",
            "Similarity between Summary 293 and KB Entry 8: 0.01\n",
            "Similarity between Summary 293 and KB Entry 9: 0.00\n",
            "Similarity between Summary 293 and KB Entry 10: 0.00\n",
            "Similarity between Summary 293 and KB Entry 11: 0.00\n",
            "Similarity between Summary 293 and KB Entry 12: 0.05\n",
            "Similarity between Summary 293 and KB Entry 13: 0.01\n",
            "Similarity between Summary 293 and KB Entry 14: 0.01\n",
            "Similarity between Summary 293 and KB Entry 15: 0.00\n",
            "Similarity between Summary 293 and KB Entry 16: 0.02\n",
            "Similarity between Summary 293 and KB Entry 17: 0.10\n",
            "Similarity between Summary 293 and KB Entry 18: 0.01\n",
            "Similarity between Summary 293 and KB Entry 19: 0.02\n",
            "Similarity between Summary 293 and KB Entry 20: 0.04\n",
            "Similarity between Summary 293 and KB Entry 21: 0.03\n",
            "Similarity between Summary 293 and KB Entry 22: 0.02\n",
            "Similarity between Summary 293 and KB Entry 23: 0.02\n",
            "Similarity between Summary 293 and KB Entry 24: 0.01\n",
            "Similarity between Summary 293 and KB Entry 25: 0.08\n",
            "Similarity between Summary 293 and KB Entry 26: 0.02\n",
            "Similarity between Summary 293 and KB Entry 27: 0.03\n",
            "Similarity between Summary 293 and KB Entry 28: 0.02\n",
            "Similarity between Summary 293 and KB Entry 29: 0.00\n",
            "Similarity between Summary 293 and KB Entry 30: 0.02\n",
            "Similarity between Summary 293 and KB Entry 31: 0.00\n",
            "Similarity between Summary 293 and KB Entry 32: 0.01\n",
            "Similarity between Summary 293 and KB Entry 33: 0.08\n",
            "Similarity between Summary 293 and KB Entry 34: 0.01\n",
            "Similarity between Summary 293 and KB Entry 35: 0.02\n",
            "Similarity between Summary 293 and KB Entry 36: 0.01\n",
            "Similarity between Summary 293 and KB Entry 37: 0.01\n",
            "Similarity between Summary 293 and KB Entry 38: 0.02\n",
            "Similarity between Summary 293 and KB Entry 39: 0.02\n",
            "Similarity between Summary 293 and KB Entry 40: 0.01\n",
            "Similarity between Summary 293 and KB Entry 41: 0.01\n",
            "Similarity between Summary 293 and KB Entry 42: 0.02\n",
            "Similarity between Summary 293 and KB Entry 43: 0.03\n",
            "Similarity between Summary 293 and KB Entry 44: 0.02\n",
            "Similarity between Summary 293 and KB Entry 45: 0.00\n",
            "Similarity between Summary 293 and KB Entry 46: 0.00\n",
            "Similarity between Summary 294 and KB Entry 1: 0.13\n",
            "Similarity between Summary 294 and KB Entry 2: 0.01\n",
            "Similarity between Summary 294 and KB Entry 3: 0.03\n",
            "Similarity between Summary 294 and KB Entry 4: 0.06\n",
            "Similarity between Summary 294 and KB Entry 5: 0.00\n",
            "Similarity between Summary 294 and KB Entry 6: 0.02\n",
            "Similarity between Summary 294 and KB Entry 7: 0.01\n",
            "Similarity between Summary 294 and KB Entry 8: 0.00\n",
            "Similarity between Summary 294 and KB Entry 9: 0.00\n",
            "Similarity between Summary 294 and KB Entry 10: 0.00\n",
            "Similarity between Summary 294 and KB Entry 11: 0.00\n",
            "Similarity between Summary 294 and KB Entry 12: 0.04\n",
            "Similarity between Summary 294 and KB Entry 13: 0.02\n",
            "Similarity between Summary 294 and KB Entry 14: 0.03\n",
            "Similarity between Summary 294 and KB Entry 15: 0.01\n",
            "Similarity between Summary 294 and KB Entry 16: 0.00\n",
            "Similarity between Summary 294 and KB Entry 17: 0.14\n",
            "Similarity between Summary 294 and KB Entry 18: 0.01\n",
            "Similarity between Summary 294 and KB Entry 19: 0.08\n",
            "Similarity between Summary 294 and KB Entry 20: 0.00\n",
            "Similarity between Summary 294 and KB Entry 21: 0.02\n",
            "Similarity between Summary 294 and KB Entry 22: 0.00\n",
            "Similarity between Summary 294 and KB Entry 23: 0.04\n",
            "Similarity between Summary 294 and KB Entry 24: 0.01\n",
            "Similarity between Summary 294 and KB Entry 25: 0.01\n",
            "Similarity between Summary 294 and KB Entry 26: 0.06\n",
            "Similarity between Summary 294 and KB Entry 27: 0.08\n",
            "Similarity between Summary 294 and KB Entry 28: 0.02\n",
            "Similarity between Summary 294 and KB Entry 29: 0.11\n",
            "Similarity between Summary 294 and KB Entry 30: 0.00\n",
            "Similarity between Summary 294 and KB Entry 31: 0.00\n",
            "Similarity between Summary 294 and KB Entry 32: 0.00\n",
            "Similarity between Summary 294 and KB Entry 33: 0.04\n",
            "Similarity between Summary 294 and KB Entry 34: 0.00\n",
            "Similarity between Summary 294 and KB Entry 35: 0.01\n",
            "Similarity between Summary 294 and KB Entry 36: 0.00\n",
            "Similarity between Summary 294 and KB Entry 37: 0.00\n",
            "Similarity between Summary 294 and KB Entry 38: 0.02\n",
            "Similarity between Summary 294 and KB Entry 39: 0.00\n",
            "Similarity between Summary 294 and KB Entry 40: 0.02\n",
            "Similarity between Summary 294 and KB Entry 41: 0.02\n",
            "Similarity between Summary 294 and KB Entry 42: 0.01\n",
            "Similarity between Summary 294 and KB Entry 43: 0.01\n",
            "Similarity between Summary 294 and KB Entry 44: 0.05\n",
            "Similarity between Summary 294 and KB Entry 45: 0.01\n",
            "Similarity between Summary 294 and KB Entry 46: 0.01\n",
            "Similarity between Summary 295 and KB Entry 1: 0.05\n",
            "Similarity between Summary 295 and KB Entry 2: 0.01\n",
            "Similarity between Summary 295 and KB Entry 3: 0.02\n",
            "Similarity between Summary 295 and KB Entry 4: 0.03\n",
            "Similarity between Summary 295 and KB Entry 5: 0.01\n",
            "Similarity between Summary 295 and KB Entry 6: 0.01\n",
            "Similarity between Summary 295 and KB Entry 7: 0.02\n",
            "Similarity between Summary 295 and KB Entry 8: 0.01\n",
            "Similarity between Summary 295 and KB Entry 9: 0.01\n",
            "Similarity between Summary 295 and KB Entry 10: 0.00\n",
            "Similarity between Summary 295 and KB Entry 11: 0.00\n",
            "Similarity between Summary 295 and KB Entry 12: 0.03\n",
            "Similarity between Summary 295 and KB Entry 13: 0.01\n",
            "Similarity between Summary 295 and KB Entry 14: 0.00\n",
            "Similarity between Summary 295 and KB Entry 15: 0.00\n",
            "Similarity between Summary 295 and KB Entry 16: 0.01\n",
            "Similarity between Summary 295 and KB Entry 17: 0.11\n",
            "Similarity between Summary 295 and KB Entry 18: 0.00\n",
            "Similarity between Summary 295 and KB Entry 19: 0.00\n",
            "Similarity between Summary 295 and KB Entry 20: 0.00\n",
            "Similarity between Summary 295 and KB Entry 21: 0.02\n",
            "Similarity between Summary 295 and KB Entry 22: 0.00\n",
            "Similarity between Summary 295 and KB Entry 23: 0.02\n",
            "Similarity between Summary 295 and KB Entry 24: 0.02\n",
            "Similarity between Summary 295 and KB Entry 25: 0.08\n",
            "Similarity between Summary 295 and KB Entry 26: 0.00\n",
            "Similarity between Summary 295 and KB Entry 27: 0.00\n",
            "Similarity between Summary 295 and KB Entry 28: 0.01\n",
            "Similarity between Summary 295 and KB Entry 29: 0.00\n",
            "Similarity between Summary 295 and KB Entry 30: 0.03\n",
            "Similarity between Summary 295 and KB Entry 31: 0.01\n",
            "Similarity between Summary 295 and KB Entry 32: 0.03\n",
            "Similarity between Summary 295 and KB Entry 33: 0.05\n",
            "Similarity between Summary 295 and KB Entry 34: 0.00\n",
            "Similarity between Summary 295 and KB Entry 35: 0.01\n",
            "Similarity between Summary 295 and KB Entry 36: 0.00\n",
            "Similarity between Summary 295 and KB Entry 37: 0.01\n",
            "Similarity between Summary 295 and KB Entry 38: 0.02\n",
            "Similarity between Summary 295 and KB Entry 39: 0.03\n",
            "Similarity between Summary 295 and KB Entry 40: 0.02\n",
            "Similarity between Summary 295 and KB Entry 41: 0.01\n",
            "Similarity between Summary 295 and KB Entry 42: 0.00\n",
            "Similarity between Summary 295 and KB Entry 43: 0.00\n",
            "Similarity between Summary 295 and KB Entry 44: 0.03\n",
            "Similarity between Summary 295 and KB Entry 45: 0.01\n",
            "Similarity between Summary 295 and KB Entry 46: 0.00\n",
            "Similarity between Summary 296 and KB Entry 1: 0.06\n",
            "Similarity between Summary 296 and KB Entry 2: 0.01\n",
            "Similarity between Summary 296 and KB Entry 3: 0.02\n",
            "Similarity between Summary 296 and KB Entry 4: 0.04\n",
            "Similarity between Summary 296 and KB Entry 5: 0.01\n",
            "Similarity between Summary 296 and KB Entry 6: 0.01\n",
            "Similarity between Summary 296 and KB Entry 7: 0.03\n",
            "Similarity between Summary 296 and KB Entry 8: 0.01\n",
            "Similarity between Summary 296 and KB Entry 9: 0.02\n",
            "Similarity between Summary 296 and KB Entry 10: 0.00\n",
            "Similarity between Summary 296 and KB Entry 11: 0.00\n",
            "Similarity between Summary 296 and KB Entry 12: 0.03\n",
            "Similarity between Summary 296 and KB Entry 13: 0.01\n",
            "Similarity between Summary 296 and KB Entry 14: 0.00\n",
            "Similarity between Summary 296 and KB Entry 15: 0.00\n",
            "Similarity between Summary 296 and KB Entry 16: 0.01\n",
            "Similarity between Summary 296 and KB Entry 17: 0.07\n",
            "Similarity between Summary 296 and KB Entry 18: 0.00\n",
            "Similarity between Summary 296 and KB Entry 19: 0.00\n",
            "Similarity between Summary 296 and KB Entry 20: 0.00\n",
            "Similarity between Summary 296 and KB Entry 21: 0.02\n",
            "Similarity between Summary 296 and KB Entry 22: 0.00\n",
            "Similarity between Summary 296 and KB Entry 23: 0.02\n",
            "Similarity between Summary 296 and KB Entry 24: 0.00\n",
            "Similarity between Summary 296 and KB Entry 25: 0.07\n",
            "Similarity between Summary 296 and KB Entry 26: 0.00\n",
            "Similarity between Summary 296 and KB Entry 27: 0.00\n",
            "Similarity between Summary 296 and KB Entry 28: 0.01\n",
            "Similarity between Summary 296 and KB Entry 29: 0.00\n",
            "Similarity between Summary 296 and KB Entry 30: 0.00\n",
            "Similarity between Summary 296 and KB Entry 31: 0.00\n",
            "Similarity between Summary 296 and KB Entry 32: 0.00\n",
            "Similarity between Summary 296 and KB Entry 33: 0.05\n",
            "Similarity between Summary 296 and KB Entry 34: 0.00\n",
            "Similarity between Summary 296 and KB Entry 35: 0.01\n",
            "Similarity between Summary 296 and KB Entry 36: 0.00\n",
            "Similarity between Summary 296 and KB Entry 37: 0.01\n",
            "Similarity between Summary 296 and KB Entry 38: 0.02\n",
            "Similarity between Summary 296 and KB Entry 39: 0.03\n",
            "Similarity between Summary 296 and KB Entry 40: 0.02\n",
            "Similarity between Summary 296 and KB Entry 41: 0.01\n",
            "Similarity between Summary 296 and KB Entry 42: 0.00\n",
            "Similarity between Summary 296 and KB Entry 43: 0.01\n",
            "Similarity between Summary 296 and KB Entry 44: 0.04\n",
            "Similarity between Summary 296 and KB Entry 45: 0.01\n",
            "Similarity between Summary 296 and KB Entry 46: 0.00\n",
            "Similarity between Summary 297 and KB Entry 1: 0.10\n",
            "Similarity between Summary 297 and KB Entry 2: 0.01\n",
            "Similarity between Summary 297 and KB Entry 3: 0.03\n",
            "Similarity between Summary 297 and KB Entry 4: 0.06\n",
            "Similarity between Summary 297 and KB Entry 5: 0.02\n",
            "Similarity between Summary 297 and KB Entry 6: 0.04\n",
            "Similarity between Summary 297 and KB Entry 7: 0.02\n",
            "Similarity between Summary 297 and KB Entry 8: 0.03\n",
            "Similarity between Summary 297 and KB Entry 9: 0.00\n",
            "Similarity between Summary 297 and KB Entry 10: 0.01\n",
            "Similarity between Summary 297 and KB Entry 11: 0.00\n",
            "Similarity between Summary 297 and KB Entry 12: 0.04\n",
            "Similarity between Summary 297 and KB Entry 13: 0.02\n",
            "Similarity between Summary 297 and KB Entry 14: 0.02\n",
            "Similarity between Summary 297 and KB Entry 15: 0.01\n",
            "Similarity between Summary 297 and KB Entry 16: 0.00\n",
            "Similarity between Summary 297 and KB Entry 17: 0.05\n",
            "Similarity between Summary 297 and KB Entry 18: 0.01\n",
            "Similarity between Summary 297 and KB Entry 19: 0.01\n",
            "Similarity between Summary 297 and KB Entry 20: 0.00\n",
            "Similarity between Summary 297 and KB Entry 21: 0.00\n",
            "Similarity between Summary 297 and KB Entry 22: 0.00\n",
            "Similarity between Summary 297 and KB Entry 23: 0.02\n",
            "Similarity between Summary 297 and KB Entry 24: 0.00\n",
            "Similarity between Summary 297 and KB Entry 25: 0.07\n",
            "Similarity between Summary 297 and KB Entry 26: 0.02\n",
            "Similarity between Summary 297 and KB Entry 27: 0.06\n",
            "Similarity between Summary 297 and KB Entry 28: 0.03\n",
            "Similarity between Summary 297 and KB Entry 29: 0.00\n",
            "Similarity between Summary 297 and KB Entry 30: 0.00\n",
            "Similarity between Summary 297 and KB Entry 31: 0.00\n",
            "Similarity between Summary 297 and KB Entry 32: 0.00\n",
            "Similarity between Summary 297 and KB Entry 33: 0.01\n",
            "Similarity between Summary 297 and KB Entry 34: 0.02\n",
            "Similarity between Summary 297 and KB Entry 35: 0.02\n",
            "Similarity between Summary 297 and KB Entry 36: 0.00\n",
            "Similarity between Summary 297 and KB Entry 37: 0.01\n",
            "Similarity between Summary 297 and KB Entry 38: 0.01\n",
            "Similarity between Summary 297 and KB Entry 39: 0.03\n",
            "Similarity between Summary 297 and KB Entry 40: 0.03\n",
            "Similarity between Summary 297 and KB Entry 41: 0.02\n",
            "Similarity between Summary 297 and KB Entry 42: 0.04\n",
            "Similarity between Summary 297 and KB Entry 43: 0.05\n",
            "Similarity between Summary 297 and KB Entry 44: 0.00\n",
            "Similarity between Summary 297 and KB Entry 45: 0.01\n",
            "Similarity between Summary 297 and KB Entry 46: 0.00\n",
            "Similarity between Summary 298 and KB Entry 1: 0.09\n",
            "Similarity between Summary 298 and KB Entry 2: 0.02\n",
            "Similarity between Summary 298 and KB Entry 3: 0.04\n",
            "Similarity between Summary 298 and KB Entry 4: 0.08\n",
            "Similarity between Summary 298 and KB Entry 5: 0.03\n",
            "Similarity between Summary 298 and KB Entry 6: 0.06\n",
            "Similarity between Summary 298 and KB Entry 7: 0.03\n",
            "Similarity between Summary 298 and KB Entry 8: 0.03\n",
            "Similarity between Summary 298 and KB Entry 9: 0.00\n",
            "Similarity between Summary 298 and KB Entry 10: 0.01\n",
            "Similarity between Summary 298 and KB Entry 11: 0.00\n",
            "Similarity between Summary 298 and KB Entry 12: 0.04\n",
            "Similarity between Summary 298 and KB Entry 13: 0.02\n",
            "Similarity between Summary 298 and KB Entry 14: 0.02\n",
            "Similarity between Summary 298 and KB Entry 15: 0.01\n",
            "Similarity between Summary 298 and KB Entry 16: 0.00\n",
            "Similarity between Summary 298 and KB Entry 17: 0.01\n",
            "Similarity between Summary 298 and KB Entry 18: 0.00\n",
            "Similarity between Summary 298 and KB Entry 19: 0.00\n",
            "Similarity between Summary 298 and KB Entry 20: 0.00\n",
            "Similarity between Summary 298 and KB Entry 21: 0.00\n",
            "Similarity between Summary 298 and KB Entry 22: 0.00\n",
            "Similarity between Summary 298 and KB Entry 23: 0.00\n",
            "Similarity between Summary 298 and KB Entry 24: 0.00\n",
            "Similarity between Summary 298 and KB Entry 25: 0.04\n",
            "Similarity between Summary 298 and KB Entry 26: 0.00\n",
            "Similarity between Summary 298 and KB Entry 27: 0.04\n",
            "Similarity between Summary 298 and KB Entry 28: 0.03\n",
            "Similarity between Summary 298 and KB Entry 29: 0.00\n",
            "Similarity between Summary 298 and KB Entry 30: 0.00\n",
            "Similarity between Summary 298 and KB Entry 31: 0.00\n",
            "Similarity between Summary 298 and KB Entry 32: 0.00\n",
            "Similarity between Summary 298 and KB Entry 33: 0.01\n",
            "Similarity between Summary 298 and KB Entry 34: 0.02\n",
            "Similarity between Summary 298 and KB Entry 35: 0.02\n",
            "Similarity between Summary 298 and KB Entry 36: 0.00\n",
            "Similarity between Summary 298 and KB Entry 37: 0.00\n",
            "Similarity between Summary 298 and KB Entry 38: 0.01\n",
            "Similarity between Summary 298 and KB Entry 39: 0.04\n",
            "Similarity between Summary 298 and KB Entry 40: 0.03\n",
            "Similarity between Summary 298 and KB Entry 41: 0.03\n",
            "Similarity between Summary 298 and KB Entry 42: 0.05\n",
            "Similarity between Summary 298 and KB Entry 43: 0.06\n",
            "Similarity between Summary 298 and KB Entry 44: 0.00\n",
            "Similarity between Summary 298 and KB Entry 45: 0.00\n",
            "Similarity between Summary 298 and KB Entry 46: 0.00\n",
            "Similarity between Summary 299 and KB Entry 1: 0.09\n",
            "Similarity between Summary 299 and KB Entry 2: 0.01\n",
            "Similarity between Summary 299 and KB Entry 3: 0.04\n",
            "Similarity between Summary 299 and KB Entry 4: 0.07\n",
            "Similarity between Summary 299 and KB Entry 5: 0.02\n",
            "Similarity between Summary 299 and KB Entry 6: 0.04\n",
            "Similarity between Summary 299 and KB Entry 7: 0.02\n",
            "Similarity between Summary 299 and KB Entry 8: 0.03\n",
            "Similarity between Summary 299 and KB Entry 9: 0.00\n",
            "Similarity between Summary 299 and KB Entry 10: 0.01\n",
            "Similarity between Summary 299 and KB Entry 11: 0.00\n",
            "Similarity between Summary 299 and KB Entry 12: 0.04\n",
            "Similarity between Summary 299 and KB Entry 13: 0.02\n",
            "Similarity between Summary 299 and KB Entry 14: 0.02\n",
            "Similarity between Summary 299 and KB Entry 15: 0.01\n",
            "Similarity between Summary 299 and KB Entry 16: 0.01\n",
            "Similarity between Summary 299 and KB Entry 17: 0.01\n",
            "Similarity between Summary 299 and KB Entry 18: 0.00\n",
            "Similarity between Summary 299 and KB Entry 19: 0.00\n",
            "Similarity between Summary 299 and KB Entry 20: 0.00\n",
            "Similarity between Summary 299 and KB Entry 21: 0.01\n",
            "Similarity between Summary 299 and KB Entry 22: 0.00\n",
            "Similarity between Summary 299 and KB Entry 23: 0.00\n",
            "Similarity between Summary 299 and KB Entry 24: 0.01\n",
            "Similarity between Summary 299 and KB Entry 25: 0.03\n",
            "Similarity between Summary 299 and KB Entry 26: 0.00\n",
            "Similarity between Summary 299 and KB Entry 27: 0.00\n",
            "Similarity between Summary 299 and KB Entry 28: 0.01\n",
            "Similarity between Summary 299 and KB Entry 29: 0.00\n",
            "Similarity between Summary 299 and KB Entry 30: 0.04\n",
            "Similarity between Summary 299 and KB Entry 31: 0.00\n",
            "Similarity between Summary 299 and KB Entry 32: 0.00\n",
            "Similarity between Summary 299 and KB Entry 33: 0.01\n",
            "Similarity between Summary 299 and KB Entry 34: 0.01\n",
            "Similarity between Summary 299 and KB Entry 35: 0.02\n",
            "Similarity between Summary 299 and KB Entry 36: 0.00\n",
            "Similarity between Summary 299 and KB Entry 37: 0.00\n",
            "Similarity between Summary 299 and KB Entry 38: 0.02\n",
            "Similarity between Summary 299 and KB Entry 39: 0.05\n",
            "Similarity between Summary 299 and KB Entry 40: 0.03\n",
            "Similarity between Summary 299 and KB Entry 41: 0.03\n",
            "Similarity between Summary 299 and KB Entry 42: 0.04\n",
            "Similarity between Summary 299 and KB Entry 43: 0.05\n",
            "Similarity between Summary 299 and KB Entry 44: 0.00\n",
            "Similarity between Summary 299 and KB Entry 45: 0.01\n",
            "Similarity between Summary 299 and KB Entry 46: 0.00\n",
            "Similarity between Summary 300 and KB Entry 1: 0.09\n",
            "Similarity between Summary 300 and KB Entry 2: 0.01\n",
            "Similarity between Summary 300 and KB Entry 3: 0.05\n",
            "Similarity between Summary 300 and KB Entry 4: 0.08\n",
            "Similarity between Summary 300 and KB Entry 5: 0.05\n",
            "Similarity between Summary 300 and KB Entry 6: 0.06\n",
            "Similarity between Summary 300 and KB Entry 7: 0.04\n",
            "Similarity between Summary 300 and KB Entry 8: 0.03\n",
            "Similarity between Summary 300 and KB Entry 9: 0.00\n",
            "Similarity between Summary 300 and KB Entry 10: 0.01\n",
            "Similarity between Summary 300 and KB Entry 11: 0.00\n",
            "Similarity between Summary 300 and KB Entry 12: 0.04\n",
            "Similarity between Summary 300 and KB Entry 13: 0.02\n",
            "Similarity between Summary 300 and KB Entry 14: 0.02\n",
            "Similarity between Summary 300 and KB Entry 15: 0.01\n",
            "Similarity between Summary 300 and KB Entry 16: 0.00\n",
            "Similarity between Summary 300 and KB Entry 17: 0.02\n",
            "Similarity between Summary 300 and KB Entry 18: 0.00\n",
            "Similarity between Summary 300 and KB Entry 19: 0.00\n",
            "Similarity between Summary 300 and KB Entry 20: 0.00\n",
            "Similarity between Summary 300 and KB Entry 21: 0.00\n",
            "Similarity between Summary 300 and KB Entry 22: 0.00\n",
            "Similarity between Summary 300 and KB Entry 23: 0.00\n",
            "Similarity between Summary 300 and KB Entry 24: 0.00\n",
            "Similarity between Summary 300 and KB Entry 25: 0.06\n",
            "Similarity between Summary 300 and KB Entry 26: 0.02\n",
            "Similarity between Summary 300 and KB Entry 27: 0.04\n",
            "Similarity between Summary 300 and KB Entry 28: 0.04\n",
            "Similarity between Summary 300 and KB Entry 29: 0.00\n",
            "Similarity between Summary 300 and KB Entry 30: 0.00\n",
            "Similarity between Summary 300 and KB Entry 31: 0.00\n",
            "Similarity between Summary 300 and KB Entry 32: 0.00\n",
            "Similarity between Summary 300 and KB Entry 33: 0.01\n",
            "Similarity between Summary 300 and KB Entry 34: 0.01\n",
            "Similarity between Summary 300 and KB Entry 35: 0.02\n",
            "Similarity between Summary 300 and KB Entry 36: 0.00\n",
            "Similarity between Summary 300 and KB Entry 37: 0.01\n",
            "Similarity between Summary 300 and KB Entry 38: 0.01\n",
            "Similarity between Summary 300 and KB Entry 39: 0.05\n",
            "Similarity between Summary 300 and KB Entry 40: 0.03\n",
            "Similarity between Summary 300 and KB Entry 41: 0.04\n",
            "Similarity between Summary 300 and KB Entry 42: 0.04\n",
            "Similarity between Summary 300 and KB Entry 43: 0.05\n",
            "Similarity between Summary 300 and KB Entry 44: 0.00\n",
            "Similarity between Summary 300 and KB Entry 45: 0.00\n",
            "Similarity between Summary 300 and KB Entry 46: 0.00\n",
            "Similarity between Summary 301 and KB Entry 1: 0.10\n",
            "Similarity between Summary 301 and KB Entry 2: 0.01\n",
            "Similarity between Summary 301 and KB Entry 3: 0.04\n",
            "Similarity between Summary 301 and KB Entry 4: 0.07\n",
            "Similarity between Summary 301 and KB Entry 5: 0.03\n",
            "Similarity between Summary 301 and KB Entry 6: 0.05\n",
            "Similarity between Summary 301 and KB Entry 7: 0.03\n",
            "Similarity between Summary 301 and KB Entry 8: 0.03\n",
            "Similarity between Summary 301 and KB Entry 9: 0.00\n",
            "Similarity between Summary 301 and KB Entry 10: 0.01\n",
            "Similarity between Summary 301 and KB Entry 11: 0.00\n",
            "Similarity between Summary 301 and KB Entry 12: 0.05\n",
            "Similarity between Summary 301 and KB Entry 13: 0.02\n",
            "Similarity between Summary 301 and KB Entry 14: 0.01\n",
            "Similarity between Summary 301 and KB Entry 15: 0.01\n",
            "Similarity between Summary 301 and KB Entry 16: 0.00\n",
            "Similarity between Summary 301 and KB Entry 17: 0.01\n",
            "Similarity between Summary 301 and KB Entry 18: 0.00\n",
            "Similarity between Summary 301 and KB Entry 19: 0.00\n",
            "Similarity between Summary 301 and KB Entry 20: 0.00\n",
            "Similarity between Summary 301 and KB Entry 21: 0.00\n",
            "Similarity between Summary 301 and KB Entry 22: 0.00\n",
            "Similarity between Summary 301 and KB Entry 23: 0.00\n",
            "Similarity between Summary 301 and KB Entry 24: 0.00\n",
            "Similarity between Summary 301 and KB Entry 25: 0.01\n",
            "Similarity between Summary 301 and KB Entry 26: 0.00\n",
            "Similarity between Summary 301 and KB Entry 27: 0.00\n",
            "Similarity between Summary 301 and KB Entry 28: 0.01\n",
            "Similarity between Summary 301 and KB Entry 29: 0.00\n",
            "Similarity between Summary 301 and KB Entry 30: 0.00\n",
            "Similarity between Summary 301 and KB Entry 31: 0.00\n",
            "Similarity between Summary 301 and KB Entry 32: 0.00\n",
            "Similarity between Summary 301 and KB Entry 33: 0.05\n",
            "Similarity between Summary 301 and KB Entry 34: 0.01\n",
            "Similarity between Summary 301 and KB Entry 35: 0.02\n",
            "Similarity between Summary 301 and KB Entry 36: 0.00\n",
            "Similarity between Summary 301 and KB Entry 37: 0.00\n",
            "Similarity between Summary 301 and KB Entry 38: 0.01\n",
            "Similarity between Summary 301 and KB Entry 39: 0.06\n",
            "Similarity between Summary 301 and KB Entry 40: 0.02\n",
            "Similarity between Summary 301 and KB Entry 41: 0.02\n",
            "Similarity between Summary 301 and KB Entry 42: 0.05\n",
            "Similarity between Summary 301 and KB Entry 43: 0.06\n",
            "Similarity between Summary 301 and KB Entry 44: 0.00\n",
            "Similarity between Summary 301 and KB Entry 45: 0.01\n",
            "Similarity between Summary 301 and KB Entry 46: 0.00\n",
            "Similarity between Summary 302 and KB Entry 1: 0.09\n",
            "Similarity between Summary 302 and KB Entry 2: 0.01\n",
            "Similarity between Summary 302 and KB Entry 3: 0.04\n",
            "Similarity between Summary 302 and KB Entry 4: 0.07\n",
            "Similarity between Summary 302 and KB Entry 5: 0.03\n",
            "Similarity between Summary 302 and KB Entry 6: 0.05\n",
            "Similarity between Summary 302 and KB Entry 7: 0.03\n",
            "Similarity between Summary 302 and KB Entry 8: 0.02\n",
            "Similarity between Summary 302 and KB Entry 9: 0.00\n",
            "Similarity between Summary 302 and KB Entry 10: 0.01\n",
            "Similarity between Summary 302 and KB Entry 11: 0.00\n",
            "Similarity between Summary 302 and KB Entry 12: 0.04\n",
            "Similarity between Summary 302 and KB Entry 13: 0.02\n",
            "Similarity between Summary 302 and KB Entry 14: 0.02\n",
            "Similarity between Summary 302 and KB Entry 15: 0.01\n",
            "Similarity between Summary 302 and KB Entry 16: 0.00\n",
            "Similarity between Summary 302 and KB Entry 17: 0.03\n",
            "Similarity between Summary 302 and KB Entry 18: 0.01\n",
            "Similarity between Summary 302 and KB Entry 19: 0.00\n",
            "Similarity between Summary 302 and KB Entry 20: 0.00\n",
            "Similarity between Summary 302 and KB Entry 21: 0.00\n",
            "Similarity between Summary 302 and KB Entry 22: 0.00\n",
            "Similarity between Summary 302 and KB Entry 23: 0.00\n",
            "Similarity between Summary 302 and KB Entry 24: 0.00\n",
            "Similarity between Summary 302 and KB Entry 25: 0.05\n",
            "Similarity between Summary 302 and KB Entry 26: 0.00\n",
            "Similarity between Summary 302 and KB Entry 27: 0.03\n",
            "Similarity between Summary 302 and KB Entry 28: 0.03\n",
            "Similarity between Summary 302 and KB Entry 29: 0.02\n",
            "Similarity between Summary 302 and KB Entry 30: 0.00\n",
            "Similarity between Summary 302 and KB Entry 31: 0.00\n",
            "Similarity between Summary 302 and KB Entry 32: 0.00\n",
            "Similarity between Summary 302 and KB Entry 33: 0.01\n",
            "Similarity between Summary 302 and KB Entry 34: 0.01\n",
            "Similarity between Summary 302 and KB Entry 35: 0.02\n",
            "Similarity between Summary 302 and KB Entry 36: 0.00\n",
            "Similarity between Summary 302 and KB Entry 37: 0.00\n",
            "Similarity between Summary 302 and KB Entry 38: 0.01\n",
            "Similarity between Summary 302 and KB Entry 39: 0.06\n",
            "Similarity between Summary 302 and KB Entry 40: 0.02\n",
            "Similarity between Summary 302 and KB Entry 41: 0.04\n",
            "Similarity between Summary 302 and KB Entry 42: 0.05\n",
            "Similarity between Summary 302 and KB Entry 43: 0.05\n",
            "Similarity between Summary 302 and KB Entry 44: 0.00\n",
            "Similarity between Summary 302 and KB Entry 45: 0.00\n",
            "Similarity between Summary 302 and KB Entry 46: 0.00\n",
            "Similarity between Summary 303 and KB Entry 1: 0.10\n",
            "Similarity between Summary 303 and KB Entry 2: 0.01\n",
            "Similarity between Summary 303 and KB Entry 3: 0.04\n",
            "Similarity between Summary 303 and KB Entry 4: 0.07\n",
            "Similarity between Summary 303 and KB Entry 5: 0.03\n",
            "Similarity between Summary 303 and KB Entry 6: 0.05\n",
            "Similarity between Summary 303 and KB Entry 7: 0.03\n",
            "Similarity between Summary 303 and KB Entry 8: 0.03\n",
            "Similarity between Summary 303 and KB Entry 9: 0.00\n",
            "Similarity between Summary 303 and KB Entry 10: 0.01\n",
            "Similarity between Summary 303 and KB Entry 11: 0.00\n",
            "Similarity between Summary 303 and KB Entry 12: 0.05\n",
            "Similarity between Summary 303 and KB Entry 13: 0.02\n",
            "Similarity between Summary 303 and KB Entry 14: 0.01\n",
            "Similarity between Summary 303 and KB Entry 15: 0.01\n",
            "Similarity between Summary 303 and KB Entry 16: 0.00\n",
            "Similarity between Summary 303 and KB Entry 17: 0.01\n",
            "Similarity between Summary 303 and KB Entry 18: 0.00\n",
            "Similarity between Summary 303 and KB Entry 19: 0.00\n",
            "Similarity between Summary 303 and KB Entry 20: 0.00\n",
            "Similarity between Summary 303 and KB Entry 21: 0.00\n",
            "Similarity between Summary 303 and KB Entry 22: 0.00\n",
            "Similarity between Summary 303 and KB Entry 23: 0.00\n",
            "Similarity between Summary 303 and KB Entry 24: 0.00\n",
            "Similarity between Summary 303 and KB Entry 25: 0.01\n",
            "Similarity between Summary 303 and KB Entry 26: 0.00\n",
            "Similarity between Summary 303 and KB Entry 27: 0.00\n",
            "Similarity between Summary 303 and KB Entry 28: 0.01\n",
            "Similarity between Summary 303 and KB Entry 29: 0.00\n",
            "Similarity between Summary 303 and KB Entry 30: 0.00\n",
            "Similarity between Summary 303 and KB Entry 31: 0.00\n",
            "Similarity between Summary 303 and KB Entry 32: 0.00\n",
            "Similarity between Summary 303 and KB Entry 33: 0.05\n",
            "Similarity between Summary 303 and KB Entry 34: 0.01\n",
            "Similarity between Summary 303 and KB Entry 35: 0.02\n",
            "Similarity between Summary 303 and KB Entry 36: 0.00\n",
            "Similarity between Summary 303 and KB Entry 37: 0.00\n",
            "Similarity between Summary 303 and KB Entry 38: 0.01\n",
            "Similarity between Summary 303 and KB Entry 39: 0.06\n",
            "Similarity between Summary 303 and KB Entry 40: 0.02\n",
            "Similarity between Summary 303 and KB Entry 41: 0.02\n",
            "Similarity between Summary 303 and KB Entry 42: 0.05\n",
            "Similarity between Summary 303 and KB Entry 43: 0.06\n",
            "Similarity between Summary 303 and KB Entry 44: 0.00\n",
            "Similarity between Summary 303 and KB Entry 45: 0.01\n",
            "Similarity between Summary 303 and KB Entry 46: 0.00\n",
            "Similarity between Summary 304 and KB Entry 1: 0.10\n",
            "Similarity between Summary 304 and KB Entry 2: 0.01\n",
            "Similarity between Summary 304 and KB Entry 3: 0.04\n",
            "Similarity between Summary 304 and KB Entry 4: 0.07\n",
            "Similarity between Summary 304 and KB Entry 5: 0.03\n",
            "Similarity between Summary 304 and KB Entry 6: 0.05\n",
            "Similarity between Summary 304 and KB Entry 7: 0.02\n",
            "Similarity between Summary 304 and KB Entry 8: 0.03\n",
            "Similarity between Summary 304 and KB Entry 9: 0.00\n",
            "Similarity between Summary 304 and KB Entry 10: 0.01\n",
            "Similarity between Summary 304 and KB Entry 11: 0.00\n",
            "Similarity between Summary 304 and KB Entry 12: 0.05\n",
            "Similarity between Summary 304 and KB Entry 13: 0.02\n",
            "Similarity between Summary 304 and KB Entry 14: 0.02\n",
            "Similarity between Summary 304 and KB Entry 15: 0.01\n",
            "Similarity between Summary 304 and KB Entry 16: 0.00\n",
            "Similarity between Summary 304 and KB Entry 17: 0.04\n",
            "Similarity between Summary 304 and KB Entry 18: 0.02\n",
            "Similarity between Summary 304 and KB Entry 19: 0.00\n",
            "Similarity between Summary 304 and KB Entry 20: 0.00\n",
            "Similarity between Summary 304 and KB Entry 21: 0.00\n",
            "Similarity between Summary 304 and KB Entry 22: 0.00\n",
            "Similarity between Summary 304 and KB Entry 23: 0.01\n",
            "Similarity between Summary 304 and KB Entry 24: 0.00\n",
            "Similarity between Summary 304 and KB Entry 25: 0.06\n",
            "Similarity between Summary 304 and KB Entry 26: 0.01\n",
            "Similarity between Summary 304 and KB Entry 27: 0.05\n",
            "Similarity between Summary 304 and KB Entry 28: 0.03\n",
            "Similarity between Summary 304 and KB Entry 29: 0.00\n",
            "Similarity between Summary 304 and KB Entry 30: 0.00\n",
            "Similarity between Summary 304 and KB Entry 31: 0.00\n",
            "Similarity between Summary 304 and KB Entry 32: 0.00\n",
            "Similarity between Summary 304 and KB Entry 33: 0.01\n",
            "Similarity between Summary 304 and KB Entry 34: 0.01\n",
            "Similarity between Summary 304 and KB Entry 35: 0.02\n",
            "Similarity between Summary 304 and KB Entry 36: 0.00\n",
            "Similarity between Summary 304 and KB Entry 37: 0.01\n",
            "Similarity between Summary 304 and KB Entry 38: 0.01\n",
            "Similarity between Summary 304 and KB Entry 39: 0.04\n",
            "Similarity between Summary 304 and KB Entry 40: 0.03\n",
            "Similarity between Summary 304 and KB Entry 41: 0.03\n",
            "Similarity between Summary 304 and KB Entry 42: 0.04\n",
            "Similarity between Summary 304 and KB Entry 43: 0.05\n",
            "Similarity between Summary 304 and KB Entry 44: 0.00\n",
            "Similarity between Summary 304 and KB Entry 45: 0.00\n",
            "Similarity between Summary 304 and KB Entry 46: 0.00\n",
            "Similarity between Summary 305 and KB Entry 1: 0.09\n",
            "Similarity between Summary 305 and KB Entry 2: 0.01\n",
            "Similarity between Summary 305 and KB Entry 3: 0.03\n",
            "Similarity between Summary 305 and KB Entry 4: 0.06\n",
            "Similarity between Summary 305 and KB Entry 5: 0.03\n",
            "Similarity between Summary 305 and KB Entry 6: 0.05\n",
            "Similarity between Summary 305 and KB Entry 7: 0.02\n",
            "Similarity between Summary 305 and KB Entry 8: 0.03\n",
            "Similarity between Summary 305 and KB Entry 9: 0.00\n",
            "Similarity between Summary 305 and KB Entry 10: 0.01\n",
            "Similarity between Summary 305 and KB Entry 11: 0.00\n",
            "Similarity between Summary 305 and KB Entry 12: 0.04\n",
            "Similarity between Summary 305 and KB Entry 13: 0.02\n",
            "Similarity between Summary 305 and KB Entry 14: 0.01\n",
            "Similarity between Summary 305 and KB Entry 15: 0.01\n",
            "Similarity between Summary 305 and KB Entry 16: 0.00\n",
            "Similarity between Summary 305 and KB Entry 17: 0.02\n",
            "Similarity between Summary 305 and KB Entry 18: 0.01\n",
            "Similarity between Summary 305 and KB Entry 19: 0.00\n",
            "Similarity between Summary 305 and KB Entry 20: 0.00\n",
            "Similarity between Summary 305 and KB Entry 21: 0.00\n",
            "Similarity between Summary 305 and KB Entry 22: 0.00\n",
            "Similarity between Summary 305 and KB Entry 23: 0.00\n",
            "Similarity between Summary 305 and KB Entry 24: 0.02\n",
            "Similarity between Summary 305 and KB Entry 25: 0.05\n",
            "Similarity between Summary 305 and KB Entry 26: 0.00\n",
            "Similarity between Summary 305 and KB Entry 27: 0.00\n",
            "Similarity between Summary 305 and KB Entry 28: 0.01\n",
            "Similarity between Summary 305 and KB Entry 29: 0.00\n",
            "Similarity between Summary 305 and KB Entry 30: 0.05\n",
            "Similarity between Summary 305 and KB Entry 31: 0.00\n",
            "Similarity between Summary 305 and KB Entry 32: 0.00\n",
            "Similarity between Summary 305 and KB Entry 33: 0.01\n",
            "Similarity between Summary 305 and KB Entry 34: 0.01\n",
            "Similarity between Summary 305 and KB Entry 35: 0.02\n",
            "Similarity between Summary 305 and KB Entry 36: 0.00\n",
            "Similarity between Summary 305 and KB Entry 37: 0.00\n",
            "Similarity between Summary 305 and KB Entry 38: 0.01\n",
            "Similarity between Summary 305 and KB Entry 39: 0.05\n",
            "Similarity between Summary 305 and KB Entry 40: 0.03\n",
            "Similarity between Summary 305 and KB Entry 41: 0.02\n",
            "Similarity between Summary 305 and KB Entry 42: 0.04\n",
            "Similarity between Summary 305 and KB Entry 43: 0.05\n",
            "Similarity between Summary 305 and KB Entry 44: 0.00\n",
            "Similarity between Summary 305 and KB Entry 45: 0.00\n",
            "Similarity between Summary 305 and KB Entry 46: 0.00\n",
            "Similarity between Summary 306 and KB Entry 1: 0.08\n",
            "Similarity between Summary 306 and KB Entry 2: 0.01\n",
            "Similarity between Summary 306 and KB Entry 3: 0.03\n",
            "Similarity between Summary 306 and KB Entry 4: 0.05\n",
            "Similarity between Summary 306 and KB Entry 5: 0.02\n",
            "Similarity between Summary 306 and KB Entry 6: 0.04\n",
            "Similarity between Summary 306 and KB Entry 7: 0.02\n",
            "Similarity between Summary 306 and KB Entry 8: 0.02\n",
            "Similarity between Summary 306 and KB Entry 9: 0.00\n",
            "Similarity between Summary 306 and KB Entry 10: 0.01\n",
            "Similarity between Summary 306 and KB Entry 11: 0.00\n",
            "Similarity between Summary 306 and KB Entry 12: 0.03\n",
            "Similarity between Summary 306 and KB Entry 13: 0.01\n",
            "Similarity between Summary 306 and KB Entry 14: 0.01\n",
            "Similarity between Summary 306 and KB Entry 15: 0.01\n",
            "Similarity between Summary 306 and KB Entry 16: 0.01\n",
            "Similarity between Summary 306 and KB Entry 17: 0.00\n",
            "Similarity between Summary 306 and KB Entry 18: 0.01\n",
            "Similarity between Summary 306 and KB Entry 19: 0.00\n",
            "Similarity between Summary 306 and KB Entry 20: 0.00\n",
            "Similarity between Summary 306 and KB Entry 21: 0.01\n",
            "Similarity between Summary 306 and KB Entry 22: 0.00\n",
            "Similarity between Summary 306 and KB Entry 23: 0.00\n",
            "Similarity between Summary 306 and KB Entry 24: 0.00\n",
            "Similarity between Summary 306 and KB Entry 25: 0.04\n",
            "Similarity between Summary 306 and KB Entry 26: 0.00\n",
            "Similarity between Summary 306 and KB Entry 27: 0.01\n",
            "Similarity between Summary 306 and KB Entry 28: 0.02\n",
            "Similarity between Summary 306 and KB Entry 29: 0.00\n",
            "Similarity between Summary 306 and KB Entry 30: 0.00\n",
            "Similarity between Summary 306 and KB Entry 31: 0.01\n",
            "Similarity between Summary 306 and KB Entry 32: 0.00\n",
            "Similarity between Summary 306 and KB Entry 33: 0.05\n",
            "Similarity between Summary 306 and KB Entry 34: 0.01\n",
            "Similarity between Summary 306 and KB Entry 35: 0.01\n",
            "Similarity between Summary 306 and KB Entry 36: 0.00\n",
            "Similarity between Summary 306 and KB Entry 37: 0.00\n",
            "Similarity between Summary 306 and KB Entry 38: 0.01\n",
            "Similarity between Summary 306 and KB Entry 39: 0.06\n",
            "Similarity between Summary 306 and KB Entry 40: 0.02\n",
            "Similarity between Summary 306 and KB Entry 41: 0.02\n",
            "Similarity between Summary 306 and KB Entry 42: 0.03\n",
            "Similarity between Summary 306 and KB Entry 43: 0.05\n",
            "Similarity between Summary 306 and KB Entry 44: 0.00\n",
            "Similarity between Summary 306 and KB Entry 45: 0.01\n",
            "Similarity between Summary 306 and KB Entry 46: 0.00\n",
            "Similarity between Summary 307 and KB Entry 1: 0.10\n",
            "Similarity between Summary 307 and KB Entry 2: 0.01\n",
            "Similarity between Summary 307 and KB Entry 3: 0.04\n",
            "Similarity between Summary 307 and KB Entry 4: 0.07\n",
            "Similarity between Summary 307 and KB Entry 5: 0.03\n",
            "Similarity between Summary 307 and KB Entry 6: 0.05\n",
            "Similarity between Summary 307 and KB Entry 7: 0.03\n",
            "Similarity between Summary 307 and KB Entry 8: 0.03\n",
            "Similarity between Summary 307 and KB Entry 9: 0.00\n",
            "Similarity between Summary 307 and KB Entry 10: 0.01\n",
            "Similarity between Summary 307 and KB Entry 11: 0.00\n",
            "Similarity between Summary 307 and KB Entry 12: 0.05\n",
            "Similarity between Summary 307 and KB Entry 13: 0.02\n",
            "Similarity between Summary 307 and KB Entry 14: 0.01\n",
            "Similarity between Summary 307 and KB Entry 15: 0.01\n",
            "Similarity between Summary 307 and KB Entry 16: 0.00\n",
            "Similarity between Summary 307 and KB Entry 17: 0.01\n",
            "Similarity between Summary 307 and KB Entry 18: 0.00\n",
            "Similarity between Summary 307 and KB Entry 19: 0.00\n",
            "Similarity between Summary 307 and KB Entry 20: 0.00\n",
            "Similarity between Summary 307 and KB Entry 21: 0.00\n",
            "Similarity between Summary 307 and KB Entry 22: 0.00\n",
            "Similarity between Summary 307 and KB Entry 23: 0.00\n",
            "Similarity between Summary 307 and KB Entry 24: 0.00\n",
            "Similarity between Summary 307 and KB Entry 25: 0.01\n",
            "Similarity between Summary 307 and KB Entry 26: 0.00\n",
            "Similarity between Summary 307 and KB Entry 27: 0.00\n",
            "Similarity between Summary 307 and KB Entry 28: 0.01\n",
            "Similarity between Summary 307 and KB Entry 29: 0.00\n",
            "Similarity between Summary 307 and KB Entry 30: 0.00\n",
            "Similarity between Summary 307 and KB Entry 31: 0.00\n",
            "Similarity between Summary 307 and KB Entry 32: 0.00\n",
            "Similarity between Summary 307 and KB Entry 33: 0.04\n",
            "Similarity between Summary 307 and KB Entry 34: 0.01\n",
            "Similarity between Summary 307 and KB Entry 35: 0.02\n",
            "Similarity between Summary 307 and KB Entry 36: 0.00\n",
            "Similarity between Summary 307 and KB Entry 37: 0.00\n",
            "Similarity between Summary 307 and KB Entry 38: 0.01\n",
            "Similarity between Summary 307 and KB Entry 39: 0.06\n",
            "Similarity between Summary 307 and KB Entry 40: 0.02\n",
            "Similarity between Summary 307 and KB Entry 41: 0.02\n",
            "Similarity between Summary 307 and KB Entry 42: 0.05\n",
            "Similarity between Summary 307 and KB Entry 43: 0.06\n",
            "Similarity between Summary 307 and KB Entry 44: 0.00\n",
            "Similarity between Summary 307 and KB Entry 45: 0.01\n",
            "Similarity between Summary 307 and KB Entry 46: 0.00\n",
            "Similarity between Summary 308 and KB Entry 1: 0.10\n",
            "Similarity between Summary 308 and KB Entry 2: 0.01\n",
            "Similarity between Summary 308 and KB Entry 3: 0.04\n",
            "Similarity between Summary 308 and KB Entry 4: 0.07\n",
            "Similarity between Summary 308 and KB Entry 5: 0.03\n",
            "Similarity between Summary 308 and KB Entry 6: 0.05\n",
            "Similarity between Summary 308 and KB Entry 7: 0.03\n",
            "Similarity between Summary 308 and KB Entry 8: 0.03\n",
            "Similarity between Summary 308 and KB Entry 9: 0.00\n",
            "Similarity between Summary 308 and KB Entry 10: 0.01\n",
            "Similarity between Summary 308 and KB Entry 11: 0.00\n",
            "Similarity between Summary 308 and KB Entry 12: 0.05\n",
            "Similarity between Summary 308 and KB Entry 13: 0.02\n",
            "Similarity between Summary 308 and KB Entry 14: 0.01\n",
            "Similarity between Summary 308 and KB Entry 15: 0.01\n",
            "Similarity between Summary 308 and KB Entry 16: 0.00\n",
            "Similarity between Summary 308 and KB Entry 17: 0.01\n",
            "Similarity between Summary 308 and KB Entry 18: 0.00\n",
            "Similarity between Summary 308 and KB Entry 19: 0.00\n",
            "Similarity between Summary 308 and KB Entry 20: 0.00\n",
            "Similarity between Summary 308 and KB Entry 21: 0.00\n",
            "Similarity between Summary 308 and KB Entry 22: 0.00\n",
            "Similarity between Summary 308 and KB Entry 23: 0.00\n",
            "Similarity between Summary 308 and KB Entry 24: 0.00\n",
            "Similarity between Summary 308 and KB Entry 25: 0.01\n",
            "Similarity between Summary 308 and KB Entry 26: 0.00\n",
            "Similarity between Summary 308 and KB Entry 27: 0.00\n",
            "Similarity between Summary 308 and KB Entry 28: 0.01\n",
            "Similarity between Summary 308 and KB Entry 29: 0.00\n",
            "Similarity between Summary 308 and KB Entry 30: 0.00\n",
            "Similarity between Summary 308 and KB Entry 31: 0.00\n",
            "Similarity between Summary 308 and KB Entry 32: 0.00\n",
            "Similarity between Summary 308 and KB Entry 33: 0.05\n",
            "Similarity between Summary 308 and KB Entry 34: 0.01\n",
            "Similarity between Summary 308 and KB Entry 35: 0.02\n",
            "Similarity between Summary 308 and KB Entry 36: 0.00\n",
            "Similarity between Summary 308 and KB Entry 37: 0.00\n",
            "Similarity between Summary 308 and KB Entry 38: 0.01\n",
            "Similarity between Summary 308 and KB Entry 39: 0.06\n",
            "Similarity between Summary 308 and KB Entry 40: 0.02\n",
            "Similarity between Summary 308 and KB Entry 41: 0.02\n",
            "Similarity between Summary 308 and KB Entry 42: 0.05\n",
            "Similarity between Summary 308 and KB Entry 43: 0.06\n",
            "Similarity between Summary 308 and KB Entry 44: 0.00\n",
            "Similarity between Summary 308 and KB Entry 45: 0.01\n",
            "Similarity between Summary 308 and KB Entry 46: 0.00\n",
            "Similarity between Summary 309 and KB Entry 1: 0.10\n",
            "Similarity between Summary 309 and KB Entry 2: 0.01\n",
            "Similarity between Summary 309 and KB Entry 3: 0.04\n",
            "Similarity between Summary 309 and KB Entry 4: 0.07\n",
            "Similarity between Summary 309 and KB Entry 5: 0.03\n",
            "Similarity between Summary 309 and KB Entry 6: 0.05\n",
            "Similarity between Summary 309 and KB Entry 7: 0.03\n",
            "Similarity between Summary 309 and KB Entry 8: 0.03\n",
            "Similarity between Summary 309 and KB Entry 9: 0.00\n",
            "Similarity between Summary 309 and KB Entry 10: 0.01\n",
            "Similarity between Summary 309 and KB Entry 11: 0.00\n",
            "Similarity between Summary 309 and KB Entry 12: 0.05\n",
            "Similarity between Summary 309 and KB Entry 13: 0.02\n",
            "Similarity between Summary 309 and KB Entry 14: 0.01\n",
            "Similarity between Summary 309 and KB Entry 15: 0.01\n",
            "Similarity between Summary 309 and KB Entry 16: 0.00\n",
            "Similarity between Summary 309 and KB Entry 17: 0.01\n",
            "Similarity between Summary 309 and KB Entry 18: 0.00\n",
            "Similarity between Summary 309 and KB Entry 19: 0.00\n",
            "Similarity between Summary 309 and KB Entry 20: 0.00\n",
            "Similarity between Summary 309 and KB Entry 21: 0.00\n",
            "Similarity between Summary 309 and KB Entry 22: 0.00\n",
            "Similarity between Summary 309 and KB Entry 23: 0.00\n",
            "Similarity between Summary 309 and KB Entry 24: 0.00\n",
            "Similarity between Summary 309 and KB Entry 25: 0.01\n",
            "Similarity between Summary 309 and KB Entry 26: 0.00\n",
            "Similarity between Summary 309 and KB Entry 27: 0.00\n",
            "Similarity between Summary 309 and KB Entry 28: 0.01\n",
            "Similarity between Summary 309 and KB Entry 29: 0.00\n",
            "Similarity between Summary 309 and KB Entry 30: 0.00\n",
            "Similarity between Summary 309 and KB Entry 31: 0.00\n",
            "Similarity between Summary 309 and KB Entry 32: 0.00\n",
            "Similarity between Summary 309 and KB Entry 33: 0.04\n",
            "Similarity between Summary 309 and KB Entry 34: 0.01\n",
            "Similarity between Summary 309 and KB Entry 35: 0.02\n",
            "Similarity between Summary 309 and KB Entry 36: 0.00\n",
            "Similarity between Summary 309 and KB Entry 37: 0.00\n",
            "Similarity between Summary 309 and KB Entry 38: 0.01\n",
            "Similarity between Summary 309 and KB Entry 39: 0.06\n",
            "Similarity between Summary 309 and KB Entry 40: 0.02\n",
            "Similarity between Summary 309 and KB Entry 41: 0.02\n",
            "Similarity between Summary 309 and KB Entry 42: 0.05\n",
            "Similarity between Summary 309 and KB Entry 43: 0.06\n",
            "Similarity between Summary 309 and KB Entry 44: 0.00\n",
            "Similarity between Summary 309 and KB Entry 45: 0.01\n",
            "Similarity between Summary 309 and KB Entry 46: 0.00\n",
            "Similarity between Summary 310 and KB Entry 1: 0.10\n",
            "Similarity between Summary 310 and KB Entry 2: 0.01\n",
            "Similarity between Summary 310 and KB Entry 3: 0.04\n",
            "Similarity between Summary 310 and KB Entry 4: 0.08\n",
            "Similarity between Summary 310 and KB Entry 5: 0.03\n",
            "Similarity between Summary 310 and KB Entry 6: 0.06\n",
            "Similarity between Summary 310 and KB Entry 7: 0.03\n",
            "Similarity between Summary 310 and KB Entry 8: 0.03\n",
            "Similarity between Summary 310 and KB Entry 9: 0.00\n",
            "Similarity between Summary 310 and KB Entry 10: 0.01\n",
            "Similarity between Summary 310 and KB Entry 11: 0.00\n",
            "Similarity between Summary 310 and KB Entry 12: 0.06\n",
            "Similarity between Summary 310 and KB Entry 13: 0.02\n",
            "Similarity between Summary 310 and KB Entry 14: 0.01\n",
            "Similarity between Summary 310 and KB Entry 15: 0.01\n",
            "Similarity between Summary 310 and KB Entry 16: 0.01\n",
            "Similarity between Summary 310 and KB Entry 17: 0.01\n",
            "Similarity between Summary 310 and KB Entry 18: 0.00\n",
            "Similarity between Summary 310 and KB Entry 19: 0.00\n",
            "Similarity between Summary 310 and KB Entry 20: 0.00\n",
            "Similarity between Summary 310 and KB Entry 21: 0.00\n",
            "Similarity between Summary 310 and KB Entry 22: 0.00\n",
            "Similarity between Summary 310 and KB Entry 23: 0.00\n",
            "Similarity between Summary 310 and KB Entry 24: 0.00\n",
            "Similarity between Summary 310 and KB Entry 25: 0.02\n",
            "Similarity between Summary 310 and KB Entry 26: 0.00\n",
            "Similarity between Summary 310 and KB Entry 27: 0.00\n",
            "Similarity between Summary 310 and KB Entry 28: 0.01\n",
            "Similarity between Summary 310 and KB Entry 29: 0.00\n",
            "Similarity between Summary 310 and KB Entry 30: 0.00\n",
            "Similarity between Summary 310 and KB Entry 31: 0.00\n",
            "Similarity between Summary 310 and KB Entry 32: 0.00\n",
            "Similarity between Summary 310 and KB Entry 33: 0.03\n",
            "Similarity between Summary 310 and KB Entry 34: 0.01\n",
            "Similarity between Summary 310 and KB Entry 35: 0.02\n",
            "Similarity between Summary 310 and KB Entry 36: 0.00\n",
            "Similarity between Summary 310 and KB Entry 37: 0.00\n",
            "Similarity between Summary 310 and KB Entry 38: 0.01\n",
            "Similarity between Summary 310 and KB Entry 39: 0.06\n",
            "Similarity between Summary 310 and KB Entry 40: 0.02\n",
            "Similarity between Summary 310 and KB Entry 41: 0.02\n",
            "Similarity between Summary 310 and KB Entry 42: 0.05\n",
            "Similarity between Summary 310 and KB Entry 43: 0.05\n",
            "Similarity between Summary 310 and KB Entry 44: 0.00\n",
            "Similarity between Summary 310 and KB Entry 45: 0.01\n",
            "Similarity between Summary 310 and KB Entry 46: 0.00\n",
            "Similarity between Summary 311 and KB Entry 1: 0.08\n",
            "Similarity between Summary 311 and KB Entry 2: 0.02\n",
            "Similarity between Summary 311 and KB Entry 3: 0.04\n",
            "Similarity between Summary 311 and KB Entry 4: 0.08\n",
            "Similarity between Summary 311 and KB Entry 5: 0.03\n",
            "Similarity between Summary 311 and KB Entry 6: 0.06\n",
            "Similarity between Summary 311 and KB Entry 7: 0.03\n",
            "Similarity between Summary 311 and KB Entry 8: 0.04\n",
            "Similarity between Summary 311 and KB Entry 9: 0.00\n",
            "Similarity between Summary 311 and KB Entry 10: 0.01\n",
            "Similarity between Summary 311 and KB Entry 11: 0.00\n",
            "Similarity between Summary 311 and KB Entry 12: 0.04\n",
            "Similarity between Summary 311 and KB Entry 13: 0.02\n",
            "Similarity between Summary 311 and KB Entry 14: 0.02\n",
            "Similarity between Summary 311 and KB Entry 15: 0.01\n",
            "Similarity between Summary 311 and KB Entry 16: 0.00\n",
            "Similarity between Summary 311 and KB Entry 17: 0.01\n",
            "Similarity between Summary 311 and KB Entry 18: 0.01\n",
            "Similarity between Summary 311 and KB Entry 19: 0.00\n",
            "Similarity between Summary 311 and KB Entry 20: 0.00\n",
            "Similarity between Summary 311 and KB Entry 21: 0.00\n",
            "Similarity between Summary 311 and KB Entry 22: 0.00\n",
            "Similarity between Summary 311 and KB Entry 23: 0.00\n",
            "Similarity between Summary 311 and KB Entry 24: 0.00\n",
            "Similarity between Summary 311 and KB Entry 25: 0.04\n",
            "Similarity between Summary 311 and KB Entry 26: 0.00\n",
            "Similarity between Summary 311 and KB Entry 27: 0.04\n",
            "Similarity between Summary 311 and KB Entry 28: 0.04\n",
            "Similarity between Summary 311 and KB Entry 29: 0.00\n",
            "Similarity between Summary 311 and KB Entry 30: 0.00\n",
            "Similarity between Summary 311 and KB Entry 31: 0.00\n",
            "Similarity between Summary 311 and KB Entry 32: 0.00\n",
            "Similarity between Summary 311 and KB Entry 33: 0.01\n",
            "Similarity between Summary 311 and KB Entry 34: 0.06\n",
            "Similarity between Summary 311 and KB Entry 35: 0.02\n",
            "Similarity between Summary 311 and KB Entry 36: 0.00\n",
            "Similarity between Summary 311 and KB Entry 37: 0.00\n",
            "Similarity between Summary 311 and KB Entry 38: 0.01\n",
            "Similarity between Summary 311 and KB Entry 39: 0.04\n",
            "Similarity between Summary 311 and KB Entry 40: 0.04\n",
            "Similarity between Summary 311 and KB Entry 41: 0.03\n",
            "Similarity between Summary 311 and KB Entry 42: 0.04\n",
            "Similarity between Summary 311 and KB Entry 43: 0.06\n",
            "Similarity between Summary 311 and KB Entry 44: 0.00\n",
            "Similarity between Summary 311 and KB Entry 45: 0.00\n",
            "Similarity between Summary 311 and KB Entry 46: 0.00\n",
            "Similarity between Summary 312 and KB Entry 1: 0.08\n",
            "Similarity between Summary 312 and KB Entry 2: 0.02\n",
            "Similarity between Summary 312 and KB Entry 3: 0.04\n",
            "Similarity between Summary 312 and KB Entry 4: 0.08\n",
            "Similarity between Summary 312 and KB Entry 5: 0.03\n",
            "Similarity between Summary 312 and KB Entry 6: 0.05\n",
            "Similarity between Summary 312 and KB Entry 7: 0.03\n",
            "Similarity between Summary 312 and KB Entry 8: 0.03\n",
            "Similarity between Summary 312 and KB Entry 9: 0.00\n",
            "Similarity between Summary 312 and KB Entry 10: 0.01\n",
            "Similarity between Summary 312 and KB Entry 11: 0.00\n",
            "Similarity between Summary 312 and KB Entry 12: 0.05\n",
            "Similarity between Summary 312 and KB Entry 13: 0.02\n",
            "Similarity between Summary 312 and KB Entry 14: 0.01\n",
            "Similarity between Summary 312 and KB Entry 15: 0.01\n",
            "Similarity between Summary 312 and KB Entry 16: 0.00\n",
            "Similarity between Summary 312 and KB Entry 17: 0.01\n",
            "Similarity between Summary 312 and KB Entry 18: 0.01\n",
            "Similarity between Summary 312 and KB Entry 19: 0.00\n",
            "Similarity between Summary 312 and KB Entry 20: 0.00\n",
            "Similarity between Summary 312 and KB Entry 21: 0.00\n",
            "Similarity between Summary 312 and KB Entry 22: 0.00\n",
            "Similarity between Summary 312 and KB Entry 23: 0.02\n",
            "Similarity between Summary 312 and KB Entry 24: 0.00\n",
            "Similarity between Summary 312 and KB Entry 25: 0.05\n",
            "Similarity between Summary 312 and KB Entry 26: 0.01\n",
            "Similarity between Summary 312 and KB Entry 27: 0.04\n",
            "Similarity between Summary 312 and KB Entry 28: 0.03\n",
            "Similarity between Summary 312 and KB Entry 29: 0.00\n",
            "Similarity between Summary 312 and KB Entry 30: 0.00\n",
            "Similarity between Summary 312 and KB Entry 31: 0.00\n",
            "Similarity between Summary 312 and KB Entry 32: 0.00\n",
            "Similarity between Summary 312 and KB Entry 33: 0.01\n",
            "Similarity between Summary 312 and KB Entry 34: 0.06\n",
            "Similarity between Summary 312 and KB Entry 35: 0.02\n",
            "Similarity between Summary 312 and KB Entry 36: 0.00\n",
            "Similarity between Summary 312 and KB Entry 37: 0.00\n",
            "Similarity between Summary 312 and KB Entry 38: 0.01\n",
            "Similarity between Summary 312 and KB Entry 39: 0.04\n",
            "Similarity between Summary 312 and KB Entry 40: 0.03\n",
            "Similarity between Summary 312 and KB Entry 41: 0.03\n",
            "Similarity between Summary 312 and KB Entry 42: 0.04\n",
            "Similarity between Summary 312 and KB Entry 43: 0.06\n",
            "Similarity between Summary 312 and KB Entry 44: 0.00\n",
            "Similarity between Summary 312 and KB Entry 45: 0.00\n",
            "Similarity between Summary 312 and KB Entry 46: 0.00\n",
            "Similarity between Summary 313 and KB Entry 1: 0.07\n",
            "Similarity between Summary 313 and KB Entry 2: 0.01\n",
            "Similarity between Summary 313 and KB Entry 3: 0.04\n",
            "Similarity between Summary 313 and KB Entry 4: 0.07\n",
            "Similarity between Summary 313 and KB Entry 5: 0.03\n",
            "Similarity between Summary 313 and KB Entry 6: 0.05\n",
            "Similarity between Summary 313 and KB Entry 7: 0.02\n",
            "Similarity between Summary 313 and KB Entry 8: 0.03\n",
            "Similarity between Summary 313 and KB Entry 9: 0.00\n",
            "Similarity between Summary 313 and KB Entry 10: 0.01\n",
            "Similarity between Summary 313 and KB Entry 11: 0.00\n",
            "Similarity between Summary 313 and KB Entry 12: 0.05\n",
            "Similarity between Summary 313 and KB Entry 13: 0.02\n",
            "Similarity between Summary 313 and KB Entry 14: 0.02\n",
            "Similarity between Summary 313 and KB Entry 15: 0.01\n",
            "Similarity between Summary 313 and KB Entry 16: 0.00\n",
            "Similarity between Summary 313 and KB Entry 17: 0.04\n",
            "Similarity between Summary 313 and KB Entry 18: 0.02\n",
            "Similarity between Summary 313 and KB Entry 19: 0.00\n",
            "Similarity between Summary 313 and KB Entry 20: 0.00\n",
            "Similarity between Summary 313 and KB Entry 21: 0.00\n",
            "Similarity between Summary 313 and KB Entry 22: 0.00\n",
            "Similarity between Summary 313 and KB Entry 23: 0.02\n",
            "Similarity between Summary 313 and KB Entry 24: 0.00\n",
            "Similarity between Summary 313 and KB Entry 25: 0.06\n",
            "Similarity between Summary 313 and KB Entry 26: 0.02\n",
            "Similarity between Summary 313 and KB Entry 27: 0.04\n",
            "Similarity between Summary 313 and KB Entry 28: 0.03\n",
            "Similarity between Summary 313 and KB Entry 29: 0.00\n",
            "Similarity between Summary 313 and KB Entry 30: 0.00\n",
            "Similarity between Summary 313 and KB Entry 31: 0.00\n",
            "Similarity between Summary 313 and KB Entry 32: 0.00\n",
            "Similarity between Summary 313 and KB Entry 33: 0.01\n",
            "Similarity between Summary 313 and KB Entry 34: 0.05\n",
            "Similarity between Summary 313 and KB Entry 35: 0.02\n",
            "Similarity between Summary 313 and KB Entry 36: 0.00\n",
            "Similarity between Summary 313 and KB Entry 37: 0.01\n",
            "Similarity between Summary 313 and KB Entry 38: 0.01\n",
            "Similarity between Summary 313 and KB Entry 39: 0.04\n",
            "Similarity between Summary 313 and KB Entry 40: 0.03\n",
            "Similarity between Summary 313 and KB Entry 41: 0.04\n",
            "Similarity between Summary 313 and KB Entry 42: 0.04\n",
            "Similarity between Summary 313 and KB Entry 43: 0.06\n",
            "Similarity between Summary 313 and KB Entry 44: 0.00\n",
            "Similarity between Summary 313 and KB Entry 45: 0.01\n",
            "Similarity between Summary 313 and KB Entry 46: 0.00\n",
            "Similarity between Summary 314 and KB Entry 1: 0.08\n",
            "Similarity between Summary 314 and KB Entry 2: 0.01\n",
            "Similarity between Summary 314 and KB Entry 3: 0.04\n",
            "Similarity between Summary 314 and KB Entry 4: 0.07\n",
            "Similarity between Summary 314 and KB Entry 5: 0.03\n",
            "Similarity between Summary 314 and KB Entry 6: 0.05\n",
            "Similarity between Summary 314 and KB Entry 7: 0.03\n",
            "Similarity between Summary 314 and KB Entry 8: 0.03\n",
            "Similarity between Summary 314 and KB Entry 9: 0.00\n",
            "Similarity between Summary 314 and KB Entry 10: 0.01\n",
            "Similarity between Summary 314 and KB Entry 11: 0.00\n",
            "Similarity between Summary 314 and KB Entry 12: 0.04\n",
            "Similarity between Summary 314 and KB Entry 13: 0.02\n",
            "Similarity between Summary 314 and KB Entry 14: 0.02\n",
            "Similarity between Summary 314 and KB Entry 15: 0.01\n",
            "Similarity between Summary 314 and KB Entry 16: 0.00\n",
            "Similarity between Summary 314 and KB Entry 17: 0.03\n",
            "Similarity between Summary 314 and KB Entry 18: 0.01\n",
            "Similarity between Summary 314 and KB Entry 19: 0.00\n",
            "Similarity between Summary 314 and KB Entry 20: 0.00\n",
            "Similarity between Summary 314 and KB Entry 21: 0.00\n",
            "Similarity between Summary 314 and KB Entry 22: 0.00\n",
            "Similarity between Summary 314 and KB Entry 23: 0.00\n",
            "Similarity between Summary 314 and KB Entry 24: 0.00\n",
            "Similarity between Summary 314 and KB Entry 25: 0.05\n",
            "Similarity between Summary 314 and KB Entry 26: 0.00\n",
            "Similarity between Summary 314 and KB Entry 27: 0.03\n",
            "Similarity between Summary 314 and KB Entry 28: 0.03\n",
            "Similarity between Summary 314 and KB Entry 29: 0.01\n",
            "Similarity between Summary 314 and KB Entry 30: 0.00\n",
            "Similarity between Summary 314 and KB Entry 31: 0.00\n",
            "Similarity between Summary 314 and KB Entry 32: 0.00\n",
            "Similarity between Summary 314 and KB Entry 33: 0.01\n",
            "Similarity between Summary 314 and KB Entry 34: 0.05\n",
            "Similarity between Summary 314 and KB Entry 35: 0.02\n",
            "Similarity between Summary 314 and KB Entry 36: 0.00\n",
            "Similarity between Summary 314 and KB Entry 37: 0.00\n",
            "Similarity between Summary 314 and KB Entry 38: 0.01\n",
            "Similarity between Summary 314 and KB Entry 39: 0.06\n",
            "Similarity between Summary 314 and KB Entry 40: 0.03\n",
            "Similarity between Summary 314 and KB Entry 41: 0.04\n",
            "Similarity between Summary 314 and KB Entry 42: 0.04\n",
            "Similarity between Summary 314 and KB Entry 43: 0.05\n",
            "Similarity between Summary 314 and KB Entry 44: 0.00\n",
            "Similarity between Summary 314 and KB Entry 45: 0.00\n",
            "Similarity between Summary 314 and KB Entry 46: 0.00\n",
            "Similarity between Summary 315 and KB Entry 1: 0.07\n",
            "Similarity between Summary 315 and KB Entry 2: 0.00\n",
            "Similarity between Summary 315 and KB Entry 3: 0.02\n",
            "Similarity between Summary 315 and KB Entry 4: 0.04\n",
            "Similarity between Summary 315 and KB Entry 5: 0.00\n",
            "Similarity between Summary 315 and KB Entry 6: 0.02\n",
            "Similarity between Summary 315 and KB Entry 7: 0.01\n",
            "Similarity between Summary 315 and KB Entry 8: 0.00\n",
            "Similarity between Summary 315 and KB Entry 9: 0.00\n",
            "Similarity between Summary 315 and KB Entry 10: 0.01\n",
            "Similarity between Summary 315 and KB Entry 11: 0.00\n",
            "Similarity between Summary 315 and KB Entry 12: 0.04\n",
            "Similarity between Summary 315 and KB Entry 13: 0.01\n",
            "Similarity between Summary 315 and KB Entry 14: 0.01\n",
            "Similarity between Summary 315 and KB Entry 15: 0.01\n",
            "Similarity between Summary 315 and KB Entry 16: 0.00\n",
            "Similarity between Summary 315 and KB Entry 17: 0.08\n",
            "Similarity between Summary 315 and KB Entry 18: 0.01\n",
            "Similarity between Summary 315 and KB Entry 19: 0.04\n",
            "Similarity between Summary 315 and KB Entry 20: 0.00\n",
            "Similarity between Summary 315 and KB Entry 21: 0.01\n",
            "Similarity between Summary 315 and KB Entry 22: 0.01\n",
            "Similarity between Summary 315 and KB Entry 23: 0.07\n",
            "Similarity between Summary 315 and KB Entry 24: 0.02\n",
            "Similarity between Summary 315 and KB Entry 25: 0.19\n",
            "Similarity between Summary 315 and KB Entry 26: 0.03\n",
            "Similarity between Summary 315 and KB Entry 27: 0.05\n",
            "Similarity between Summary 315 and KB Entry 28: 0.03\n",
            "Similarity between Summary 315 and KB Entry 29: 0.07\n",
            "Similarity between Summary 315 and KB Entry 30: 0.04\n",
            "Similarity between Summary 315 and KB Entry 31: 0.02\n",
            "Similarity between Summary 315 and KB Entry 32: 0.00\n",
            "Similarity between Summary 315 and KB Entry 33: 0.04\n",
            "Similarity between Summary 315 and KB Entry 34: 0.01\n",
            "Similarity between Summary 315 and KB Entry 35: 0.00\n",
            "Similarity between Summary 315 and KB Entry 36: 0.04\n",
            "Similarity between Summary 315 and KB Entry 37: 0.04\n",
            "Similarity between Summary 315 and KB Entry 38: 0.02\n",
            "Similarity between Summary 315 and KB Entry 39: 0.03\n",
            "Similarity between Summary 315 and KB Entry 40: 0.01\n",
            "Similarity between Summary 315 and KB Entry 41: 0.00\n",
            "Similarity between Summary 315 and KB Entry 42: 0.01\n",
            "Similarity between Summary 315 and KB Entry 43: 0.02\n",
            "Similarity between Summary 315 and KB Entry 44: 0.00\n",
            "Similarity between Summary 315 and KB Entry 45: 0.01\n",
            "Similarity between Summary 315 and KB Entry 46: 0.00\n",
            "Similarity between Summary 316 and KB Entry 1: 0.07\n",
            "Similarity between Summary 316 and KB Entry 2: 0.01\n",
            "Similarity between Summary 316 and KB Entry 3: 0.03\n",
            "Similarity between Summary 316 and KB Entry 4: 0.06\n",
            "Similarity between Summary 316 and KB Entry 5: 0.00\n",
            "Similarity between Summary 316 and KB Entry 6: 0.02\n",
            "Similarity between Summary 316 and KB Entry 7: 0.02\n",
            "Similarity between Summary 316 and KB Entry 8: 0.00\n",
            "Similarity between Summary 316 and KB Entry 9: 0.00\n",
            "Similarity between Summary 316 and KB Entry 10: 0.00\n",
            "Similarity between Summary 316 and KB Entry 11: 0.00\n",
            "Similarity between Summary 316 and KB Entry 12: 0.06\n",
            "Similarity between Summary 316 and KB Entry 13: 0.01\n",
            "Similarity between Summary 316 and KB Entry 14: 0.01\n",
            "Similarity between Summary 316 and KB Entry 15: 0.01\n",
            "Similarity between Summary 316 and KB Entry 16: 0.01\n",
            "Similarity between Summary 316 and KB Entry 17: 0.12\n",
            "Similarity between Summary 316 and KB Entry 18: 0.01\n",
            "Similarity between Summary 316 and KB Entry 19: 0.01\n",
            "Similarity between Summary 316 and KB Entry 20: 0.00\n",
            "Similarity between Summary 316 and KB Entry 21: 0.00\n",
            "Similarity between Summary 316 and KB Entry 22: 0.01\n",
            "Similarity between Summary 316 and KB Entry 23: 0.00\n",
            "Similarity between Summary 316 and KB Entry 24: 0.01\n",
            "Similarity between Summary 316 and KB Entry 25: 0.08\n",
            "Similarity between Summary 316 and KB Entry 26: 0.01\n",
            "Similarity between Summary 316 and KB Entry 27: 0.03\n",
            "Similarity between Summary 316 and KB Entry 28: 0.02\n",
            "Similarity between Summary 316 and KB Entry 29: 0.00\n",
            "Similarity between Summary 316 and KB Entry 30: 0.06\n",
            "Similarity between Summary 316 and KB Entry 31: 0.00\n",
            "Similarity between Summary 316 and KB Entry 32: 0.00\n",
            "Similarity between Summary 316 and KB Entry 33: 0.05\n",
            "Similarity between Summary 316 and KB Entry 34: 0.00\n",
            "Similarity between Summary 316 and KB Entry 35: 0.01\n",
            "Similarity between Summary 316 and KB Entry 36: 0.00\n",
            "Similarity between Summary 316 and KB Entry 37: 0.01\n",
            "Similarity between Summary 316 and KB Entry 38: 0.04\n",
            "Similarity between Summary 316 and KB Entry 39: 0.03\n",
            "Similarity between Summary 316 and KB Entry 40: 0.02\n",
            "Similarity between Summary 316 and KB Entry 41: 0.01\n",
            "Similarity between Summary 316 and KB Entry 42: 0.01\n",
            "Similarity between Summary 316 and KB Entry 43: 0.02\n",
            "Similarity between Summary 316 and KB Entry 44: 0.00\n",
            "Similarity between Summary 316 and KB Entry 45: 0.00\n",
            "Similarity between Summary 316 and KB Entry 46: 0.00\n",
            "Similarity between Summary 317 and KB Entry 1: 0.07\n",
            "Similarity between Summary 317 and KB Entry 2: 0.01\n",
            "Similarity between Summary 317 and KB Entry 3: 0.02\n",
            "Similarity between Summary 317 and KB Entry 4: 0.04\n",
            "Similarity between Summary 317 and KB Entry 5: 0.00\n",
            "Similarity between Summary 317 and KB Entry 6: 0.01\n",
            "Similarity between Summary 317 and KB Entry 7: 0.01\n",
            "Similarity between Summary 317 and KB Entry 8: 0.00\n",
            "Similarity between Summary 317 and KB Entry 9: 0.00\n",
            "Similarity between Summary 317 and KB Entry 10: 0.00\n",
            "Similarity between Summary 317 and KB Entry 11: 0.00\n",
            "Similarity between Summary 317 and KB Entry 12: 0.06\n",
            "Similarity between Summary 317 and KB Entry 13: 0.01\n",
            "Similarity between Summary 317 and KB Entry 14: 0.01\n",
            "Similarity between Summary 317 and KB Entry 15: 0.01\n",
            "Similarity between Summary 317 and KB Entry 16: 0.00\n",
            "Similarity between Summary 317 and KB Entry 17: 0.10\n",
            "Similarity between Summary 317 and KB Entry 18: 0.01\n",
            "Similarity between Summary 317 and KB Entry 19: 0.04\n",
            "Similarity between Summary 317 and KB Entry 20: 0.00\n",
            "Similarity between Summary 317 and KB Entry 21: 0.02\n",
            "Similarity between Summary 317 and KB Entry 22: 0.01\n",
            "Similarity between Summary 317 and KB Entry 23: 0.05\n",
            "Similarity between Summary 317 and KB Entry 24: 0.01\n",
            "Similarity between Summary 317 and KB Entry 25: 0.16\n",
            "Similarity between Summary 317 and KB Entry 26: 0.04\n",
            "Similarity between Summary 317 and KB Entry 27: 0.07\n",
            "Similarity between Summary 317 and KB Entry 28: 0.03\n",
            "Similarity between Summary 317 and KB Entry 29: 0.00\n",
            "Similarity between Summary 317 and KB Entry 30: 0.01\n",
            "Similarity between Summary 317 and KB Entry 31: 0.01\n",
            "Similarity between Summary 317 and KB Entry 32: 0.00\n",
            "Similarity between Summary 317 and KB Entry 33: 0.05\n",
            "Similarity between Summary 317 and KB Entry 34: 0.03\n",
            "Similarity between Summary 317 and KB Entry 35: 0.01\n",
            "Similarity between Summary 317 and KB Entry 36: 0.02\n",
            "Similarity between Summary 317 and KB Entry 37: 0.04\n",
            "Similarity between Summary 317 and KB Entry 38: 0.02\n",
            "Similarity between Summary 317 and KB Entry 39: 0.02\n",
            "Similarity between Summary 317 and KB Entry 40: 0.02\n",
            "Similarity between Summary 317 and KB Entry 41: 0.01\n",
            "Similarity between Summary 317 and KB Entry 42: 0.01\n",
            "Similarity between Summary 317 and KB Entry 43: 0.01\n",
            "Similarity between Summary 317 and KB Entry 44: 0.00\n",
            "Similarity between Summary 317 and KB Entry 45: 0.01\n",
            "Similarity between Summary 317 and KB Entry 46: 0.00\n",
            "Similarity between Summary 318 and KB Entry 1: 0.06\n",
            "Similarity between Summary 318 and KB Entry 2: 0.01\n",
            "Similarity between Summary 318 and KB Entry 3: 0.02\n",
            "Similarity between Summary 318 and KB Entry 4: 0.06\n",
            "Similarity between Summary 318 and KB Entry 5: 0.00\n",
            "Similarity between Summary 318 and KB Entry 6: 0.02\n",
            "Similarity between Summary 318 and KB Entry 7: 0.02\n",
            "Similarity between Summary 318 and KB Entry 8: 0.00\n",
            "Similarity between Summary 318 and KB Entry 9: 0.00\n",
            "Similarity between Summary 318 and KB Entry 10: 0.00\n",
            "Similarity between Summary 318 and KB Entry 11: 0.00\n",
            "Similarity between Summary 318 and KB Entry 12: 0.03\n",
            "Similarity between Summary 318 and KB Entry 13: 0.01\n",
            "Similarity between Summary 318 and KB Entry 14: 0.01\n",
            "Similarity between Summary 318 and KB Entry 15: 0.01\n",
            "Similarity between Summary 318 and KB Entry 16: 0.01\n",
            "Similarity between Summary 318 and KB Entry 17: 0.13\n",
            "Similarity between Summary 318 and KB Entry 18: 0.00\n",
            "Similarity between Summary 318 and KB Entry 19: 0.00\n",
            "Similarity between Summary 318 and KB Entry 20: 0.00\n",
            "Similarity between Summary 318 and KB Entry 21: 0.00\n",
            "Similarity between Summary 318 and KB Entry 22: 0.01\n",
            "Similarity between Summary 318 and KB Entry 23: 0.00\n",
            "Similarity between Summary 318 and KB Entry 24: 0.01\n",
            "Similarity between Summary 318 and KB Entry 25: 0.09\n",
            "Similarity between Summary 318 and KB Entry 26: 0.00\n",
            "Similarity between Summary 318 and KB Entry 27: 0.02\n",
            "Similarity between Summary 318 and KB Entry 28: 0.02\n",
            "Similarity between Summary 318 and KB Entry 29: 0.00\n",
            "Similarity between Summary 318 and KB Entry 30: 0.06\n",
            "Similarity between Summary 318 and KB Entry 31: 0.00\n",
            "Similarity between Summary 318 and KB Entry 32: 0.02\n",
            "Similarity between Summary 318 and KB Entry 33: 0.07\n",
            "Similarity between Summary 318 and KB Entry 34: 0.01\n",
            "Similarity between Summary 318 and KB Entry 35: 0.00\n",
            "Similarity between Summary 318 and KB Entry 36: 0.00\n",
            "Similarity between Summary 318 and KB Entry 37: 0.02\n",
            "Similarity between Summary 318 and KB Entry 38: 0.02\n",
            "Similarity between Summary 318 and KB Entry 39: 0.03\n",
            "Similarity between Summary 318 and KB Entry 40: 0.03\n",
            "Similarity between Summary 318 and KB Entry 41: 0.00\n",
            "Similarity between Summary 318 and KB Entry 42: 0.01\n",
            "Similarity between Summary 318 and KB Entry 43: 0.02\n",
            "Similarity between Summary 318 and KB Entry 44: 0.00\n",
            "Similarity between Summary 318 and KB Entry 45: 0.00\n",
            "Similarity between Summary 318 and KB Entry 46: 0.01\n",
            "Similarity between Summary 319 and KB Entry 1: 0.08\n",
            "Similarity between Summary 319 and KB Entry 2: 0.01\n",
            "Similarity between Summary 319 and KB Entry 3: 0.04\n",
            "Similarity between Summary 319 and KB Entry 4: 0.08\n",
            "Similarity between Summary 319 and KB Entry 5: 0.00\n",
            "Similarity between Summary 319 and KB Entry 6: 0.03\n",
            "Similarity between Summary 319 and KB Entry 7: 0.03\n",
            "Similarity between Summary 319 and KB Entry 8: 0.01\n",
            "Similarity between Summary 319 and KB Entry 9: 0.00\n",
            "Similarity between Summary 319 and KB Entry 10: 0.01\n",
            "Similarity between Summary 319 and KB Entry 11: 0.00\n",
            "Similarity between Summary 319 and KB Entry 12: 0.11\n",
            "Similarity between Summary 319 and KB Entry 13: 0.01\n",
            "Similarity between Summary 319 and KB Entry 14: 0.01\n",
            "Similarity between Summary 319 and KB Entry 15: 0.01\n",
            "Similarity between Summary 319 and KB Entry 16: 0.01\n",
            "Similarity between Summary 319 and KB Entry 17: 0.08\n",
            "Similarity between Summary 319 and KB Entry 18: 0.00\n",
            "Similarity between Summary 319 and KB Entry 19: 0.00\n",
            "Similarity between Summary 319 and KB Entry 20: 0.00\n",
            "Similarity between Summary 319 and KB Entry 21: 0.01\n",
            "Similarity between Summary 319 and KB Entry 22: 0.01\n",
            "Similarity between Summary 319 and KB Entry 23: 0.00\n",
            "Similarity between Summary 319 and KB Entry 24: 0.01\n",
            "Similarity between Summary 319 and KB Entry 25: 0.04\n",
            "Similarity between Summary 319 and KB Entry 26: 0.00\n",
            "Similarity between Summary 319 and KB Entry 27: 0.01\n",
            "Similarity between Summary 319 and KB Entry 28: 0.01\n",
            "Similarity between Summary 319 and KB Entry 29: 0.00\n",
            "Similarity between Summary 319 and KB Entry 30: 0.05\n",
            "Similarity between Summary 319 and KB Entry 31: 0.00\n",
            "Similarity between Summary 319 and KB Entry 32: 0.00\n",
            "Similarity between Summary 319 and KB Entry 33: 0.04\n",
            "Similarity between Summary 319 and KB Entry 34: 0.00\n",
            "Similarity between Summary 319 and KB Entry 35: 0.01\n",
            "Similarity between Summary 319 and KB Entry 36: 0.00\n",
            "Similarity between Summary 319 and KB Entry 37: 0.01\n",
            "Similarity between Summary 319 and KB Entry 38: 0.05\n",
            "Similarity between Summary 319 and KB Entry 39: 0.04\n",
            "Similarity between Summary 319 and KB Entry 40: 0.01\n",
            "Similarity between Summary 319 and KB Entry 41: 0.01\n",
            "Similarity between Summary 319 and KB Entry 42: 0.01\n",
            "Similarity between Summary 319 and KB Entry 43: 0.03\n",
            "Similarity between Summary 319 and KB Entry 44: 0.02\n",
            "Similarity between Summary 319 and KB Entry 45: 0.00\n",
            "Similarity between Summary 319 and KB Entry 46: 0.00\n",
            "Similarity between Summary 320 and KB Entry 1: 0.07\n",
            "Similarity between Summary 320 and KB Entry 2: 0.01\n",
            "Similarity between Summary 320 and KB Entry 3: 0.04\n",
            "Similarity between Summary 320 and KB Entry 4: 0.07\n",
            "Similarity between Summary 320 and KB Entry 5: 0.00\n",
            "Similarity between Summary 320 and KB Entry 6: 0.03\n",
            "Similarity between Summary 320 and KB Entry 7: 0.02\n",
            "Similarity between Summary 320 and KB Entry 8: 0.00\n",
            "Similarity between Summary 320 and KB Entry 9: 0.00\n",
            "Similarity between Summary 320 and KB Entry 10: 0.00\n",
            "Similarity between Summary 320 and KB Entry 11: 0.00\n",
            "Similarity between Summary 320 and KB Entry 12: 0.08\n",
            "Similarity between Summary 320 and KB Entry 13: 0.01\n",
            "Similarity between Summary 320 and KB Entry 14: 0.01\n",
            "Similarity between Summary 320 and KB Entry 15: 0.01\n",
            "Similarity between Summary 320 and KB Entry 16: 0.00\n",
            "Similarity between Summary 320 and KB Entry 17: 0.09\n",
            "Similarity between Summary 320 and KB Entry 18: 0.01\n",
            "Similarity between Summary 320 and KB Entry 19: 0.00\n",
            "Similarity between Summary 320 and KB Entry 20: 0.00\n",
            "Similarity between Summary 320 and KB Entry 21: 0.00\n",
            "Similarity between Summary 320 and KB Entry 22: 0.01\n",
            "Similarity between Summary 320 and KB Entry 23: 0.00\n",
            "Similarity between Summary 320 and KB Entry 24: 0.01\n",
            "Similarity between Summary 320 and KB Entry 25: 0.05\n",
            "Similarity between Summary 320 and KB Entry 26: 0.00\n",
            "Similarity between Summary 320 and KB Entry 27: 0.01\n",
            "Similarity between Summary 320 and KB Entry 28: 0.01\n",
            "Similarity between Summary 320 and KB Entry 29: 0.00\n",
            "Similarity between Summary 320 and KB Entry 30: 0.07\n",
            "Similarity between Summary 320 and KB Entry 31: 0.00\n",
            "Similarity between Summary 320 and KB Entry 32: 0.00\n",
            "Similarity between Summary 320 and KB Entry 33: 0.04\n",
            "Similarity between Summary 320 and KB Entry 34: 0.00\n",
            "Similarity between Summary 320 and KB Entry 35: 0.01\n",
            "Similarity between Summary 320 and KB Entry 36: 0.00\n",
            "Similarity between Summary 320 and KB Entry 37: 0.01\n",
            "Similarity between Summary 320 and KB Entry 38: 0.03\n",
            "Similarity between Summary 320 and KB Entry 39: 0.04\n",
            "Similarity between Summary 320 and KB Entry 40: 0.02\n",
            "Similarity between Summary 320 and KB Entry 41: 0.01\n",
            "Similarity between Summary 320 and KB Entry 42: 0.01\n",
            "Similarity between Summary 320 and KB Entry 43: 0.03\n",
            "Similarity between Summary 320 and KB Entry 44: 0.00\n",
            "Similarity between Summary 320 and KB Entry 45: 0.00\n",
            "Similarity between Summary 320 and KB Entry 46: 0.00\n",
            "Similarity between Summary 321 and KB Entry 1: 0.06\n",
            "Similarity between Summary 321 and KB Entry 2: 0.01\n",
            "Similarity between Summary 321 and KB Entry 3: 0.02\n",
            "Similarity between Summary 321 and KB Entry 4: 0.05\n",
            "Similarity between Summary 321 and KB Entry 5: 0.00\n",
            "Similarity between Summary 321 and KB Entry 6: 0.02\n",
            "Similarity between Summary 321 and KB Entry 7: 0.01\n",
            "Similarity between Summary 321 and KB Entry 8: 0.00\n",
            "Similarity between Summary 321 and KB Entry 9: 0.00\n",
            "Similarity between Summary 321 and KB Entry 10: 0.00\n",
            "Similarity between Summary 321 and KB Entry 11: 0.00\n",
            "Similarity between Summary 321 and KB Entry 12: 0.04\n",
            "Similarity between Summary 321 and KB Entry 13: 0.01\n",
            "Similarity between Summary 321 and KB Entry 14: 0.01\n",
            "Similarity between Summary 321 and KB Entry 15: 0.01\n",
            "Similarity between Summary 321 and KB Entry 16: 0.01\n",
            "Similarity between Summary 321 and KB Entry 17: 0.12\n",
            "Similarity between Summary 321 and KB Entry 18: 0.00\n",
            "Similarity between Summary 321 and KB Entry 19: 0.01\n",
            "Similarity between Summary 321 and KB Entry 20: 0.00\n",
            "Similarity between Summary 321 and KB Entry 21: 0.00\n",
            "Similarity between Summary 321 and KB Entry 22: 0.01\n",
            "Similarity between Summary 321 and KB Entry 23: 0.00\n",
            "Similarity between Summary 321 and KB Entry 24: 0.02\n",
            "Similarity between Summary 321 and KB Entry 25: 0.08\n",
            "Similarity between Summary 321 and KB Entry 26: 0.01\n",
            "Similarity between Summary 321 and KB Entry 27: 0.01\n",
            "Similarity between Summary 321 and KB Entry 28: 0.02\n",
            "Similarity between Summary 321 and KB Entry 29: 0.00\n",
            "Similarity between Summary 321 and KB Entry 30: 0.06\n",
            "Similarity between Summary 321 and KB Entry 31: 0.00\n",
            "Similarity between Summary 321 and KB Entry 32: 0.02\n",
            "Similarity between Summary 321 and KB Entry 33: 0.07\n",
            "Similarity between Summary 321 and KB Entry 34: 0.01\n",
            "Similarity between Summary 321 and KB Entry 35: 0.01\n",
            "Similarity between Summary 321 and KB Entry 36: 0.00\n",
            "Similarity between Summary 321 and KB Entry 37: 0.03\n",
            "Similarity between Summary 321 and KB Entry 38: 0.02\n",
            "Similarity between Summary 321 and KB Entry 39: 0.04\n",
            "Similarity between Summary 321 and KB Entry 40: 0.02\n",
            "Similarity between Summary 321 and KB Entry 41: 0.00\n",
            "Similarity between Summary 321 and KB Entry 42: 0.01\n",
            "Similarity between Summary 321 and KB Entry 43: 0.02\n",
            "Similarity between Summary 321 and KB Entry 44: 0.00\n",
            "Similarity between Summary 321 and KB Entry 45: 0.00\n",
            "Similarity between Summary 321 and KB Entry 46: 0.00\n",
            "Similarity between Summary 322 and KB Entry 1: 0.07\n",
            "Similarity between Summary 322 and KB Entry 2: 0.00\n",
            "Similarity between Summary 322 and KB Entry 3: 0.01\n",
            "Similarity between Summary 322 and KB Entry 4: 0.03\n",
            "Similarity between Summary 322 and KB Entry 5: 0.00\n",
            "Similarity between Summary 322 and KB Entry 6: 0.01\n",
            "Similarity between Summary 322 and KB Entry 7: 0.01\n",
            "Similarity between Summary 322 and KB Entry 8: 0.00\n",
            "Similarity between Summary 322 and KB Entry 9: 0.00\n",
            "Similarity between Summary 322 and KB Entry 10: 0.00\n",
            "Similarity between Summary 322 and KB Entry 11: 0.00\n",
            "Similarity between Summary 322 and KB Entry 12: 0.05\n",
            "Similarity between Summary 322 and KB Entry 13: 0.01\n",
            "Similarity between Summary 322 and KB Entry 14: 0.01\n",
            "Similarity between Summary 322 and KB Entry 15: 0.01\n",
            "Similarity between Summary 322 and KB Entry 16: 0.00\n",
            "Similarity between Summary 322 and KB Entry 17: 0.10\n",
            "Similarity between Summary 322 and KB Entry 18: 0.02\n",
            "Similarity between Summary 322 and KB Entry 19: 0.06\n",
            "Similarity between Summary 322 and KB Entry 20: 0.00\n",
            "Similarity between Summary 322 and KB Entry 21: 0.01\n",
            "Similarity between Summary 322 and KB Entry 22: 0.00\n",
            "Similarity between Summary 322 and KB Entry 23: 0.05\n",
            "Similarity between Summary 322 and KB Entry 24: 0.01\n",
            "Similarity between Summary 322 and KB Entry 25: 0.15\n",
            "Similarity between Summary 322 and KB Entry 26: 0.03\n",
            "Similarity between Summary 322 and KB Entry 27: 0.05\n",
            "Similarity between Summary 322 and KB Entry 28: 0.03\n",
            "Similarity between Summary 322 and KB Entry 29: 0.00\n",
            "Similarity between Summary 322 and KB Entry 30: 0.04\n",
            "Similarity between Summary 322 and KB Entry 31: 0.01\n",
            "Similarity between Summary 322 and KB Entry 32: 0.01\n",
            "Similarity between Summary 322 and KB Entry 33: 0.07\n",
            "Similarity between Summary 322 and KB Entry 34: 0.01\n",
            "Similarity between Summary 322 and KB Entry 35: 0.00\n",
            "Similarity between Summary 322 and KB Entry 36: 0.01\n",
            "Similarity between Summary 322 and KB Entry 37: 0.04\n",
            "Similarity between Summary 322 and KB Entry 38: 0.02\n",
            "Similarity between Summary 322 and KB Entry 39: 0.02\n",
            "Similarity between Summary 322 and KB Entry 40: 0.02\n",
            "Similarity between Summary 322 and KB Entry 41: 0.00\n",
            "Similarity between Summary 322 and KB Entry 42: 0.01\n",
            "Similarity between Summary 322 and KB Entry 43: 0.01\n",
            "Similarity between Summary 322 and KB Entry 44: 0.00\n",
            "Similarity between Summary 322 and KB Entry 45: 0.01\n",
            "Similarity between Summary 322 and KB Entry 46: 0.00\n",
            "Similarity between Summary 323 and KB Entry 1: 0.07\n",
            "Similarity between Summary 323 and KB Entry 2: 0.01\n",
            "Similarity between Summary 323 and KB Entry 3: 0.03\n",
            "Similarity between Summary 323 and KB Entry 4: 0.06\n",
            "Similarity between Summary 323 and KB Entry 5: 0.00\n",
            "Similarity between Summary 323 and KB Entry 6: 0.02\n",
            "Similarity between Summary 323 and KB Entry 7: 0.02\n",
            "Similarity between Summary 323 and KB Entry 8: 0.00\n",
            "Similarity between Summary 323 and KB Entry 9: 0.00\n",
            "Similarity between Summary 323 and KB Entry 10: 0.00\n",
            "Similarity between Summary 323 and KB Entry 11: 0.00\n",
            "Similarity between Summary 323 and KB Entry 12: 0.08\n",
            "Similarity between Summary 323 and KB Entry 13: 0.01\n",
            "Similarity between Summary 323 and KB Entry 14: 0.01\n",
            "Similarity between Summary 323 and KB Entry 15: 0.01\n",
            "Similarity between Summary 323 and KB Entry 16: 0.00\n",
            "Similarity between Summary 323 and KB Entry 17: 0.09\n",
            "Similarity between Summary 323 and KB Entry 18: 0.01\n",
            "Similarity between Summary 323 and KB Entry 19: 0.00\n",
            "Similarity between Summary 323 and KB Entry 20: 0.00\n",
            "Similarity between Summary 323 and KB Entry 21: 0.00\n",
            "Similarity between Summary 323 and KB Entry 22: 0.01\n",
            "Similarity between Summary 323 and KB Entry 23: 0.00\n",
            "Similarity between Summary 323 and KB Entry 24: 0.01\n",
            "Similarity between Summary 323 and KB Entry 25: 0.06\n",
            "Similarity between Summary 323 and KB Entry 26: 0.01\n",
            "Similarity between Summary 323 and KB Entry 27: 0.01\n",
            "Similarity between Summary 323 and KB Entry 28: 0.01\n",
            "Similarity between Summary 323 and KB Entry 29: 0.00\n",
            "Similarity between Summary 323 and KB Entry 30: 0.05\n",
            "Similarity between Summary 323 and KB Entry 31: 0.00\n",
            "Similarity between Summary 323 and KB Entry 32: 0.00\n",
            "Similarity between Summary 323 and KB Entry 33: 0.06\n",
            "Similarity between Summary 323 and KB Entry 34: 0.00\n",
            "Similarity between Summary 323 and KB Entry 35: 0.01\n",
            "Similarity between Summary 323 and KB Entry 36: 0.00\n",
            "Similarity between Summary 323 and KB Entry 37: 0.03\n",
            "Similarity between Summary 323 and KB Entry 38: 0.04\n",
            "Similarity between Summary 323 and KB Entry 39: 0.04\n",
            "Similarity between Summary 323 and KB Entry 40: 0.02\n",
            "Similarity between Summary 323 and KB Entry 41: 0.01\n",
            "Similarity between Summary 323 and KB Entry 42: 0.01\n",
            "Similarity between Summary 323 and KB Entry 43: 0.03\n",
            "Similarity between Summary 323 and KB Entry 44: 0.00\n",
            "Similarity between Summary 323 and KB Entry 45: 0.00\n",
            "Similarity between Summary 323 and KB Entry 46: 0.00\n",
            "Similarity between Summary 324 and KB Entry 1: 0.08\n",
            "Similarity between Summary 324 and KB Entry 2: 0.00\n",
            "Similarity between Summary 324 and KB Entry 3: 0.02\n",
            "Similarity between Summary 324 and KB Entry 4: 0.05\n",
            "Similarity between Summary 324 and KB Entry 5: 0.01\n",
            "Similarity between Summary 324 and KB Entry 6: 0.02\n",
            "Similarity between Summary 324 and KB Entry 7: 0.02\n",
            "Similarity between Summary 324 and KB Entry 8: 0.00\n",
            "Similarity between Summary 324 and KB Entry 9: 0.00\n",
            "Similarity between Summary 324 and KB Entry 10: 0.00\n",
            "Similarity between Summary 324 and KB Entry 11: 0.00\n",
            "Similarity between Summary 324 and KB Entry 12: 0.03\n",
            "Similarity between Summary 324 and KB Entry 13: 0.01\n",
            "Similarity between Summary 324 and KB Entry 14: 0.01\n",
            "Similarity between Summary 324 and KB Entry 15: 0.01\n",
            "Similarity between Summary 324 and KB Entry 16: 0.00\n",
            "Similarity between Summary 324 and KB Entry 17: 0.11\n",
            "Similarity between Summary 324 and KB Entry 18: 0.03\n",
            "Similarity between Summary 324 and KB Entry 19: 0.01\n",
            "Similarity between Summary 324 and KB Entry 20: 0.00\n",
            "Similarity between Summary 324 and KB Entry 21: 0.03\n",
            "Similarity between Summary 324 and KB Entry 22: 0.00\n",
            "Similarity between Summary 324 and KB Entry 23: 0.06\n",
            "Similarity between Summary 324 and KB Entry 24: 0.00\n",
            "Similarity between Summary 324 and KB Entry 25: 0.05\n",
            "Similarity between Summary 324 and KB Entry 26: 0.02\n",
            "Similarity between Summary 324 and KB Entry 27: 0.05\n",
            "Similarity between Summary 324 and KB Entry 28: 0.02\n",
            "Similarity between Summary 324 and KB Entry 29: 0.00\n",
            "Similarity between Summary 324 and KB Entry 30: 0.01\n",
            "Similarity between Summary 324 and KB Entry 31: 0.02\n",
            "Similarity between Summary 324 and KB Entry 32: 0.00\n",
            "Similarity between Summary 324 and KB Entry 33: 0.04\n",
            "Similarity between Summary 324 and KB Entry 34: 0.00\n",
            "Similarity between Summary 324 and KB Entry 35: 0.01\n",
            "Similarity between Summary 324 and KB Entry 36: 0.02\n",
            "Similarity between Summary 324 and KB Entry 37: 0.02\n",
            "Similarity between Summary 324 and KB Entry 38: 0.01\n",
            "Similarity between Summary 324 and KB Entry 39: 0.02\n",
            "Similarity between Summary 324 and KB Entry 40: 0.02\n",
            "Similarity between Summary 324 and KB Entry 41: 0.02\n",
            "Similarity between Summary 324 and KB Entry 42: 0.02\n",
            "Similarity between Summary 324 and KB Entry 43: 0.02\n",
            "Similarity between Summary 324 and KB Entry 44: 0.00\n",
            "Similarity between Summary 324 and KB Entry 45: 0.00\n",
            "Similarity between Summary 324 and KB Entry 46: 0.01\n",
            "Similarity between Summary 325 and KB Entry 1: 0.08\n",
            "Similarity between Summary 325 and KB Entry 2: 0.00\n",
            "Similarity between Summary 325 and KB Entry 3: 0.03\n",
            "Similarity between Summary 325 and KB Entry 4: 0.05\n",
            "Similarity between Summary 325 and KB Entry 5: 0.01\n",
            "Similarity between Summary 325 and KB Entry 6: 0.03\n",
            "Similarity between Summary 325 and KB Entry 7: 0.02\n",
            "Similarity between Summary 325 and KB Entry 8: 0.00\n",
            "Similarity between Summary 325 and KB Entry 9: 0.00\n",
            "Similarity between Summary 325 and KB Entry 10: 0.00\n",
            "Similarity between Summary 325 and KB Entry 11: 0.00\n",
            "Similarity between Summary 325 and KB Entry 12: 0.02\n",
            "Similarity between Summary 325 and KB Entry 13: 0.01\n",
            "Similarity between Summary 325 and KB Entry 14: 0.01\n",
            "Similarity between Summary 325 and KB Entry 15: 0.01\n",
            "Similarity between Summary 325 and KB Entry 16: 0.00\n",
            "Similarity between Summary 325 and KB Entry 17: 0.11\n",
            "Similarity between Summary 325 and KB Entry 18: 0.03\n",
            "Similarity between Summary 325 and KB Entry 19: 0.01\n",
            "Similarity between Summary 325 and KB Entry 20: 0.00\n",
            "Similarity between Summary 325 and KB Entry 21: 0.03\n",
            "Similarity between Summary 325 and KB Entry 22: 0.00\n",
            "Similarity between Summary 325 and KB Entry 23: 0.06\n",
            "Similarity between Summary 325 and KB Entry 24: 0.00\n",
            "Similarity between Summary 325 and KB Entry 25: 0.05\n",
            "Similarity between Summary 325 and KB Entry 26: 0.02\n",
            "Similarity between Summary 325 and KB Entry 27: 0.05\n",
            "Similarity between Summary 325 and KB Entry 28: 0.02\n",
            "Similarity between Summary 325 and KB Entry 29: 0.00\n",
            "Similarity between Summary 325 and KB Entry 30: 0.01\n",
            "Similarity between Summary 325 and KB Entry 31: 0.02\n",
            "Similarity between Summary 325 and KB Entry 32: 0.00\n",
            "Similarity between Summary 325 and KB Entry 33: 0.04\n",
            "Similarity between Summary 325 and KB Entry 34: 0.00\n",
            "Similarity between Summary 325 and KB Entry 35: 0.01\n",
            "Similarity between Summary 325 and KB Entry 36: 0.02\n",
            "Similarity between Summary 325 and KB Entry 37: 0.02\n",
            "Similarity between Summary 325 and KB Entry 38: 0.01\n",
            "Similarity between Summary 325 and KB Entry 39: 0.02\n",
            "Similarity between Summary 325 and KB Entry 40: 0.03\n",
            "Similarity between Summary 325 and KB Entry 41: 0.02\n",
            "Similarity between Summary 325 and KB Entry 42: 0.02\n",
            "Similarity between Summary 325 and KB Entry 43: 0.02\n",
            "Similarity between Summary 325 and KB Entry 44: 0.00\n",
            "Similarity between Summary 325 and KB Entry 45: 0.00\n",
            "Similarity between Summary 325 and KB Entry 46: 0.01\n",
            "Similarity between Summary 326 and KB Entry 1: 0.11\n",
            "Similarity between Summary 326 and KB Entry 2: 0.01\n",
            "Similarity between Summary 326 and KB Entry 3: 0.04\n",
            "Similarity between Summary 326 and KB Entry 4: 0.08\n",
            "Similarity between Summary 326 and KB Entry 5: 0.01\n",
            "Similarity between Summary 326 and KB Entry 6: 0.05\n",
            "Similarity between Summary 326 and KB Entry 7: 0.03\n",
            "Similarity between Summary 326 and KB Entry 8: 0.01\n",
            "Similarity between Summary 326 and KB Entry 9: 0.00\n",
            "Similarity between Summary 326 and KB Entry 10: 0.02\n",
            "Similarity between Summary 326 and KB Entry 11: 0.04\n",
            "Similarity between Summary 326 and KB Entry 12: 0.04\n",
            "Similarity between Summary 326 and KB Entry 13: 0.01\n",
            "Similarity between Summary 326 and KB Entry 14: 0.01\n",
            "Similarity between Summary 326 and KB Entry 15: 0.00\n",
            "Similarity between Summary 326 and KB Entry 16: 0.02\n",
            "Similarity between Summary 326 and KB Entry 17: 0.06\n",
            "Similarity between Summary 326 and KB Entry 18: 0.00\n",
            "Similarity between Summary 326 and KB Entry 19: 0.01\n",
            "Similarity between Summary 326 and KB Entry 20: 0.00\n",
            "Similarity between Summary 326 and KB Entry 21: 0.00\n",
            "Similarity between Summary 326 and KB Entry 22: 0.00\n",
            "Similarity between Summary 326 and KB Entry 23: 0.00\n",
            "Similarity between Summary 326 and KB Entry 24: 0.01\n",
            "Similarity between Summary 326 and KB Entry 25: 0.03\n",
            "Similarity between Summary 326 and KB Entry 26: 0.00\n",
            "Similarity between Summary 326 and KB Entry 27: 0.00\n",
            "Similarity between Summary 326 and KB Entry 28: 0.02\n",
            "Similarity between Summary 326 and KB Entry 29: 0.00\n",
            "Similarity between Summary 326 and KB Entry 30: 0.03\n",
            "Similarity between Summary 326 and KB Entry 31: 0.00\n",
            "Similarity between Summary 326 and KB Entry 32: 0.03\n",
            "Similarity between Summary 326 and KB Entry 33: 0.04\n",
            "Similarity between Summary 326 and KB Entry 34: 0.01\n",
            "Similarity between Summary 326 and KB Entry 35: 0.02\n",
            "Similarity between Summary 326 and KB Entry 36: 0.00\n",
            "Similarity between Summary 326 and KB Entry 37: 0.00\n",
            "Similarity between Summary 326 and KB Entry 38: 0.02\n",
            "Similarity between Summary 326 and KB Entry 39: 0.05\n",
            "Similarity between Summary 326 and KB Entry 40: 0.01\n",
            "Similarity between Summary 326 and KB Entry 41: 0.03\n",
            "Similarity between Summary 326 and KB Entry 42: 0.03\n",
            "Similarity between Summary 326 and KB Entry 43: 0.04\n",
            "Similarity between Summary 326 and KB Entry 44: 0.10\n",
            "Similarity between Summary 326 and KB Entry 45: 0.01\n",
            "Similarity between Summary 326 and KB Entry 46: 0.01\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Combine all texts to ensure the vocabulary is the same for both sets\n",
        "all_texts = selected_summaries + knowledge_base\n",
        "\n",
        "# Create a TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(all_texts)\n",
        "\n",
        "# Extract TF-IDF vectors for summaries and KB entries\n",
        "tfidf_summaries = tfidf_matrix[:len(selected_summaries)]\n",
        "tfidf_kb_entries = tfidf_matrix[len(selected_summaries):]\n",
        "\n",
        "# Calculate cosine similarity between each summary and each KB entry\n",
        "similarity_matrix = cosine_similarity(tfidf_summaries, tfidf_kb_entries)\n",
        "\n",
        "# Print out similarity scores\n",
        "for i, summary in enumerate(selected_summaries):\n",
        "    for j, entry in enumerate(knowledge_base):\n",
        "        print(f\"Similarity between Summary {i+1} and KB Entry {j+1}: {similarity_matrix[i][j]:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijGnHfIGcfzI",
        "outputId": "15054646-7d00-4426-96b5-5052e7d280da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(326, 46)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_matrix = similarity_matrix.T\n",
        "similarity_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7W8DAcwVdPfI",
        "outputId": "c239f075-b1e3-4ab4-9287-e8a9bb8b5e59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46, 326)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "CKGk3AaAdCEb",
        "outputId": "b94db5ef-6616-4822-e4e8-a03a8c7f593d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"321de47d-8d0c-489b-adc7-b8206fa8e504\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"321de47d-8d0c-489b-adc7-b8206fa8e504\")) {                    Plotly.newPlot(                        \"321de47d-8d0c-489b-adc7-b8206fa8e504\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"hoverongaps\":false,\"x\":[\"Summary 1\",\"Summary 2\",\"Summary 3\",\"Summary 4\",\"Summary 5\",\"Summary 6\",\"Summary 7\",\"Summary 8\",\"Summary 9\",\"Summary 10\"],\"y\":[\"Investment\",\"Objective\",\"Fees\",\"Expenses\",\"Shareholder\",\"Annual\",\"Operating\",\"Fee\",\"Waiver\",\"Expense\"],\"z\":[[0.08956232638918345,0.09807531626908574,0.10055279405964773,0.08194909428905205,0.08951824656169606,0.09337629477941709,0.09436289028685066,0.11750978326504816,0.08405912821263484,0.09756376612789831,0.0980620465747628,0.07850241879297243,0.09316727302431836,0.05851607178020634,0.0786640903484874,0.08609296288036394,0.09494612071500959,0.062149392782808836,0.09273165181485399,0.09301666579768987,0.09297631375694328,0.09346249490696851,0.09341732503331038,0.09282894661026407,0.09332043251577478,0.0928085294871835,0.10012452012867379,0.10624356476164844,0.10322535590718811,0.11136908845938864,0.09525237837650709,0.11202108835244431,0.1148007706456475,0.09675120099554942,0.0969529512750741,0.09879434029825776,0.10136652037447745,0.08274385190187465,0.08565099278502733,0.10149755081794763,0.09317761891174799,0.17162725678265472,0.14116282882191994,0.061227239130052194,0.08770030725892286,0.09371019406084373,0.09258056182145746,0.10263178713313649,0.10112380231796987,0.09815172730296184,0.0954192518777056,0.08405048614626154,0.08717718154315057,0.09032465015530422,0.10037032403310206,0.09134742055318598,0.07699388324782816,0.07408286800195023,0.05486365681419125,0.08269201593629401,0.08407642481586064,0.08662621919118442,0.06491483099105325,0.06299180969350475,0.062468806206500756,0.06855735951087792,0.06886404510966469,0.08813889985525233,0.0757645347892372,0.1259667855702494,0.0845773801639697,0.08342520729089309,0.08570702307096896,0.09339341777968106,0.06779859526008583,0.09699842184689139,0.10687867561937013,0.10316942313324722,0.09680667249669184,0.08579309827767585,0.11490913912420074,0.11346376829930423,0.08580997875862388,0.08744012735350902,0.0953117529638724,0.08639011232588409,0.10483784364506807,0.10449748839662867,0.07878757122115027,0.0852564811929466,0.11938278500530912,0.10304754485873258,0.0976441349475296,0.08801674229908618,0.0862113459230894,0.08713137961383849,0.08550433619464128,0.089631174296516,0.08863186047570684,0.0897658172447169,0.0901672556822711,0.09016363518814713,0.09002738939125673,0.08802769154970864,0.08581615581510683,0.09004383354179991,0.08498388490451392,0.08003210536160553,0.08864046089429453,0.08904145082286344,0.08856948627202624,0.11420830536019055,0.08888403033523999,0.10379050982510495,0.10437144623688188,0.08873163850760694,0.1310794365208763,0.09709860273981517,0.13414940720836652,0.12032923904098464,0.11985315829061097,0.10445143422253664,0.07800779669423079,0.08475893417285991,0.08818551854274584,0.08594826918051296,0.08745806002977366,0.08832070650091561,0.07405172253702819,0.08355793376356975,0.08816177883678106,0.08776016153727371,0.1309551485763665,0.1732976469239096,0.0843480009370811,0.08894350423713451,0.08827357403318555,0.05200260723652482,0.05409455338748541,0.05438912388951589,0.05926690606316237,0.054888451253358735,0.05430906903129797,0.04886899024969084,0.05803625620552807,0.05076546577349001,0.0587986269419901,0.05261189615476032,0.055108841808864335,0.053453433786219515,0.056591362612706836,0.05140215047896873,0.056660561296595906,0.047221375064356176,0.0918283469376957,0.06976407584657071,0.0872396029692604,0.07278329632432146,0.05789078785199139,0.07309188829146145,0.06774612325943856,0.08549853283220352,0.09239790768388413,0.09383741949146265,0.10088506602799152,0.11310688772982633,0.10691437533282429,0.07516841915473642,0.1023613423261716,0.1692376078978226,0.07881714867778265,0.08932309064900407,0.15100985303030917,0.09377618121935613,0.15583616812912876,0.08176928073883613,0.05162450615357911,0.05314562540526079,0.06411728080377505,0.054653118031195554,0.054809018793975844,0.05415310235070369,0.07384579301372765,0.060006915805351564,0.045111055374027584,0.06648200136501141,0.04861100903957914,0.05235504624822225,0.0529647094267808,0.05085800996067744,0.0698936962259967,0.04868960181717392,0.0527451119999,0.060920523358488354,0.06381946524394151,0.048755996648415664,0.05827819467350418,0.04832825408866185,0.07086579399145629,0.05772239795782152,0.06472568363389278,0.04832825408866185,0.06830977256083305,0.061527246993117936,0.038314540560358185,0.0581779695637607,0.07789802075753512,0.06310936852308142,0.06868325028937247,0.06414258628014022,0.0763638248644467,0.08553518164426994,0.0710218333643458,0.06251690417682201,0.07737180676248481,0.05712093448107048,0.09016545498100403,0.06244361357997407,0.07025475002237504,0.06267999217622217,0.06000548873193586,0.07119147866097211,0.07838850520156841,0.05645386409523491,0.06315895291226402,0.06595399354728965,0.10475518195409281,0.054533562421457515,0.07587262184122594,0.07808859652821266,0.0857729805658709,0.08742805216906961,0.09746321230659177,0.05882878555584155,0.09160430929773321,0.07079902192335955,0.06763867430837246,0.10078705985366579,0.0775354991785342,0.06813295262954339,0.0778723888518086,0.09550661674024183,0.09382118652917742,0.09436416297159488,0.09650911470280135,0.10079056291607487,0.09938304671648575,0.10078074993048075,0.10136582775256388,0.09175196206251421,0.10643992658607594,0.1317653992897557,0.10419738157044424,0.10082816580569452,0.09760406007732056,0.09984415561539021,0.096633140239827,0.09655016665893175,0.06778416903690898,0.10503776815790776,0.08256715895044907,0.051636095984787835,0.052088405604454366,0.080347818952104,0.05812469251581383,0.06128986811784982,0.05926885811266096,0.05210637460027446,0.06873071026612107,0.06919409200197447,0.06697244197813468,0.06861232285605331,0.06859218329414868,0.06914660424932934,0.09079779623425312,0.08717171080562464,0.08195994960106745,0.1228064430418457,0.10257387341740622,0.09592988417745456,0.10008895388624735,0.07981238471641154,0.07594227312887433,0.08923746112572066,0.08795368290424403,0.06198700792257761,0.060603959064701736,0.06681913213295998,0.07606666853582049,0.059495670903999785,0.10662076163084848,0.06171457951893828,0.07621022508785702,0.13104152907414174,0.053167698417096884,0.05599831480203866,0.1022763166451702,0.089525767199786,0.0875574524903687,0.08795676259980804,0.10126284788524306,0.0932179653887812,0.10071545783564645,0.098712803882435,0.09123010132451105,0.08228599031984932,0.1018365174760352,0.10076342439699505,0.10168892082340743,0.10311867036781423,0.08452184547560081,0.08217592560439645,0.07156682963507005,0.0820081491172198,0.07149433772345613,0.06858642675569389,0.06651322453868197,0.06380852810567748,0.07536928811735624,0.06592083326986523,0.05778769671737212,0.06582874598634485,0.07288247581723219,0.0813253198226818,0.08304712073272559,0.10669466455830623],[0.004994163807555953,0.008413637135728428,0.008626173785464273,0.008308428478813482,0.008681227536435807,0.008010519784583834,0.008418963650392679,0.007083855760849258,0.008522354771642565,0.008059761688893417,0.008412498761699342,0.008754885107334864,0.008312291861912667,0.006869402621369363,0.007975377570446725,0.006400940762138708,0.008145191242100143,0.006601080113140679,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.004557658449367566,0.0110220298429622,0.004698808193385163,0.00517512490359217,0.016165288119564015,0.0050991890815630025,0.012310590266978828,0.0020750111459978777,0.002079338059508142,0.02754479135372892,0.01798487049761799,0.008389005169030928,0.02089526463341148,0.008085277678153356,0.01222531604668606,0.0,0.004770609027912902,0.0024386757406644334,0.01150666851282489,0.009797731335105034,0.005736073659200223,0.011166715171534218,0.010024628364868497,0.006841406201524734,0.0057521697200752136,0.0062490843020328625,0.005719016051664573,0.009827653492424688,0.010920659685076982,0.00565967112925397,0.005599987530984869,0.0091800001940689,0.004894881144930967,0.012720172060718401,0.006466564986949402,0.0034503149619126245,0.008043940214087436,0.004014333498430139,0.007333427690098405,0.011468662017208794,0.006981797645466727,0.0057821069014343295,0.0038407027190967306,0.01139050530318126,0.012303114334344412,0.004229042273864233,0.01911673936714938,0.0031562379822343382,0.0022912589194114684,0.01423372231407024,0.016107448694091166,0.003434579773253131,0.018614214396045888,0.019135938228965255,0.021358499230200237,0.02013121464065289,0.019139703378460743,0.019027613646689763,0.01518503614115183,0.019269100734780827,0.015589214364359996,0.015334148783401648,0.012203731081950974,0.008643748689258362,0.016138202859116286,0.009193799933327933,0.015020194914699619,0.006134973913849825,0.006009133540966423,0.019434438568688372,0.006357176853681282,0.0199920115855526,0.019769117111168855,0.020022043361901307,0.020111583211819148,0.020110775669565685,0.020080386381783905,0.01963435872757088,0.019141081155620767,0.020084054208862532,0.0063184817296406195,0.005950321005919539,0.006178448566640127,0.006206398507608487,0.006173501468567788,0.009797646092220641,0.0061954259294392825,0.00890392935776795,0.015519861839332757,0.007612066290088057,0.008599101143628772,0.008329847314461958,0.007874129803122012,0.010322745749108445,0.007862632445480265,0.008960628415855954,0.00621408784991353,0.006301756828329953,0.031471298636382004,0.03195091452464656,0.031211686123061813,0.025695280418102727,0.005505684476819874,0.005481585387126183,0.03146282650412827,0.0313194989127142,0.00811367271387036,0.00966340280667971,0.007236004939933877,0.02587647193150778,0.031502723531103886,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.007983871355792321,0.008456090391412957,0.0,0.006761526898656033,0.00474364149773721,0.008215213161479964,0.007470194685931789,0.015334796293900306,0.006513727030736007,0.004797799301885407,0.008467143006265969,0.012768929276837886,0.0083115291190046,0.004527783698944439,0.005490325203591612,0.010626529909659673,0.010038295537877094,0.007739930191720565,0.009670855994641228,0.00542128262589573,0.0076158674899009186,0.008438319533962695,0.0068062519474869874,0.007086189069586685,0.004936406898324195,0.006787307702882169,0.007839329973466832,0.009283548108616169,0.0085854508255985,0.007221559489282594,0.00449145727492537,0.004939512485528038,0.009656128499173595,0.006276914580648331,0.00449145727492537,0.005860125269176921,0.005718125066268482,0.003715636279015228,0.005724905346195066,0.00914471617304127,0.004692129483493016,0.00478738405713629,0.005109587540689095,0.007096984221679397,0.006578762262841245,0.006092786211387727,0.007537427429417532,0.006903035999834529,0.006590008478823424,0.008379658987440978,0.004974247663640395,0.0087056378381934,0.004660205706346108,0.006083670793322497,0.005881141893755802,0.005640116796789822,0.005474736808925188,0.009605078267565393,0.0052538839362681125,0.008653845948503502,0.007932767038061077,0.016117333822334545,0.008708734091372116,0.012342871627831887,0.008125254436606015,0.00724630942634838,0.008865956090727179,0.009637789841497204,0.01263323728733175,0.005028879631882584,0.00832603861027563,0.007205875494933277,0.009498054032389567,0.016542136757758345,0.016568622373827172,0.006975527814524812,0.01601454901805952,0.011134199570666484,0.010877944643779502,0.01146576340991037,0.010876885565320222,0.00942058208129842,0.010585369679850559,0.01112866977248565,0.010752419336395211,0.011245629709339492,0.010882002981583106,0.011260522771914553,0.01077580247957819,0.01114850832363096,0.010420294697015131,0.0065735178846702885,0.012238723843294445,0.013154571747411255,0.004429732079881045,0.004468534595719304,0.006892839289505238,0.009723426603270562,0.00891557829680834,0.012590259151309468,0.010254880490218034,0.014600204583985024,0.014698639011881178,0.0145736950471648,0.014575055994650433,0.014570777823758542,0.014688551368363917,0.012151334232793094,0.008837924700543053,0.015234136586556082,0.020042687684546343,0.01510867359762588,0.0086744283384725,0.01174978602081892,0.004944987464351894,0.00941040892265061,0.004976048709316233,0.010325184885460423,0.00942685138393013,0.009655402194136627,0.010645601458447595,0.006059457910145029,0.005769722669830853,0.008493391782308632,0.007647380119595531,0.010199101249217248,0.01043874597363084,0.006352994753266433,0.007806428448866245,0.01200656804690005,0.0153603852257803,0.011487925334852022,0.00653951273361599,0.007528809196863406,0.007425727307574703,0.007488111198281093,0.013344028234691064,0.012717905188580528,0.010796286164250468,0.00757146105765258,0.0074916774725442125,0.00756048736829921,0.008214415786457709,0.01571032369822638,0.015274280680716061,0.013302336849085215,0.007035274879480407,0.0033222156411328325,0.006953651242405377,0.005856161885549331,0.013684936793197044,0.009339407317842384,0.0077386730019707445,0.005370584468999354,0.0027703658232217853,0.006773439934811923,0.0019297246066527997,0.0020134189928244584,0.009915825356466863],[0.0313468142362142,0.0377212754881099,0.03480673640526268,0.037249588313205476,0.03892097676595481,0.035913959530545034,0.03397064050326624,0.03175940088244545,0.03438782517789607,0.0361347281955179,0.03771617175952416,0.007850241879297244,0.03354021828875461,0.012319173006359228,0.0393320451742437,0.01147906171738186,0.025562417115579505,0.011837979577677873,0.03551424963122068,0.035623403922519524,0.035607949949467636,0.035794146985647514,0.035776847885097586,0.035551511467760706,0.03573974011242439,0.03554369214402773,0.022476933090110437,0.024707805758522893,0.023173039081205497,0.02088170408613537,0.04348478143275323,0.02514759126279362,0.041946435428217355,0.029769600306322894,0.029831677315407416,0.027785908208884998,0.03455676830948095,0.03384975759622145,0.021412748196256833,0.050748775408973816,0.04384829125258729,0.04290681419566368,0.0470542762739733,0.030613619565026097,0.03611189122426236,0.026355992079612298,0.028288505001000896,0.02503214320320402,0.03146073849892397,0.02607155256484924,0.03094678439276938,0.02241346297233641,0.02820438226396048,0.02203040247690347,0.026928623521076164,0.03044914018439533,0.01841158077665456,0.030181909185979724,0.026334555270811803,0.03136593707928394,0.03479024475139061,0.03403172896796531,0.01983508724726627,0.019797425903672918,0.032878319056053026,0.01713933987771948,0.034432022554832346,0.04406944992762617,0.04132610988503847,0.017022538590574246,0.04412732878120159,0.04550465852230532,0.019284080190968014,0.03396124282897493,0.02465403464003121,0.020420720388819237,0.02310890283662057,0.020017947772122596,0.030043450085180227,0.019303447112477067,0.025535364249822386,0.02578722006802369,0.019307245220690373,0.01919417429711174,0.030635920595530417,0.01943777527332392,0.03145135309352042,0.02474940514656995,0.017508349160255617,0.031002356797435127,0.02894128121340827,0.028853312560445123,0.026936313088973683,0.04950941754323598,0.04849388208173779,0.05227882776830309,0.05130260171678476,0.044815587148258,0.04431593023785342,0.04488290862235845,0.04508362784113555,0.045081817594073564,0.04501369469562837,0.04401384577485432,0.05148969348906411,0.04502191677089996,0.05099033094270835,0.04268378952618962,0.04986025925304067,0.05008581608786069,0.04982033602801476,0.07906728832628578,0.04999726706357249,0.06387108296929536,0.05566477132633701,0.054604085235450434,0.061684440715706494,0.059752986301424726,0.06354445604606836,0.07404876248675978,0.056401486254405164,0.06427780567540717,0.050147869303434074,0.05085536050371595,0.04232904890051801,0.039392956707735106,0.03848154641310041,0.042240337891742245,0.04936781502468546,0.04915172574327632,0.04231765384165491,0.04212487753789138,0.05820228825616289,0.06065417642336836,0.05190646211512684,0.04253819767862955,0.03884037257460164,0.018720938605148937,0.019474039219494747,0.020395921458568455,0.02222508977368589,0.020583169220009526,0.02036590088673674,0.016289663416563616,0.020893052233990107,0.02115227740562084,0.020353370864535033,0.018940282615713715,0.020665815678324123,0.020045037669832316,0.021221760979765063,0.019275806429613275,0.020397802066774526,0.015740458354785394,0.020735433179479675,0.017441018961642678,0.02492560084836011,0.02911331852972858,0.02150229263073966,0.029236755316584578,0.029356653412423373,0.027481671267493988,0.046198953841942066,0.04691870974573133,0.040354026411196606,0.03456043791744694,0.051318900159755654,0.0286355882494234,0.030329286615161957,0.04615571124486071,0.030314287952993325,0.02977436354966802,0.0331485043237264,0.02679319463410175,0.041250750387122316,0.029203314549584334,0.024378239016967913,0.045553393204509254,0.02518893174434019,0.034779256928942626,0.028419491226505993,0.0369225697845707,0.045260324750349204,0.054006224224816414,0.032965771234866305,0.03179573978326632,0.03888880723166332,0.03642090173789374,0.03530980628452053,0.03865208757011486,0.03812383430508911,0.039836946941324114,0.028401214153792306,0.035146455783743286,0.03884663101805136,0.048755996648415664,0.06907045294637533,0.06645134937191005,0.06200756974252425,0.04040567857047506,0.05346904300191142,0.06645134937191005,0.04991867994830108,0.015381811748279484,0.07329738194155479,0.06331131981938665,0.028699270805407674,0.01682916493948838,0.05795149243165802,0.054979359668691614,0.03818191243222335,0.020646423155513433,0.019121262828862333,0.016896460588330275,0.07737180676248481,0.06106030927286844,0.02254136374525101,0.05352309735426349,0.04163244445770373,0.05432265988605921,0.06546053316211185,0.021093771455102845,0.06827385936910797,0.06381741158591774,0.03732119944815601,0.03768799631273694,0.038798215538552894,0.02845229343728218,0.0361298199243933,0.025378793871669116,0.024901833067510912,0.03278551956340111,0.03898528492263671,0.023849507657773602,0.019012215137265382,0.0311515696462782,0.02029160229251174,0.05225995696116004,0.04522904118747828,0.02838873026230974,0.0333738809364894,0.027590800391625415,0.027103898330651258,0.026668133013711594,0.02329530354895205,0.02275915936814594,0.02398901127639311,0.0227569435326892,0.01971002206299853,0.02214702532543446,0.023283733940704113,0.028924112039214665,0.02352844099977773,0.022767650343221344,0.023559600708318758,0.022545454493797794,0.02332524074754445,0.021801650535887816,0.02062996448949404,0.01724500671249232,0.04324946421213999,0.01787403322550348,0.018030601940003433,0.024722405831416612,0.023249877006325533,0.02131821499751298,0.02257861261434703,0.018390485153038046,0.026183127720427073,0.026359654095990278,0.026135587113418412,0.026138027754686974,0.026130355540628068,0.026341563523554035,0.0145276473974805,0.03962350491164756,0.050086635867319,0.02396223278865282,0.015482848817721691,0.020741596578909092,0.02107135871289418,0.031038149611937824,0.03375212139061082,0.03123311139400223,0.032403988438405695,0.05353423411495339,0.05483215343949205,0.05409167839334856,0.03531666753448809,0.04397506110295636,0.03807884343958874,0.027428702008417013,0.042677726049199935,0.02808032765874466,0.015190770976313396,0.018666104934012887,0.03229778420373796,0.04131958486143969,0.041203507054291155,0.05277405755988483,0.04050513915409723,0.03995055659519194,0.04028618313425858,0.03589556504815818,0.034211287996691646,0.029042114230535054,0.040734606990414084,0.040305369758798025,0.04067556832936298,0.044193715871920385,0.042260922737800403,0.04108796280219822,0.04174731728712419,0.03784991497717837,0.016384119061625364,0.034293213377846944,0.017503480141758412,0.02454174157910673,0.03628891650094931,0.03816469294571145,0.024078206965571718,0.014904621732757323,0.033404468082898084,0.024224563351437134,0.02527521065778605,0.03556488818610208],[0.049259279514050895,0.04903765813454287,0.04640898187368357,0.04842446480716711,0.050597269795741244,0.04668814738970854,0.045294187337688314,0.04128722114717909,0.04585043357052809,0.046975146654173267,0.0490310232873814,0.031400967517188974,0.044720291051672814,0.030797932515898074,0.06436152846694425,0.04591624686952744,0.03651773873654215,0.029594948944194684,0.039460277368022975,0.03958155991391058,0.03956438883274182,0.03778271070707238,0.03776445054538079,0.03950167940862301,0.0377252812297813,0.03949299127114192,0.030650363304696056,0.03212014748607976,0.031599598747098404,0.03712302948646288,0.049696893066003694,0.03429216990380948,0.0485695568116201,0.037212000382903614,0.037289596644259265,0.04630984701480833,0.03686055286344635,0.045133010128295264,0.042825496392513665,0.050748775408973816,0.09317761891174799,0.08581362839132736,0.08555322958904238,0.06778730046541494,0.05158841603466051,0.043926653466020496,0.05400532772918352,0.04505785776576724,0.05842708578371593,0.04754224291237214,0.05415687268734642,0.03922356020158872,0.043588590771575286,0.055076006192258664,0.04406502030721554,0.05328599532269183,0.03514938148270416,0.06036381837195945,0.043890925451353,0.06558332298395732,0.07827805069062888,0.08043863210609982,0.0522925027427929,0.05219321374604678,0.06904447001771136,0.0359926137432109,0.06260367737242245,0.07517729693536229,0.06543300731797758,0.047663108053607885,0.06986827057023585,0.07204904266031675,0.029997458074839136,0.04245155353621866,0.036981051960046814,0.038288850729036074,0.05777225709155143,0.024637474181073964,0.07677770577323835,0.03002758439718655,0.05107072849964477,0.05931060615645448,0.03003349256551836,0.03199029049518623,0.07148381472290431,0.03239629212220653,0.07338649055154764,0.054998678103488775,0.028451067385415377,0.06588000819454964,0.07958852333687275,0.0638894778124142,0.08754301753916446,0.05501046393692886,0.053882091201930875,0.06970510369107079,0.057002890796427515,0.05377870457790961,0.053179116285424106,0.05385949034683013,0.05410035340936266,0.05409818111288828,0.054016433634754044,0.05281661492982519,0.06865292465208547,0.05402630012507995,0.056655923269675945,0.05869021059851073,0.05540028805893408,0.05565090676428965,0.055355928920016395,0.09663779684323817,0.05555251895952499,0.08782273908278111,0.07653906057371337,0.07508061719874434,0.07710555089463313,0.08216035616445899,0.07766544627852799,0.09256095310844971,0.0775520435998071,0.08838198280368484,0.06686382573791211,0.06780714733828794,0.04938389038393767,0.046555312472777846,0.0454781912154823,0.04992039932660448,0.06417815953209109,0.06389724346625922,0.049370596148597394,0.049145690460873276,0.08002814635222397,0.0866488234619548,0.07137138540829939,0.05027241543838038,0.04590225849725648,0.027041355762992905,0.028129167761492414,0.029460775440154435,0.03210290745087962,0.02973124442890265,0.029417412391953068,0.022805528783189057,0.030178853226874594,0.02749796062730709,0.02939931347099505,0.027358186000475366,0.029850622646468178,0.028953943300868902,0.030653654748549537,0.027842831509441397,0.02946349187422987,0.02203664169669955,0.053319685318662026,0.055811260677256565,0.062314002120900276,0.03396553828468334,0.024810337650853453,0.03410954786934867,0.03161485752107133,0.0335887093269371,0.08884414200373474,0.09022828797256024,0.08070805282239321,0.06283715984990351,0.06414862519969457,0.06085062503002472,0.07203205571100965,0.09231142248972142,0.06669143349658532,0.04678828557804975,0.0662970086474528,0.056935538597466216,0.08250150077424463,0.037964308914459635,0.03585035149554105,0.06326860167292951,0.043508154831133065,0.054653118031195554,0.038569309521686704,0.0566146070030084,0.05002456946091228,0.07500864475668946,0.04337601478271883,0.04335782697718135,0.04861100903957914,0.06146027168269568,0.0504425804064579,0.06102961195281293,0.046595797483997795,0.05311592925509882,0.04463047938453077,0.05154813514949015,0.05272042781021256,0.06928483734248542,0.08202116287382069,0.07450605838668703,0.07086579399145629,0.054836278059930445,0.06753984379188811,0.07450605838668703,0.060427875726890776,0.035890894079318794,0.07662908112071637,0.07186690357876321,0.05739854161081535,0.050487494818465144,0.07082960186091536,0.06872419958586452,0.05515165129098929,0.04424233533324307,0.04097413463327643,0.04562044358849174,0.086656423573983,0.07287843364826234,0.04883962144804385,0.06244361357997407,0.08066286113680098,0.06267999217622217,0.07364309980737582,0.03955082147831784,0.07838850520156841,0.08345353822773857,0.05454636842422801,0.053391328109710666,0.03103857243084231,0.054533562421457515,0.03251683793195397,0.027331008784874437,0.022134962726676363,0.02914268405635654,0.04873160615329589,0.020669573303403785,0.022468981525859088,0.028319608769343817,0.02029160229251174,0.08958849764770292,0.054920978584795055,0.02838873026230974,0.02966567194354613,0.05518160078325083,0.054207796661302515,0.05333626602742319,0.0332790050699315,0.04876962721745558,0.030843014498219714,0.04876487899861972,0.045051479001139504,0.03163860760776352,0.0498937155872231,0.05463443385184993,0.03025085271399994,0.04878782216404574,0.03029091519640983,0.04831168820099527,0.033321772496492076,0.04671782257690246,0.05599561790005524,0.03762546919089234,0.07470362000278725,0.03773407014272957,0.0380646040955628,0.061806014578541534,0.026156111632116223,0.02931254562158035,0.02540093919114041,0.024520646870717394,0.034365355133060535,0.032949567619987845,0.03430295808636167,0.03430616142802666,0.03429609164707434,0.03292695440444254,0.03268720664433113,0.07132230884096562,0.0865132801344601,0.05391502377446884,0.03483640983987381,0.03889049358545455,0.03950879758667659,0.0532082564776077,0.05906621243356893,0.04908060361914637,0.04629141205486528,0.06480459919178569,0.06926166750251628,0.07636472243766856,0.07335000180239834,0.09571042710643443,0.06854191819125974,0.051428816265781906,0.06706499807731418,0.05616065531748932,0.03228038832466597,0.039665472984777385,0.05921260437351959,0.07575257224597276,0.06695569896322312,0.07622919425316697,0.07425942178251159,0.07324268709118523,0.07385800241280739,0.06580853592162333,0.06272069466060134,0.05324387608931426,0.07468011281575915,0.0738931778911297,0.07457187527049879,0.08102181243185405,0.07747835835263407,0.07532793180403008,0.07156682963507005,0.06939151079149368,0.038726099600205406,0.05923373219809927,0.035006960283516825,0.05890017978985614,0.07816074323281388,0.06939035081038446,0.04574859323458626,0.029809243465514647,0.060735396514360156,0.046718800749200186,0.048745049125730244,0.07557538739546692],[0.005063657255154459,0.004265356160335647,0.004373103201671463,0.004212019846247751,0.0044010131117457685,0.004060992809586755,0.004268056476711285,0.0035912135644832048,0.0043204713775244555,0.004085956360605805,0.004264779053122751,0.008876708734448782,0.004213978417153058,0.0069649898887270975,0.004043177201765848,0.012980018829570379,0.00412926551040235,0.006692933691159493,0.0022309974276095686,0.0022378544764175543,0.002236883661195971,0.002248580518459165,0.002247493792729983,0.0022333382080662037,0.0022451626905319105,0.0022328469998521747,0.0023105389773899134,0.0027938501584791682,0.00238209589391281,0.002623568206228828,0.00234146099963575,0.0025850719743308716,0.002496378257609758,0.002103884784087712,0.0021082719063033523,0.0034910094050429933,0.0026050183913955425,0.004252868800921464,0.0030265744015406213,0.004098891881857938,0.012395430482816524,0.0,0.0,0.009890438986804325,0.005833391508851738,0.0066227107307396775,0.0058158907316105644,0.0028305248122334993,0.002541030095628518,0.003468301950308155,0.005832210768071071,0.004224026588286342,0.005798595768633421,0.00498220230910025,0.0027681549793054784,0.00573842506568884,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00879384678489,0.011682437503764876,0.0,0.012474311328323391,0.012863667323051225,0.004845686871789613,0.016000784088774526,0.011615708152345442,0.005772713434385135,0.0065326330961321104,0.006964743431493912,0.007549291966189263,0.004850553374955646,0.007218567095095072,0.0058318111756187185,0.004851507760278907,0.004823095397099525,0.00769816743992179,0.004884307238198348,0.00790306860768355,0.0062190089657222156,0.00494941806590974,0.008764025860720543,0.012272073635592759,0.0069912982726557755,0.011421899924254844,0.01244068331200847,0.0121855004458885,0.0098524337256723,0.012891273069073263,0.010135099529290044,0.010022101511419716,0.010150324362520707,0.010195717257921528,0.010195307868347202,0.01017990179202644,0.009953784742778051,0.009703713994975273,0.010181761224347146,0.012812805940986213,0.012066238630994238,0.012528842511225713,0.012585520236193984,0.012518810638018808,0.019867959334152436,0.012563269714506978,0.018055653850853122,0.015735819654700358,0.015435975343141258,0.017437514095098087,0.016891513139552387,0.015967395560907427,0.02093277209950715,0.015944080875734443,0.018170629894055133,0.012601112914147955,0.012778890686650593,0.023931914702338724,0.02429663198523358,0.023734495949581696,0.02605282848662277,0.011164591399048894,0.011115722545293858,0.02392547218629305,0.02381648069751324,0.01645314782882324,0.019595736790808282,0.014673386906930836,0.026236541267536724,0.02395581132982472,0.00235209057233224,0.0024467098055010947,0.002562534688486899,0.0027923505988928688,0.002586060415677454,0.002558762916917605,0.001841963594935568,0.002624993982582542,0.002391806628215215,0.00255718865038571,0.002379648858282981,0.0025964440807029325,0.002518449802099659,0.0026662928062306146,0.0024218039241218838,0.0025627709672827992,0.0017798618986585785,0.0,0.0,0.0,0.002743338494694107,0.001870296009695859,0.002754969902796815,0.0025534780257239504,0.0,0.016073768598829665,0.016324189634005726,0.01825222428669996,0.0,0.019343052791437824,0.00809496637931909,0.017147512621006635,0.0,0.006855613082714859,0.01923859577815794,0.0,0.007574141933751739,0.0,0.00660436509659131,0.004864560350826028,0.011446616962314143,0.005178643221545147,0.008427183477882683,0.00918157499849818,0.008350084054590527,0.008080798009581686,0.01696329622216625,0.011771446185965671,0.006536950195977381,0.00549671940262087,0.015443683529637492,0.008555738172787812,0.01610224111425876,0.007184792905535234,0.010010193324966858,0.009175670166756605,0.007948413713550465,0.012550304060284019,0.014508194643795942,0.00488136466357128,0.006830933393288777,0.005008245463720677,0.009790492866406906,0.0031821287087336527,0.006830933393288777,0.0029708342556252084,0.00579769238523652,0.0037673391035521783,0.0038697113415295087,0.0,0.004757420144142391,0.002427000089329506,0.00259034355081747,0.0023985794238101776,0.0,0.0,0.003821155108130952,0.006999091273351852,0.004454471997205613,0.0,0.007565195969188963,0.00882677619292753,0.0023625260749106196,0.003084162328032891,0.0,0.0028592993180133427,0.0055509173969489605,0.0,0.0017756637905610947,0.008774263622637057,0.0026810503161680075,0.004085401354864165,0.0022074788825643325,0.0031286554604572224,0.004119158398013264,0.011020711989154759,0.0017978650525947357,0.003908759611025594,0.003202256979902263,0.002549428073900381,0.01266284230159765,0.003653072379649796,0.00321007293474522,0.004193079864663702,0.0,0.0,0.0,0.007526087463803632,0.007352873666032034,0.007750205815387539,0.007352157789056328,0.006367779224164665,0.007155109583012583,0.007522349633840912,0.007268025677068023,0.007601407918088127,0.0073556168722296355,0.0076114747837691685,0.007283831355748094,0.007535759369325455,0.007043528256396311,0.01666246984041551,0.0017727178354281616,0.008891744475348134,0.013474114495850243,0.013592141846422153,0.020966258029488472,0.0032862424730055765,0.003013212652885495,0.0031913629364413248,0.006931717633620115,0.0037008413578956713,0.003725792391951624,0.0036941217540929576,0.003694466725337147,0.00369338230000038,0.0037232353888550142,0.0,0.008960903817913514,0.02059482473944715,0.0,0.0,0.005863421610102591,0.008934962616887329,0.005013796626500177,0.00954135411879282,0.020181160346249876,0.005234429563260483,0.003186008458598593,0.003263252151628352,0.00359791142473101,0.009215662278413918,0.005850007965921296,0.0,0.0038768964452994704,0.010341021045108202,0.0,0.006441396240480719,0.00791505436648673,0.024347277239167728,0.031148247869968712,0.023295558059383673,0.046413567240335275,0.03053428824636636,0.03011622317947204,0.03036923101257695,0.0270594189487135,0.025789747937818647,0.0218930314947296,0.030707269680418786,0.030383694607478657,0.03066276413045991,0.03331487527983803,0.03185786355465185,0.030973642502136505,0.026974875911946826,0.028532680991832086,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.007826306369962262,0.00816574232127217,0.010053803387696639],[0.0313468142362142,0.02263276529286594,0.023204490936841786,0.022349752987923282,0.023352586059572883,0.02154837571832702,0.022647093668844157,0.01905564052946727,0.022925216785264046,0.021680836917310736,0.022629703055714497,0.019625604698243107,0.022360145525836407,0.015398966257949037,0.021453842822314745,0.028697654293454646,0.02191064324192529,0.014797474472097342,0.01381109707880804,0.013853545969868705,0.013847536091459636,0.011931382328549171,0.011925615961699196,0.013825587793018054,0.011913246704141461,0.013822546944899672,0.010216787768232018,0.012353902879261447,0.010533199582366133,0.01160094671451965,0.018636334899751385,0.011430723301269829,0.01986936415020822,0.014884800153161447,0.014915838657703708,0.01234929253728222,0.011518922769826983,0.022566505064147632,0.010706374098128416,0.025374387704486908,0.06029140047230752,0.023837118997590934,0.021388307397260595,0.032800306676813676,0.03611189122426236,0.026355992079612298,0.030860187273819156,0.02503214320320402,0.029213542891857965,0.019937069608414126,0.03094678439276938,0.02241346297233641,0.030768417015229615,0.028639523219974504,0.024480566837341965,0.03044914018439533,0.01339024056483968,0.02195047940798525,0.017556370180541202,0.02281159060311559,0.031891057688774725,0.030937935425423006,0.01983508724726627,0.019797425903672918,0.026302655244842422,0.013711471902175584,0.025041470948968976,0.03110784700773612,0.02755073992335898,0.010213523154344546,0.03309549658590119,0.034128493891728985,0.01071337788387112,0.016980621414487466,0.014381520206684872,0.012762950243012024,0.020220289982042998,0.009239052817902736,0.023367127844029063,0.010724137284709482,0.019151523187366792,0.01805105404761658,0.010726247344827985,0.010663430165062077,0.0238279382409681,0.010798764040735511,0.02446216351718255,0.01924953733622107,0.01094271822515976,0.04650353519615269,0.021705960910056204,0.016487607177397213,0.026936313088973683,0.022004185574771545,0.02155283648077235,0.026139413884151544,0.022801156318571006,0.026889352288954806,0.026589558142712053,0.026929745173415065,0.02705017670468133,0.02704909055644414,0.027008216817377022,0.026408307464912593,0.025744846744532056,0.027013150062539976,0.02266236930787038,0.032012842144642215,0.022160115223573633,0.02226036270571586,0.02214237156800656,0.05271152555085718,0.022221007583809998,0.047903312226971514,0.041748578494752754,0.04095306392658782,0.03855277544731656,0.044814739726068545,0.03530247558114909,0.046280476554224854,0.04230111469080387,0.048208354256555376,0.033431912868956054,0.03390357366914397,0.021164524450259004,0.02148706729512824,0.020989934407145677,0.02304018430458668,0.029620689014811272,0.029491035445965794,0.021158826920827455,0.02106243876894569,0.04365171619212216,0.0433244117309774,0.032441538821954274,0.023202653279252482,0.02118565776796453,0.00832041715784397,0.008655128541997665,0.009064853981585982,0.009877817677193729,0.009148075208893124,0.009051511505216329,0.006515865366625446,0.009285800992884492,0.008460910962248335,0.009045942606460015,0.008417903384761652,0.009184806968144055,0.008908905631036586,0.009431893768784472,0.008567025079828122,0.009065689807455346,0.006296183341914157,0.020735433179479675,0.024417426546299748,0.02907986765642013,0.01698276914234167,0.013232180080455175,0.017054773934674337,0.018065632869183616,0.02137463320805088,0.03909142248164328,0.03970044670792651,0.03228322112895728,0.015709289962475878,0.021382875066564857,0.04653283090531302,0.04549392992274293,0.025642061802700393,0.04547143192948999,0.025520883042572592,0.018415835735403556,0.0368406426218899,0.022917083548401287,0.020442320184709033,0.017208168717859705,0.03036892880300617,0.02060912597264198,0.027326559015597777,0.01826967293132528,0.027076551175351845,0.023821223552815372,0.036004149483210936,0.022555527687013792,0.020233652589351298,0.016203669679859718,0.03186828902065702,0.02522129020322895,0.03458344677326066,0.023297898741998897,0.02434480090858696,0.022315239692265385,0.025774067574745076,0.0277475935843224,0.03592547121462207,0.01942606489116806,0.01610941802955395,0.019931004560097082,0.025975079081019682,0.019699121105967367,0.01610941802955395,0.01576379366788455,0.015381811748279484,0.014992646306227117,0.015400050766877832,0.02459937497606372,0.012621873704616286,0.015024461000800227,0.016035646570035055,0.014848521501420194,0.01769693413329723,0.01638965385331057,0.015206814529497245,0.027853850434494534,0.01575749916719186,0.02254136374525101,0.015610903394993518,0.02602027778606483,0.014625331507785172,0.019092655505615955,0.015820328591327135,0.01770063020680577,0.01963612664182084,0.017225168976072004,0.014132998617276352,0.03103857243084231,0.023710244531068483,0.028903855939514642,0.015617719305642534,0.022134962726676363,0.02914268405635654,0.03248773743553059,0.012719737417479254,0.013827065554374823,0.022655687015475056,0.01803697981556599,0.033595686617888594,0.035537103790161506,0.022710984209847795,0.02966567194354613,0.014856584826259839,0.014594406793427599,0.014359763930460089,0.01663950253496575,0.019507850886982234,0.013708006443653206,0.019505951599447888,0.016894304625427313,0.01581930380388176,0.01995748623488924,0.019282741359476444,0.013444823428444419,0.019515128865618295,0.013462628976182146,0.019324675280398107,0.016660886248246038,0.018687129030760984,0.017682826705280603,0.014109550946584625,0.04324946421213999,0.011916022150335654,0.012020401293335623,0.03708360874712492,0.02034364238053484,0.02131821499751298,0.019756286037553653,0.015325404294198371,0.01636445482526692,0.016474783809993922,0.016334741945886508,0.01633626734667936,0.016331472212892544,0.01646347720222127,0.00726382369874025,0.047548205893977076,0.05919329693410427,0.008985837295744807,0.007741424408860846,0.020741596578909092,0.02107135871289418,0.031038149611937824,0.03375212139061082,0.026771238337716198,0.027774847232919165,0.022540730153664586,0.023087222500838757,0.02545490747922285,0.019016667133955122,0.018107378101217327,0.01903942171979437,0.02400011425736489,0.02743568103162853,0.015600182032635922,0.011393078232235046,0.013999578700509665,0.04306371227165061,0.055092779815252915,0.041203507054291155,0.05863784173320537,0.05400685220546297,0.05326740879358926,0.05371491084567811,0.04786075339754424,0.045615050662255525,0.03872281897404673,0.05431280932055211,0.05374049301173069,0.054234091105817304,0.05892495449589385,0.05634789698373387,0.054783950402930964,0.047711219756713365,0.05046655330290449,0.016384119061625364,0.024940518820252326,0.014002784113406731,0.019633393263285382,0.030706006270034027,0.027756140324153782,0.019262565572457372,0.009936414488504882,0.02429415860574406,0.022494237397763052,0.02708058284762791,0.053347332279153115],[0.022390581597295862,0.01508851019524396,0.015469660624561189,0.014899835325282189,0.015568390706381923,0.014365583812218015,0.015098062445896105,0.01270376035297818,0.015283477856842698,0.014453891278207159,0.015086468703809664,0.015700483758594487,0.014906763683890939,0.015398966257949037,0.014302561881543165,0.02295812343476372,0.014607095494616858,0.011837979577677873,0.01381109707880804,0.013853545969868705,0.013847536091459636,0.011931382328549171,0.011925615961699196,0.013825587793018054,0.011913246704141461,0.013822546944899672,0.010216787768232018,0.009883122303409158,0.010533199582366133,0.01624132540032751,0.01656563102200123,0.011430723301269829,0.01766165702240731,0.013024200134016267,0.013051358825490744,0.018523938805923332,0.009215138215861587,0.015044336709431757,0.016059561147192623,0.021749475175274494,0.03836725484601388,0.019069695198072747,0.017110645917808476,0.032800306676813676,0.025794208017330254,0.0175706613864082,0.02571682272818263,0.017522500242242816,0.022471956070659972,0.01686982813019657,0.025788986993974486,0.01681009722925231,0.020512278010153075,0.024233442724593813,0.01468834010240518,0.025374283486996104,0.01004268042362976,0.016462859555988942,0.01536182390797355,0.01996014177772614,0.028991870626158843,0.024750348340338405,0.01983508724726627,0.019797425903672918,0.02301482333923712,0.010283603926631687,0.025041470948968976,0.0259232058397801,0.020663054942519236,0.013618030872459396,0.02574094178903426,0.026544384138011436,0.01071337788387112,0.01981072498356871,0.012327017320015605,0.01531554029161443,0.02310890283662057,0.006159368545268491,0.026705288964604643,0.010724137284709482,0.015959602656138994,0.02062977605441895,0.010726247344827985,0.010663430165062077,0.02723192941824926,0.010798764040735511,0.02795675830535149,0.02199947124139551,0.01094271822515976,0.027127062197755736,0.014470640606704135,0.01236570538304791,0.020202234816730263,0.011002092787385773,0.010776418240386176,0.017426275922767697,0.011400578159285503,0.0179262348593032,0.017726372095141368,0.017953163448943377,0.01803345113645422,0.018032727037629426,0.018005477878251346,0.01760553830994173,0.017163231163021368,0.018008766708359984,0.01133118465393519,0.02134189476309481,0.011080057611786816,0.01113018135285793,0.01107118578400328,0.035141017033904785,0.011110503791904999,0.03193554148464768,0.027832385663168504,0.027302042617725217,0.030842220357853247,0.029876493150712363,0.02824198046491927,0.03702438124337989,0.028200743127202582,0.032138902837703584,0.022287941912637367,0.022602382446095977,0.014109682966839334,0.014324711530085492,0.013993289604763785,0.015360122869724454,0.01974712600987418,0.01966069029731053,0.01410588461388497,0.014041625845963794,0.029101144128081444,0.03465952938478192,0.02595323105756342,0.015468435519501654,0.014123771845309687,0.00832041715784397,0.008655128541997665,0.009064853981585982,0.009877817677193729,0.009148075208893124,0.009051511505216329,0.006515865366625446,0.009285800992884492,0.008460910962248335,0.009045942606460015,0.008417903384761652,0.009184806968144055,0.008908905631036586,0.009431893768784472,0.008567025079828122,0.009065689807455346,0.006296183341914157,0.026659842659331013,0.027905630338628282,0.02907986765642013,0.009704439509909527,0.006616090040227588,0.009745585105528193,0.009032816434591808,0.012214076118886216,0.03909142248164328,0.03970044670792651,0.03631862377007695,0.012567431969980704,0.0299360250931908,0.025056139718245475,0.02653812578826671,0.020513649442160314,0.027282859157693993,0.01701392202838173,0.014732668588322844,0.023444045304839033,0.01833366683872103,0.0175219887297506,0.012906126538394777,0.027838184736088987,0.01831922308679287,0.02484232637781616,0.01623970927228914,0.024615046523047135,0.021439101197533835,0.03300380369294336,0.022555527687013792,0.020233652589351298,0.014583302711873743,0.027315676303420303,0.022699161182906054,0.030514805976406465,0.019061917152544555,0.02434480090858696,0.02028658153842308,0.028117164626994626,0.02497283422589016,0.03592547121462207,0.015109161582019602,0.008054709014776975,0.015501892435631062,0.02308895918312861,0.011256640631981353,0.008054709014776975,0.0105091957785897,0.010254541165519654,0.011660947127065535,0.015400050766877832,0.016399583317375812,0.012621873704616286,0.008585406286171559,0.011454033264310753,0.01272730414407445,0.011797956088864818,0.013658044877758808,0.016896460588330275,0.02166410589349575,0.01575749916719186,0.015027575830167339,0.008920516225710582,0.020816222228851863,0.008357332290162955,0.01363761107543997,0.010546885727551423,0.010114645832460441,0.01963612664182084,0.014354307480060004,0.01256266543757898,0.015519286215421155,0.018968195624854786,0.014451927969757321,0.007808859652821267,0.011067481363338181,0.01457134202817827,0.022741416204871415,0.006359868708739627,0.006913532777187412,0.011327843507737528,0.009018489907782996,0.029862832549234306,0.01938387479463355,0.01419436513115487,0.014832835971773066,0.012734215565365576,0.012509491537223657,0.012308369083251506,0.01663950253496575,0.019507850886982234,0.013708006443653206,0.019505951599447888,0.016894304625427313,0.01581930380388176,0.01995748623488924,0.019282741359476444,0.013444823428444419,0.019515128865618295,0.013462628976182146,0.019324675280398107,0.016660886248246038,0.018687129030760984,0.023577102273707472,0.010974095180676931,0.027522386316816354,0.01588802953378087,0.016027201724447496,0.030903007289270767,0.011624938503162766,0.015988661248134736,0.011289306307173515,0.018390485153038046,0.018000900307793614,0.018122262190993315,0.017968216140475158,0.017969894081347297,0.017964619434181796,0.0181098249224434,0.010895735548110375,0.027736453438153293,0.03187331373374845,0.01198111639432641,0.009676780511076058,0.018148897006545456,0.018437438873782408,0.022170106865669875,0.02109507586913176,0.017847492225144132,0.01851656482194611,0.019723138884456513,0.020201319688233913,0.022273044044319998,0.032600000801065926,0.031041219602086844,0.015231537375835496,0.017142938755260635,0.02438727202811425,0.012480145626108738,0.02088731009243092,0.02566589428426772,0.021531856135825304,0.027546389907626458,0.020601753527145578,0.03518270503992322,0.027003426102731484,0.02663370439679463,0.026857455422839054,0.02393037669877212,0.022807525331127763,0.019361409487023366,0.027156404660276055,0.026870246505865347,0.027117045552908652,0.029462477247946924,0.028173948491866933,0.027391975201465482,0.023855609878356682,0.025233276651452245,0.013405188323148024,0.018705389115189243,0.008751740070879206,0.017179219105374708,0.02512309603911875,0.017347587702596114,0.01444692417934303,0.008694362677441772,0.018220618954308047,0.01903358549041489,0.01985909408826047,0.031119277162839316],[0.03922473902859961,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.004911562730210093,0.0,0.003853791509571981,0.0,0.007181961088047566,0.0,0.0037032603701069554,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.010364411336757058,0.0,0.011050148227123757,0.0,0.0,0.007726427529645341,0.0,0.014118903204303177,0.006698523281777104,0.013607722324356041,0.006858503101272734,0.005965548937945919,0.005352701997715571,0.008208703185982399,0.045187351366137975,0.00366440537491437,0.009653953852117658,0.0031323096410156735,0.008435848750289913,0.005757127930808353,0.00968104392071167,0.007011575635662217,0.009625245476709583,0.008270091959009062,0.00306329006268708,0.009525366504376208,0.0,0.0,0.002746068681142258,0.0,0.007255592550443137,0.007742620567444586,0.004512716783279073,0.004504148382485274,0.0,0.0,0.0,0.009731428937445169,0.012927995354589782,0.004260111594039804,0.0138042971642091,0.014235165507352468,0.0,0.014165404252515449,0.007712490872837023,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0048492142833371265,0.03168782702830599,0.028367886615713978,0.046345492546724126,0.013767083796830651,0.013484693849809173,0.016354320414191884,0.014265714522163622,0.01682352500375985,0.016635956546881565,0.016848797114980257,0.016924146006085057,0.016923466449291356,0.016897893487778436,0.01652255570043722,0.01610745652294906,0.01690098000962756,0.014178881387634078,0.020029074872250842,0.013864642351505356,0.013927362940839764,0.013853540900273548,0.03297936144246343,0.013902740113547592,0.029971066701536223,0.026120311364525042,0.02562259170640314,0.06753833298960969,0.02803867814354891,0.061844324396706105,0.08107603668401064,0.026466009781127165,0.03016191853600044,0.020916927117855283,0.02121202523624745,0.013241743514509147,0.013443544865360962,0.013132509944129282,0.014415264174982328,0.02470987509178326,0.024601716787640716,0.013238178812473142,0.013177872842071796,0.027311023743656758,0.03252749190222831,0.024356750597779826,0.014516914107946612,0.01325496573328968,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01482660496180587,0.017459366990421502,0.02079318557521237,0.0,0.0,0.0,0.0,0.0,0.026681281929749664,0.027096962558694305,0.030297359268561554,0.003931454051179742,0.021405369945330724,0.004479017658501138,0.00474393643098245,0.006417259341168811,0.0075865446793650934,0.015967331952473733,0.00460880231893066,0.004190840811388469,0.005735298105312135,0.007308509141284234,0.010766419866972696,0.0221673061822101,0.014326949211078136,0.01865134546095078,0.010160495948739221,0.021560823952870633,0.011923141792465093,0.02628064396349055,0.013026493962405078,0.007233906600360207,0.010137947507339583,0.017090257822014072,0.018935867333720678,0.015273453843358733,0.01325136831483374,0.01661618982708171,0.01523094233367596,0.020523667505865387,0.01736049010937925,0.022477040605374206,0.02700902944029065,0.012598722818973633,0.016626643387245302,0.007222890271843981,0.021128405001588652,0.012598722818973633,0.016437892966943573,0.0,0.04169005176718576,0.02355260674574636,0.005130261172271605,0.01052929330946285,0.01880033349994853,0.014332603697202644,0.015925866655125423,0.0036907398720758314,0.0,0.006342838402238056,0.011617980336605584,0.022182294551808764,0.004701057783168797,0.016743563715143787,0.016279782020575187,0.01568648295102736,0.017064947377959667,0.006598738186123718,0.02214906418469768,0.03071372489617047,0.003592352068690655,0.007859925885600229,0.014564636787080002,0.011867593906381767,0.013562935745292317,0.0073285074446021465,0.010386679127331452,0.009116669465113494,0.016260957339213875,0.003979099574148571,0.006488255478866725,0.010631025420946015,0.008463728811463345,0.014012928928419304,0.01212766669769209,0.010656973249351397,0.013920412669272167,0.007967257510148191,0.007826657235892268,0.007700823463592445,0.02082125920616609,0.016273644360042767,0.008576517079261525,0.01627205995538177,0.01761674740449589,0.023753918671755955,0.016648734665270885,0.016085855740275785,0.008411854651198923,0.016279715722627475,0.008422994825731665,0.01612083743660179,0.02084801696746716,0.01558898997735157,0.0036877977326814472,0.0058851642734732606,0.004919882140797011,0.02236604598399425,0.022561962765840906,0.054137155430877756,0.0036366149967744597,0.003334475289625213,0.0035316195959813478,0.015341526687027337,0.012286252727873847,0.012369086516352564,0.012263944624778537,0.012265089878919442,0.01226148974520293,0.012360597639572188,0.00681699869369055,0.00495814862667051,0.028488254107325604,0.0,0.007265220395101396,0.0032442838796689043,0.0032958634179818267,0.038838502352573544,0.005279316995468529,0.01674962612398758,0.01737754155910122,0.01762847117272083,0.018055867469229273,0.019907567307831994,0.023795840939440333,0.022658033928433036,0.004764862818829014,0.01287072990176193,0.011443559787055609,0.0039041483732140444,0.011880274792420986,0.014598235748930776,0.02694313467916541,0.0344692110389458,0.02577928332826372,0.029349764500510057,0.02534234421182536,0.02499536547295017,0.025205352735240317,0.029944439450596657,0.028539398685309775,0.024227222218868246,0.025485912485257552,0.02521735699083593,0.02544897450401842,0.027650129909812374,0.03525448451224032,0.03427598960005569,0.029850882606296807,0.03157477771205901,0.003727580733421253,0.0,0.0,0.0,0.006985979346340046,0.0,0.0,0.0031083961375995882,0.0,0.004330365660499445,0.0045181786233465,0.0055628597820537974],[0.017554701559202808,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.003867214154469909,0.0038791001727503283,0.0038774173602469063,0.0038976927094746747,0.0038958089775304287,0.0038712716666850196,0.003891768241622651,0.003870420205659303,0.004005091591428055,0.004842863888872868,0.00412912845359695,0.0045476969075738975,0.028410843085295987,0.004480967483753339,0.030290579672063198,0.003646876915100471,0.0036544815590681206,0.0,0.004515542631823368,0.0,0.0,0.0355251254595728,0.0,0.0,0.0,0.00428602529639316,0.020223218487317694,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01109431287458296,0.008053874096855845,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02156469837216517,0.021122364024476245,0.0,0.022345751306075176,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.022209736273227747,0.020915635422757938,0.021717513655069798,0.02181575890516643,0.021700124391603386,0.0,0.021777189818825295,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.021842787275591,0.022150947522512024,0.0,0.0,0.0,0.0,0.019352718812202414,0.01926800947071443,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01741824568313064,0.020511205666739665,0.024427764536586388,0.0,0.0,0.0,0.0,0.0,0.02786229364131134,0.02829637382438331,0.03163843186843789,0.0,0.025146956677306598,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.008432235918866212,0.024801977912232823,0.013465001429047243,0.024346153297975452,0.007957677663609806,0.024123412878998846,0.009338177939407123,0.029404202104847784,0.013603094515957724,0.0,0.006352014219858274,0.022308419395684086,0.019774038496132743,0.019936891386119256,0.008302753580787883,0.013013762645875183,0.019881399854217063,0.01837038903958454,0.021754715135119937,0.025148525492657347,0.01269204680817477,0.0,0.013021949850775288,0.0,0.0,0.0,0.0,0.0,0.009795466542663313,0.010061644819808313,0.0,0.012369778395419624,0.0,0.0,0.0,0.0,0.0,0.009935393652440649,0.018198352341715414,0.011582082264035266,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.014432952316830954,0.0,0.0,0.007604660600812366,0.0,0.007081640592992265,0.0038264470746131986,0.005423215881563596,0.00714015510020939,0.019103318035853,0.003116421871750315,0.0033877247698969157,0.005550796861382711,0.004419182295406885,0.0,0.018996722773931954,0.005564345048765323,0.007268290676975182,0.01663983528588836,0.016346187766426448,0.01608338049029611,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.024228627911591846,0.0,0.0,0.0,0.018023173995484938,0.012830087480680336,0.012916587797422724,0.012806791938859717,0.012807987886162843,0.012804228397281403,0.01290772317172136,0.01423748827782234,0.0,0.0,0.0,0.015173611564102112,0.0,0.0,0.017381844588149096,0.0,0.0,0.0,0.016567894953453365,0.016969577939724145,0.01870987453780749,0.010649628178215794,0.010140412234276988,0.0,0.006720217882429568,0.0,0.0,0.014887367361617995,0.018293288852584636,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0033915326836083557,0.0035386273753364537,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.002891117086079801,0.002900003035800547,0.0028987449704886772,0.0,0.0,0.0028941504693949004,0.0,0.0028935139198216792,0.0,0.0,0.0,0.006799687685566715,0.0,0.0,0.0,0.008179180985793276,0.008196236609219002,0.00904789652706975,0.0,0.0,0.007844187408105921,0.0,0.02409458685251571,0.0,0.0,0.009612656918508074,0.0,0.0,0.007536728127449475,0.0,0.006585767813803364,0.00449452200353438,0.007557877025100591,0.005473854559543301,0.007514315836719085,0.009684545157171785,0.0,0.007436341498778721,0.0,0.0,0.0,0.0,0.008496533538573289,0.009066859098051532,0.005284537304519868,0.005274503430069186,0.0,0.002511479476054494,0.0,0.015194424029079124,0.025231834467258202,0.0,0.02694213073494858,0.027783065343384646,0.006279455070387122,0.01658814652038246,0.012042101668272968,0.0037403876482895717,0.03386217649126425,0.0,0.03913207020528103,0.006285761500990163,0.004677218002892084,0.03022943679623649,0.006286998275035994,0.012500358214476209,0.039903772441204285,0.012659005281909923,0.0409658862020587,0.03223649271267471,0.009620818221988469,0.01703576028049679,0.0,0.009059921647517288,0.00986764921609933,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.017362433935663432,0.02044548342055337,0.02434949280645315,0.0,0.0,0.0,0.0,0.0,0.031244644071751496,0.031731419532281965,0.03547918758748594,0.0,0.02506638050326618,0.01573522361850073,0.01666590897041495,0.0,0.013326133777903515,0.0,0.0,0.01472283039375292,0.0,0.008558500577888484,0.016810434498927003,0.03708376068480698,0.020132785069899253,0.032761993141167976,0.014872836711270444,0.03246225708063067,0.020943576989860862,0.04396497722248423,0.02542407622628456,0.00847113858965431,0.018994983063792995,0.0333554077442277,0.02587026525517296,0.03279046545142272,0.018621337050481832,0.025944127589409626,0.023781234767057912,0.024033878430433885,0.028461573552936433,0.04136210808147057,0.02846560230601075,0.020654916648438916,0.012980224766066787,0.016916476225338473,0.028865719862562082,0.020654916648438916,0.02694902602324569,0.007513145155327104,0.04393835907155573,0.025073512948152646,0.0,0.0061650715030754115,0.02516091265491388,0.01678394247771317,0.021757989086294165,0.008643951513877875,0.00800541902739526,0.004951779273683608,0.009070020483663595,0.02308994163993079,0.011010181413515337,0.016339378862110683,0.011438490762276732,0.021430942016643736,0.02797704741713398,0.0038636679169119117,0.029642594868904075,0.03237008868324598,0.004206760457094455,0.011505284274408433,0.011370440486950588,0.010423002216571092,0.01058842427550157,0.005721279491908919,0.00810875812427669,0.010675914797019978,0.009521053479877526,0.004659654294260386,0.005065304673579564,0.00829951639929361,0.006607533449361559,0.0054698643281582285,0.009467926625812329,0.008319773563475743,0.010867502301887834,0.009329916223215924,0.00916526875473658,0.009017913337629352,0.009752947174505455,0.009528481935736082,0.0,0.009527554241185482,0.008251912390186874,0.009272202339733563,0.009748103375074606,0.00941852866211165,0.0,0.009532036816710115,0.0,0.009439011011003464,0.009765480856061087,0.009127605723047454,0.017274121666211124,0.0022972392345141125,0.017284023320420533,0.01164060587330731,0.011742572490163758,0.0,0.004258593777442155,0.015619113634000386,0.004135640767328579,0.008982711964805948,0.016785532527267406,0.016898700413494578,0.0167550550986794,0.01675661974992498,0.016751701231403546,0.01688710287269243,0.005321950631476638,0.02322460959755198,0.020016400159915838,0.0,0.005671872037369351,0.01899580675225207,0.01929781329005932,0.0,0.006182250946550016,0.0,0.0,0.02064350988723134,0.025372805728067726,0.027974886206982904,0.027865699350518493,0.05685705116018349,0.0,0.02009605464400182,0.004466926206941256,0.0,0.0,0.0,0.007887820527554447,0.010091140234393283,0.00754709363419251,0.008592380866693687,0.009892234899945881,0.009756793791516824,0.009838761083382483,0.008766476766609249,0.00835513972203549,0.007092715195139709,0.009948275930448034,0.009843446873898081,0.00993385740688553,0.010793065463701325,0.01032103539307303,0.010034573095855407,0.008739087243981349,0.009243771474843936,0.006547676395634762,0.0,0.0025648380538097378,0.0035961758575477247,0.008180807756677748,0.0,0.0,0.0,0.0,0.0025354991210519715,0.002645466647943442,0.019542866160137617]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"nticks\":36,\"title\":{\"text\":\"Summaries\"}},\"yaxis\":{\"nticks\":36,\"title\":{\"text\":\"Knowledge Base Entries\"}},\"font\":{\"size\":18},\"title\":{\"text\":\"Cosine Similarity between Summaries and Knowledge Base Entries\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('321de47d-8d0c-489b-adc7-b8206fa8e504');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'similarity_matrix' is already calculated as shown previously\n",
        "kb_entries_labels = [f\"{knowledge_base[i]}\" for i in range(10)]\n",
        "summaries_labels = [f\"Summary {j+1}\" for j in range(10)]\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Create the heatmap\n",
        "fig = go.Figure(data=go.Heatmap(\n",
        "                   z=similarity_matrix[:10][:10],\n",
        "                   x=summaries_labels,\n",
        "                   y=kb_entries_labels,\n",
        "                   hoverongaps = False,\n",
        "                   colorscale = 'Viridis'))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Cosine Similarity between Summaries and Knowledge Base Entries',\n",
        "    xaxis_nticks=36,\n",
        "    yaxis_nticks=36,\n",
        "    xaxis_title=\"Summaries\",\n",
        "    yaxis_title=\"Knowledge Base Entries\",\n",
        "    font=dict(\n",
        "        size=18  # Adjust the font size here\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "-hDW1_Etw4xg",
        "outputId": "e48a5797-f944-4164-cc26-70878991a74d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"442be82d-9267-4b04-a592-1a534c4596ee\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"442be82d-9267-4b04-a592-1a534c4596ee\")) {                    Plotly.newPlot(                        \"442be82d-9267-4b04-a592-1a534c4596ee\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"hoverongaps\":false,\"x\":[\"Summary 1\",\"Summary 2\",\"Summary 3\",\"Summary 4\",\"Summary 5\",\"Summary 6\",\"Summary 7\",\"Summary 8\",\"Summary 9\",\"Summary 10\"],\"y\":[\"Reimbursement\",\"Portfolio\",\"Turnover\",\"Principal\",\"Strategies\",\"Equity\",\"Securities\",\"High-Yield\",\"Debt\",\"Dynamic\"],\"z\":[[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.008353066667075863,0.008378740110318632,0.008375105285747817,0.0,0.0,0.008361830771850385,0.0,0.00835999164155448,0.0,0.0,0.0,0.024557222546566285,0.0,0.0,0.0,0.023631434501689596,0.023680711910830023,0.0,0.0,0.0,0.0,0.0,0.046409671256775,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.006959778523988649,0.0,0.0,0.021949999447240316,0.0,0.0,0.0,0.0,0.0,0.011981691647419544,0.008698063330875166,0.005403397105102144,0.03668819992007216,0.0,0.04239790124973293,0.0,0.006756750527800414,0.032752283980848826,0.0,0.0,0.04323400716033862,0.0,0.044384761365584086,0.03492684203774295,0.0,0.03281334679305913,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.011993091172233909,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.006270481437157447,0.007383931581099,0.008793873209990656,0.0,0.0,0.0,0.0,0.0,0.007522714898479008,0.007639914921648971,0.008542258072692143,0.0,0.009052778788093917,0.03030832442807432,0.03210095949130328,0.0,0.025668067750733554,0.0,0.0,0.02835830814305857,0.0,0.0,0.006071125619061722,0.016071458680670465,0.009694666506387683,0.015776088429169006,0.004297086312274874,0.015631754640437902,0.005042546117256391,0.019053658576684108,0.00734556911200488,0.0,0.0034300400837229406,0.014455655182725203,0.010677832623039866,0.012918926356070804,0.004483424721932066,0.009369779090619257,0.004294322780783037,0.009919872433907342,0.01174738316708309,0.016296018396810365,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.008212919486970855,0.0,0.007648065716397255,0.004132505498219902,0.005856991880871772,0.007711260507305174,0.013754198133505894,0.003365688919422147,0.0036586919837300873,0.005994777427173643,0.004772650654066884,0.0,0.013677450609866105,0.006009409266516467,0.007849645009998378,0.026956159121327306,0.026480456740612557,0.02605471486084648,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.018715761796856144,0.0,0.03329153743972156,0.012612091711849675,0.012722568119807914,0.0,0.0,0.0,0.0,0.012976505215654383,0.01039222665752801,0.01046229094188215,0.01037335753048002,0.010374326234353885,0.010371281090614122,0.01045511069469666,0.0038440684949817166,0.03355047659937749,0.03855449179734578,0.0,0.004096818275138673,0.0,0.0,0.0,0.0,0.0,0.0,0.011928718844403345,0.01221792658149162,0.013470922745622947,0.01725215825894696,0.03833022637797942,0.0,0.007257734605197222,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03764239658720034],[0.07184371650154243,0.05295266749011532,0.05816818213500571,0.03735037055290673,0.03902628110319611,0.06121891777314208,0.06812510248693211,0.08279785515912685,0.07662414366709228,0.06159523993100288,0.06807278949175964,0.07477907369700101,0.06726192896291694,0.06793877023638659,0.05019440579421022,0.07481577604033174,0.05858646542219298,0.06528504585297495,0.01978352041670264,0.019844325760273326,0.01983571699070714,0.019939439662734423,0.01992980304891113,0.019804277445546227,0.019909131842679215,0.019799921623522034,0.018439974434924396,0.02229718953088726,0.019011056647445564,0.020938201486559886,0.03114459540693387,0.020630970343096928,0.03320520428399936,0.05410338734117651,0.052346681982330855,0.04333946645514362,0.03465026487319551,0.07919646297833133,0.04294136477222473,0.0036347200685694515,0.06045452448654448,0.05736387011771328,0.05147082110460494,0.019733430581733265,0.07759198996767136,0.044045501129024514,0.030943682392339782,0.03764980500636728,0.033799134069499345,0.02921763177145084,0.04913164686248003,0.03745684114911583,0.0437065237743898,0.028717010124522706,0.03682020194552473,0.03816440397078781,0.06377572827783726,0.06602960543954901,0.06601451467331537,0.060042437415797914,0.0697687460148435,0.04343029725835953,0.04520171120021781,0.0415066148026427,0.06263782139528669,0.0549942782793624,0.07532766896129112,0.04418868393979199,0.024172120895145227,0.03413718931673153,0.03318503954250804,0.05323240489624134,0.02363320064202956,0.025539846107167023,0.035021046113480475,0.07422539326115764,0.04054999572968664,0.021616116522192152,0.0870270135076816,0.023656935367114156,0.08001391425749281,0.05688537756007585,0.023661590059097192,0.02352301835657103,0.04778481390605997,0.023821558431617658,0.045552646629203636,0.033088489297860416,0.024139114496626795,0.054400913995536974,0.05441172103572582,0.05372970179946292,0.050642234623986905,0.038611509918949634,0.03781951196198641,0.026210136509421174,0.04000998220844927,0.026962103942610963,0.026661498675309543,0.027002606113792186,0.027123363483812682,0.027122274396900008,0.027081290070114887,0.026479757606875362,0.025814501831559138,0.027086236662633316,0.039766447812591754,0.032099455878555505,0.03888512509824911,0.03906103284261581,0.03885398968855179,0.061663165089929944,0.038991975041105,0.05603840563021172,0.048838455367945136,0.041063866265406875,0.046388500297807354,0.05242532188761265,0.04955718561573409,0.06496796978756518,0.04241556430685204,0.056395250871039526,0.03910942703643808,0.03966118677938794,0.02475875155552118,0.025136069655953656,0.02455451207394579,0.02695294195394498,0.029700830555042704,0.02957082619635913,0.024752086453453448,0.024639329357921014,0.043769819986656876,0.052129955967272934,0.03903517492171379,0.027143001928535224,0.02478347380070296,0.03337171529383727,0.03471418320207827,0.02726813937163961,0.029713629106051943,0.027518478541967095,0.027228003644583273,0.024500604933199412,0.02793277378385117,0.02545140824091417,0.03628166899571659,0.031652545531753465,0.027628971963334345,0.026799028521514896,0.028372237914494943,0.027918162890168397,0.027270653633462535,0.023674568452159577,0.04455328892208611,0.059459904708335634,0.04582057221336934,0.041355457053287394,0.02653596195867657,0.04153079895848471,0.03849333614265299,0.039803147937886335,0.0427605687007476,0.043426756335148274,0.048555849597692616,0.047255378740402545,0.04288145686375667,0.02153479838065598,0.04941843616510596,0.061707453109125295,0.02735667548093082,0.07250480782885323,0.04431758759695735,0.030223896889773495,0.05514981085927938,0.026354094159801552,0.014378939187746248,0.02030072985057218,0.01607268902363131,0.019927631689368026,0.020354559152820265,0.017277151381048718,0.021497106687895274,0.021059244541914504,0.015657614150883938,0.020288396625933545,0.014622759199209549,0.02282465118042458,0.022760575883227507,0.02447789330685905,0.02123721216609005,0.02441066804086285,0.026443909412985692,0.032892111281854444,0.027822667289949282,0.018011335465930797,0.058435871771451035,0.05855463792093793,0.057734241512057256,0.020257499953548027,0.07054435327751632,0.05855463792093793,0.05532255429309331,0.3110391449736905,0.04844034433506949,0.06348261450742962,0.3617669862730344,0.3058538979296605,0.03658669834463233,0.052831106816287735,0.04253913017988097,0.29574691402012354,0.3314189514456048,0.30157072461757206,0.05585842325590452,0.0691255799180136,0.3239670383081239,0.0491955833346657,0.039136017116243496,0.04608969108213842,0.06016783918525963,0.3093310733701182,0.040568047805229684,0.061528918800476916,0.031664917678705565,0.029917055392425174,0.25676103904327474,0.023774394811807518,0.2535930076830503,0.2505595920587338,0.24136900392233704,0.2849099400179643,0.26060508834400853,0.27421426487999906,0.2460944484934235,0.28396230115470905,0.23059370199751134,0.04491544384711572,0.2785872487185223,0.2590364014701272,0.25655869100764306,0.04469034211162897,0.04390167997167898,0.04319584683824342,0.023358331168115067,0.022820736399160435,0.024053915786594,0.022818514568553945,0.028233356240418516,0.022206946170632805,0.0233467302572116,0.025779883489235017,0.02359209939408529,0.02282925034736183,0.023623343408127596,0.0226064533263181,0.023388349364593917,0.02186063693734052,0.0,0.059734841651398335,0.03153925794645739,0.0019913770101717635,0.004017641203849763,0.10535450208856248,0.037883270294569955,0.040079800160571395,0.039619477028703116,0.0491739795413301,0.02133134950176988,0.02147516523889748,0.021292618250314505,0.021294606636593792,0.021288356096884006,0.021460426880384888,0.0400591215864562,0.035757639003952804,0.03652519995487581,0.03604059727073167,0.04269303255538801,0.018198000542215365,0.018487323086419354,0.08892036064052311,0.0719173119272584,0.08053101126914194,0.0881916498068184,0.05932950503560889,0.057874217843236604,0.06699991753479129,0.027240169289629558,0.01556260226023857,0.03818186930647369,0.24752621630795288,0.04584985138119403,0.043798691389416396,0.026655774295091427,0.03275406369205174,0.043180225166668265,0.04143137885687522,0.04131498699037962,0.035277895133914536,0.054152972787487,0.040058646556807645,0.05386024155309055,0.04799024513529544,0.04002115813635051,0.03397413877976758,0.05445975769812254,0.053885892934082365,0.05438082650390674,0.05908438146293727,0.042375263610766434,0.048065651809609755,0.04784030691723523,0.03795232145672998,0.04181786719285143,0.05939399459205095,0.06318301479058426,0.034451398173860975,0.11196030631800312,0.07653590217290436,0.04104369976516654,0.046080255034356525,0.08221462443182395,0.029495127706154,0.023533338307629333,0.040118751351320876],[0.013691146168348938,0.019221158314568693,0.01970670345115094,0.01898080658344424,0.019832475081917027,0.01830022693843454,0.019233326866643714,0.016183240477373493,0.01946952639341268,0.018412721264393292,0.019218557671460218,0.012000448554598196,0.018989632575934924,0.021970643902815667,0.018219943697006708,0.017547725498469658,0.0186078871528717,0.009048196673210326,0.008042911896408586,0.008067632068090315,0.00806413220690793,0.008106300248550873,0.008102382521355311,0.008051350584301526,0.008093978724305348,0.008049579742103621,0.008329665107806312,0.010072037913773674,0.006440724841197665,0.009458158792915443,0.010551426626433338,0.006989532757225833,0.008999629554740568,0.005688496011650273,0.005700357938413109,0.015731686154597545,0.007043463996606079,0.011498931593159444,0.01909429575174272,0.0,0.016757418799139515,0.014575658922042444,0.01307828658210643,0.006685456726935622,0.01577235815548075,0.00895326204720427,0.007862519725695495,0.007653189579128646,0.0068704520674281915,0.004688807571770593,0.007884582830818393,0.00761396523304729,0.007839138614557373,0.006735453903869764,0.007484553659261872,0.007757793664893966,0.008528871652552898,0.008388773331270754,0.006709484892200769,0.00871786257322782,0.011818419773563503,0.0,0.005512973016318971,0.005502505405645009,0.010052036165518776,0.00873347894348611,0.009570051740923844,0.007925618161421275,0.010529014334045635,0.006939169578577308,0.011242705363579939,0.011593619703863363,0.006550898284060244,0.008652602762345597,0.008375098610831645,0.007804148211029307,0.008831485828972285,0.004707828528903988,0.010205909935099542,0.006557477323953503,0.0195176040251101,0.007884042620610902,0.006558767560269202,0.006520356803213995,0.0104071751243735,0.006603109270599563,0.010684181613609714,0.008407496447878972,0.006691132789414095,0.011848112247345916,0.014747246502964073,0.008401383667025369,0.01372559998553471,0.01681859623155436,0.01647361376693846,0.013319534029958304,0.017427749844751143,0.013701670758326416,0.013548908406784797,0.013722253254992987,0.013783620043326122,0.013783066588360721,0.013762239068629448,0.013456550767030425,0.013118479390150503,0.013764752840633568,0.017321669904313153,0.016312383369841792,0.016937778911359475,0.017014401693859236,0.016924216792568923,0.02685955245428595,0.016984321148377144,0.02440949135977825,0.02127330071086229,0.020867940307260253,0.023573826412284532,0.022835686120223398,0.021586368857182958,0.028299075952598892,0.02155484966596525,0.024564927809563118,0.01703548148088535,0.01727581977257556,0.010784541875823301,0.010948895997051709,0.010695578212336196,0.011740298396190096,0.015093443834362279,0.01502737788774249,0.010781638657048523,0.01073252335267468,0.022243058771856058,0.026491534000089564,0.013224663176865537,0.011823085678508833,0.010795310516068727,0.006359596276824606,0.006615428314100274,0.0069285963116531004,0.007549973917330785,0.006992205310732711,0.006918398173574884,0.0049803119651057595,0.00709747411714929,0.006466980781526345,0.006914141662497999,0.006434108531917837,0.007020280725094986,0.0068093993374249645,0.007209138118612078,0.006548087646035264,0.006929235163646462,0.004812401034687792,0.009056481605595357,0.010664642134960621,0.012701026510704655,0.009889939603602356,0.006742556418949325,0.00993187169614694,0.009205478471715735,0.012447547847172136,0.010865087439457894,0.01103435990516115,0.012337617754061189,0.009605743564214042,0.008716643253585397,0.010943608773511602,0.011590886284751552,0.01567932546428393,0.009268123419446496,0.013004357009176492,0.011260712356670734,0.010239504679079326,0.014013085781180427,0.008928460530630386,0.00438427559712355,0.007737357509960694,0.007001022949147186,0.007595156028497005,0.006206299075245283,0.007525668737618868,0.007282969675291954,0.009173091951998443,0.005304617533136253,0.008837322128905973,0.0049540207137226825,0.006959453675725407,0.007711018341043405,0.006219619130278194,0.006475428391134186,0.006766404847308903,0.010337179492627352,0.007163655863421264,0.014138994035360375,0.007845468344243546,0.015397972789119483,0.008208674555536324,0.015798210682170636,0.008823864000517795,0.008603858255497776,0.008208674555536324,0.008032559074629181,0.01828847376508927,0.0050930767756808,0.012206772909898647,0.012534795675278801,0.01500699721792947,0.006562137067982223,0.007003786076630929,0.006485293105956399,0.009017605270686586,0.008351470817437314,0.01205360517666355,0.009462092005884853,0.00802935166467923,0.011486120645902334,0.00909103164743772,0.00795529640357982,0.006387811849866275,0.008338976181105216,0.008061366868101978,0.0077309902565249715,0.010005735330618068,0.014628689671811294,0.008001750275675967,0.011861952707686418,0.007249039560485545,0.011046132130858428,0.0059685943423534405,0.008459276973361473,0.011137404622000106,0.009932621892289512,0.004861078067830251,0.005284263574219513,0.008658281193070237,0.006893158570306452,0.015216829885066247,0.00987719851347206,0.00867941401758975,0.011337273916838274,0.006488814872415682,0.006374305061543435,0.006271821609475865,0.010174539700314981,0.009940371459440094,0.010477525956683463,0.009939403663258491,0.0086086193962939,0.009673013615984888,0.010169486517033281,0.009825665214481053,0.0102763656432168,0.009944080007938618,0.010289975068435694,0.009847032957813064,0.010187615177737051,0.009522166493501766,0.0,0.004793084874648721,0.012020775416787862,0.0,0.0,0.018896230452989073,0.008885361661624432,0.008147142033552858,0.008628825814502458,0.012494679179824008,0.0050031782784313895,0.005036909654499918,0.004994094026356202,0.004994560393992289,0.004993094356201201,0.005033452834519362,0.007402671488487261,0.012114272134699176,0.013921101963026664,0.00915760132792483,0.005917051142261226,0.0,0.0,0.013556332708323253,0.012898984597683434,0.013641484910246275,0.01415288133602955,0.01148579779456627,0.011764267061228422,0.012970738666964337,0.008305787229409405,0.007908642914753418,0.011642015844645318,0.010482375334175014,0.009320037772727057,0.019078054898535028,0.007740571072367667,0.00951145350761285,0.021943436972255637,0.021054703793468778,0.015746666608389557,0.017927610738409396,0.02063969688617624,0.020357105191561427,0.020528126207115475,0.02133932954093414,0.01743261791179329,0.014798626721698734,0.020756623940017194,0.020537902895284756,0.020726540348302454,0.02251923876622372,0.021534369555426706,0.020936679039209607,0.018233706902634417,0.01928670752924649,0.00607174583483598,0.009531471056221114,0.008919029341059686,0.007503256887841998,0.008534441109098201,0.010607511817968146,0.0073615383683738956,0.006328967985948941,0.009284452791650143,0.005290203259727006,0.005519645488436598,0.013591766266237707],[0.018058303036568343,0.015211356184075925,0.015595609822442779,0.015021145181608806,0.01569514373408977,0.014482543957767486,0.015220986206201978,0.012807190445296893,0.015407911212145537,0.014571570395864566,0.015209298071449035,0.027699546432472175,0.015028129948773023,0.009314603930482043,0.014419008922001963,0.017358781037619453,0.014726021953676071,0.00895077056278733,0.013923542764667422,0.013966337261485691,0.013960278452503201,0.014033277950530769,0.014026495749898678,0.013938151457796028,0.01401194745829511,0.013935085852031652,0.01441995757726593,0.017436278356151125,0.0148665406951953,0.01403447764665335,0.01878806618132518,0.013828546463019724,0.022256815972254408,0.01313023914804119,0.013157618957191726,0.009337377496611421,0.016257788792793052,0.015166823051388416,0.018888698655045374,0.014617701788835369,0.0110513226235624,0.024031193456651,0.021562444388763355,0.004408980885470555,0.015602529894360326,0.005904572094482232,0.007777860346300417,0.0050471894360353065,0.004530983158979656,0.003092214010793824,0.0051997905918571,0.005648986615959498,0.005169820660252762,0.004441953441637435,0.004935976009987577,0.0051161746128928955,0.011811852296102515,0.008298447536374444,0.0044248271807491016,0.005749328881699115,0.005845582696112166,0.024951858030590187,0.010907224581890272,0.010886514779734749,0.006629200834592104,0.02764621294124653,0.006311337717391489,0.00784027937204114,0.010415643576291085,0.02059335700936372,0.011121649965055238,0.015291714464862946,0.023761326373399894,0.011412581592234072,0.014498610101434986,0.015440234689356378,0.005824262096165063,0.02173330677419157,0.0067306787943735985,0.023785189774623468,0.009653724486412593,0.028596888812326405,0.02378986970169098,0.02365054674244753,0.0068634108437553975,0.023950705331466853,0.01056914009812754,0.03049555319265821,0.024269983004297828,0.007813692102289894,0.0,0.00623319156811709,0.0,0.011091668428068541,0.01086415650862318,0.013176116458473846,0.011493398144765249,0.01355413854428507,0.013403021055500893,0.009049666279805805,0.009090136962335753,0.009089771965228886,0.009076036458420955,0.013311657873088033,0.01297722666678401,0.00907769426179465,0.011423439658931576,0.010757826938634047,0.011170268017984783,0.011220799851071354,0.011161323958520137,0.01771356216937501,0.011200962081495982,0.016097775398906916,0.014029494174596311,0.01376216370725407,0.031093328188156348,0.015059869164214808,0.028471917945286262,0.0186629111589027,0.02843034486590502,0.016200283928091724,0.011234701725223568,0.011393202030795732,0.010668419735069413,0.01083100417960515,0.010580413984414618,0.011613885183783616,0.014930925757138816,0.014865571173063747,0.010665547776591372,0.010616961319372405,0.029338076653579064,0.03494171656593028,0.01308226712365076,0.011695781057217233,0.01067907242439428,0.006291119567985368,0.006544196943618108,0.006853992916776188,0.007468679862932249,0.006916917008399423,0.0068439045867583394,0.004926686647158155,0.007021052336982966,0.006397347814153982,0.006839693907501117,0.0063648295152315465,0.006944690121815044,0.006736079391393457,0.007131514000595495,0.006477581363612057,0.006854624889955228,0.0047605836912393,0.011945288383307823,0.017583018350108174,0.020940447825327328,0.007337587543860867,0.005002467151107883,0.007368697986621416,0.0068297691266726735,0.00923513951508401,0.014330797369918383,0.014554063811151995,0.0162730305711907,0.022172066207759883,0.01724557426376741,0.032477321658124794,0.007644054574347187,0.020680665238794024,0.024448878016596932,0.017152444125556394,0.018565771780898344,0.030387753616271083,0.018482933890442838,0.00588821578301822,0.01301120423367972,0.005102697206613338,0.011542732838717797,0.005008916984967004,0.008185963984187654,0.004963090925540057,0.01440910115764472,0.006049547357636256,0.012244167290672861,0.0058281110680304905,0.011434916466902431,0.006884518025365103,0.010170653662657571,0.012305299239984574,0.006405704464449577,0.004462365228533106,0.016361398894664723,0.00472434764922794,0.0055947011838869435,0.005173995043295898,0.0065280753034555805,0.010150359959119776,0.008930345174263577,0.005819235589025649,0.008511216541934478,0.010150359959119776,0.007946068803070307,0.01292253808979072,0.005038237266963068,0.006900192543467646,0.012399827743911311,0.010603864250950543,0.006491479508947397,0.006928373078845283,0.00427697530755569,0.008920508552016213,0.008261546675927092,0.008517013175373251,0.009360209293351948,0.005957171946587922,0.011362444282667129,0.00899314431307367,0.0,0.006319031330927181,0.008249186575112175,0.007974566409732483,0.005098498077094193,0.004948999479725143,0.002894235163439311,0.007915591736677427,0.01955704931191634,0.009561314406966594,0.01092719332707288,0.009840546219729284,0.016736384066409545,0.011017483045169087,0.016376121278771586,0.01122038539135628,0.015682096406957908,0.01427508913769216,0.013637873499898888,0.011289737439957898,0.009770846157549855,0.01144794501367712,0.011215200255045757,0.010698244678846043,0.010509449960715393,0.010340483351664412,0.013419980979433253,0.013111118521662208,0.013819612797408155,0.013109842021031064,0.008515926417329806,0.012758479750813432,0.013413315948333721,0.009719867741377966,0.010165715270544485,0.013116010010788734,0.013572237542399525,0.012988007211138276,0.013437227229727578,0.012559515908305346,0.011884529878463328,0.011063442873494962,0.01189134217882637,0.010010865601298642,0.008078845124863733,0.018692766016794617,0.02050927403219177,0.018805308653556344,0.01991713561531352,0.027810322202883864,0.014847920244997872,0.01494802476931168,0.01482096093177905,0.01482234496990044,0.014817994213044134,0.014937765972899433,0.010984445261007088,0.007989221449610557,0.013771207031910138,0.015098328678468293,0.009755565868623665,0.013069042656695156,0.010621457603060679,0.013410365416157468,0.008506730184047306,0.022491001241690487,0.014000490729409551,0.011362124907620433,0.011637595767141021,0.006415538368082345,0.008216354984180009,0.007823486905690296,0.019194434809734436,0.010369506760061641,0.012292912831597141,0.02830894901190194,0.0038286123852085477,0.004704519648502253,0.02170716185681205,0.020827998078419573,0.020769486640021914,0.023646101170423397,0.013611639828049322,0.020137910842685507,0.013538060264012065,0.021109559129072596,0.011496608578309982,0.01463928307642125,0.013688751858900124,0.013544507876048486,0.013668912080369784,0.01485117581804131,0.021302499057694452,0.01380749610078152,0.0240498348844557,0.019079038646119338,0.013514329225313098,0.006285894204950915,0.014116790455885408,0.007422465857265555,0.005628364561329759,0.010493295841568074,0.007282273286516888,0.011269477918901231,0.006122988535025993,0.010466482398315432,0.009100354862458858,0.013445417444596963],[0.009327717721523219,0.003928587208866829,0.004027827139243902,0.0038794620353954233,0.004053533437052785,0.0037403592589527737,0.00393107432318377,0.0033076711869771637,0.003979350833080763,0.0037633518259354137,0.003928055666850287,0.004087926433351785,0.003881265968365383,0.0032075363883079426,0.0037239502730738797,0.0059775941360882805,0.0076064830491928154,0.0030822483164939197,0.008219400798110182,0.008244663414618632,0.008241086754552443,0.008284180106761052,0.008280176411277039,0.008228024659579211,0.008271588206275007,0.008226214959067476,0.008512446352379598,0.010293052756680571,0.008776075063690478,0.009665703035470968,0.0129395530700616,0.00952387590681967,0.01379566815433374,0.00968886833948015,0.009709072035926854,0.019292271565345395,0.014396043209429018,0.003917085782345104,0.016725676872395963,0.007550532059825935,0.0,0.014895498560703293,0.013365268767755557,0.004554772290173733,0.005372819151445477,0.006099818089460927,0.010713400277727075,0.0026070422149332686,0.0023404044013633552,0.003194463994630704,0.005371731635431913,0.009726301978583934,0.005340770690588699,0.004588835147116482,0.0025495967593488745,0.00528535073383695,0.010459229001268876,0.005715234407826922,0.004571142573581964,0.0029697207311280764,0.009058317140332462,0.0064442347618587845,0.0056339464355597245,0.005623249129828166,0.006848408067927956,0.010710145488042264,0.0065200341974345054,0.005399688825850197,0.007173371198161208,0.010637157917491646,0.00765960576041204,0.007898682158425038,0.0022315491071663008,0.0,0.0,0.00265846594121164,0.0030084262435502193,0.0256593831131355,0.0034766207954880857,0.0022337902426508094,0.003324314464035975,0.005371363592591395,0.0022342297588169107,0.002221145218820206,0.0035451813400046743,0.0022493346650156094,0.0036395429919384935,0.005727990384897152,0.0022793196832990035,0.0,0.0037677128395039415,0.0021464346653111144,0.0035066966084143325,0.01145843570663827,0.011223400669451128,0.0136118100069181,0.011873449386506883,0.01400233211764004,0.013846217639406971,0.014023366264440012,0.01408607964928115,0.014085514049627327,0.014064229503121438,0.013751833358230443,0.013406343543007447,0.014066798435851654,0.011801177589233325,0.005556777554201772,0.011539634342665313,0.011591837107679078,0.0115303945307293,0.009149647529116943,0.011571343364225004,0.008315039600421884,0.00724670314654643,0.007108618015696552,0.00803037217213845,0.00777892630345194,0.007353349122733238,0.009640018045969805,0.007342612179497281,0.008367988685524075,0.005803099336974556,0.005884970047979818,0.011021191484265344,0.011189152095123295,0.010930275654763937,0.011997920560436087,0.010283096959264618,0.010238086520145998,0.01101822455897487,0.01096803149741093,0.00757704909932112,0.009024282851286277,0.006757428681968056,0.012082524477913767,0.011032196425183239,0.0021663824987204713,0.002253531120117354,0.0023602111104070096,0.0025718820265220026,0.002381879376185038,0.0023567371370774924,0.0016965323284264255,0.0024177389637996052,0.002202962794307375,0.00235528716593134,0.0021917649347034628,0.0023914432044016814,0.002319606923029693,0.0024557770605554683,0.0022305916694984815,0.002360428733934895,0.0016393338389048575,0.015425352802538251,0.003632886911467823,0.0043265767748253805,0.0025267396472230716,0.0017226277722861077,0.0025374527036187687,0.0023518695116874454,0.003180172368767542,0.007402336328073288,0.003758830457561649,0.004202782380337926,0.009816526319702427,0.004453958058856369,0.0,0.007896819891995617,0.016023383308787862,0.0,0.008859811285335095,0.015343747691353415,0.0,0.014320580647570191,0.0030414604626021946,0.001493493849253924,0.0026357138356417308,0.0023848830853372646,0.0025872732134189507,0.0021141621438192496,0.002563602520455237,0.004961855236239092,0.0031247936187995705,0.0018070063076283981,0.0030104143662994104,0.0016875762714085739,0.004741445207360035,0.0026267414556211317,0.0021186995913000666,0.00220584045395963,0.0023049609444369522,0.002112802489104704,0.0048805672605120075,0.00288985035160237,0.002672541553804586,0.004495959084835627,0.004194400427495026,0.004612822078166174,0.0030058298844334893,0.005861770821555592,0.004194400427495026,0.005472547200088528,0.005339938633352594,0.0034698908267754725,0.0035641803185653357,0.008539901211942914,0.004381800539726193,0.0044707551484320825,0.0047716486772871975,0.004418401694779139,0.006143654844876147,0.005689820369070553,0.005279186725541147,0.006446481704359663,0.004102771504337956,0.007825443522619057,0.004645259934524498,0.00812986272272667,0.004351988143366602,0.005681307828242646,0.005492173823191522,0.005267089689497312,0.0051126476344273185,0.008969815791528127,0.019625606282681063,0.012122244382191852,0.004938738798120513,0.011288521921140285,0.012199131292993985,0.008644902344054,0.011381797241844769,0.016917629120796827,0.018215071196235624,0.010800436657464533,0.008848273394659677,0.00939255728671707,0.0,0.013458583887754462,0.011826493260508676,0.011586052350276842,0.0066312015881882375,0.006514179041752652,0.006409446753426405,0.006931869187867603,0.006772331394364517,0.007138292392919621,0.006771672039078777,0.005865014565858122,0.006590181670468458,0.006928426476302972,0.006694182533727319,0.007001242755313099,0.006774858012160094,0.007010514796910865,0.006708740283363189,0.006940777453177718,0.0064874101887878784,0.0030693786601883456,0.022858553639992382,0.0,0.0020683788125147214,0.002086496906382439,0.00643695938597917,0.006053557855139897,0.005550612066491589,0.005878781109790594,0.003192213757452521,0.013634573502560853,0.013726497655719967,0.013609817258481188,0.013611088195365616,0.013607092974946172,0.013717077190670144,0.007565111333345468,0.0,0.0,0.009358550315232304,0.008062521883876008,0.0027002391209260384,0.0027431691148346086,0.004617934951809103,0.0,0.00929388372460423,0.004821147931131104,0.011737835348133751,0.012022415179683827,0.013255360884772438,0.00848804451194164,0.008082185497334513,0.011897481354709093,0.003570798126247504,0.0031748503897689275,0.012997794967718045,0.0,0.0,0.005606237693700703,0.0071722385869263,0.005364067382377016,0.006107001208409323,0.007030867395789058,0.006934603155914548,0.006992861089104402,0.006230739190658771,0.005938382989595481,0.005041119677960561,0.007070698339773835,0.006996191496448428,0.007060450430354339,0.007671129207593898,0.007335635674840178,0.007132033713705871,0.006211272194213733,0.006569974544069988,0.00930747095148295,0.006493749346481552,0.007291794596631993,0.010223871892283664,0.005814477224753173,0.014453702378032595,0.010030767483163174,0.007761416539422928,0.006325456888301155,0.007208384468247371,0.007521020432612119,0.0],[0.018629546467255013,0.02092338844813632,0.021451933571981094,0.02066175111326836,0.026986054458565917,0.01992089918075816,0.04710742796236288,0.013212323939436062,0.04768594213566017,0.025054195037127077,0.026150696864356456,0.0,0.025839198422066174,0.021353900984629477,0.024791882546608558,0.007959065017851092,0.015191854390098828,0.016415845033059217,0.01641598874160414,0.016466443858512606,0.016459300465360076,0.01654536756466215,0.016537371285905978,0.01643321252911153,0.016520218712368463,0.016429598150891508,0.00850063325274891,0.0,0.008763896114795864,0.00965228951035351,0.005742931679084587,0.009510659201503681,0.0,0.005160225422315798,0.010341971547437353,0.05137466353013571,0.006389362302797594,0.026077665790292765,0.0,0.0,0.038003040840063035,0.02644413762881675,0.017795628254753428,0.015161504768339072,0.0,0.004060902067437282,0.007132355211096121,0.003471232408983005,0.003116208691061374,0.008506749053754962,0.0035761846966770013,0.03108097394439493,0.007111145421399542,0.027494802101436004,0.0033947447610150764,0.0035186773453544824,0.011605238072164214,0.007609737497822379,0.006086398661521423,0.0039541326904767235,0.01206099534877426,0.0,0.0,0.0,0.009118538970777922,0.0,0.0043406573710567,0.017973984793332513,0.0047756109283715225,0.0,0.015297952371048824,0.03680936376417258,0.0,0.01962266504714598,0.002848999762690185,0.04247642672045136,0.044062352648191416,0.0021353145373574976,0.032403430588660395,0.0,0.04868895042445186,0.0,0.0,0.0,0.0330424409887153,0.0,0.038767917190254624,0.0,0.0,0.032243459378361435,0.025083228114436636,0.040011177969577066,0.018676427786053617,0.0,0.0,0.054371681176028884,0.0,0.05593160183945068,0.055308010514480935,0.05601562166657409,0.05626612708534785,0.05626386782636354,0.056178847790379606,0.054930997314799876,0.053550955860112916,0.05618910926121259,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.048244310499619136,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02445754863925274,0.024830276471393364,0.024255793835765004,0.026625045585651246,0.0,0.0,0.024450964621571494,0.02433957927396133,0.0,0.0,0.0,0.026812793383131747,0.024481970125637017,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0369694712539086,0.0,0.034564580737588356,0.010092932713858086,0.1513808740635096,0.16892875785842373,0.012525897162547421,0.016937381879565318,0.0,0.0,0.0,0.013070537987225472,0.0,0.0,0.04731516674717263,0.0071116208660300315,0.008407425440439693,0.005898344087979365,0.0,0.0,0.006355869929858792,0.00809930584779228,0.027839863548935962,0.02456585729327389,0.019052587817807914,0.00344491031939172,0.022519767756528527,0.02048035916361066,0.03963975559595461,0.016642438421332575,0.0,0.0240498934453212,0.020222812162957925,0.0,0.0,0.0,0.002937039081673038,0.0030690163304372972,0.0,0.009747588561398299,0.019238933186683835,0.021350661994150488,0.01197258624762428,0.01675431868740827,0.039922312388632336,0.01600884565807039,0.01560969648536016,0.01675431868740827,0.010929905406876625,0.003555018775664207,0.0069301510105260165,0.011864113824466827,0.017056100023970035,0.0029171464804197875,0.020834570787691697,0.01588342282875555,0.014707566942117356,0.028630602104346415,0.01893974784266669,0.011715245697341831,0.012875071271138988,0.013656926354062132,0.020838890152821483,0.015462711670440336,0.05051561231969741,0.023178393046697335,0.007564564833603785,0.02193820835922117,0.02103912126141535,0.013614806897009658,0.03981052435567224,0.02177596773083795,0.026900937345807164,0.0,0.02004063349017934,0.024364404034073178,0.019184234287476818,0.02020622616289381,0.07208171424414654,0.02645788121229847,0.03355472839330684,0.019635542784303628,0.0218855532421839,0.010352772366257725,0.008959937875686757,0.04330363073992491,0.020568842437653237,0.023544885957036205,0.02312938320484486,0.02275751850553406,0.0,0.0,0.0,0.0,0.04685500339859716,0.0,0.0,0.03565276117067713,0.037288143039942864,0.0,0.0,0.0,0.0,0.0,0.0,0.006521951945863541,0.010904448341814374,0.0,0.0,0.017141404084620986,0.016120418837907557,0.014781091295363558,0.015654994304834857,0.0,0.018154202932982276,0.018276598380891202,0.018121240414661018,0.018122932645526224,0.018117613077426573,0.018264055191754742,0.02014563438018252,0.04945168056975762,0.012628298254782533,0.01246075071943705,0.026837777214667655,0.0,0.0,0.0061487019180107285,0.01755165199378841,0.0061873241264318495,0.019257829640635892,0.03125745662142346,0.03201528304138791,0.03529857555234524,0.0,0.0,0.0,0.00475445702826235,0.021136296726442377,0.0,0.013165746561921467,0.012942237480514585,0.0,0.0,0.014284329141292663,0.0,0.0,0.0,0.0,0.0,0.0,0.013424330379818248,0.0,0.0,0.0,0.010213978188142861,0.0,0.0,0.0,0.0,0.0,0.012969475364572845,0.0,0.010209683771469115,0.007741877622174752,0.004811214777903559,0.010016847341908159,0.0,0.00421111918067997,0.0,0.0,0.02465909360842356],[0.0806060937502651,0.06412616832978683,0.061878642498244756,0.0707742177950904,0.06616566050212318,0.07182791906109007,0.07549031222948052,0.060342861676646355,0.07641738928421349,0.07949640203013937,0.0716607263430959,0.12167874912910728,0.0857138911823729,0.0831544177929248,0.0750884498781016,0.034437185152145576,0.06208015585212165,0.062149392782808836,0.12035384597247008,0.1207237577374273,0.12067138593986255,0.12130238700691658,0.12124376227727518,0.1204801221963002,0.12111800815877154,0.12045362337698287,0.12464481077243064,0.1383637122477282,0.12218511515544715,0.0928075737161572,0.107676601643008,0.09373193107041258,0.11038535639004568,0.11535720118700121,0.11373326976499079,0.08027040149233444,0.10827787403637364,0.09402710443394847,0.08832758630955943,0.0942477257595228,0.0493293276591607,0.08104620459180917,0.11549685994520721,0.04592042934753915,0.020635366413864202,0.06442575841683006,0.08486551500300268,0.03254178616416523,0.03595512971305596,0.07208017473811261,0.0851036570801158,0.08965385188934565,0.0820491120406123,0.06388816718302005,0.03182473688854456,0.08373513550708715,0.11883838501295214,0.08505810770594285,0.13167277635405902,0.03706883473006283,0.10437073425417183,0.06806345793593062,0.05409569249254438,0.053992979737289774,0.09205929335694849,0.08741063337636934,0.11581680313898152,0.08813889985525233,0.048213794865878214,0.13958481644270881,0.05515916097650199,0.0644649329065992,0.0535668894193556,0.04528165710529991,0.12943368186016382,0.10210360194409619,0.04910641852781871,0.14166547654117528,0.060086900170360454,0.05362068642354741,0.08618185434315055,0.04641699612244264,0.05363123672413993,0.05331715082531038,0.051059867659217356,0.05399382020367755,0.052418921822534034,0.04674887638796546,0.05471359112579881,0.04650353519615269,0.01808830075838017,0.11129134844743119,0.016835195680608553,0.03300627836215732,0.03232925472115853,0.039209120826227316,0.028501445398213757,0.0403340284334322,0.039884337214068075,0.040394617760122604,0.04057526505702199,0.04057363583466621,0.04051232522606553,0.03961246119736889,0.03861727011679808,0.04051972509380996,0.028327961634837973,0.026677368453868512,0.033240172835360446,0.033390544058573786,0.033213557352009836,0.035141017033904785,0.033331511375714995,0.0399194268558096,0.10437144623688188,0.04095306392658782,0.061684440715706494,0.029876493150712363,0.049423465813608715,0.027768285932534918,0.056401486254405164,0.048208354256555376,0.033431912868956054,0.028252978057619973,0.03880162815880817,0.039392956707735106,0.03848154641310041,0.04992039932660448,0.04443103352221691,0.04423655316894869,0.03879118268818367,0.03861447107640043,0.04365171619212216,0.0866488234619548,0.09732461646586282,0.05027241543838038,0.03884037257460164,0.07488375442059575,0.07573237474247958,0.06572019136649836,0.0691447237403561,0.06632354526447513,0.06562345841281839,0.05375588927465993,0.06732205719841257,0.06134160447630044,0.08367496910975514,0.06944770292428364,0.0665898505190444,0.06458956582501525,0.06838122982368743,0.06853620063862498,0.06572625110405125,0.05351755840627033,0.07109291375821603,0.15348096686245558,0.04985120169672022,0.08976606546666313,0.06119883287210519,0.09014666222613578,0.09710277667186193,0.06107038059443108,0.14570439288612497,0.1443652607560964,0.16141610564478642,0.16966033159473948,0.17106300053251886,0.07874786768591435,0.04549392992274293,0.07692618540810119,0.07881714867778265,0.0808161296348132,0.11417818155950205,0.07033213591451709,0.10083516761296567,0.05548629764421023,0.10755105448662314,0.055676369472177974,0.12365475583585187,0.05962158330675879,0.08322851002048184,0.06399912095992255,0.0643173035926015,0.03300380369294336,0.11104259784376021,0.05491991417109637,0.09722201807915828,0.059183965324077326,0.11854006395517606,0.07730417514022972,0.07412967781545104,0.10623185851019765,0.15823533599970002,0.07732220272423522,0.041621390376483595,0.03849157630138079,0.05827819467350418,0.11075224895318342,0.07972401824038833,0.04906403826414829,0.0590973633179021,0.11075224895318342,0.0735643704501279,0.14099994102589525,0.03331699179161581,0.06502243657126196,0.08609781241622302,0.13884061075077914,0.062244195574743796,0.08246903950303743,0.059394086005680774,0.09733313773313475,0.10380114107096694,0.11489593200064585,0.037138467245992714,0.051211872293373525,0.09016545498100403,0.07136412980568466,0.09887705558704635,0.08357332290162954,0.06000548873193586,0.11865246443495352,0.050573229162302204,0.041726769113869286,0.08038412188833602,0.1256266543757898,0.10475518195409281,0.14226146718641092,0.057807711879029285,0.13275061409796154,0.17431283147257634,0.09835655869020332,0.09096566481948566,0.09698799780827932,0.1434558051266388,0.16425373086219414,0.12625885870896195,0.07838993544174006,0.0387677495892671,0.1220715401279319,0.06303955288003553,0.07216055487040493,0.072972033967138,0.08205579388834337,0.0133116020279726,0.013005233924654821,0.013708006443653206,0.013003967732965258,0.045051479001139504,0.012655443043105407,0.013304990823259493,0.02571032181263526,0.03361205857111105,0.013010085910412196,0.013462628976182146,0.012883116853598739,0.01332870899859683,0.012458086020507322,0.07957272017376273,0.06898002684996928,0.035385925264478174,0.10128618827785306,0.09015300970001718,0.09888962332566645,0.1017182119026742,0.09859674436349754,0.09878143018776826,0.131798476930106,0.06873071026612107,0.06919409200197447,0.06860591617272334,0.06861232285605331,0.06859218329414868,0.06914660424932934,0.10532544363173361,0.055472906876306585,0.018213322133570544,0.1198111639432641,0.08902638070189972,0.10889338203927275,0.10799071340358267,0.06207629922387565,0.07172325795504798,0.07585184195686256,0.06480797687681139,0.06198700792257761,0.057718056252096896,0.044546088088639996,0.029883334067643767,0.031041219602086844,0.1332759520385606,0.07885751827419892,0.097549088112457,0.14352167470025048,0.10633539683419377,0.07233115661929994,0.053829640339563264,0.013773194953813229,0.010300876763572789,0.023455136693282145,0.006750856525682871,0.02663370439679463,0.006714363855709764,0.0388868621355047,0.022807525331127763,0.004840352371755841,0.006789101165069014,0.006717561626466337,0.006779261388227163,0.007365619311986731,0.014086974245933467,0.013695987600732741,0.04174731728712419,0.03154159581431531,0.07894166456964948,0.11846746439619854,0.10327053283637462,0.12761705621135497,0.07816074323281388,0.0902074560534998,0.12279885552441575,0.0981220930739857,0.08806632494582223,0.10728020912779303,0.10651695920066978,0.06223855432567863],[0.0,0.014313016975330661,0.01467457769235173,0.014134039290878267,0.011467393081147628,0.013627246315519178,0.014322078275881054,0.01205083439185557,0.014497964025370295,0.013711015106698407,0.014311080408951612,0.03627222079388238,0.014140611557662396,0.015671609448285117,0.013567463477326739,0.004867625772571651,0.010759320534136321,0.016119275149527636,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0052366418185973455,0.002880080108512841,0.0031897293916971006,0.07193358065088971,0.009063380907310712,0.0,0.017880008480232145,0.016043176932559695,0.003709005075134368,0.004375150332648198,0.007450731280249372,0.0021810122148016326,0.010614726917454981,0.009529095253840224,0.006503224757239928,0.0021871323777326365,0.006336194409311514,0.002174526445510495,0.001868371431688059,0.010380834339811108,0.002151961881602502,0.026003451559312236,0.012738144833271917,0.007444671181984199,0.009673115195899857,0.002458765012845332,0.019338555826291456,0.0749454785095878,0.0332634384598251,0.002788369940615305,0.020123896665012388,0.002654670572720531,0.010878618443910503,0.0,0.0,0.0,0.0,0.009853185248821065,0.005938234853179202,0.027607432309234233,0.005355945046707248,0.0073493914698441985,0.03554053207234671,0.0028310535309529483,0.00986308076177467,0.005414057359158,0.004373965053816895,0.00986502140210857,0.00980724790473443,0.008660649585523483,0.009931715627417749,0.008891169021155191,0.004664370478791607,0.01006411152177059,0.0,0.0030680932334459276,0.001747867195086409,0.002855544621983536,0.0,0.0,0.029366507750470075,0.0,0.03020903130798499,0.02987222547300331,0.030254410977162853,0.03038971062511999,0.03038849038426964,0.03034257049561319,0.029668598128566065,0.028923228531774894,0.030348112784470735,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03789818014370874,0.0,0.01307845452820353,0.0,0.0,0.0,0.005979176148333873,0.0,0.0,0.0,0.010392935524465803,0.01055132164830629,0.010307202293579613,0.011313986785393991,0.01653027516673842,0.016457920024415637,0.010390137726850743,0.010342805888604912,0.012340161823041379,0.04371057581923236,0.008111368790092253,0.01139376791075762,0.010403313135777022,0.009656889661489655,0.010045364282881627,0.006677006364404799,0.007275820617853288,0.0067383056049123815,0.006667178539288359,0.004799467769799756,0.0068397519093008514,0.006232152934658787,0.008581014852277512,0.0062004743362853824,0.010660122656209704,0.00656213764933758,0.006947361187559417,0.009943109143887253,0.006677622018519097,0.004637653990987405,0.006215414736425949,0.010277389561500096,0.008716646351227347,0.01018111873323102,0.006941070443122609,0.010224285388442316,0.017037856232726037,0.01663138987237734,0.01332823830435439,0.01353588539176441,0.01513459605828682,0.0,0.01603910219018344,0.015021079974046468,0.00947905208142835,0.0,0.09175346616613808,0.0,0.03255544616451313,0.016895006745353748,0.0,0.0024766973128269774,0.015684128522654165,0.0021462930241511963,0.009609528976749934,0.0,0.0017215872982276916,0.027911702316243125,0.0020202487721500194,0.0025445564898773504,0.04298876940007211,0.0,0.042824718512210466,0.005691456393397197,0.003153043807864707,0.04104905870076891,0.003592484066140175,0.003753914047183717,0.012769831485259057,0.003974303781953325,0.0023532394020213893,0.0,0.0,0.01950663092974435,0.0018781378528538483,0.0024476829106047622,0.0,0.01950663092974435,0.0,0.027008300173679837,0.0,0.0029023542886594277,0.0,0.022162236760353247,0.0091014723013657,0.0,0.0,0.0125071274411889,0.0,0.027757186567344397,0.0,0.0,0.0,0.0,0.0022067478663196994,0.0,0.0,0.0,0.012867160734914554,0.0,0.004869484893982737,0.022995513119280518,0.00814079450198311,0.01683153768107064,0.007580901217115904,0.007407513354369203,0.029027782007118218,0.013822429325620545,0.048880334800725345,0.014692958864864842,0.021759370440329218,0.035652791578318924,0.024659304039794553,0.007832421532018621,0.0027398711046155784,0.042837855354755025,0.007780710262810922,0.0017999553565601054,0.0017681910742511154,0.0017397628262374504,0.009805083638605529,0.009579418472916282,0.010097067912346084,0.009578485819176138,0.004775950893842604,0.009321768879546045,0.009800213945609319,0.014920029620867317,0.0127538095856744,0.00958299235726652,0.00991632733833199,0.009489469262228467,0.009817684321635357,0.009176399290733666,0.034473816656223476,0.028344562244934937,0.0066689709991366395,0.030766779438470296,0.03273534213902108,0.0,0.0280251382200321,0.02795669933443809,0.029609584307208215,0.011495447867292447,0.01782622774567997,0.017946411988277317,0.01779386073067881,0.017795522389574703,0.017790298925190004,0.01793409540533346,0.0,0.0033604208855415995,0.0,0.0,0.0,0.025930141611068092,0.02634239429372301,0.0,0.0,0.0,0.005787128610820245,0.0,0.0,0.0,0.002303971758784099,0.010969032448472369,0.007989853012874979,0.0,0.011566928543761443,0.006546583360001357,0.0,0.001978811850814128,0.013695677456722455,0.0,0.004368023663338877,0.004973003485752286,0.0,0.005646929563266664,0.0,0.01775817677087141,0.009671391342227173,0.012315130556747723,0.0,0.0,0.0,0.0,0.005973495097881425,0.005807699607120316,0.02023165034272305,0.005350008161775684,0.011902159475663547,0.005287937079689196,0.011798644472777514,0.0020813550228302043,0.002367398868916905,0.005884910601377152,0.004084086440809308,0.022456330115006903,0.0051508945357963765,0.026110168448949166,0.027242596627373997,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.037421569473437936,0.0,0.0,0.0,0.0,0.0,0.0,0.06180575120120331,0.06199571334430403,0.061968818663339816,0.062292858951732054,0.062262753179663226,0.06187059829279071,0.062198174206735846,0.06185699025708051,0.06122629275917884,0.07403341358974058,0.06312245844296407,0.05372089808092457,0.05922542786191059,0.052932638738026665,0.06615079318450758,0.0532161229801146,0.053327091811260705,0.0,0.04706564736490476,0.0563477597261182,0.025518278817518118,0.014811181413199039,0.007465065147171561,0.006493138634309629,0.06408701051811105,0.00297822538204592,0.0,0.0,0.0035025813149846363,0.0,0.0030606367775748745,0.0020887616646315553,0.003512409947846624,0.0025438917759778713,0.003492165539145202,0.003000498035576976,0.0,0.0034559281355265796,0.06383036666483607,0.0,0.0029889294064079862,0.0,0.0,0.029495807076732914,0.08104501093429729,0.08334237520811019,0.0,0.03734951692369576,0.004263249642687666,0.007061380588000106,0.0,0.0881005945712416,0.0,0.0,0.00875484757810945,0.0,0.013990965171882856,0.020859468458176045,0.0,0.014680645607693494,0.0,0.008763640035109726,0.008694667556534806,0.014048677183853577,0.008765364351652873,0.008714030884272321,0.0,0.008824624150608933,0.0,0.014981426306837384,0.008942261832815842,0.005278075988766253,0.0,0.008420925298404724,0.0,0.0,0.0,0.059335623496330495,0.007763683030130922,0.06103795940294485,0.060357436394024244,0.05501668494899273,0.05526272305930287,0.05526050409009285,0.055177000231795566,0.05994600322172638,0.05843996885983993,0.055187078707962293,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06633754537248834,0.0,0.042006505189177264,0.0,0.03846502895016761,0.0,0.02880664837275219,0.0,0.0,0.0,0.02402139274861196,0.024387473657874425,0.0238232358750437,0.04184037812758764,0.013447601073797244,0.013388739192807362,0.024014926144909444,0.023905527152359135,0.03963519317492923,0.10621261339628305,0.0,0.04213541757884173,0.024045378722210315,0.0028330616478143516,0.005894058498285875,0.006173077544329071,0.0033633489636968727,0.006229750392070998,0.0030819957237364776,0.0022186205237444802,0.006323540313691279,0.0028808991061367753,0.0030800995407461573,0.0028662552347981773,0.012509528726932083,0.003033439115909334,0.0032115140377801167,0.0029170304480038763,0.00308682336681524,0.0021438198608549975,0.004034465331462732,0.042757792436121426,0.0056580307191004845,0.0033043145394627284,0.002252746538529599,0.0033183244150149205,0.003075630142950714,0.004158833620893628,0.0532417582870083,0.05407123745630509,0.06045754035201784,0.08558299145398682,0.06407073331449839,0.0,0.005163487424063829,0.0,0.012386241451770712,0.0,0.08527883619863921,0.022807381739489697,0.0,0.007954869460985043,0.015624794413976174,0.0,0.03742563914311954,0.0,0.0027647710828779723,0.0,0.0,0.0,0.0330832822861798,0.0,0.03089671681320435,0.018601710335250616,0.027480725979053353,0.024936343895907674,0.0,0.0,0.0442078881624981,0.006382505367127698,0.0,0.0,0.0,0.05759437561657399,0.0030161823513535735,0.0,0.0038328314858144413,0.05759437561657399,0.003578330141972106,0.07681567261573403,0.0022688547911660457,0.006991523361446625,0.005583978501942407,0.07449323646328974,0.005846578319051394,0.0062400683500955095,0.0,0.008034293541748769,0.007440796756845753,0.04832656752365014,0.012645467795330522,0.0,0.015350449840342265,0.015186962335140289,0.0,0.008536893213453885,0.0037148322900337673,0.010773490159842837,0.0,0.0,0.011730172821257078,0.004277526591557386,0.005284241612442974,0.02260502482838173,0.0,0.047859818416063404,0.07160004979046847,0.004961471218819793,0.013274300248192959,0.028151557447984768,0.056496584314142576,0.06557028722860443,0.05527353654225981,0.0,0.0,0.06186383891906655,0.0,0.037578134335884694,0.03691498318419648,0.036321479284837026,0.07252057383370754,0.07085150420480325,0.07468015429855046,0.07084460609083337,0.05752428705532973,0.06894587065307473,0.07248455650397374,0.08316527769414785,0.07782425077984204,0.07087793744631832,0.07334335691612652,0.07018621988746346,0.07261377128083814,0.06787068492420083,0.01204183329112291,0.04483951357635496,0.005354993670650975,0.01622939076644566,0.016371553132228565,0.0,0.03166588098334712,0.03266436919400105,0.03075163191704165,0.012523741822885265,0.004457613936738495,0.004487667123673017,0.004449520263796683,0.004449935777048174,0.004448629601228394,0.004484587247629313,0.0568858242057812,0.00539664442239387,0.006201547763414988,0.07751072734767397,0.05008243112653413,0.0,0.0,0.0,0.005746216735898127,0.0,0.0,0.0,0.0,0.0,0.003700047334812127,0.0,0.025931322647716942,0.0,0.01660749545773239,0.08073915093109865,0.0,0.0,0.007331492480176284,0.0,0.0,0.0,0.0,0.0,0.0,0.004074088543693236,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04260108107514857,0.008492125575655414,0.04291092008196467,0.003342537544420651,0.0,0.0,0.006558810060429599,0.055824464742241946,0.0,0.00942668138786848,0.012294409316363993,0.006054835882469163],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01718885413036791,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.040539327891674956,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.043046469609581944,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"nticks\":36,\"title\":{\"text\":\"Summaries\"}},\"yaxis\":{\"nticks\":36,\"title\":{\"text\":\"Knowledge Base Entries\"}},\"font\":{\"size\":18},\"title\":{\"text\":\"Cosine Similarity between Summaries and Knowledge Base Entries\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('442be82d-9267-4b04-a592-1a534c4596ee');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'similarity_matrix' is already calculated as shown previously\n",
        "kb_entries_labels = [f\"{knowledge_base[i]}\" for i in range(10, 20)]\n",
        "summaries_labels = [f\"Summary {j+1}\" for j in range(10)]\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Create the heatmap\n",
        "fig = go.Figure(data=go.Heatmap(\n",
        "                   z=similarity_matrix[10:20][:10],\n",
        "                   x=summaries_labels,\n",
        "                   y=kb_entries_labels,\n",
        "                   hoverongaps = False,\n",
        "                   colorscale = 'Viridis'))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Cosine Similarity between Summaries and Knowledge Base Entries',\n",
        "    xaxis_nticks=36,\n",
        "    yaxis_nticks=36,\n",
        "    xaxis_title=\"Summaries\",\n",
        "    yaxis_title=\"Knowledge Base Entries\",\n",
        "    font=dict(\n",
        "        size=18  # Adjust the font size here\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "0m-3ALE8w4xg",
        "outputId": "eeba748f-9ed3-412e-a60f-1a7fc9106f18"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"e87cc186-c8a0-4c90-9d14-2061450662b9\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e87cc186-c8a0-4c90-9d14-2061450662b9\")) {                    Plotly.newPlot(                        \"e87cc186-c8a0-4c90-9d14-2061450662b9\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"hoverongaps\":false,\"x\":[\"Summary 1\",\"Summary 2\",\"Summary 3\",\"Summary 4\",\"Summary 5\",\"Summary 6\",\"Summary 7\",\"Summary 8\",\"Summary 9\",\"Summary 10\"],\"y\":[\"Asset\",\"Allocation\",\"Derivatives\",\"Currency\",\"Risk\",\"Credit\",\"Interest\",\"Rate\",\"Inflation\",\"Foreign\"],\"z\":[[0.0,0.00825310195829576,0.008461583333454644,0.00814990071982932,0.008515586639352547,0.007857676229032193,0.008258326841173077,0.006948693283179973,0.008359745223198885,0.007905978580361543,0.008251985304846466,0.004293919398851287,0.008153690388210209,0.006738331985580352,0.00782320454079142,0.006278808544596031,0.011984667161139138,0.0064751291658731456,0.02374234811969284,0.023815321058997106,0.023804989611427737,0.023929467951748672,0.023917902980739043,0.02376725878242397,0.02389309531435436,0.02376203132842855,0.02458883191276843,0.021623451217086528,0.025350342975682894,0.012690954217317786,0.020387376893588258,0.012504736868214267,0.0169059797804005,0.024425030378072695,0.024475962631682672,0.010132210115926877,0.012601223426164718,0.01234340996737463,0.0175684933553008,0.003965503857753149,0.005996026342592795,0.0,0.0,0.014352869661177865,0.0,0.01601797858329164,0.0140665683538465,0.016430475434677946,0.014750032356034188,0.011744022057854206,0.014106040709673483,0.010216415932584183,0.014024737997995255,0.01687024216838065,0.016068434443777677,0.013879206497331287,0.02929673485260693,0.006003228358644615,0.002400742539234622,0.0062387333355733736,0.012686361271894419,0.0033844817300209004,0.005917844238675211,0.005906607889551745,0.0035967516457988745,0.01687475382400065,0.003424291236398649,0.028358911266008393,0.0037674207504867375,0.014897560568577996,0.0,0.0,0.014063988905339575,0.00309601584330395,0.013485245324728577,0.01954699298919658,0.022120158012778408,0.011791663710175575,0.010955429154303056,0.014078113310887395,0.01047548574887303,0.00564202969513834,0.014080883292719261,0.013998420027737027,0.011171475203733211,0.014176079599407062,0.011468824973367443,0.006016627116740232,0.014365055483070032,0.016957645803715397,0.0,0.011272973716639692,0.0,0.006017916438002383,0.0058944771440178146,0.08578630167900672,0.006235879667017168,0.08824750614672172,0.08726361908692908,0.08838007056409355,0.08877531185445532,0.0887717472511801,0.08863760472886108,0.086668776930401,0.0844913814553921,0.08865379502523427,0.0061979228596525686,0.005836786772976426,0.006060561579014731,0.006087978225206979,0.00605570887332633,0.009610703533555023,0.006077215007716738,0.008734039231032236,0.007611868688438952,0.007466825368380217,0.00843502724721698,0.008170910876505105,0.007723888616738518,0.010125784102950886,0.007712610632753998,0.008789656451003906,0.006095520852136571,0.0061815170753844045,0.0578827783282042,0.0587648995416901,0.05740529267585275,0.06301251341024297,0.005400634066383075,0.005376994795858851,0.05786719617638786,0.057603584582281424,0.00795886096388169,0.009479021657463515,0.007097939402022446,0.06345684919807949,0.0579405757593236,0.002275547759542387,0.002367087850123811,0.0024791435065164413,0.0027014806419070033,0.002501903648676694,0.0024754944776716453,0.0017820215687775031,0.0025395702215476614,0.0023139713572751697,0.002473971441645008,0.002302209231081664,0.002511949403700973,0.0024364932507702545,0.0025795250798892446,0.0023429924673870417,0.002479372096219135,0.0017219408144523145,0.01296211616580121,0.003815950173593114,0.00454459546837041,0.00265406351213663,0.0018094319770706998,0.0026653164056092632,0.002470381569836969,0.0033404230845576685,0.019438360788867116,0.019741200437263462,0.02207281501551722,0.017185311216956677,0.023391977843045975,0.007831536261703343,0.004147372595410493,0.0,0.006632514569875879,0.0,0.008058463983775951,0.0109914910870428,0.005014067649206506,0.0031947214056146193,0.017256270501742426,0.002768528972622251,0.005010117432923357,0.005435294799138041,0.0022206959909058847,0.002692783926764837,0.013029714942613185,0.0032822537675094065,0.0037961247907342195,0.0031621108786527075,0.005317842632677452,0.007470554039953915,0.01931373128446287,0.006676386248929421,0.0023169940238533396,0.002421109252887747,0.024411946046485996,0.0076897527801624566,0.0030354715738728157,0.002807212460696975,0.00472251305045833,0.028637431412415402,0.004845264837275203,0.006314590764214563,0.009235723239884933,0.028637431412415402,0.01149662400569294,0.03645863789177375,0.005467110933588014,0.009359453539837373,0.004485115874280669,0.0368208159245183,0.009392078146390061,0.012530237000318958,0.013923142496652333,0.009679855722096686,0.011953067383700042,0.025877637252653282,0.006771323627268371,0.010773781303768756,0.004109886062557908,0.01707768039558975,0.008539531183904235,0.011428218325990443,0.005967592199190994,0.011537855245564735,0.008298752055089585,0.005370276890956326,0.006281206647479605,0.02576818984677959,0.016977455003638127,0.015562814064920506,0.015809809382764568,0.025627705078425968,0.012107365264194174,0.027895775961354834,0.014216094550370727,0.050441384942805284,0.03403403062823217,0.02478438128807319,0.01479878048044576,0.012250762265616066,0.028273539350028295,0.015528046327280916,0.01622650692767627,0.006965351652345801,0.006842432272451105,0.008976563285126245,0.007281170065401421,0.0071135930706727885,0.007497995054548589,0.007112900490094753,0.0092408340375519,0.00692226471736595,0.0072775538736198336,0.010547259365962377,0.007354039406833647,0.007116247006193105,0.007363778671943407,0.007046797566992645,0.0072905272233270485,0.006814314521580479,0.009672139251730565,0.008575146183060298,0.008602385238608826,0.02607126733427395,0.019724730176104394,0.0,0.019075800357498944,0.017490931808377224,0.018525048819114633,0.0033530712457480708,0.05191589971573609,0.05226591617323409,0.05182163621092335,0.051826475513878055,0.05181126304957918,0.05223004619030354,0.015892643294017145,0.0043346469830260505,0.0049811546210514444,0.013106844068376356,0.008468797001430533,0.00850891717249528,0.008644196955516303,0.0,0.00461542749318768,0.0,0.0,0.009246983719668237,0.009471173699442307,0.010442479610970702,0.0,0.0,0.0,0.0075014653975092865,0.026678663423796937,0.020479142004182924,0.01661807296682645,0.020419944075487976,0.0,0.0,0.0056343658246924295,0.0,0.0,0.0,0.0,0.0,0.0,0.005295144599600248,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.008147066474165326,0.0034104865565391996,0.019148080806608965,0.0026847646701442856,0.012214944156456216,0.003795508189672229,0.0026340559072883006,0.013587531308983564,0.0033221001505406122,0.03217938121702716,0.03357503816675867,0.00486331394778474],[0.0,0.007217617513009285,0.00739994154488078,0.007127364530569039,0.00744716926706072,0.00687180430446672,0.007222186850253548,0.012153735792103604,0.007310880664282436,0.006914046348565522,0.00721664096170381,0.0,0.007130678724070176,0.0,0.006841657644216205,0.0,0.013974663753002957,0.0,0.022651078362084104,0.022720697245530663,0.02271084066237774,0.02282959760363634,0.022818564193491996,0.022674844055802758,0.022794896762097804,0.022669856871321784,0.01954887934421366,0.01891044130858812,0.02015430411351588,0.022197339589059607,0.02377260319898259,0.021871632816767825,0.016896974371117403,0.01424034485485057,0.014270039510063443,0.0059073075430905305,0.0264484732200673,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01601311752346793,0.010500053520457091,0.008398123024756279,0.010911967696356321,0.01109465310801708,0.011839376142690039,0.006900473936088123,0.006887371844999523,0.012581925099116832,0.006558908629791141,0.011978635195525307,0.04464149311954376,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.005527093784003828,0.008839036930648326,0.0,0.0,0.0,0.0,0.0,0.0,0.006513222582576208,0.0,0.006686584220066868,0.0,0.0,0.0,0.0,0.023660634636157123,0.0,0.0,0.0,0.09169481408375268,0.0,0.09432553346053235,0.09327388139882359,0.09446722822259952,0.09488969166872817,0.09488588155419699,0.09474249999555617,0.09263806962136625,0.09031070651839891,0.09475980539498294,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0809927237878545,0.08222703564804483,0.08032459995775286,0.07347543951784112,0.0,0.0,0.08097092039564473,0.08060206075128423,0.0,0.0,0.0,0.07399355513548427,0.0810735970891974,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0027438533978875385,0.0,0.008763035161525594,0.0,0.0,0.0,0.03190579709989206,0.0,0.0,0.0,0.015502112341513661,0.0,0.004825860830949227,0.0,0.0,0.0,0.003881649925569629,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0032740637943252287,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.003768814829253402,0.0,0.0,0.004978739722130173,0.0,0.0,0.0,0.0,0.0,0.0,0.030046874376281143,0.029694720162136257,0.0,0.027652428784956697,0.02241229708865492,0.02117660293277006,0.02788091655166284,0.02486491346207469,0.057802850274446003,0.0330710153644727,0.021674781838129105,0.017256047113207943,0.042854828026034734,0.024726168875497657,0.02172768487406313,0.02838126105020202,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08141086772498123,0.08195973895092473,0.08126305031714236,0.08127063897215718,0.08124678385406064,0.08190349016294944,0.017373319320805162,0.0,0.0,0.02292475914298039,0.01851562535532627,0.0,0.0,0.0,0.0,0.0,0.0,0.010782401085853228,0.011043816738203927,0.012176403345108342,0.005198090769316137,0.014848626360461338,0.0,0.0,0.023331395798124772,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0056999087093046385,0.011930344552991856,0.0066982583793905506,0.009391670961759647,0.010682382855509294,0.013277202447747456,0.009214284831452847,0.004753102745117804,0.011621156916599644,0.0,0.0,0.0],[0.0,0.00666585312352183,0.006834239050755176,0.013164999401239734,0.013755712721201001,0.006346476258210845,0.006670073149158711,0.011224620526957626,0.0,0.006385489029543272,0.006664951226523528,0.0,0.006585560534345358,0.021769623853130256,0.025274536865144036,0.0,0.012906344214031812,0.020919290804184216,0.020919473937055913,0.020983770673595623,0.020974667595539915,0.0210843459383451,0.02107415599805785,0.020941422817475474,0.021052297868113953,0.020936816887722316,0.021665314051863147,0.026197195411815016,0.02233628436840929,0.02460050649681758,0.0219552616916262,0.024239537492596438,0.023407879924386695,0.0197275722341145,0.01976870912101226,0.016367136814913995,0.0,0.006646338011388961,0.023649491003458416,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0751997378828303,0.06750861052967322,0.05420225303520536,0.0,0.0,0.0,0.07007519376615941,0.07354273241595993,0.0,0.05324027234297926,0.08727621405165437,0.0,0.08566114475892933,0.0,0.0,0.0,0.0,0.0,0.06057500483779282,0.0,0.045809766605921315,0.0,0.04211353852496948,0.0,0.0,0.030291151083979565,0.05001170949746101,0.03993639063868963,0.04961844248692352,0.05615021137856447,0.029932173606030336,0.0,0.030321572360994222,0.0,0.0,0.03032753837381844,0.030149928221018422,0.0,0.03053257307115258,0.0,0.0,0.034807039987602414,0.0,0.0,0.010925926388428023,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.012476837756710065,0.0,0.012458619786024588,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.012856401988937,0.015312004248250416,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.017271606385735293,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.016689295173433528,0.020938445439755808,0.0,0.0,0.0,0.017537271959714378,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03349743733837821,0.0,0.0214277580409491,0.0,0.0455605374947935,0.0,0.0,0.0,0.005068188695183108,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.021350619730025278,0.003913416302506314,0.0,0.0,0.021350619730025278,0.027856728570258393,0.036242287342594555,0.0,0.02721394628851959,0.0,0.03345680461619127,0.037928898591605004,0.03238529023161809,0.0299877947692173,0.04690926889775366,0.05309829634585823,0.04478745341923287,0.0,0.0,0.0,0.0275865510404906,0.045981305698376544,0.04430556668338469,0.0,0.051253827771442696,0.040216342355117465,0.0,0.0355123695472481,0.03329986124405105,0.0,0.0,0.0,0.0241487712067271,0.0,0.0,0.0,0.022477474660528782,0.021379987435961763,0.0,0.03984219007930583,0.03298225819674842,0.05138084304167777,0.02508333875818764,0.0,0.02250305948131282,0.022105942113054052,0.021750531878200453,0.05292760155120497,0.0517094665088316,0.05450372551601349,0.05170443206676431,0.044781738607684904,0.05031868030849386,0.052901315067572605,0.051112768613157854,0.05345729656367972,0.05172875824910139,0.05352809232019972,0.051223922870592214,0.052995619729861804,0.049533978825272426,0.0,0.055407690594737095,0.0,0.0,0.0,0.0,0.046221342244136265,0.04709016602377165,0.04488685169222931,0.0,0.03180999475501128,0.03202445740976913,0.031752237466587105,0.031755202612187006,0.03174588160624841,0.032002479095319586,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02154778322302794,0.03859464694600447,0.023488605831726492,0.024739125122690272,0.01902483262044721,0.0,0.0,0.0,0.0,0.0,0.0,0.010572042845876543,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.024202639106633013,0.021078024213588176,0.0,0.06580210541294365,0.0,0.05258267772010356,0.0,0.0,0.0,0.0,0.04609229979144655,0.0,0.055038906624355406,0.05742600760736809,0.0],[0.0,0.021702423028625333,0.022250647322975617,0.021431044225165206,0.016794491136606055,0.020662608363031076,0.016287121816873706,0.022840424407964008,0.01648713975928417,0.015592218459792978,0.016274615000826817,0.0,0.01608075717562517,0.0,0.030857942003198798,0.0,0.015757488390584776,0.0,0.00851360029439154,0.008539767143365847,0.008536062462825211,0.008580698268410196,0.008576551267443996,0.008522532832339854,0.008567655662225379,0.008520658356670895,0.008817134916729443,0.010661475104074693,0.009090199770160415,0.010011670464738387,0.005956756623475524,0.009864766874817816,0.006350871410213758,0.008028531945178746,0.008045273427945325,0.00444062348237707,0.006627255615034772,0.0054097216230811285,0.003849854239644219,0.005213860356838235,0.007883599453592665,0.013714362347913317,0.012305471885433438,0.018871210523971678,0.0,0.004212100480942564,0.011096868250951176,0.007200951639086305,0.006464467208695981,0.02867630488325737,0.0037093357659616294,0.016119101510611737,0.011063869019291041,0.009506169420132814,0.00704228065739716,0.010949061779272929,0.012037332605773506,0.019732671732866986,0.01262602362907069,0.008202711580177722,0.01251005896364249,0.0,0.0025936017700622905,0.0025886772377832555,0.01418707041433734,0.004930443094042547,0.004502271834339719,0.007457282026032948,0.0049534198939405775,0.014690529233172,0.0052891788958436365,0.005454268050353416,0.0,0.024423924195133753,0.023640606094607164,0.029371959636354538,0.024928862024719136,0.019933362874467953,0.02400707022727696,0.0,0.022955351040653268,0.0,0.0,0.0,0.024480500579291815,0.0,0.025132095026312612,0.0,0.0,0.011147990315080882,0.0,0.014821750998918292,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.023935194475473227,0.02489805269771042,0.013038351252405858,0.01420767027732558,0.01315805175673731,0.01301916022143748,0.07497629110057431,0.016695185500382497,0.015212094048235314,0.02927508805341633,0.015134769595060786,0.013210884552522586,0.01601755543000879,0.01695784953935824,0.024644607051778775,0.013039553455032923,0.07697649913496071,0.08095255072214262,0.0,0.0,0.02442701336018976,0.07375050075696592,0.024530580806085407,0.022736473085602525,0.0,0.005111526925933556,0.005191161882493512,0.005804285119946184,0.02259531602745336,0.006151173233910287,0.0,0.01090596420324761,0.014752811652505533,0.008720456724412675,0.0,0.015892951088625675,0.0,0.013185032460170288,0.0504051900148124,0.01443820864139315,0.0,0.0,0.007146347374129563,0.02043845989017364,0.04602628021453725,0.017131521399826766,0.0,0.004991160081038071,0.0,0.0186451221205005,0.0,0.0,0.0,0.03960310930903563,0.00636656828792396,0.0,0.0,0.0,0.0,0.0062091790757674336,0.01737812747738401,0.006370573616782503,0.0,0.004047721970481159,0.01737812747738401,0.01889475911855504,0.011062145340666713,0.0023960597850502144,0.014767016406538599,0.005897048317584447,0.04236063673723206,0.015435927461036331,0.013179844640427025,0.015255169605575386,0.021211855130203464,0.01571594087662826,0.017012010559068803,0.008902963429101358,0.005666164325941919,0.00540369465806899,0.009623058253878047,0.011227809807495532,0.015025867233157774,0.0039231070639745005,0.015170018294187923,0.0,0.0,0.07845627877767475,0.011293373076826712,0.0,0.0,0.0,0.002807950774525612,0.003979703086993684,0.005239639710917119,0.004672844515100204,0.011434574995937235,0.012430022166807617,0.004073325474579964,0.0259433278071136,0.01073823419990084,0.0,0.00408326750239653,0.0,0.009158072253693455,0.008996457360628336,0.008851816023605059,0.0,0.0,0.0,0.0,0.016199847478251185,0.0,0.0,0.018490105151527252,0.019338240940530167,0.0,0.0,0.0,0.0,0.0,0.0,0.011274636551049334,0.00565522528519817,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.004707533303887323,0.004739271444603415,0.004698985853285931,0.004699424662590049,0.00469804525507302,0.004736018893069491,0.00783589164911914,0.0056992112166279075,0.0,0.008616465541668604,0.008351106165778787,0.0,0.0,0.0,0.006068382556114136,0.0,0.0,0.020263285392281328,0.02075456186469354,0.004576604674021639,0.003907493179486047,0.014882619742035955,0.010954072444173308,0.014794435130027097,0.008769303384159254,0.008975352646878095,0.02458069751698803,0.0,0.0,0.0,0.01481617351189914,0.0,0.0,0.0,0.0,0.0,0.016402499536642284,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.017138873016048665,0.013452364157888851,0.005035194669243381,0.014119757370793653,0.012045193129838158,0.014971048114475518,0.017316336290853447,0.014291952474225579,0.013103731755916694,0.00248879878385086,0.0025967408631512173,0.012788609319159943],[0.018706225559156957,0.07484637573657936,0.06865948182074001,0.09725060037307044,0.07316224798389431,0.07876139304606578,0.06701020592439827,0.06965020533818853,0.06384295621713737,0.06415116074876188,0.0590812491651712,0.07788206333400861,0.06616115860584429,0.07719045660712023,0.09708631051731378,0.02996934179106499,0.0724583238280744,0.0710847165972014,0.01854400144986781,0.01860099708843892,0.018592927693712683,0.01869015171350009,0.01868111887318922,0.018563457965435456,0.018661742803093448,0.01855937505358607,0.014937338156723653,0.01806188295666078,0.015399944444699972,0.014538027406651239,0.017299708645394648,0.014324707519233575,0.018444303164590437,0.02525964127312821,0.0253123138977066,0.07415504938392861,0.019246982629242272,0.09819375484803569,0.0838560657455019,0.007571088663888356,0.03434351499773993,0.0049786840363187975,0.01786887494472506,0.03425379620219982,0.016162340553614787,0.055047825637557876,0.04297027163209885,0.09410903943208061,0.08917749709342075,0.1361343442655335,0.040397672807914606,0.06436836250078005,0.04016483352917064,0.13343852421759303,0.09203537272510558,0.03974805223184772,0.15906352038581512,0.14326985864609593,0.08479637206285054,0.10422320671540493,0.04541489372648113,0.07754135316509457,0.10357022617428668,0.10337357496598264,0.04120231868001595,0.1467704915130721,0.05230228186223878,0.0839230400290961,0.057543207742118865,0.028442981267015634,0.049922985590899124,0.055441306298461494,0.053702989980496135,0.07093235451115204,0.07509406346280191,0.06131118541068867,0.054299102323899395,0.07879580281956187,0.05229129037159237,0.05375692366991529,0.053333840538793684,0.02423694298292005,0.053767500776279925,0.053452616860848325,0.049767665190867845,0.05413100549308856,0.043793421395474603,0.02584613273191007,0.057138130395543656,0.03237617324712124,0.05289158808771089,0.09254797177771473,0.04219492464260626,0.0,0.0,0.022748114442316423,0.0,0.023400756645112562,0.023139857468945438,0.02343590900018945,0.02354071587412511,0.023539770641591955,0.023504199817467705,0.02298212205913086,0.022404738018995635,0.023508493028709405,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.007266432565104106,0.0071279714923551275,0.008052235158734435,0.007800104719328304,0.022120106666770094,0.0,0.02945041085584213,0.0,0.0,0.0,0.022102394175116672,0.022439229954839383,0.021920067472666522,0.024061170689855936,0.015466639609185626,0.015398940136618494,0.022096444169407054,0.02199578474132925,0.022793033691026306,0.03619540718653447,0.02710330413047041,0.024230839199428644,0.022124463979673506,0.015205963888935222,0.018077331538549568,0.018933094982763698,0.023209956638045263,0.02149527718153913,0.01890522753195588,0.025517268010843072,0.019394570783650297,0.017671683538903228,0.018893596181984124,0.01758185676936143,0.019183631979011358,0.01860737711247535,0.019699704038750567,0.017893316305545845,0.018934840710891906,0.023013157806638308,0.0247477582378412,0.04371333097271002,0.021691780204214004,0.027869806687691578,0.029364400736766032,0.027987971141678968,0.02122445307432117,0.02869947455576764,0.022267468391250014,0.022614384078818953,0.02528534766910167,0.019686504354654466,0.026796504750913427,0.048594853769118984,0.059387394581602235,0.005355669188390871,0.09180708004303233,0.022209831126833543,0.03077104322903757,0.07344878430006554,0.004786522986814836,0.036596891420554487,0.05690727778639398,0.037000455302797795,0.05739302443545882,0.031131805930428372,0.044518278604895746,0.03341756630633553,0.04477827664323541,0.021933106898668866,0.048922000634818684,0.03320471364385374,0.05245729357571822,0.04278918571289003,0.050043964279712916,0.044613824422749235,0.04644876466756002,0.04160225315242455,0.057200976154247504,0.034256983503466204,0.03477261691863586,0.024118358827314543,0.0293032967531539,0.10304258604315226,0.04162842591891288,0.036168160415655584,0.038205243117621066,0.10304258604315226,0.041155848098742516,0.14457087399635754,0.020876026400822093,0.04646049111476247,0.06422363557710459,0.13620563478935488,0.04482926945428395,0.04545407684690344,0.03765866313919847,0.0646840023212281,0.0656110778388614,0.13939706703194704,0.04201621118701414,0.039082443795817344,0.0549272400834702,0.08384232289111974,0.0543466438402871,0.04363836592779,0.03702904009925996,0.06883908088099076,0.03961072152651284,0.028196118541609576,0.059961576321877506,0.07051655184772976,0.05672448900023519,0.08913932456382694,0.0490501064797465,0.07747151124747943,0.0837949046481254,0.05325966150264936,0.050891063983887715,0.0863420404568,0.08844370352157438,0.10351090339008953,0.09653582094720033,0.07796538232407622,0.0607285142209075,0.09190485779050707,0.05034291516914474,0.06427613438189003,0.06314183665011806,0.062126668200018206,0.048655190214928895,0.047535385227415766,0.05010408661420888,0.047530757174580746,0.05292884057328136,0.049560927636865246,0.04863102562360547,0.06041166924949612,0.06318273508952311,0.04755311970366056,0.04920720828737985,0.04708903554627009,0.04871771784368266,0.04878804303043185,0.07386564378310116,0.14571071673131467,0.020529995587790856,0.1037005025339769,0.10042451864308623,0.02581793698825518,0.12747081671755325,0.1280116477235618,0.12379051250537908,0.17925066196852973,0.12304524721945716,0.1238748170001898,0.12282183442459155,0.12283330399810741,0.12279724912010814,0.12378980198664646,0.04741067268763574,0.02482761168242139,0.01902041437220324,0.028152087948508438,0.05052795249535423,0.06498217493415356,0.06601529987204133,0.013891522353865109,0.026435841718588843,0.023297966670864558,0.02900564211298003,0.06473385622534619,0.06027573325843338,0.059811520937696,0.0,0.0027013965158777984,0.007953248459821137,0.0787714346499138,0.07640385690989364,0.0130331819474327,0.08130261063738409,0.07309973050692516,0.07307951149347924,0.035958826364768916,0.032272027530720115,0.06123627746096376,0.014100018386992437,0.0486743800945646,0.014023798826459084,0.05935317479119821,0.047636403663336296,0.04043875450863694,0.014179897157411716,0.014030477775462598,0.014159345537944441,0.015384028283743474,0.04413364329306178,0.05006015658330577,0.062281826135336824,0.052702892350916075,0.19287809166372702,0.08139286025429496,0.15902831742884793,0.09482828756111872,0.04372730516269799,0.050725685919174174,0.08046461296252269,0.14786839840200725,0.06025544270708475,0.04517505976737312,0.047134354313581164,0.02785566406171574],[0.0,0.010305863806683397,0.010566199940839337,0.010176993726840618,0.005316817639152394,0.009812085378640048,0.010312388254292502,0.008677014651307694,0.010439032034768467,0.009872401785350917,0.010304469412378585,0.04289543373635988,0.010181725984651474,0.004207165504468678,0.019538079363767436,0.0,0.004988522220907908,0.0040428313894205195,0.02964768973034072,0.02973881294411457,0.0297259117959022,0.029881351148125398,0.029866909667000393,0.02967879632501731,0.02983593168654964,0.02967226866678593,0.030704716134483584,0.037127430819319324,0.03165563487283634,0.02535604118818654,0.028286944001656263,0.024983986046156273,0.03317433140677515,0.027958491809580537,0.028016792207711316,0.0,0.047206429685666566,0.041102768446460075,0.025594608852584324,0.019807312639244637,0.0,0.0,0.046748150530832776,0.0,0.0,0.004000413579571564,0.0035130582031990356,0.006839054493873974,0.012279166901818798,0.012570057293006049,0.007045832470749994,0.005103002082159412,0.007005222543578178,0.009028419291055797,0.010032536723827711,0.006932530950380665,0.03887007224110962,0.007496387925078604,0.008993609591625248,0.007790469136032782,0.0,0.042262906652623285,0.022169299638295024,0.022127206271097113,0.0,0.03980256372458166,0.008552003669667815,0.014165005046110124,0.0,0.05580891804587096,0.0,0.0,0.014635058326104617,0.003866075784069591,0.03648531851907163,0.013947908735739247,0.0,0.033656133066187255,0.0,0.014649756254295914,0.013081012446262261,0.01761337431828061,0.01465263871146681,0.014566827018859614,0.0,0.014751700471980341,0.0,0.01878279825999121,0.029896699473737638,0.0,0.0,0.030969084266202537,0.0,0.0,0.0,0.017853932296212315,0.0,0.018366160671531965,0.01816139309665286,0.006131250037603374,0.006158669377290771,0.006158422087671905,0.006149116128310668,0.018037593942455445,0.017584432183153247,0.00615023930862285,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.009505139087559348,0.0,0.031599115988662496,0.0,0.03858008518219582,0.0,0.019261876365224112,0.0,0.0,0.0,0.01445594718730701,0.014676252743523579,0.01433669742818261,0.015737074002097364,0.020231738117060156,0.020143181194919948,0.014452055619379078,0.014386219883907694,0.0795074991823134,0.07102021037621634,0.0,0.015848044741027245,0.014470381819436908,0.0056830717502222745,0.00295584437525457,0.003095771197846428,0.0033734093814144907,0.0031241923813613774,0.003091214560294734,0.0022252568405426087,0.0031712276139362655,0.0028895164243879835,0.003089312705459726,0.0028748287504394695,0.006273473555673256,0.003042512710399947,0.0032211202882985136,0.0029257558419843073,0.0030960566437739684,0.0021502324346153543,0.0,0.028590459427883772,0.0,0.00331419837396703,0.0022594849327414843,0.003328250155726918,0.003084829938843725,0.0,0.02912782610866085,0.029581622635698707,0.02756290017129639,0.0343355945965309,0.029210173221847442,0.014669165578844416,0.0,0.0,0.016564388080599693,0.0,0.04528266429687182,0.027450723557722503,0.0,0.0,0.015671531151749504,0.0,0.02815318977161557,0.0,0.0,0.0,0.003254109020269707,0.0,0.02607176054081854,0.0,0.019921586645125694,0.015547792996556292,0.03100829182601773,0.02778992583635736,0.0,0.0,0.030483834136848555,0.0,0.0,0.0,0.0,0.013753964611914152,0.0,0.0,0.0,0.013753964611914152,0.0,0.021012393526801457,0.0,0.0,0.0,0.020115862288855015,0.0,0.0,0.0,0.0,0.0,0.032314080997936985,0.0,0.0,0.0,0.009139433660235822,0.007109023637331154,0.0,0.0,0.0,0.0,0.0,0.011765260003632582,0.04075805414339587,0.005300047786145379,0.04858423021194787,0.0,0.0186678240986952,0.02267817447931793,0.0,0.0,0.015203872988375831,0.03069385386416476,0.007737225935729841,0.024639497877227634,0.020397128752394012,0.0,0.0077561106813648605,0.0,0.023194177044370733,0.022784863343963135,0.022418537693114575,0.04091484188845532,0.03997318193794206,0.04213323949059034,0.03996929014244892,0.011539270632110287,0.03889805675146611,0.03635068581307811,0.013170638035086153,0.013774771402096068,0.039988095111404644,0.04137904174162886,0.039597840138837666,0.0409674222613368,0.038291455730927126,0.020129754515596995,0.025699221203835294,0.0,0.03798185058996914,0.035577801063222295,0.0,0.03970074958508133,0.03640230505249229,0.03855451988571261,0.06280601360689168,0.024590211302409733,0.024755998252001747,0.024545562947779594,0.024547855106499063,0.024540649650875872,0.024739008265032326,0.024806948063889316,0.0,0.0,0.03273371650724546,0.021150415672609602,0.05312653470489418,0.053971171683000904,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.007067333078236259,0.036412443445832623,0.0,0.016657171641604962,0.05540781802832734,0.0,0.0,0.02206026711413121,0.0,0.0,0.01602049779601848,0.0,0.0,0.0,0.012258824756829536,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00935473291164741,0.016294031899134094,0.0,0.03255505449699581,0.012776290712447076,0.038257133174790924,0.0033525357112170963,0.0038132798891495814,0.004739550132492339,0.0065784287112596665,0.028844078425294323,0.008296786317832872,0.016546037179666597,0.017263657932675314,0.0],[0.004613471206717594,0.003886143323004939,0.00398431107958163,0.0038375488907758464,0.004009739650280964,0.007399897921070562,0.003888603566899874,0.006543871175345394,0.003936358504392606,0.0037226931191622456,0.003885617523691177,0.06470017711425664,0.003839333334315889,0.009518647892492918,0.011051151764872818,0.0059130130768545175,0.003762151855309995,0.012195792612623246,0.03048974844434984,0.03058345975510206,0.03057019218628924,0.030730046353367492,0.030715194702845304,0.030521738533806252,0.03068333688053779,0.030515025475918243,0.0294716769123164,0.0356364683815619,0.030384408679770377,0.02390319045779732,0.04479914606028891,0.023552453335438654,0.034116554396039424,0.028752573637640038,0.02881252989357029,0.012722560442772217,0.026107602489057434,0.046497193874707285,0.03308995017531913,0.06722061486857461,0.005646705409329607,0.01964609300899413,0.04406957448108614,0.013516689574804277,0.005314771993346038,0.01810174962113731,0.010597654256471831,0.007736628327981478,0.01852095209588182,0.017379733081684622,0.015941088680092808,0.013469708593667353,0.013207674448519098,0.01588740313434025,0.012610256430525536,0.01568474571546871,0.05345551654952001,0.0226139513800342,0.015826148144955098,0.008812908898457341,0.008960452397012698,0.04780959138787459,0.05573078096192538,0.05562496362599093,0.00677441886139724,0.06003512957601941,0.01612398173632021,0.034718783915980864,0.01064380670572321,0.04208894243051082,0.011365278737669142,0.011720018914645232,0.06401575346291662,0.011662583458360794,0.08043087560767946,0.02366769835019151,0.011903694572683546,0.0761464885894435,0.013756239556563835,0.06408004421779742,0.016441995265911974,0.05578998768145426,0.06409265248101768,0.06811159693843204,0.014027518861952172,0.06897602857527871,0.018001109489167815,0.05666106008354395,0.06989552157474808,0.003992428686025795,0.011181021050919901,0.04671138772962732,0.013875243069402734,0.011334640430771495,0.005551072339002155,0.02244124997955455,0.011745170363093482,0.023085088257109122,0.022827708523651527,0.018495813134929474,0.018578527586310664,0.018577781600980964,0.01854970881250699,0.02267210091180957,0.022102505589448408,0.01855309705031226,0.005836839689912712,0.005496742936225586,0.005707480904261561,0.011466600582442348,0.005702910911086926,0.009050796065535872,0.00572316412520866,0.008225205119736092,0.021505232453429484,0.007031817538666789,0.04766167918212305,0.007694883912994991,0.050917332244467615,0.009535868690515452,0.04357970198095511,0.008277582150609858,0.005740403494217688,0.0058213896859470385,0.01817020021916506,0.018447110200502315,0.01802031090570104,0.027692692459903277,0.025429999681479135,0.025318689299306914,0.018165308767397782,0.018082557462374933,0.04497112656521736,0.05356071485690612,0.006684422403515086,0.027887968820986903,0.01818834362772154,0.01071488608357211,0.013375105782346542,0.011673558661099318,0.010176383145948072,0.01178072948600086,0.009325101164775423,0.013425625915588251,0.009566472252144638,0.013074973824590656,0.013979045911952781,0.008672341698176054,0.01182803199602608,0.00917818490635262,0.0097169808068678,0.013238956085598464,0.009339708018298993,0.012972981712830537,0.009155219718164832,0.05749820365903976,0.008559666134944058,0.01249720559450186,0.01363213401536981,0.012550192164950326,0.01628522178445297,0.012583256992740176,0.051256537927265415,0.05205508838594386,0.058203265815106285,0.038841879977934826,0.061681733996445505,0.051626965846916284,0.01171725569448532,0.021133692002340557,0.05309195739879549,0.004382045585227062,0.04173943418937571,0.05520608361300326,0.01888781756437441,0.009025802895948155,0.032501883887624324,0.007821713898023889,0.03774587447543663,0.005118641378470372,0.0062739631288389885,0.012679528655008994,0.02454124036308402,0.012364135208767899,0.03753715715016852,0.002977890286530526,0.03672556673215061,0.05393752219944841,0.04677052540101332,0.05868266511809238,0.006546026621800759,0.006840175443065589,0.048069449788110355,0.033794868242648,0.005717257655890165,0.007931003408551036,0.008894770791190873,0.051863559177614905,0.01368895745433577,0.00892006600422336,0.011596882201194189,0.051863559177614905,0.016240267783889477,0.07395145396235965,0.00858100657508319,0.010577020295527682,0.01689527471810222,0.06284967294109452,0.011056134397154372,0.011800241194285254,0.008741331848643051,0.015193199224632322,0.014070870939593388,0.06092509685007493,0.015942087129775625,0.00608766863495317,0.019352246417198706,0.04365319559550431,0.013403381443573281,0.015067394633468423,0.011239855606529448,0.019014930110911557,0.0052101848171552155,0.005057411331626678,0.014788178673220721,0.04206274384346802,0.01598836988501936,0.07816610209823473,0.0037221874563814535,0.04826933459817841,0.054159525803106276,0.0037529433189418117,0.006693941404734346,0.040950632298752496,0.046296251333792775,0.06418630484547981,0.044132636941554684,0.05383955875753813,0.006656589650657771,0.04094552540492254,0.0038202927742397555,0.02623823619572449,0.025775203188392715,0.025360800084840922,0.03771338053732557,0.04354456670960731,0.038836442250245164,0.043540327203512086,0.03190907389976404,0.03585440267445969,0.0411214365750303,0.03642022756612911,0.027702409380032163,0.0435608122934015,0.03814125817047962,0.04313569017745184,0.037761846656702985,0.041712587481074904,0.05465191569747439,0.043608072493957435,0.0040506105614426646,0.04705874400644956,0.059854686204834,0.0,0.053893404854223545,0.05765176262527011,0.05233740850932765,0.0884163152167347,0.026974535099746615,0.02715639713565403,0.026925557537321253,0.026928071949054937,0.02692016783577884,0.0271377597602279,0.03180436061733376,0.004082115916122438,0.004690958834452963,0.03394395361968614,0.025920100595804584,0.045408124201120593,0.04341651702343258,0.0,0.004346538507848145,0.0,0.004769060948805659,0.008708266109327114,0.011892526751467432,0.013112151890154316,0.00839634091130822,0.01332477789762214,0.07453663705820086,0.0035322197416912875,0.034546047437823885,0.07714421206724992,0.003912481248115897,0.0024037879855987624,0.055456687155578735,0.03547375381240626,0.0,0.03624613232371924,0.0,0.034298413550834086,0.0,0.04622567391754809,0.0,0.014959968458452,0.0,0.0,0.0,0.0,0.036281912659894486,0.035274901284371246,0.036864999066988764,0.03249496746454367,0.05370700058826116,0.02569436728515542,0.06672038973433812,0.015170121996954323,0.011503316913897119,0.014297546675893585,0.014883594791276152,0.0499041615924444,0.0125142351407887,0.051696169434873714,0.05021840983325565,0.0045799834102045085],[0.013434348958377517,0.00377212754881099,0.0038674151561402972,0.003724958831320547,0.0038920976765954808,0.0035913959530545036,0.0037745156114740263,0.009527820264733635,0.0038208694642106744,0.0036134728195517897,0.003771617175952416,0.019625604698243107,0.0037266909209727347,0.009239379754769423,0.010726921411157372,0.01147906171738186,0.0036517738736542146,0.008878484683258405,0.011838083210406893,0.011874467974173176,0.011869316649822544,0.011931382328549171,0.011925615961699196,0.011850503822586903,0.011913246704141461,0.011847897381342577,0.012260145321878423,0.014824683455113735,0.010533199582366133,0.01160094671451965,0.012424223266500924,0.011430723301269829,0.01324624276680548,0.009303000095725903,0.009322399161064816,0.009261969402961666,0.009215138215861587,0.030088673418863513,0.01338296762266052,0.03262421276291174,0.021924145626293644,0.019069695198072747,0.017110645917808476,0.006560061335362735,0.015476524810398152,0.014642217822006831,0.015430093636909578,0.020025714562563218,0.015730369249461983,0.01840344886930535,0.007736696098192345,0.011206731486168206,0.007692104253807404,0.024233442724593813,0.019584453469873572,0.005074856697399222,0.03180182134149424,0.02195047940798525,0.01536182390797355,0.02281159060311559,0.011596748250463538,0.012375174170169203,0.02704784624627219,0.025196723877401895,0.013151327622421211,0.03085081177989506,0.009390551605863367,0.01814624408784607,0.006887684980839745,0.017022538590574246,0.007354554796866932,0.007584109753717553,0.0449961871122587,0.005660207138162489,0.047253566393393155,0.025525900486024048,0.020220289982042998,0.05697415904373354,0.010014483361726743,0.04504137659577982,0.025535364249822386,0.02062977605441895,0.04505023884827754,0.04478640669326072,0.010211973531843473,0.04535480897108914,0.010483784364506808,0.01924953733622107,0.04595941654567099,0.015501178398717563,0.014470640606704135,0.02679236166327047,0.013468156544486841,0.011002092787385773,0.010776418240386176,0.021782844903459622,0.017100867238928254,0.022407793574129,0.02215796511892671,0.022441454311179224,0.022541813920567776,0.022540908797036782,0.022506847347814184,0.02200692288742716,0.02145403895377671,0.02251095838544998,0.01133118465393519,0.010670947381547405,0.011080057611786816,0.016695272029286893,0.01107118578400328,0.017570508516952393,0.011110503791904999,0.01596777074232384,0.027832385663168504,0.013651021308862608,0.05397388562624319,0.014938246575356182,0.0423629706973789,0.018512190621689944,0.04230111469080387,0.016069451418851792,0.011143970956318684,0.011301191223047988,0.014109682966839334,0.014324711530085492,0.013993289604763785,0.015360122869724454,0.02468390751234273,0.02457586287163816,0.01410588461388497,0.014041625845963794,0.04365171619212216,0.05198929407717288,0.006488307764390855,0.015468435519501654,0.014123771845309687,0.01456073002622695,0.015146474948495916,0.011331067476982476,0.009877817677193729,0.011435094011116404,0.009051511505216329,0.013031730733250892,0.009285800992884492,0.01057613870281042,0.013568913909690023,0.008417903384761652,0.013777210452216084,0.008908905631036586,0.011789867210980591,0.012850537619742183,0.009065689807455346,0.014166412519306854,0.017773228439554006,0.024417426546299748,0.012462800424180055,0.01455665926486429,0.013232180080455175,0.014618377658292289,0.015807428760535664,0.009160557089164663,0.03909142248164328,0.03970044670792651,0.04438942905231627,0.012567431969980704,0.042765750133129714,0.017897242655889625,0.01895580413447622,0.020513649442160314,0.027282859157693993,0.008506961014190864,0.02209900288248427,0.02009489597557631,0.01833366683872103,0.0175219887297506,0.010038098418751494,0.007592232200751542,0.01602932020094376,0.004968465275563233,0.006089890977108427,0.00738451395691414,0.009528489421126149,0.006000691580535157,0.013880324730470026,0.005781043596957513,0.0113425687759018,0.01821045086894687,0.02017703216258316,0.014240242788989685,0.004235981589454345,0.006639491156887353,0.018257923384580772,0.016401679365746866,0.005549518716864479,0.005132210173517438,0.006475354963722686,0.012082063522165462,0.004429112124466018,0.008658359693673227,0.005628320315990676,0.012082063522165462,0.00525459788929485,0.023072717622419223,0.0033316991791615814,0.005133350255625944,0.008199791658687906,0.01682916493948838,0.006439054714628669,0.004581613305724302,0.004242434714691484,0.008848467066648614,0.0054632179511035234,0.02027575270599633,0.0061897445409987845,0.005909062187696945,0.0075137879150836695,0.011150645282138227,0.007806083335819449,0.004178666145081477,0.005455044430175987,0.005273442863775711,0.00758598437434533,0.0073635474906828145,0.014354307480060004,0.02983633041425008,0.011639464661565867,0.023710244531068483,0.01083894597731799,0.033187653524490386,0.019368092385841817,0.01457134202817827,0.006497547487106119,0.01748963894903397,0.038024430274530764,0.039647452277081344,0.02029160229251174,0.02239712441192573,0.009691937397316774,0.022710984209847795,0.0111246269788298,0.012734215565365576,0.012509491537223657,0.012308369083251506,0.0199674030419589,0.019507850886982234,0.020562009665479813,0.019505951599447888,0.014078587187856094,0.018983164564658112,0.01995748623488924,0.016068951132897035,0.013444823428444419,0.019515128865618295,0.02019394346427322,0.019324675280398107,0.019993063497895244,0.018687129030760984,0.011788551136853736,0.025083646127261557,0.01572707789532363,0.011916022150335654,0.02804760301778312,0.012361202915708306,0.02034364238053484,0.023982991872202104,0.019756286037553653,0.04291113202375544,0.011455118377686846,0.011532348666995746,0.011434319362120556,0.011435387142675554,0.01143203054902478,0.01152443404155489,0.010895735548110375,0.015849401964659025,0.013659991600177909,0.01198111639432641,0.009676780511076058,0.01555619743418182,0.015803519034670636,0.013302064119401925,0.012657045521479057,0.008923746112572066,0.013887423616459582,0.00845277380762422,0.008657708437814535,0.00954559030470857,0.010866666933688643,0.007760304900521711,0.03807884343958874,0.006857175502104253,0.015242045017571404,0.024960291252217475,0.005696539116117523,0.006999789350254832,0.03229778420373796,0.03443298738453308,0.010300876763572789,0.03518270503992322,0.013501713051365742,0.03329213049599329,0.013428727711419527,0.03290426796081167,0.011403762665563881,0.019361409487023366,0.013578202330138027,0.013435123252932673,0.013558522776454326,0.014731238623973462,0.03521743561483367,0.034239969001831856,0.029819512347945852,0.03154159581431531,0.03276823812325073,0.015587824262657703,0.028005568226813462,0.017179219105374708,0.005582910230915277,0.006939035081038446,0.019262565572457372,0.028567191654451537,0.009110309477154023,0.020763911444088973,0.01805372189841861,0.01778244409305104],[0.0,0.0,0.0,0.0,0.0,0.016659259040956588,0.0,0.007366050599854513,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04802643978480531,0.0,0.020481598469988312,0.0,0.0,0.007160518710564408,0.0,0.0,0.006207901531242078,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.006363798494214308,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.004969570041957323,0.006563941860818918,0.009530137093434813,0.0,0.0,0.035714008377813675,0.0,0.00497456096047577,0.0,0.0,0.004975539745287182,0.00494640100136638,0.0,0.005009177763420222,0.0,0.0,0.005075953192242364,0.0,0.0,0.0,0.0,0.0,0.0,0.010104317670321983,0.0,0.010394210011018305,0.010278323124542386,0.010409824077118487,0.010456377471729044,0.01045595761584114,0.010440157673052123,0.010208259792802677,0.009951795821949442,0.010442064642982397,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02671888617259258,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.026907295691513365,0.0,0.00964889325580017,0.01505556930007431,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.015735389155135476,0.0,0.0,0.0,0.0,0.004967437866807892,0.0,0.0,0.006870327964367206,0.008090292928384094,0.0,0.005626947493264295,0.0,0.005650805038657711,0.005237518739937692,0.0,0.008242352529539016,0.008370764136315753,0.009359427199303378,0.0,0.009918785325559721,0.00830191951599602,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.006773210031635274,0.003325950689261134,0.0,0.0,0.0,0.004708153999400849,0.0,0.0,0.006958789616332876,0.004024130315205646,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.004705126103077568,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.003968643055713007,0.0,0.004879046717396065,0.0,0.0,0.0,0.0,0.0,0.003918845450289396,0.0,0.0,0.0,0.0,0.012069918038054987,0.0,0.0,0.0,0.0,0.0,0.019975418733248592,0.0473475548673757,0.0,0.010998372519508701,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00683538273395405,0.0,0.0,0.004606196363361682,0.004646544629153024,0.0,0.0,0.0,0.0,0.0,0.030363646399533185,0.030568357788677527,0.030308515240404937,0.030311345565691438,0.030302448370624686,0.030547378792184658,0.0,0.00918999521442818,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.005999567265046423,0.0,0.0,0.0,0.10854587337274353,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.015443082110909357,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.014631068868608715,0.0690912106129014,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00401319551844877,0.004187252445714688,0.0],[0.027230270882153688,0.004587467034289221,0.004703350909302219,0.004530102872092396,0.004733368518051163,0.004367670586035846,0.0,0.003862414584122931,0.0,0.0,0.0,0.0,0.0,0.0,0.008697019160731002,0.0,0.004441099099988778,0.0,0.01199738869161347,0.01203426308636117,0.012029042440466674,0.012091943339105191,0.012086099374063894,0.012009976448386491,0.012073563662994018,0.012007334932175272,0.012425130507017807,0.012019343772463153,0.012809934241201568,0.014108473250375604,0.010073133163217615,0.01390145631188584,0.010739598318560998,0.01131382905453033,0.011337421197581363,0.02252785928305897,0.014008719957987975,0.022870183276616555,0.02929621535641888,0.0,0.046660277131334436,0.023191580068038054,0.02080908534179446,0.026593361199550643,0.0,0.0391756427999697,0.053168305536209555,0.012177120763427232,0.010931693728399286,0.05595331408648758,0.034499559934512,0.047701671553753454,0.053010196672367206,0.034829911488758344,0.011908801268654814,0.04937423244958746,0.0386757354163292,0.06006384290507732,0.05337788052156256,0.010403355122941204,0.05641346917945204,0.0,0.021929464013380397,0.021887826027687154,0.0639758662922324,0.006253194436914028,0.038067682290037055,0.018915879806435016,0.008376447345247114,0.020701933753218462,0.008944230343731482,0.00922340324641921,0.0,0.04474373853063345,0.03747870721160322,0.040356269275205525,0.02810385613683856,0.037453532241193285,0.04871639327449614,0.0,0.04658219009914664,0.0031361087459863012,0.0,0.0,0.049677102723774694,0.0,0.050999352004341886,0.0033443278291155343,0.0,0.023564667411355135,0.0,0.035089911061678546,0.0,0.02007026697157919,0.019658586349128416,0.015894703709977295,0.02079719301672818,0.01635072192055806,0.016168424828908148,0.016375283792271506,0.01644851510171478,0.0164478546429726,0.016423000375969134,0.01605821096437304,0.015654777604298713,0.016426000155173877,0.02067060381180243,0.019466184018451575,0.020212492170944465,0.020303929035216776,0.020196307981664986,0.032052519786595346,0.02026803278263039,0.029128769219874926,0.025386234306085855,0.024902502405516405,0.028131538632727427,0.027250687905343192,0.017173220243665355,0.033770357620694545,0.0,0.029314257414094352,0.020329084342324062,0.020615889115523017,0.012869601697664698,0.013065731686488894,0.012763437993371351,0.009340094733766867,0.0,0.0,0.01286613717689944,0.012807526026622584,0.026543483277047513,0.031613349446544516,0.0,0.00940595686380089,0.0128824523233454,0.0303565870421124,0.03157776322526431,0.027560520073266724,0.03003223139891506,0.027813543487695633,0.027519953993707158,0.0297159731303523,0.028232280981097202,0.02572430917109704,0.03300362696984214,0.025593550175416344,0.02792522166698216,0.027086379215130425,0.02867645723489343,0.0312563225610135,0.027563061294084753,0.028714100811599513,0.04683224875775996,0.0,0.0,0.035406116915635485,0.030173053432074683,0.03555623437141955,0.032955736849516706,0.0,0.017287626353369234,0.017556958667103228,0.019630594508454887,0.026746759875797492,0.020803800125393138,0.0,0.027663685954446585,0.024947642769539678,0.025806671804430324,0.020691454734549135,0.01791711192198233,0.0,0.02787057540869241,0.06747957432611419,0.03662345320016164,0.02462208359389139,0.025063756403149708,0.03927554341421191,0.04443726847259925,0.07184532103591328,0.043455215797018956,0.007297731705100744,0.0316510036290719,0.007030607152504914,0.04335334873060103,0.005536652854379872,0.006134566547519042,0.004948071158361588,0.07469794483255099,0.034989962858103976,0.00493429889852324,0.005699107650123453,0.006749038530738839,0.006241529396713071,0.04199996180335927,0.024489304509154788,0.0754104092158505,0.02807960169375471,0.027379491890369555,0.024489304509154788,0.025561484105365486,0.031177610605592716,0.01620736303828315,0.043700411340536295,0.03988865533895057,0.04605021605046778,0.08352902769940765,0.05571921874830602,0.025797151802178578,0.07174032946833829,0.05647471390718413,0.039042347956174735,0.0903317780167451,0.04072234831762936,0.03655152580824273,0.07322853527541054,0.03164452024010858,0.0838509921806376,0.026536575097417837,0.05451295915760761,0.0,0.0,0.03840533103083498,0.028646373703546918,0.0,0.0,0.0,0.021367648092652913,0.03701417553816596,0.039872058474415904,0.03950991120412091,0.017402724920882077,0.021019705256137427,0.0378849328315294,0.03564542290814437,0.0317779325686195,0.0,0.03107241902205897,0.0,0.01032446426368608,0.010142265746169764,0.012474003217158573,0.0,0.0,0.0,0.0,0.03766763406365496,0.0,0.0,0.03126756776652709,0.03270180207944959,0.0,0.0,0.0,0.0,0.0,0.0,0.04194497602531567,0.023908076561872035,0.026568028208612787,0.00243643204701488,0.03006611528703271,0.0,0.0,0.0,0.0,0.015921284966875608,0.01602862610501316,0.01589237674934846,0.015893860840384248,0.01588919556480438,0.016017625694288863,0.011042359825346865,0.02891283821340713,0.0,0.0182135200168004,0.011768401523592851,0.006306215081079654,0.006406475007290942,0.02156971270496682,0.03591664105641551,0.021705199829043318,0.02251889142394786,0.0479725291758345,0.07370341027952959,0.015478473011686084,0.01982322006049771,0.009437682699355686,0.01852381041972308,0.029187701515962956,0.022243907126195017,0.0,0.030020627693121624,0.0,0.0,0.0,0.03758218562258946,0.0,0.0,0.0,0.0,0.0,0.04854033861889921,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03803963069257393,0.05687132448406425,0.006386049021138986,0.05670816140297305,0.05092235676347852,0.06751117351601589,0.061493615066584524,0.03625246494070816,0.05170428041023032,0.006312999628199458,0.006586801717348612,0.032439137467001763]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"nticks\":36,\"title\":{\"text\":\"Summaries\"}},\"yaxis\":{\"nticks\":36,\"title\":{\"text\":\"Knowledge Base Entries\"}},\"font\":{\"size\":18},\"title\":{\"text\":\"Cosine Similarity between Summaries and Knowledge Base Entries\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('e87cc186-c8a0-4c90-9d14-2061450662b9');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'similarity_matrix' is already calculated as shown previously\n",
        "kb_entries_labels = [f\"{knowledge_base[i]}\" for i in range(20, 30)]\n",
        "summaries_labels = [f\"Summary {j+1}\" for j in range(10)]\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Create the heatmap\n",
        "fig = go.Figure(data=go.Heatmap(\n",
        "                   z=similarity_matrix[20:30][:10],\n",
        "                   x=summaries_labels,\n",
        "                   y=kb_entries_labels,\n",
        "                   hoverongaps = False,\n",
        "                   colorscale = 'Viridis'))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Cosine Similarity between Summaries and Knowledge Base Entries',\n",
        "    xaxis_nticks=36,\n",
        "    yaxis_nticks=36,\n",
        "    xaxis_title=\"Summaries\",\n",
        "    yaxis_title=\"Knowledge Base Entries\",\n",
        "    font=dict(\n",
        "        size=18  # Adjust the font size here\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "X3W3tI_xw4xg",
        "outputId": "67aeb52d-23ee-4218-da71-4ad755b0624a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"ded8bd6b-0e7d-41c0-bb75-4c7c5fc4402c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ded8bd6b-0e7d-41c0-bb75-4c7c5fc4402c\")) {                    Plotly.newPlot(                        \"ded8bd6b-0e7d-41c0-bb75-4c7c5fc4402c\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"hoverongaps\":false,\"x\":[\"Summary 1\",\"Summary 2\",\"Summary 3\",\"Summary 4\",\"Summary 5\",\"Summary 6\",\"Summary 7\",\"Summary 8\",\"Summary 9\",\"Summary 10\"],\"y\":[\"Non-U.S.\",\"Emerging\",\"Market\",\"Short\",\"Sale\",\"Leverage\",\"Liquidity\",\"Management\",\"Performance\",\"Information\"],\"z\":[[0.0,0.027810248223207646,0.03991786696388424,0.038447491430683434,0.028694735555590746,0.042364469018552245,0.03339342523893796,0.02809778228966534,0.03943744149540598,0.03196866747241096,0.033367782560548565,0.0,0.03297031658309468,0.004541193991696806,0.03690628878591554,0.0,0.03230751979636316,0.004363812546851137,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.003255292003455243,0.0,0.0,0.00455229689874987,0.0,0.005545766054155452,0.00394667090901161,0.0,0.0,0.0,0.0,0.022570084073179935,0.0,0.0,0.0,0.0,0.0033135182641587085,0.002261343121778484,0.003802618657227387,0.0,0.0,0.0032484106298737094,0.0,0.003741470102101043,0.007404029471260229,0.0,0.0,0.0,0.0,0.0,0.005317652055529158,0.005307555305327024,0.0,0.005054434562071417,0.004615495592033899,0.0,0.0,0.0,0.010844383803327237,0.0,0.03159402161291104,0.016692093623047105,0.018176342506205718,0.022582957318958746,0.008518592170285695,0.011352583252130979,0.004922160673041419,0.028463176221639862,0.014119581239003188,0.022814148730605013,0.03163197397789108,0.028302052077239365,0.005019227921899798,0.028661244788949863,0.005152824088842894,0.024328873351407845,0.01936221123854005,0.0,0.0,0.009116694271539567,0.0,0.008111362286474268,0.007944982303599695,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00816884234490854,0.008205796389092513,0.00816230153392956,0.0,0.008191288983193663,0.011772339672216888,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.011847304392183405,0.008215962861200913,0.008331874494274909,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.009567091628868804,0.0,0.0,0.006134280018002412,0.015952620241632316,0.016707801901774323,0.007282483371829128,0.016861190338333228,0.01668320983967204,0.01441158849137861,0.017115038345192325,0.015594649903126529,0.016672945575358405,0.015515380883859104,0.01692889214117693,0.016420367139650123,0.006953723158367276,0.01579023315897446,0.016709342446506546,0.01160475218107686,0.008735616496452981,0.005143400484873244,0.006125518801929068,0.007154659224679641,0.014633262309262427,0.007184994074512794,0.006659500877160153,0.004502452320182646,0.020960289261315858,0.021286839771368027,0.023801008354661823,0.0,0.012611727586241347,0.0,0.0,0.0,0.00893975998185188,0.0,0.0,0.0,0.0,0.008612131122876262,0.008457887267736797,0.0037316140443109593,0.010129472056040626,0.0036630323554503108,0.002993207017068166,0.010888558962660558,0.003512469456093201,0.004424047707989018,0.005116678468292712,0.004262110847000669,0.01194625765148913,0.003356442434466284,0.007437822098910133,0.00899889325274145,0.006246008277678513,0.013053351263764945,0.014956410165974389,0.003454926154586999,0.004091417669160879,0.0037837543140390563,0.015913320934872324,0.01187677002795221,0.006530781687307702,0.004255620189067541,0.008299029290075907,0.01187677002795221,0.007747970858540816,0.007560225139208098,0.004912632458928734,0.005046126462350516,0.0,0.009305555982008095,0.006329644923877997,0.0067556466024117565,0.009383285238340842,0.0,0.0,0.00498280884699379,0.013690284585764895,0.017425973441223815,0.0,0.006576706839999628,0.01534689110489647,0.0061614959320906585,0.0080435318110937,0.0,0.007457086422733057,0.007238429095849498,0.0,0.013892856470653065,0.0,0.0034961054593703298,0.0,0.0028785655107765825,0.012239355639651325,0.0,0.004790357858271735,0.014066559932164362,0.005097045636578976,0.008351524059231038,0.003324469277463784,0.0,0.0,0.004185954080929091,0.0,0.0,0.0,0.0,0.004907031268907682,0.004794095360846642,0.005053157096497051,0.004793628606942786,0.004151810873412936,0.013995457782745153,0.0049045941927252515,0.004738774221283388,0.0049561404277023305,0.004795883939394716,0.004962704053877863,0.004749079570494705,0.004913337379892143,0.01377720371858542,0.0,0.0023116345355359523,0.0057974436764808845,0.00585677498168607,0.005908077769279061,0.0,0.004285279609041657,0.019646235548935125,0.004161556132550207,0.013558501149103903,0.021716635524927228,0.02186304885642741,0.021677204711081585,0.021679229011518204,0.021672865574797976,0.02184804429424408,0.0,0.005842535772226196,0.0,0.008833153614394273,0.005707413962698063,0.007645936436944163,0.0077674960433210824,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.004005759360921685,0.003814222482823356,0.0,0.020221983520544332,0.0,0.004600533031197007,0.005599745847490457,0.003440425892670089,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.007137160618481875,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01976611924817345,0.004596888693659292,0.007742730666661423,0.0,0.0,0.0,0.0,0.009157105300598224,0.0,0.01530832464895928,0.01597226437921616,0.0],[0.014033033832292903,0.0768344395910602,0.02423856990664038,0.029182177044327247,0.006098316175588898,0.022508651995203337,0.02365633293006098,0.024881038995126833,0.023946850253554294,0.022647016161011717,0.023638167326117763,0.0,0.02335659730376326,0.0,0.02240990635951121,0.0,0.005721765878902168,0.0,0.01545704063477758,0.015504548391060947,0.01549782228275478,0.0155788617298554,0.015571332557680234,0.015473258286213452,0.01555518196021494,0.015469855043685954,0.016008129108431857,0.0038713317095450932,0.01650389757176841,0.018176892483125873,0.006488946579359381,0.017910178674598494,0.0034591362311872692,0.014576364901226185,0.014606760241676911,0.0,0.01443869890008335,0.0,0.0,0.0,0.0257638135688589,0.007469817072504814,0.0067024351291859055,0.01027860333384325,0.0,0.0,0.0,0.0,0.0,0.016820628505126785,0.0,0.017559218081433577,0.0,0.0,0.0,0.0,0.0,0.0,0.058454758449004274,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.012185298414771685,0.09712745105354442,0.016003013962479398,0.03457035578913349,0.029707822767820174,0.0,0.07538370121617442,0.03540997721640327,0.01599805809257667,0.02263005191520953,0.021714254084119304,0.020921532448419915,0.0,0.02000498674412265,0.0,0.0,0.0,0.02666764323876589,0.0,0.021901962072504503,0.0,0.0,0.11536777861605914,0.0,0.012916767499348553,0.0,0.0,0.0,0.02730428400580315,0.0,0.02808764247291944,0.0277744883774004,0.028129835415500504,0.028255633826571282,0.028254499275503227,0.028211804049634207,0.027585160490982818,0.02689213347759028,0.028216957138666596,0.0,0.0,0.0,0.0,0.0,0.0,0.008704222070344264,0.0250190315601705,0.021804525708023454,0.13902877865870322,0.0,0.1404355568051149,0.0,0.0,0.0,0.03776752422339411,0.02619132303071734,0.01770722190590587,0.011053847438943715,0.011222305719595694,0.010962662224484068,0.006016735288964406,0.0,0.0,0.011050871722609372,0.01100052993825571,0.0,0.0,0.0,0.006059162589037651,0.011064884987665616,0.013036809134171412,0.013561250198539482,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01063019662613109,0.0,0.0,0.0,0.0,0.010067404256415882,0.0,0.0,0.004641317505858758,0.0,0.0,0.21667635843700842,0.0,0.019087284103570867,0.01769128602085236,0.0,0.0,0.0,0.0,0.014768419250307498,0.0,0.0,0.0237606548611983,0.008035430416208975,0.01899912365374202,0.0,0.005770954291693738,0.0,0.02154451911229304,0.0,0.015728150484849178,0.0,0.0,0.011677227041353152,0.06361279313311727,0.0,0.04105659762004651,0.0,0.0,0.0,0.015233189265541356,0.0,0.0,0.0,0.01991138752899627,0.02080611520271146,0.0,0.0,0.0,0.004020690501408528,0.14204234137692165,0.00946536412161221,0.04857814435692205,0.0,0.017637418007671907,0.00946536412161221,0.01234971548781837,0.012050462140051966,0.010440516495079228,0.02681055778489627,0.02569561519965552,0.02636870328031138,0.036993017016363955,0.03589340357592437,0.033236201136547024,0.05545672727197306,0.047080104981123576,0.026474145172570938,0.0436426833988643,0.03703435269724685,0.017659418463996646,0.03494267931723599,0.0040769758135894745,0.03601028598021881,0.01709442488411416,0.049576024944992164,0.003962022116079154,0.003845847364192894,0.022490983723614466,0.012302348279179302,0.0,0.0,0.0,0.006117638750443523,0.00867051731858279,0.011415521676758971,0.010180653784859911,0.004982466197386694,0.0054162192561499735,0.022186227401608468,0.02119587204147178,0.011697612053713745,0.0,0.008896151502266981,0.0,0.0033254249686779725,0.0032667403256853144,0.00964265705956899,0.0,0.0,0.0,0.0,0.022058972592959598,0.0,0.0,0.030213078733690276,0.026332453282409223,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00616047575710462,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0076921722827557265,0.00774403282851563,0.007678205634330752,0.00767892265459352,0.007676668684290146,0.007738718115874761,0.011381290306517041,0.02483356595999845,0.0,0.018772559678678368,0.012129616884628224,0.0,0.0,0.0,0.019831636267237246,0.0,0.0,0.09712407151643558,0.0,0.0,0.042565973571876754,0.02431839940037146,0.0059663668846689204,0.026860338407483718,0.014329158834628687,0.0,0.029751991105459397,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.023071872098529175,0.0,0.0,0.022636099792711008,0.01362272403159686,0.0,0.0,0.0,0.027862344541418674],[0.04030304687513255,0.0377212754881099,0.03867415156140298,0.04097454714452602,0.023352586059572883,0.02154837571832702,0.03019612489179221,0.044463161235423626,0.030566955713685395,0.046975146654173267,0.03394455458357175,0.05887681409472933,0.04844698197264555,0.07083524478656557,0.035756404703857915,0.08035343202167301,0.04016951261019636,0.0651088876772283,0.04143329123642412,0.04156063790960611,0.04154260827437891,0.041759838149922096,0.04173965586594719,0.04147676337905416,0.041696363464495116,0.04146764083469901,0.034737078411988864,0.03706170863778434,0.031599598747098404,0.02784227211484716,0.04555548531050338,0.032006025243555516,0.0485695568116201,0.042793800440339154,0.042883036140898154,0.061746462686411104,0.04377190652534253,0.05265517848301115,0.06959143163783471,0.0724982505842483,0.032886218439440465,0.038139390396145494,0.03422129183561695,0.05466717779468946,0.025794208017330254,0.038069766337217766,0.04114691636509221,0.03504500048448563,0.029213542891857965,0.0506094843905897,0.028367885693371935,0.054165868849813,0.033332451766498745,0.04406080495380694,0.026928623521076164,0.03044914018439533,0.05188718218875376,0.05213238859396498,0.0746145732673001,0.03992028355545228,0.04928618006447003,0.04950069668067681,0.03245741549552662,0.03419555383361686,0.04931747858407954,0.04799015165761454,0.04695275802931683,0.04925409109558219,0.034438424904198725,0.047663108053607885,0.03309549658590119,0.01896027438429388,0.04285351153548448,0.08490310707243733,0.07190760103342436,0.04594662087484328,0.060660869946128994,0.06467336972531916,0.060086900170360454,0.042896549138837926,0.07660609274946717,0.02578722006802369,0.04290498937931194,0.04265372066024831,0.07488780590018547,0.043195056162942044,0.05591351661070298,0.027499339051744388,0.041582329255607085,0.031002356797435127,0.04702958197178844,0.04946282153219164,0.03703743049733881,0.06051151033062175,0.059270300322123964,0.07841824165245463,0.057002890796427515,0.0806680568668644,0.0842002674519215,0.08527752638248105,0.08565889289815753,0.08565545342873977,0.0855260199216939,0.08362630697222322,0.08152534802435149,0.08554164186470992,0.056655923269675945,0.05869021059851073,0.06094031686482748,0.061215997440718616,0.06089152181201803,0.08785254258476197,0.06666302275142999,0.08782273908278111,0.09045525340529763,0.10238265981646956,0.05397388562624319,0.09709860273981517,0.03530247558114909,0.08330485779760474,0.028200743127202582,0.08838198280368484,0.06686382573791211,0.06215655172676394,0.06702099409248685,0.06804237976790609,0.06996644802381893,0.06528052219632893,0.029620689014811272,0.029491035445965794,0.06700295191595361,0.06669772276832803,0.05092700222414253,0.05198929407717288,0.09083630870147195,0.06574085095788203,0.07061885922654844,0.06448323297329077,0.06058589979398366,0.06118776437570537,0.06667526932105768,0.05717547005558202,0.058834824783906135,0.0504979565913472,0.06035770645374919,0.0528806935140521,0.0655830838968351,0.05261189615476032,0.06199744703497237,0.057907886601737804,0.06838122982368743,0.05996917555879685,0.05892698374845974,0.05194351257079179,0.08590393745784436,0.05232305688492803,0.0872396029692604,0.0800616259567536,0.056236765341934496,0.0804010771206076,0.07226253147673446,0.06107038059443108,0.06396778224268901,0.06496436734024338,0.06860184489903423,0.050269727879922815,0.07270177522632051,0.021476691187067548,0.030329286615161957,0.030770474163240472,0.04244000313419066,0.025520883042572592,0.05524750720621066,0.02009489597557631,0.0320839169677618,0.04672530327933493,0.03154830931607612,0.05061488133834361,0.03205864040188752,0.034779256928942626,0.06495883708915656,0.04184557908918013,0.035731835329223055,0.04200484106374609,0.032965771234866305,0.04913887057413886,0.032407339359719435,0.03186828902065702,0.022699161182906054,0.030514805976406465,0.03812383430508911,0.04868960181717392,0.03448718861531923,0.03280335873149373,0.04717090909334808,0.04618989156165694,0.04964438805520726,0.0322188360591079,0.050934789431359206,0.04040567857047506,0.04221240236993007,0.0322188360591079,0.044664082059006224,0.023072717622419223,0.019990195074969488,0.03764456854125692,0.05329864578147139,0.03155468426154071,0.045073383002400685,0.04123451975151871,0.03393947771753187,0.0619392694665403,0.05736378848658699,0.03886185935315963,0.06189744540998785,0.045302810105676584,0.07138098519329486,0.05575322641069114,0.05464258335073614,0.05014399374097773,0.0409128332263199,0.05273442863775712,0.03540126041361154,0.03927225328364168,0.04593378393619201,0.058102327648802785,0.06595696641553991,0.049791513515243815,0.07948560383366526,0.06832752196218608,0.05810427715752546,0.08014238115498049,0.05847792738395507,0.055648851201471734,0.058765028606093,0.07363098280029393,0.06538405183142672,0.04106139475519717,0.04199839538837269,0.06245520657708143,0.08528880683769513,0.04456975447877951,0.0437832203802828,0.043079291791380266,0.04326270659091095,0.042267010255128176,0.044551020941872924,0.04226289513213709,0.0591300661889956,0.041130189890092574,0.046567467881408225,0.06748959475816756,0.06050170542799988,0.04228277920883964,0.043753544172591974,0.0418701297741959,0.04331830424543969,0.0404887795666488,0.07367844460533585,0.07211548261587698,0.03145415579064726,0.08341215505234957,0.07212240776001373,0.03708360874712492,0.03778105013527899,0.03464209937095859,0.031045592344727167,0.02758572772955707,0.029456018685480458,0.029654610857989063,0.029402535502595712,0.029405281224022847,0.029396649983206576,0.029634258963998288,0.047214854041811624,0.03566115442048281,0.009106661066785272,0.044929186478724036,0.04451319035094986,0.10889338203927275,0.11062463324269443,0.031038149611937824,0.029533106216784465,0.035694984450288264,0.032403988438405695,0.07043978173020182,0.04906034781428236,0.05409167839334856,0.05976666813528753,0.028454451301912938,0.04188672778354762,0.03428587751052127,0.07925863409137131,0.03744043687832622,0.04937000567301854,0.05133178856853544,0.005382964033956326,0.006886597476906614,0.010300876763572789,0.005863784173320536,0.0472559956797801,0.006658426099198657,0.04700054698996834,0.00598259417469303,0.011403762665563881,0.05324387608931426,0.040734606990414084,0.04702293138526436,0.04067556832936298,0.029462477247946924,0.007043487122966733,0.0068479938003663705,0.005963902469589171,0.006308319162863061,0.04170503033868274,0.04676347278797311,0.0507600924110994,0.06626270226358816,0.03908037161640694,0.04163421048623067,0.06501115880704363,0.0707969532305973,0.057698626688642146,0.03806717098082978,0.03610744379683722,0.040010499209364836],[0.005869271879236401,0.0,0.0,0.014646423558705176,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.010288969874933438,0.0,0.0,0.02811861671198773,0.007522552936497333,0.0,0.0,0.002585943282632025,0.002593891269969101,0.002592766000585164,0.0026063237972429897,0.0026050641762928872,0.002588656475136436,0.0026023622018326595,0.002588087116980428,0.005356279369844745,0.003238344410706319,0.005522162239379482,0.006081942090532683,0.005427962640047075,0.005992700327139142,0.011574182034071482,0.002438607350019525,0.0024436924519041004,0.06878913778678368,0.006038940006829162,0.009858978205494194,0.06665379496976001,0.00475101485862422,0.007183755524701831,0.0,0.0,0.0,0.00676146883927189,0.00383818334235399,0.010111775601223706,0.013123415623766357,0.005890602674335593,0.0040200997184244615,0.0033800501228607657,0.004896058169525469,0.003360568593900732,0.00866228649649495,0.00641712239147603,0.003325696741704671,0.0065812517582936195,0.0035961920798376255,0.008628888447555973,0.014949078775123177,0.015199352482485272,0.004054900351851444,0.007090086636531487,0.0070766245233783494,0.012927653931210956,0.00449275715040484,0.012307786698463536,0.01019292480594521,0.013541082752389478,0.0,0.004819647210366284,0.00497008104871122,0.014041557445080392,0.00741858679336012,0.00538549477428235,0.010036705562813619,0.007571957934054062,0.00201820397337086,0.013125546856532357,0.014055659322805994,0.008367022238026722,0.006759637079155239,0.014058424886635414,0.013976093147030778,0.008922925743205346,0.014153469359289168,0.009160426150789727,0.007208437024855279,0.01434214383450729,0.005079179725372095,0.018966037933941457,0.01080479405388478,0.017652125767304117,0.0,0.0,0.028549825400043215,0.0,0.02936891838402559,0.029041479116675567,0.029413036044959213,0.02954457301076686,0.029543386704804997,0.029498743847892257,0.028843514647091516,0.02811887377294645,0.0295041320057401,0.0,0.0,0.0,0.0,0.0,0.0,0.0072810265319161,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01849294648786891,0.018774775053600694,0.01834039478125261,0.02013184356760468,0.0,0.0,0.018487968152204517,0.01840374698583703,0.01907080061122463,0.0,0.0,0.020273804236812947,0.018511412166810005,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.007764865287235874,0.0045718366757012295,0.0,0.0,0.0,0.0,0.0,0.0,0.009315531569048338,0.009460662752466407,0.010578052713816233,0.0,0.011210240947074937,0.0,0.004968909256391581,0.0,0.003973161595835155,0.005574851510822399,0.0,0.0,0.0,0.003827551154077012,0.0018794997260717149,0.0033169359449098153,0.006002551812106403,0.003255975441963024,0.002660584891035519,0.0032261868620077384,0.009366431835635873,0.003932422455906545,0.0022740420805174677,0.003788480936596151,0.002123744360528847,0.0029834555304225057,0.009916933736487894,0.0026662950794648322,0.0027759582210841426,0.005801394449450721,0.007976621466836942,0.0030709951814630134,0.010910268455952865,0.003363282092390444,0.0028289885065812224,0.0026392390094040668,0.005805044216728369,0.0037827115573546605,0.0036883970626703805,0.0026392390094040668,0.0034434862147638317,0.0033600450392345664,0.0021833564502730146,0.004485372293806348,0.005373554767749587,0.013785783112247783,0.002813129455139512,0.006004920868172223,0.005560374272154287,0.0038657667066363194,0.014320803303485409,0.022145454453422926,0.00405631419356797,0.0,0.004923997164266711,0.00584586590619852,0.006820728797777817,0.010953591174695477,0.0035748444870547526,0.013823343432426376,0.0033142063603243664,0.0,0.011288139105167837,0.04322151235423882,0.0,0.009322795225615691,0.0,0.010234731994354006,0.014505665441861236,0.0,0.0,0.035426311555141525,0.009061266081678246,0.01855863844565792,0.002955035411815781,0.0,0.0,0.0074415742838910915,0.0,0.01947187820096375,0.01912825288047596,0.01882071670699732,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.003862685041465835,0.006164257818225075,0.005153198881440142,0.002602968477892273,0.005251538686890874,0.00810064494656359,0.03428167549053044,0.013970427616709366,0.014796401727408,0.016069071555109678,0.012868906612489246,0.012955668647415724,0.012845540586916289,0.012846740152716644,0.01284296928900283,0.012946777200613253,0.01904075424994587,0.010386560175944923,0.00596785187119424,0.003925781763947732,0.02029269511857998,0.0,0.0,0.005811478554985687,0.011059358601386796,0.005847982542165171,0.0,0.011078682211771242,0.011347281099395267,0.01251098916360974,0.003560616680376311,0.0033903644655984377,0.04491745237174499,0.02246850264395872,0.011986250443957826,0.004089295729869608,0.004977470355546979,0.0,0.021165649021320957,0.01805192631517434,0.0067504551028744935,0.007685406340346732,0.008848053409147556,0.00872690887777568,0.00880022405716295,0.007841125430759247,0.007473207343859647,0.006344038884763229,0.008898178991081463,0.008804415235917339,0.00888528242444587,0.009653796198448309,0.05538954947144168,0.06282756900912921,0.05471638919296091,0.04960823385531692,0.00585653202136436,0.00408605637177129,0.02523515337737427,0.00964973730752492,0.003658638553025531,0.004547345419903306,0.009467476923145111,0.008139515866916754,0.003980161851613741,0.004535725620918536,0.004732445282562019,0.005826668604269463],[0.013434348958377517,0.02263276529286594,0.01933707578070149,0.018624794156602738,0.019460488382977405,0.02154837571832702,0.01887257805737013,0.015879700441222725,0.019104347321053372,0.01806736409775895,0.01885808587976208,0.007850241879297244,0.01863345460486367,0.006159586503179614,0.017878202351928957,0.01147906171738186,0.02191064324192529,0.005918989788838936,0.011838083210406893,0.011874467974173176,0.011869316649822544,0.011931382328549171,0.011925615961699196,0.011850503822586903,0.011913246704141461,0.011847897381342577,0.010216787768232018,0.009883122303409158,0.008426559665892909,0.00696056802871179,0.01035351938875077,0.009144578641015862,0.011038535639004568,0.009303000095725903,0.009322399161064816,0.01234929253728222,0.011518922769826983,0.011283252532073816,0.010706374098128416,0.007249825058424831,0.027405182032867056,0.004767423799518187,0.004277661479452119,0.008746748447150314,0.030953049620796303,0.011713774257605466,0.010286729091273053,0.010012857281281609,0.00898878242826399,0.009201724434652675,0.012894493496987243,0.011206731486168206,0.010256139005076537,0.008812160990761387,0.009792226734936786,0.012687141743498052,0.00502134021181488,0.005487619851996313,0.006583638817702951,0.005702897650778897,0.005798374125231769,0.006187587085084601,0.005409569249254437,0.005399297973728978,0.0065756638112106055,0.005141801963315843,0.006260367737242244,0.01036928233591204,0.010331527471259618,0.010213523154344546,0.011031832195300397,0.01137616463057633,0.014998729037419568,0.016980621414487466,0.016436023093354138,0.01531554029161443,0.017331677127465427,0.013858579226854104,0.013352644482302322,0.015013792198593275,0.012767682124911193,0.015472332040814213,0.01501674628275918,0.014928802231086908,0.01361596470912463,0.015118269657029714,0.01747297394084468,0.01924953733622107,0.013131261870191714,0.019376472998396954,0.010852980455028102,0.006182852691523955,0.010101117408365131,0.02750523196846443,0.026941045600965437,0.013069706942075772,0.028501445398213757,0.013444676144477403,0.013294779071356027,0.013464872586707533,0.013525088352340665,0.01352454527822207,0.013504108408688511,0.013204153732456297,0.012872423372266028,0.013506575031269988,0.03399355396180557,0.026677368453868512,0.033240172835360446,0.027825453382144826,0.033213557352009836,0.02635576277542859,0.027776259479762495,0.023951656113485757,0.020874289247376377,0.02047653196329391,0.015421110178926624,0.037345616438390454,0.014120990232459635,0.018512190621689944,0.03525092890900323,0.024104177128277688,0.022287941912637367,0.022602382446095977,0.02821936593367867,0.028649423060170983,0.02798657920952757,0.03072024573944891,0.034557470517279816,0.03440620802029343,0.024685298074298697,0.024572845230436638,0.0363764301601018,0.01732976469239096,0.01297661552878171,0.027069762159127896,0.01765471480663711,0.004160208578921985,0.004327564270998833,0.004532426990792991,0.004938908838596864,0.004574037604446562,0.004525755752608164,0.003257932683312723,0.004642900496442246,0.004230455481124168,0.004522971303230008,0.004208951692380826,0.004592403484072027,0.004454452815518293,0.004715946884392236,0.004283512539914061,0.004532844903727673,0.0031480916709570785,0.005924409479851336,0.010464611376985606,0.012462800424180055,0.007278329632432145,0.004962067530170691,0.007309188829146144,0.006774612325943855,0.006107038059443108,0.017768828400746946,0.01804565759451205,0.01614161056447864,0.009425573977485528,0.017106300053251887,0.017897242655889625,0.01895580413447622,0.005128412360540078,0.015157143976496663,0.012760441521286296,0.007366334294161422,0.016745746646313592,0.009166833419360514,0.0087609943648753,0.004302042179464926,0.007592232200751542,0.006869708657547325,0.01242116318890808,0.006089890977108427,0.00738451395691414,0.007146367065844611,0.009001037370802734,0.00520512177392626,0.00867156539543627,0.004861100903957915,0.011381531793091794,0.012610645101614476,0.010171601992135489,0.010589953973635864,0.006639491156887353,0.01014329076921154,0.014058582313497313,0.00832427807529672,0.007698315260276157,0.006475354963722686,0.01006838626847122,0.006643668186699027,0.008658359693673227,0.011256640631981353,0.01006838626847122,0.007881896833942276,0.007690905874139742,0.006663398358323163,0.005133350255625944,0.004099895829343953,0.006310936852308143,0.006439054714628669,0.006872419958586452,0.008484869429382967,0.0029494890222162046,0.0027316089755517617,0.0067585842353321095,0.009284616811498178,0.005909062187696945,0.0037568939575418347,0.008920516225710582,0.010408111114425932,0.008357332290162955,0.008182566645263982,0.0026367214318878556,0.00758598437434533,0.0073635474906828145,0.008612584488036002,0.010992332257881607,0.0038798215538552888,0.007113073359320545,0.0036129819924393303,0.0039044298264106336,0.008300611022503637,0.007285671014089135,0.006497547487106119,0.009539803063109439,0.005185149582890559,0.005663921753868764,0.006763867430837246,0.018664270343271443,0.006461291598211183,0.0028388730262309744,0.0037082089929432664,0.0021223692608942626,0.002084915256203943,0.004102789694417169,0.0133116020279726,0.013005233924654821,0.013708006443653206,0.013003967732965258,0.011262869750284876,0.012655443043105407,0.013304990823259493,0.016068951132897035,0.016806029285555524,0.013010085910412196,0.013462628976182146,0.012883116853598739,0.01332870899859683,0.012458086020507322,0.005894275568426868,0.007838639414769236,0.01572707789532363,0.007944014766890436,0.008013600862223748,0.012361202915708306,0.011624938503162766,0.01065910749875649,0.011289306307173515,0.009195242576519023,0.0049093364475800766,0.004942435142998177,0.004900422583765952,0.0049008802040038085,0.004899441663867763,0.004939043160666381,0.00726382369874025,0.01981175245582378,0.018213322133570544,0.008985837295744807,0.005806068306645634,0.005185399144727273,0.005267839678223545,0.00886804274626795,0.01687606069530541,0.008923746112572066,0.013887423616459582,0.011270365076832293,0.011543611250419378,0.00954559030470857,0.008150000200266481,0.007760304900521711,0.003807884343958874,0.006857175502104253,0.015242045017571404,0.006240072813054369,0.007595385488156698,0.009333052467006444,0.01614889210186898,0.020659792430719845,0.015451315145359181,0.01759135251996161,0.020252569577048615,0.01997527829759597,0.02014309156712929,0.01794778252407909,0.017105643998345823,0.014521057115267527,0.020367303495207042,0.020152684879399013,0.02033778416468149,0.022096857935960192,0.021130461368900202,0.02054398140109911,0.017891707408767513,0.018924957488589186,0.004468396107716008,0.0062351297050630815,0.005251044042527523,0.0049083483158213455,0.005582910230915277,0.006939035081038446,0.007223462089671515,0.003726155433189331,0.009110309477154023,0.012112281675718567,0.012637605328893025,0.0222280551163138],[0.0,0.013939836409016587,0.014291970222306077,0.0137655251756525,0.014383184077843895,0.013271945717043548,0.0,0.011736635281307398,0.0,0.0,0.0,0.0,0.0,0.005690663099964328,0.013213721585408292,0.0,0.013495071347072115,0.005468382782354633,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.017113729139845685,0.0,0.0,0.009891308123229163,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01387588211312198,0.012456712585753425,0.019836147317411252,0.0,0.0,0.0,0.012211949460045259,0.013570130880918,0.0,0.009278140810585755,0.015209557873211267,0.0,0.015806224593521732,0.0,0.0,0.0,0.0,0.0,0.03483598447541613,0.0,0.009579878833039561,0.0,0.0,0.0,0.0,0.035632003382969527,0.0,0.0037961911111740313,0.009433055281499486,0.010674822131740013,0.011380923469959187,0.0,0.03566778845572874,0.0,0.0,0.03567480637949618,0.03546588049391744,0.0,0.03591599222973943,0.0,0.0,0.03639477455609792,0.0,0.0,0.0,0.0,0.0,0.0,0.01609963027750326,0.0,0.016561527820491143,0.01637688041656468,0.016586406362471245,0.016660581825461103,0.01665991285158423,0.01663473814453241,0.016265245591352034,0.015856610862619695,0.016637776599164326,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02609194562308154,0.0,0.02605384764427014,0.0,0.0,0.0,0.013035526357189698,0.013234185002485384,0.012927993909954449,0.014190771471516463,0.0,0.0,0.013032017169196821,0.012972650359546622,0.02688570198193182,0.03202093270876114,0.0,0.014290838383317815,0.013048542662876732,0.0,0.0,0.0,0.0,0.0,0.0,0.0030099093978995383,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.002908430476294602,0.005473389877496741,0.0,0.0,0.004482824926346171,0.006112413461281779,0.004501831536821755,0.0041725783984483825,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0070050867903247325,0.0,0.005601298066574515,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0029940199746716543,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.011162267632984831,0.0,0.0,0.0,0.011162267632984831,0.014563711199603242,0.014210809196582748,0.0,0.009485106464144471,0.0,0.01166098258482002,0.011897711329899703,0.012698458458404047,0.0117583867062051,0.01634968353847584,0.01514192525035197,0.009366089565302318,0.0,0.0,0.0,0.012362108842552929,0.004807875806973233,0.011581644917208462,0.0,0.014615942173635014,0.01401694134296473,0.0,0.005304611136488,0.008704711339704914,0.0,0.0,0.0,0.0036071893345577086,0.0,0.0,0.0,0.008813547020427404,0.006387212168418355,0.0,0.012497881402216467,0.006897350948826583,0.005969399675947326,0.005245504699874683,0.0,0.0,0.0,0.0,0.018447303830271017,0.018022736939379096,0.018996643622758408,0.01802098224278017,0.015608157443985556,0.01753799448272806,0.018438141980196887,0.01781476478394848,0.018631922905122684,0.018029460852493264,0.018656597947862997,0.017853506315754643,0.018471010780347914,0.017264495849636862,0.0,0.008690269591673436,0.0,0.0,0.0,0.0,0.02147988620507367,0.019695279769320527,0.020859724526399274,0.005663478395116966,0.012094915680084459,0.01217645947617121,0.01207295498695072,0.012074082405747427,0.012070538337860929,0.012168102798903426,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0052061815052640995,0.00533240360770846,0.005879262456588778,0.0,0.0,0.0,0.0,0.005632673109126036,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04128221404647464,0.0,0.02263933981885696,0.0,0.0,0.0,0.0,0.011474955998770556,0.0,0.01598597901076761,0.016679309393790465,0.0],[0.0,0.026797086179661506,0.016484403969471418,0.021169600768150377,0.016589610320933836,0.020410539275560715,0.01608843054509587,0.018049430014201305,0.016286008411242232,0.015402004513434176,0.01071738420219074,0.011153578740306633,0.015884583405311417,0.004375752628216725,0.020320998077091174,0.0,0.01556525826892472,0.00420483341073791,0.011212987255826671,0.01124745076526196,0.011242571450488818,0.011301359824604491,0.011295897943922292,0.01122475201230022,0.011284181830351053,0.011222283201096896,0.002903190719422232,0.003510470903510005,0.0029931019384030174,0.0032965117414720906,0.011768176880894867,0.0032481412511784686,0.012546790615663436,0.01057411944081884,0.010596169105639134,0.0,0.022912427378554683,0.02137490750786319,0.003802888763261417,0.015450764935505701,0.0,0.0,0.0,0.018640995212687483,0.0,0.008321431717469279,0.0036538314571648556,0.01422621032821279,0.015964013296444778,0.03486335312348016,0.003664084514753674,0.029191176605716747,0.007285931804619234,0.01252026790944107,0.01739092463811294,0.007210327355579749,0.03329336004913966,0.015593557767315561,0.03429798664722544,0.016205288696548123,0.004119148388413647,0.00879128832297504,0.03586746349160177,0.035799361100644786,0.004671332757372817,0.03652721403155061,0.004447347328542279,0.014732617006244281,0.004892991703530837,0.01934842033650812,0.005224654685041278,0.005387729869591534,0.009132903595050491,0.01608397982447709,0.029190259448036666,0.003626705334251274,0.004104124614142088,0.021877988957701384,0.0,0.00914207573213577,0.0,0.003663833470925681,0.009143874508940896,0.00909032433521103,0.0048363711858663465,0.009205693292888775,0.0049651002777505076,0.003907090356399025,0.009328410861773382,0.0,0.0,0.014640936206159852,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0029554002713900697,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.003213105872811607,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0042086835437264445,0.02478009993715977,0.0,0.0,0.0,0.0,0.0,0.0,0.025245849712400143,0.025639167046789212,0.028667384902666668,0.017855735427756644,0.030380666534369355,0.010171319980510433,0.0,0.0,0.017228146741909454,0.0,0.020932091224864422,0.014275356606077308,0.0,0.008298380440116831,0.012224633821621273,0.0035956666884831697,0.009760442749794544,0.007059167032243685,0.01730496450362682,0.006994583448827303,0.010153517433168238,0.004262874129795951,0.014790814461775093,0.016427347322853017,0.009208832463257217,0.012936652194051051,0.010750279438740852,0.014451753905001846,0.01203691680509029,0.015722251737068347,0.014411529481478108,0.009987176651473546,0.019711811091639393,0.014583629692504173,0.0,0.014305105595455718,0.0,0.004100582635547475,0.0,0.014305105595455718,0.0,0.021854390111909157,0.0,0.0,0.0,0.014944238277327037,0.0,0.0,0.0,0.0,0.0,0.02160575506485796,0.0,0.008395561742582446,0.0,0.00950566380540807,0.00369694617814128,0.0,0.0,0.0,0.0,0.0,0.004078903585471538,0.00892448158289801,0.011024856524073801,0.010106213925456948,0.005133304140125358,0.01941587044203271,0.01965576773634381,0.015527159528533034,0.004615839144233299,0.01807213013601814,0.01964541561640482,0.020118169042444258,0.022423482994604924,0.02121447080024838,0.004590083064496705,0.016133818202622968,0.005268602117519523,0.0030154501009476767,0.0029622356654084377,0.002914610060123205,0.009456523993876552,0.009238880969851721,0.009738128556594476,0.009237981470898248,0.008001110445584495,0.008990390528411213,0.00945182741296416,0.009132269527009833,0.009551164095602268,0.00924232780665139,0.009563813105770399,0.009152129351971535,0.009468676736862002,0.008850188664230102,0.02931093549488184,0.040093538490354796,0.0,0.05925575629259028,0.054081971680147084,0.0,0.01651664610337528,0.015144398939133864,0.01603978179991725,0.01741939737914694,0.011625261886334696,0.011703639281414456,0.011604153941836537,0.011605237582195345,0.011601831132872895,0.011695607099602923,0.012900498931323607,0.0,0.0,0.017022701612967515,0.013748714376252247,0.07367385432181331,0.07484516470419592,0.0,0.0,0.0,0.0,0.004003217552059178,0.004100274202015035,0.004520773360587017,0.007719649098279299,0.011025796795512853,0.03246132171519401,0.009742635714260076,0.012993486204427614,0.0,0.01348935029768819,0.00994526065362666,0.007648084496263351,0.0,0.0,0.0083312309988529,0.0,0.0,0.0,0.008500035568931023,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.008473478501279861,0.0,0.04020825359418875,0.013288254908077729,0.037303266636665604,0.024408136199483562,0.007932166908741342,0.009858941335580957,0.03421017867285704,0.03882340232558622,0.034517001527463946,0.019667497707653015,0.020520499810906333,0.0],[0.022390581597295862,0.02263276529286594,0.023204490936841786,0.022349752987923282,0.019460488382977405,0.017956979765272517,0.015098062445896105,0.015879700441222725,0.015283477856842698,0.014453891278207159,0.015086468703809664,0.011775362818945867,0.014906763683890939,0.015398966257949037,0.014302561881543165,0.02295812343476372,0.014607095494616858,0.01775696936651681,0.01578411094720919,0.015832623965564233,0.015825755533096727,0.015908509771398894,0.015900821282265595,0.015800671763449205,0.015884328938855285,0.01579719650845677,0.014303502875524825,0.014824683455113735,0.014746479415312588,0.01624132540032751,0.01656563102200123,0.016003012621777758,0.01766165702240731,0.013024200134016267,0.013051358825490744,0.01234929253728222,0.013822707323792378,0.018805420886789694,0.008029780573596311,0.021749475175274494,0.027405182032867056,0.028604542797109122,0.025665968876712714,0.010933435558937893,0.025794208017330254,0.058568871288027326,0.04371859863791047,0.03254178616416523,0.03595512971305596,0.03067241478217558,0.05415687268734642,0.03362019445850462,0.04871666027411355,0.03745168421073589,0.03672085025601295,0.05074856697399221,0.021759140917864482,0.03566952903797604,0.032918194088514756,0.01996014177772614,0.04638699300185415,0.024750348340338405,0.01803189749751479,0.017997659912429926,0.02301482333923712,0.013711471902175584,0.03756220642345347,0.01814624408784607,0.034438424904198725,0.027236061744918792,0.03309549658590119,0.05308876827602287,0.017141404614193792,0.01981072498356871,0.010272514433346336,0.028078490534626452,0.028886128545775713,0.012318737090536982,0.03338161120575581,0.01715861965553517,0.028727284781050185,0.02062977605441895,0.01716199575172478,0.017061488264099325,0.03403991177281158,0.017278022465176818,0.03494594788168936,0.01924953733622107,0.019696892805287566,0.019376472998396954,0.010852980455028102,0.008243803588698606,0.010101117408365131,0.011002092787385773,0.010776418240386176,0.008713137961383849,0.011400578159285503,0.0089631174296516,0.008863186047570684,0.008976581724471688,0.00901672556822711,0.009016363518814713,0.009002738939125673,0.008802769154970864,0.008581615581510684,0.009004383354179992,0.01133118465393519,0.016006421072321107,0.011080057611786816,0.01113018135285793,0.01107118578400328,0.017570508516952393,0.016665755687857498,0.01596777074232384,0.013916192831584252,0.02047653196329391,0.023131665268389934,0.014938246575356182,0.02824198046491927,0.018512190621689944,0.021150557345401937,0.016069451418851792,0.011143970956318684,0.016951786834571984,0.010582262225129502,0.01074353364756412,0.010494967203572838,0.01152009215229334,0.014810344507405636,0.014745517722982897,0.010579413460413727,0.010531219384472846,0.02182585809606108,0.02599464703858644,0.02595323105756342,0.011601326639626241,0.010592828883982264,0.004160208578921985,0.004327564270998833,0.004532426990792991,0.004938908838596864,0.004574037604446562,0.004525755752608164,0.003257932683312723,0.004642900496442246,0.004230455481124168,0.004522971303230008,0.004208951692380826,0.004592403484072027,0.004454452815518293,0.004715946884392236,0.004283512539914061,0.004532844903727673,0.0031480916709570785,0.03554645687910801,0.013952815169314141,0.02492560084836011,0.004852219754954763,0.003308045020113794,0.004872792552764097,0.004516408217295904,0.006107038059443108,0.01421506272059756,0.014436526075609638,0.01614161056447864,0.018851147954971056,0.017106300053251887,0.010738345593533774,0.015164643307580978,0.030770474163240472,0.009094286385898,0.02126740253547716,0.02209900288248427,0.010047447987788154,0.027500500258081543,0.020442320184709033,0.00717007029910821,0.017715208468420264,0.01831922308679287,0.014905395826689698,0.020299636590361422,0.017230532566132994,0.011910611776407686,0.027003112112408207,0.013880324730470026,0.020233652589351298,0.0113425687759018,0.01593414451032851,0.012610645101614476,0.012205922390562587,0.01694392635781738,0.02434480090858696,0.016229265230738463,0.025774067574745076,0.0277475935843224,0.025661050867587194,0.012950709927445372,0.008054709014776975,0.015501892435631062,0.01443059948945538,0.011256640631981353,0.008054709014776975,0.013136494723237125,0.010254541165519654,0.008329247947903953,0.010266700511251888,0.016399583317375812,0.00841458246974419,0.012878109429257338,0.009163226611448604,0.016969738858765935,0.01769693413329723,0.010926435902207047,0.008448230294165138,0.015474361352496963,0.01969687395898982,0.026298257702792843,0.011150645282138227,0.018214194450245382,0.010446665362703693,0.010910088860351974,0.01318360715943928,0.01517196874869066,0.02699967413250365,0.017225168976072004,0.015703331796973724,0.027158750876987024,0.009484097812427393,0.025290873947075312,0.027331008784874437,0.016601222045007274,0.03278551956340111,0.029238963691977534,0.019079606126218878,0.02419736472015594,0.025487647892409437,0.01803697981556599,0.02239712441192573,0.02907581219195032,0.01987211118361682,0.025957462950602864,0.029713169652519678,0.029188813586855197,0.028719527860920177,0.00332790050699315,0.0032513084811637053,0.0034270016109133015,0.0032509919332413145,0.002815717437571219,0.0031638607607763517,0.003326247705814873,0.0032137902265794074,0.0033612058571111047,0.003252521477603049,0.0033656572440455366,0.0032207792133996846,0.0033321772496492075,0.0031145215051268304,0.008841413352640302,0.04076092495680003,0.01965884736915454,0.007944014766890436,0.006010200646667812,0.049444811662833224,0.017437407754744148,0.018653438122823857,0.014111632883966893,0.015325404294198371,0.021273791272847,0.0214172189529921,0.019601690335063808,0.02123714755068317,0.021230913876760304,0.021402520362887652,0.025423382945590874,0.011887051473494269,0.02276665266696318,0.017971674591489614,0.02515962932879775,0.00777809871709091,0.007901759517335318,0.02660412823880385,0.07594227312887433,0.022309365281430165,0.01851656482194611,0.01690554761524844,0.014429514063024224,0.01909118060941714,0.016300000400532963,0.02069414640139123,0.02665519040771212,0.0377144652615734,0.021338863024599967,0.01872021843916311,0.01708961734835257,0.020999368050764498,0.005382964033956326,0.006886597476906614,0.020601753527145578,0.005863784173320536,0.006750856525682871,0.006658426099198657,0.006714363855709764,0.014956485436732577,0.011403762665563881,0.009680704743511683,0.006789101165069014,0.006717561626466337,0.006779261388227163,0.007365619311986731,0.007043487122966733,0.0068479938003663705,0.005963902469589171,0.006308319162863061,0.02085251516934137,0.04052834308291003,0.022754524184285935,0.02454174157910673,0.04745473696277986,0.03469517540519223,0.021670386269014543,0.016146673543820433,0.03644123790861609,0.013842607629392649,0.012637605328893025,0.0222280551163138],[0.06286325193884963,0.0718643344508708,0.06980181856200686,0.07096570405052278,0.07414993409607261,0.06121891777314208,0.06434037457099144,0.07005972359618426,0.06513052211702844,0.07246498815412104,0.06429096785332855,0.03148592576715832,0.06352515513164378,0.0401456369578648,0.06812097929214245,0.04028541786787093,0.062248119511080044,0.03264252292648748,0.001978352041670264,0.0019844325760273326,0.001983571699070714,0.001993943966273442,0.001992980304891113,0.0019804277445546227,0.0019909131842679216,0.0019799921623522036,0.002048886048324933,0.0024774655034319176,0.0021123396274939513,0.002326466831839987,0.002076306360462258,0.0022923300381218806,0.0022136802855999573,0.001865634046247466,0.0018695243565118164,0.05881784733198062,0.004620035316426067,0.05656890212737953,0.05636054126354496,0.0,0.03847106103689194,0.00478032250980944,0.004289235092050412,0.019733430581733265,0.051727993311780913,0.03523640090321961,0.036100962791063076,0.047689753008065223,0.04281223648803251,0.02921763177145084,0.02844463765722528,0.03183831497674845,0.030851663840745742,0.030926010903332142,0.04663892246433133,0.027987229578577726,0.028531246861137716,0.03576603627975572,0.033007257336657686,0.04860578266993165,0.046512497343228994,0.02481731271906259,0.0289290951681394,0.028874166819229705,0.04615418418600071,0.02405999674722105,0.03766383448064556,0.0181953404457967,0.034531601278778905,0.0034137189316731523,0.047933946005844955,0.034220831719012294,0.01933625507075146,0.03689088882146348,0.030900923041306302,0.015356977916101583,0.02896428266406189,0.021616116522192152,0.03012473544496671,0.01935567439127522,0.022403895992097984,0.020685591840027582,0.019359482775624978,0.019246105928103573,0.03413200993289999,0.01949036598950536,0.03504049740707972,0.022058992865240278,0.024139114496626795,0.054400913995536974,0.05803916910477421,0.03719748586116663,0.05401838359891937,0.04964336989579239,0.043222299385127325,0.0436835608490353,0.04572569395251345,0.04493683990435161,0.0444358311255159,0.04500434352298698,0.04520560580635447,0.045203790661500015,0.04513548345019148,0.04413292934479227,0.04302416971926523,0.04514372777105553,0.04544736892867629,0.04814918381783326,0.04444014296942756,0.04464118039156093,0.04440455964405919,0.07047218867420565,0.04456225718983429,0.07204937866741508,0.05581537756336587,0.054751821687209164,0.023194250148903677,0.05991465358584303,0.05663678356083897,0.02784341562324222,0.05655408574246939,0.07250817969133654,0.050283549046848966,0.05099295443064164,0.053054467618973956,0.05027213931190731,0.0526168115870267,0.05390588390788996,0.044551245832564056,0.0443562392945387,0.05304018525740025,0.05279856290983074,0.05835975998220917,0.026064977983636467,0.05204689989561839,0.05428600385707045,0.0531074438586492,0.022943054264513124,0.026035637401558703,0.024995794424002977,0.02723749334721428,0.025225271996803172,0.024959003340868,0.024500604933199412,0.025605042635196907,0.02333045755417132,0.024943647434555148,0.023211866723285873,0.025326557633056482,0.024565776144721985,0.026007884754953695,0.023623060907065566,0.027270653633462535,0.023674568452159577,0.023761754091779264,0.027981131627452062,0.03332405251881407,0.038922783108976365,0.03316995244834572,0.039087810784456195,0.036229022251908695,0.04286492854849297,0.0213802843503738,0.021713378167574137,0.016185283199230873,0.0031503585826935026,0.017152582745502666,0.03589133063442664,0.03421276349891951,0.0051422877590937745,0.030396306089923133,0.06397483043722343,0.003693132299746446,0.04029852918636466,0.004595817571606615,0.040995257581913525,0.017254727025295496,0.03045109477585827,0.025257082751420627,0.03985526337873605,0.03663820647507648,0.027149809313076555,0.03821707855625826,0.030084635059877865,0.02261655377349902,0.03767845087673373,0.019497012265612734,0.04108437212476424,0.02781848163505584,0.030597366633573812,0.023360933382699053,0.028848971321019736,0.024409762535063717,0.032892111281854444,0.03338720074793913,0.0334496230081572,0.06492874641272338,0.042401634356541255,0.04885205051020229,0.028939285647925757,0.05925725675311371,0.042401634356541255,0.05532255429309331,0.028276285906699134,0.10356211547497615,0.05833537549331371,0.04933186176450469,0.01476536058970775,0.055956126880025915,0.05053410217210131,0.05317391272485121,0.04436203710301853,0.04656299317830811,0.03219013352659477,0.04344544031014796,0.04937541422715257,0.048971761604716404,0.0491955833346657,0.033917881500744367,0.052374648956975495,0.06563764274755596,0.0370139745912962,0.06085207170784453,0.063990075552496,0.031664917678705565,0.020469564215869856,0.03501286896044656,0.023774394811807518,0.03985032977876504,0.031319949007341724,0.027743563669234146,0.0292215323095348,0.039090763251601275,0.019131227782325514,0.025995892446488394,0.022716984092376727,0.033910838529045785,0.029943629231410477,0.03563325274306681,0.03131209248539999,0.03718241898661494,0.004256223058250378,0.0041811123782551415,0.004113890175070803,0.040042853431054404,0.039121262398560744,0.04123528420558972,0.03911745354609248,0.031056691864460365,0.04441389234126561,0.043358213334821545,0.03222485436154377,0.04718419878817058,0.03913585773833456,0.04049716012821874,0.03875391998797389,0.04009431319644672,0.04372127387468104,0.014775557703522402,0.029867420825699167,0.05125129416299326,0.011948262061030581,0.01205292361154929,0.04957858921814705,0.04662556343947071,0.040079800160571395,0.04527940231851785,0.021513616049331916,0.034458333810551335,0.03138677996454247,0.03439576794281573,0.03439897995142074,0.0343888829257357,0.031365239286716376,0.0036417383260414727,0.043703781004831195,0.04109084994923529,0.006006766211788612,0.00582177716664382,0.018198000542215365,0.018487323086419354,0.062244252448366164,0.038073871020313274,0.07158312112812618,0.06962498668959347,0.03390257430606222,0.03761824159810379,0.03828566716273788,0.02996418621859251,0.02593767043373095,0.003818186930647368,0.04469223350004705,0.02445325406997015,0.0031284779563868852,0.026655774295091427,0.030414487714048047,0.0323851688750012,0.04143137885687522,0.04647936036417707,0.05291684270087181,0.06092209438592287,0.06008796983521147,0.060592771747226874,0.035992683851471585,0.05145577474673637,0.058241380765315855,0.06126722741038787,0.06062162955084266,0.061178429816895086,0.05908438146293727,0.042375263610766434,0.04119913012252265,0.035880230187926423,0.05692848218509496,0.02538941936708837,0.03125999715371103,0.024571172418560543,0.0319905840185852,0.039186107211301086,0.03826795108645218,0.036215029204558706,0.023662833666291187,0.039584819170878194,0.02082009014552047,0.021723081514734763,0.05349166846842783],[0.026868697916755033,0.04526553058573188,0.04640898187368357,0.04842446480716711,0.05448936747233673,0.04309675143665404,0.045294187337688314,0.04128722114717909,0.04585043357052809,0.046975146654173267,0.04525940611142899,0.019625604698243107,0.044720291051672814,0.018478759509538846,0.04648332611501528,0.028697654293454646,0.04016951261019636,0.023675959155355746,0.01381109707880804,0.013853545969868705,0.013847536091459636,0.013919946049974033,0.013913218621982396,0.013825587793018054,0.013898787821498372,0.013822546944899672,0.01634686042917123,0.017295464030966025,0.016853119331785817,0.01624132540032751,0.012424223266500924,0.018289157282031725,0.01324624276680548,0.011163600114871084,0.01118687899327778,0.009261969402961666,0.016126491877757776,0.011283252532073816,0.008029780573596311,0.025374387704486908,0.016443109219720232,0.028604542797109122,0.025665968876712714,0.032800306676813676,0.025794208017330254,0.020499104950809564,0.028288505001000896,0.02252892888288362,0.011235978035329986,0.010735345173761453,0.018052290895782138,0.01307452006719624,0.01794824325888394,0.026436482972284157,0.017136396786139377,0.017761998440897275,0.0083689003530248,0.013719049629990784,0.0219454627256765,0.02566303942850504,0.026092683563542957,0.021656554797796105,0.02344146674676923,0.023396957886158903,0.029590487150447726,0.01542540588994753,0.028171654817590097,0.01036928233591204,0.024106897432939107,0.020427046308689092,0.022063664390600795,0.02275232926115266,0.02142675576774224,0.01981072498356871,0.016436023093354138,0.012762950243012024,0.011554451418310284,0.015398421363171226,0.020028966723453487,0.021448274569418963,0.012767682124911193,0.015472332040814213,0.02145249468965597,0.021326860330124153,0.01701995588640579,0.021597528081471022,0.03494594788168936,0.02474940514656995,0.02188543645031952,0.011625883799038172,0.02894128121340827,0.018548558074571866,0.026936313088973683,0.06601255672431464,0.06465850944231706,0.026139413884151544,0.06840346895571302,0.026889352288954806,0.026589558142712053,0.026929745173415065,0.02705017670468133,0.02704909055644414,0.027008216817377022,0.026408307464912593,0.025744846744532056,0.027013150062539976,0.06798710792361114,0.04268378952618962,0.06648034567072089,0.06678108811714757,0.06642711470401967,0.05271152555085718,0.06666302275142999,0.047903312226971514,0.041748578494752754,0.04095306392658782,0.015421110178926624,0.044814739726068545,0.014120990232459635,0.018512190621689944,0.04230111469080387,0.048208354256555376,0.044575883825274734,0.045204764892191954,0.024691945191968837,0.02506824517764961,0.024488256808336623,0.026880215022017796,0.034557470517279816,0.03932138059462106,0.021158826920827455,0.02106243876894569,0.04365171619212216,0.01732976469239096,0.01297661552878171,0.023202653279252482,0.02118565776796453,0.018720938605148937,0.019474039219494747,0.020395921458568455,0.02222508977368589,0.020583169220009526,0.02036590088673674,0.014660697074907253,0.020893052233990107,0.019037049665058755,0.020353370864535033,0.018940282615713715,0.020665815678324123,0.020045037669832316,0.021221760979765063,0.019275806429613275,0.020397802066774526,0.014166412519306854,0.011848818959702672,0.013952815169314141,0.008308533616120039,0.019408879019819053,0.013232180080455175,0.019491170211056386,0.018065632869183616,0.018321114178329326,0.01421506272059756,0.014436526075609638,0.020177013205598303,0.018851147954971056,0.012829725039938913,0.010738345593533774,0.011373482480685733,0.030770474163240472,0.009094286385898,0.02126740253547716,0.025782170029564976,0.010047447987788154,0.027500500258081543,0.0175219887297506,0.008604084358929853,0.022776696602254627,0.011449514429245543,0.014905395826689698,0.020299636590361422,0.01476902791382828,0.019056978842252298,0.027003112112408207,0.012145284139161272,0.02601469618630881,0.00972220180791583,0.011381531793091794,0.01513277412193737,0.012205922390562587,0.012707944768363035,0.02213163718962451,0.012171948923053847,0.01171548526124776,0.0138737967921612,0.02309494578082847,0.021584516545742286,0.02013677253694244,0.022145560622330092,0.01443059948945538,0.02814160157995338,0.02013677253694244,0.02627298944647425,0.01281817645689957,0.016658495895807906,0.017111167518753145,0.020499479146719766,0.010518228087180238,0.021463515715428896,0.022908066528621505,0.021212173573457418,0.014747445111081024,0.02458448077996585,0.008448230294165138,0.030948722704993926,0.01969687395898982,0.018784469787709174,0.022301290564276453,0.007806083335819449,0.020893330725407385,0.02727522215087994,0.01318360715943928,0.025286614581151102,0.02454515830227605,0.011483445984048003,0.009421999078184235,0.023278929323131733,0.007113073359320545,0.025290873947075312,0.013665504392437218,0.016601222045007274,0.021857013042267403,0.019492642461318356,0.009539803063109439,0.010370299165781117,0.01699176526160629,0.013527734861674492,0.014931416274617153,0.01938387479463355,0.01987211118361682,0.025957462950602864,0.012734215565365576,0.012509491537223657,0.012308369083251506,0.0133116020279726,0.013005233924654821,0.013708006443653206,0.013003967732965258,0.011262869750284876,0.012655443043105407,0.013304990823259493,0.01285516090631763,0.013444823428444419,0.013010085910412196,0.013462628976182146,0.012883116853598739,0.01332870899859683,0.012458086020507322,0.02062996448949404,0.006270911531815389,0.01572707789532363,0.01588802953378087,0.016027201724447496,0.006180601457854153,0.029062346257906914,0.023982991872202104,0.028223265767933787,0.015325404294198371,0.02291023675537369,0.0214172189529921,0.02286863872424111,0.022870774285351107,0.02286406109804956,0.021402520362887652,0.012711691472795437,0.015849401964659025,0.013659991600177909,0.014976395492908013,0.011612136613291269,0.012963497861818184,0.013169599195558861,0.0177360854925359,0.012657045521479057,0.017847492225144132,0.02314570602743264,0.01690554761524844,0.01731541687562907,0.01590931717451428,0.016300000400532963,0.023280914701565136,0.022847306063753247,0.027428702008417013,0.009145227010542843,0.021840254845690292,0.02088731009243092,0.020999368050764498,0.026914820169781632,0.03443298738453308,0.02575219190893197,0.029318920866602684,0.020252569577048615,0.01997527829759597,0.02014309156712929,0.029912970873465155,0.028509406663909706,0.02420176185877921,0.020367303495207042,0.020152684879399013,0.02033778416468149,0.022096857935960192,0.03521743561483367,0.034239969001831856,0.029819512347945852,0.03154159581431531,0.013405188323148024,0.015587824262657703,0.015753132127582573,0.02945008989492807,0.013957275577288195,0.017347587702596114,0.024078206965571718,0.016146673543820433,0.015183849128590039,0.024224563351437134,0.02527521065778605,0.013336833069788279]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"nticks\":36,\"title\":{\"text\":\"Summaries\"}},\"yaxis\":{\"nticks\":36,\"title\":{\"text\":\"Knowledge Base Entries\"}},\"font\":{\"size\":18},\"title\":{\"text\":\"Cosine Similarity between Summaries and Knowledge Base Entries\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ded8bd6b-0e7d-41c0-bb75-4c7c5fc4402c');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'similarity_matrix' is already calculated as shown previously\n",
        "kb_entries_labels = [f\"{knowledge_base[i]}\" for i in range(30, 40)]\n",
        "summaries_labels = [f\"Summary {j+1}\" for j in range(10)]\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Create the heatmap\n",
        "fig = go.Figure(data=go.Heatmap(\n",
        "                   z=similarity_matrix[30:40][:10],\n",
        "                   x=summaries_labels,\n",
        "                   y=kb_entries_labels,\n",
        "                   hoverongaps = False,\n",
        "                   colorscale = 'Viridis'))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Cosine Similarity between Summaries and Knowledge Base Entries',\n",
        "    xaxis_nticks=36,\n",
        "    yaxis_nticks=36,\n",
        "    xaxis_title=\"Summaries\",\n",
        "    yaxis_title=\"Knowledge Base Entries\",\n",
        "    font=dict(\n",
        "        size=18  # Adjust the font size here\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "poCwBz4Nw4xg",
        "outputId": "48ee07f6-af9b-440b-91af-527fbd53481a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"7de9e8d5-790f-43c5-b679-d871038e80ff\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7de9e8d5-790f-43c5-b679-d871038e80ff\")) {                    Plotly.newPlot(                        \"7de9e8d5-790f-43c5-b679-d871038e80ff\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"hoverongaps\":false,\"x\":[\"Summary 1\",\"Summary 2\",\"Summary 3\",\"Summary 4\",\"Summary 5\",\"Summary 6\",\"Summary 7\",\"Summary 8\",\"Summary 9\",\"Summary 10\"],\"y\":[\"Average\",\"Total\",\"Returns\",\"Adviser\",\"Managers\",\"Additional\"],\"z\":[[0.013507156055711324,0.022755422963194157,0.0272186215689631,0.026216023027346016,0.027392335575997274,0.02166515656815982,0.022769828991425396,0.03193152011192771,0.023049459388687157,0.021798335637092964,0.02275234413032981,0.011839179084963377,0.022481325740578595,0.0030964841093106556,0.02157011135362861,0.00577063609372493,0.0220293873909796,0.005951067596778047,0.005951119693959967,0.005969410668973494,0.005966821048065435,0.005998022069077376,0.005995123260316401,0.005957363656638868,0.005988905114106144,0.005956053373247159,0.006163294426896839,0.007452512716661118,0.006354170386630568,0.0023327635474184208,0.0062457780072393936,0.00689560308154541,0.006659015213815291,0.005612050474581819,0.00562375299341676,0.0031040548000408523,0.0069488095594859465,0.011344401819463166,0.008073297756126127,0.014578230585515047,0.022042962951161385,0.028759564356997922,0.034406753217726634,0.010992689022533248,0.015560399425517263,0.00883294255953804,0.010342477746344857,0.007550341271515355,0.006778122671903968,0.004625796467904027,0.0077786249171926825,0.005633733034890919,0.007733791408491555,0.0066449386973852,0.0073839715857176285,0.007653539622706982,0.0033657021544765816,0.005517359862020847,0.004412879115599624,0.005733804353115678,0.008744697389678667,0.009331680823404262,0.005438886266110609,0.005428559325680267,0.009916950669856858,0.005169667822478364,0.00629429563390497,0.01303184798262546,0.02077503781992363,0.0,0.025880444139323402,0.026688240722769645,0.01077143875074167,0.008536323720600147,0.012393823262948496,0.007699271227705049,0.008712802845644962,0.006192749079493078,0.013425008784398293,0.010782256461867083,0.009627657179286885,0.010370789288886623,0.010784377957400351,0.010721220341597264,0.01711219508524437,0.010857287655615142,0.010540600955397677,0.01105934839571674,0.013202426395101764,0.019481483279129647,0.021823595788649765,0.008288480663273843,0.020311720291703347,0.01659257750551052,0.016252231129191552,0.013140537871687934,0.017193544934692648,0.00901169280648131,0.008911219848929605,0.009025230070689533,0.009065591472939878,0.009065227461410308,0.009051529043673543,0.008850475528585148,0.012942185128811894,0.009053182370591568,0.017088890562278674,0.01072877829743766,0.016710158534554466,0.016785751612586143,0.016696778671926635,0.017665731421148325,0.01675607530812839,0.01605430765172244,0.013991611268990062,0.013725002656244571,0.015504684475922412,0.015019204005878348,0.007098759281969807,0.009306258473519666,0.014176788152753072,0.01615653938397597,0.016806548116361782,0.011362437728696582,0.0070930750094468165,0.007201171961863333,0.00703456293304199,0.007721683323808989,0.009927072517378606,0.009883620443072621,0.007091165540433162,0.007058862032129627,0.021944142754269463,0.008711841445912184,0.0,0.007776133147461811,0.0071001576258333116,0.002091377359405541,0.0021755086953079007,0.0022784951792391376,0.002482837561929631,0.002299413239873636,0.0022751414828476543,0.0016377944814760074,0.0023340312861784875,0.0021266911611169175,0.0022737417130338543,0.002115880997139294,0.002308645946384764,0.0022392968021159214,0.002370752416633093,0.0021533634611722637,0.002278705268140503,0.001582576335073765,0.005956516659661929,0.010521324060379882,0.008353561493359512,0.0048785162310310175,0.003325972882231284,0.0024496002612858095,0.011352211929159289,0.003070067494994889,0.025011176531999402,0.02540083777911792,0.016229089594175843,0.00947665562529235,0.004299751798002299,0.03238962531673094,0.019058534611474796,0.01546861696531804,0.02743071788820584,0.017106128526887022,0.018515639868006115,0.02020379973055092,0.013824769244377953,0.014680790568540486,0.010092499626497749,0.012722296835828302,0.01151156476857033,0.014986175223452055,0.010204824965829749,0.012374223556924267,0.0071850966123345895,0.018099636507492547,0.010466661586240936,0.014530934522934698,0.008145742518642148,0.013731856442790857,0.022822178683996722,0.012272072062741857,0.012776815137483967,0.011125789504754144,0.018356871715392548,0.01413477242691817,0.01394898546535749,0.012900060125574816,0.010850746629914643,0.01012295162041452,0.008906231159955032,0.01450880574007974,0.011317645696885021,0.01012295162041452,0.007924612564473157,0.01031011537898282,0.006699510468731449,0.008601950518305226,0.012366345317666255,0.002115046268982247,0.008631934667492024,0.009212886474673717,0.00853085295387855,0.008896421098881396,0.008239238573511505,0.010192818304608746,0.012446579394250756,0.007921448257687156,0.018886271722766464,0.008968860726447115,0.018312905793259063,0.008402624630520203,0.010969215797134483,0.0079530332209524,0.010169461886882022,0.009871272054288546,0.011545680214532745,0.007894217793266043,0.019504240718548692,0.021454867414357114,0.01816281226189268,0.009813974450361366,0.013909326605762414,0.018312888786566006,0.02286466270593124,0.00799291981034302,0.00868875060554326,0.014236543068418815,0.011334206717858904,0.015012336688505892,0.019488925189204337,0.017125549339139196,0.018641527665411318,0.006401614154186526,0.006288643197164893,0.006187536981280296,0.010037807926183133,0.019613573166692426,0.006891148310229758,0.019611663586019738,0.01981684000402703,0.012724028880520868,0.0200656453014241,0.01938724366408173,0.006758843645945265,0.01962089058814039,0.006767794668160634,0.01942940484477397,0.010050707687230978,0.01878840343017158,0.0029631097191524596,0.004728672427719553,0.01581231037623125,0.0019967667859772348,0.0020142575898093873,0.018642291189853513,0.03506381864578948,0.03215062274614936,0.031213843107799597,0.015408459915694036,0.02138908401957109,0.021533289002218983,0.021350247939767822,0.021352241707728332,0.021345974250575224,0.02151851075349589,0.0018257974495830742,0.019919121722014013,0.018312028749087182,0.0030115119340951065,0.0019458447132038143,0.007820251916484623,0.00794458289315125,0.013374154302564683,0.012725640043483498,0.013458162176391978,0.013962686139868199,0.01133144452100028,0.011606171544967098,0.012796429837083836,0.01638833781973947,0.01820551055586473,0.02679964750410571,0.02068301334778833,0.012259719100545277,0.015684726804786345,0.005727411358544603,0.007037724522708601,0.021648547458219532,0.0276956768360376,0.025891755228947065,0.03537337677535637,0.020362327839918242,0.040167067575484154,0.02025225651683214,0.027067575082103116,0.017198347581630996,0.01946633813145629,0.02047768355549854,0.020261901819802884,0.0204480042457453,0.02221661127060255,0.02832663645735602,0.027540425283478182,0.035977342083651755,0.03805504158601946,0.004492612461731259,0.00626892082488079,0.005279501936236619,0.0049349489791423165,0.005613166664617239,0.0069766409973439645,0.004841739633730205,0.003746349233584544,0.0061064550382502825,0.01739703409218721,0.016336407208230156,0.02681822336470823],[0.022390581597295862,0.03017702039048792,0.030939321249122378,0.029799670650564377,0.031136781412763846,0.02873116762443603,0.03019612489179221,0.02540752070595636,0.030566955713685395,0.028907782556414317,0.030172937407619328,0.011775362818945867,0.029813527367781877,0.009239379754769423,0.032180764233472124,0.017218592576072788,0.029214190989233717,0.008878484683258405,0.011838083210406893,0.011874467974173176,0.011869316649822544,0.00994281860712431,0.009938013301415997,0.011850503822586903,0.009927705586784552,0.011847897381342577,0.008173430214585616,0.007412341727556867,0.008426559665892909,0.00928075737161572,0.014494927144251078,0.009144578641015862,0.015453949894606394,0.011163600114871084,0.01118687899327778,0.01234929253728222,0.006911353661896189,0.015044336709431757,0.010706374098128416,0.025374387704486908,0.027405182032867056,0.014302271398554561,0.012832984438356357,0.02624024534145094,0.025794208017330254,0.014642217822006831,0.01800177590972784,0.017522500242242816,0.01797756485652798,0.021470690347522907,0.018052290895782138,0.011206731486168206,0.015384208507614808,0.015421281733832426,0.017136396786139377,0.017761998440897275,0.01171646049423472,0.010975239703992626,0.008778185090270601,0.011405795301557794,0.017395122375695304,0.024750348340338405,0.009015948748757396,0.010798595947457955,0.013151327622421211,0.006855735951087792,0.012520735474484488,0.01814624408784607,0.03099458241377885,0.010213523154344546,0.03309549658590119,0.041712603645446544,0.02142675576774224,0.016980621414487466,0.012327017320015605,0.012762950243012024,0.017331677127465427,0.006159368545268491,0.023367127844029063,0.021448274569418963,0.015959602656138994,0.015472332040814213,0.02145249468965597,0.021326860330124153,0.020423947063686946,0.021597528081471022,0.020967568729013616,0.01649960343104663,0.017508349160255617,0.023251767598076345,0.021705960910056204,0.018548558074571866,0.023569273952851973,0.005501046393692886,0.005388209120193088,0.017426275922767697,0.0057002890796427515,0.0179262348593032,0.017726372095141368,0.017953163448943377,0.01803345113645422,0.018032727037629426,0.018005477878251346,0.01760553830994173,0.017163231163021368,0.018008766708359984,0.005665592326967595,0.010670947381547405,0.005540028805893408,0.005565090676428965,0.00553559289200164,0.017570508516952393,0.0055552518959524995,0.01596777074232384,0.013916192831584252,0.013651021308862608,0.023131665268389934,0.014938246575356182,0.02118148534868945,0.018512190621689944,0.021150557345401937,0.016069451418851792,0.011143970956318684,0.011301191223047988,0.014109682966839334,0.014324711530085492,0.013993289604763785,0.007680061434862227,0.014810344507405636,0.014745517722982897,0.01410588461388497,0.014041625845963794,0.02182585809606108,0.02599464703858644,0.02595323105756342,0.007734217759750827,0.014123771845309687,0.006240312868382978,0.006491346406498249,0.006798640486189486,0.0074083632578952965,0.006861056406669842,0.006788633628912247,0.006515865366625446,0.0069643507446633685,0.006345683221686251,0.0067844569548450116,0.006313427538571239,0.006888605226108042,0.006681679223277439,0.0070739203265883545,0.006425268809871092,0.00679926735559151,0.006296183341914157,0.020735433179479675,0.024417426546299748,0.02907986765642013,0.009704439509909527,0.009924135060341382,0.009745585105528193,0.009032816434591808,0.012214076118886216,0.031983891121344504,0.03248218367012169,0.028247818487837625,0.009425573977485528,0.017106300053251887,0.03221503678060133,0.02653812578826671,0.015385237081620236,0.027282859157693993,0.01701392202838173,0.011049501441242135,0.016745746646313592,0.013750250129040771,0.0175219887297506,0.018642182777681347,0.025307440669171805,0.0274788346301893,0.027326559015597777,0.01826967293132528,0.02953805582765656,0.019056978842252298,0.030003457902675782,0.024290568278322544,0.014452608992393784,0.027546238455761516,0.025039369944801947,0.02017703216258316,0.02848048557797937,0.021179907947271728,0.02877112834651186,0.02028658153842308,0.030460261679244177,0.022198074867457916,0.03079326104110463,0.012950709927445372,0.012082063522165462,0.015501892435631062,0.025975079081019682,0.016884960947972028,0.012082063522165462,0.0105091957785897,0.02050908233103931,0.013326796716646326,0.011977817263127202,0.028699270805407674,0.012621873704616286,0.010731757857714448,0.013744839917172904,0.01272730414407445,0.01769693413329723,0.01638965385331057,0.0185861066471633,0.018569233622996357,0.01181812437539389,0.018784469787709174,0.008920516225710582,0.031224333343277795,0.010446665362703693,0.01363761107543997,0.015820328591327135,0.012643307290575551,0.012272579151138024,0.025837753464108007,0.02355499769546059,0.019399107769276447,0.021339220077961636,0.014451927969757321,0.009761074566026583,0.013834351704172729,0.01457134202817827,0.019492642461318356,0.009539803063109439,0.010370299165781117,0.011327843507737528,0.015782357338620243,0.018664270343271443,0.02584516639284473,0.01987211118361682,0.014832835971773066,0.010611846304471312,0.010424576281019714,0.010256974236042922,0.01663950253496575,0.019507850886982234,0.013708006443653206,0.019505951599447888,0.03097289181328341,0.01581930380388176,0.023283733940704113,0.016068951132897035,0.010083617571333312,0.019515128865618295,0.013462628976182146,0.019324675280398107,0.016660886248246038,0.018687129030760984,0.023577102273707472,0.007838639414769236,0.023590616842985447,0.027804051684116524,0.02203740237111531,0.024722405831416612,0.03778105013527899,0.03197732249626947,0.031045592344727167,0.015325404294198371,0.02291023675537369,0.023064697333991493,0.02286863872424111,0.022870774285351107,0.02286406109804956,0.02304886808310978,0.003631911849370125,0.027736453438153293,0.02276665266696318,0.0029952790985816025,0.003870712204430423,0.023334296151272728,0.02370527855200595,0.022170106865669875,0.012657045521479057,0.017847492225144132,0.01851656482194611,0.01690554761524844,0.020201319688233913,0.03181863434902856,0.016300000400532963,0.010347073200695615,0.011423653031876623,0.013714351004208506,0.02438727202811425,0.009360109219581554,0.003797692744078349,0.004666526233503222,0.03768074823769429,0.0482061823383463,0.036053068672504754,0.041046489213243754,0.0472559956797801,0.0466089826943906,0.04700054698996834,0.041878159222851215,0.039913169329473586,0.03388246660229089,0.047523708155483096,0.04702293138526436,0.04745482971759014,0.051559335183907117,0.042260922737800403,0.04108796280219822,0.035783414817535025,0.03784991497717837,0.011915722953909354,0.012470259410126163,0.0070013920567033655,0.009816696631642691,0.013957275577288195,0.013878070162076891,0.009631282786228686,0.006210259055315552,0.01214707930287203,0.01730325953674081,0.021664466278102326,0.026673666139576557],[0.042203652132777894,0.043450142938345766,0.044547735770278624,0.04680743881613668,0.04483204721732775,0.048889860294281814,0.04347765040269102,0.03990852734109847,0.04401158821393636,0.041622640931864116,0.04344426408791721,0.020551106127192513,0.04292677039893339,0.016125148482405607,0.044931120080796014,0.03005097412560565,0.04206382067828183,0.015495291633878574,0.01652845576923884,0.016579256557499606,0.016572064224486815,0.01665872097519448,0.01665066991340221,0.01654579755805679,0.01663339982644577,0.016542158417491862,0.006419153741216489,0.01034918915612151,0.006617953611248004,0.0024296044964906625,0.01951518448656914,0.007181863018855104,0.020806360752151396,0.019483419258481273,0.019524047025796288,0.006465829344666076,0.019299408743096963,0.03544603957104888,0.014014079674941117,0.007591711260372332,0.04591608263202398,0.009984490563592413,0.008958773642097625,0.020608259278146062,0.05402121509952646,0.07053048170039632,0.06463097504721148,0.049803950247287954,0.04471020211961464,0.03693668909654113,0.06751285078535722,0.050852606607216744,0.06175383002148987,0.055366341628369384,0.05127003573786262,0.0584559366141058,0.019279831441029585,0.02298561694237335,0.018384290947268466,0.023887336294746802,0.024287252055672483,0.02267783147791163,0.015105794490164479,0.015077112765226613,0.027543032058120663,0.01794759438971925,0.026222373015560612,0.02443111976958665,0.046881207316876415,0.0035650570008723195,0.05390965880074865,0.05559232073497061,0.024680915180264343,0.04445347776036294,0.03872499906177049,0.024056682489618102,0.03932283734530923,0.027411782415649698,0.03845139804086332,0.024705702120700924,0.036766891239773856,0.027003290063753564,0.024710563165963637,0.024565848258819373,0.04633870931404874,0.024877623307055192,0.04391270860741802,0.028796148906975596,0.025209257368145107,0.0365224066391947,0.056823918691176756,0.03237211382426385,0.049361500732692985,0.0748860312746269,0.07334997158933909,0.03193410801576714,0.07759833234309073,0.03285029588938582,0.032484042128263224,0.03289964323669587,0.033046772531369645,0.0330454456012678,0.032995510801499046,0.03226261104536169,0.03145207158939873,0.03300153766899501,0.07712600364051173,0.07263208144005608,0.0754167008836954,0.07575786943353313,0.0753563145566847,0.06439683606056419,0.07562393360210486,0.058522717982464854,0.05100357724411317,0.05003170969342957,0.008074168331603578,0.06257080899052196,0.014786905848272068,0.009692592915295641,0.059061259388834754,0.05889538299956326,0.07585172872884928,0.0769218525715417,0.029550130712508837,0.03000046841079592,0.029306366265675815,0.03216894664658998,0.07237425343143905,0.07205746200753865,0.02954217576224117,0.02940759761502424,0.06094698335103688,0.009073499615134983,0.013588564887768322,0.032395787530701735,0.02588218261303281,0.0,0.0,0.0023730832637701366,0.0,0.0,0.0,0.005117354702655552,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.004944823384251805,0.00620379192556903,0.0,0.03480138497266584,0.012702600081599298,0.015588203980073465,0.01275645749868448,0.014188177029115668,0.0031975164386566523,0.029770829186409775,0.030234643370188254,0.0,0.006580042554929948,0.0,0.03748247647505412,0.03969943841055448,0.010740514578376277,0.03491822923768616,0.0445406552589374,0.01157057223270486,0.028056704232977986,0.009599121624437773,0.04281267232898191,0.03153442083811555,0.03710123941632594,0.035968346926091604,0.031216604656215712,0.0297596934849618,0.03608617505949721,0.032427955779854516,0.04084386362243371,0.02543605938533506,0.036321991290582625,0.03223881998469583,0.02860382501731945,0.03169280659225831,0.03195381878490384,0.02883231907935909,0.03244544483108307,0.027616229182931565,0.029443109811380142,0.03486733270909084,0.03224540519328485,0.036163833690212054,0.03584684522637443,0.027827877322104018,0.04231112371877119,0.038309308906223555,0.03584684522637443,0.033014360741186445,0.018791715836657404,0.02267729728787595,0.03225256826889934,0.025759428744681984,0.013217094199946402,0.0292183958123293,0.03358370654519934,0.026654993025651445,0.01853148359458625,0.028604257966930988,0.019462587577307358,0.03564901790542803,0.033001178069493806,0.01967030509815635,0.032694160240635206,0.02997207211236404,0.03281792309259274,0.03712990207381302,0.024849572039672797,0.031774892514848475,0.03855398299324547,0.030062451673804953,0.016443867247515377,0.02031392808879588,0.0223455319332385,0.018916812374424084,0.012265663091021688,0.014486750061709538,0.019073119086078387,0.017009894730268448,0.011654626336177755,0.012669230273623763,0.014827550392662737,0.011804728188735418,0.03127109968911343,0.02368097288635996,0.014863740949831656,0.019415400882554435,0.006667366930961431,0.006549706165275872,0.006444402686486423,0.038333208737606,0.03745096538099526,0.03947472823156789,0.03744731914891621,0.03243350696744756,0.03644367814022826,0.038314170556495865,0.03701880249588846,0.038716844286645936,0.03746493756724591,0.03876811863940103,0.03709930679284178,0.03838247140895304,0.03587535225975293,0.003086118481753138,0.027908195652614404,0.037054649612110795,0.0020796593666864796,0.0020978762732756034,0.038832392206986276,0.03651943701718981,0.03348530444736435,0.03546505734550072,0.003209623498840751,0.02570425112999049,0.02587754892454709,0.025657580017414836,0.025659976020549192,0.025652444127530188,0.025859789219826106,0.0019015925116359661,0.0373428579848625,0.038144446691037295,0.0031365300372641555,0.002026623345475567,0.010859862895810113,0.011032519400321888,0.04178808280791791,0.03534379905137,0.03737828336632248,0.0484744157718768,0.05605879378752932,0.05741792020392534,0.059974439233353306,0.05974035711985854,0.05959260440510074,0.00797491200663786,0.017951362982607175,0.03192165434572289,0.009801511896902407,0.0019883918947223543,0.0073298844044258574,0.04509450458893633,0.05769083716063377,0.053933220103599314,0.049122461276782985,0.06362291197532416,0.04880696236170746,0.06327898970107486,0.050117763886703214,0.05373692845481322,0.05068613009099653,0.06398334554637333,0.06330912683798315,0.06389061134983336,0.05399076285821766,0.05900514296308492,0.05736744401553516,0.0562063258800643,0.04624064176135408,0.015597053617788454,0.01958749515071497,0.012830234709378406,0.017989354236226624,0.026307847369910563,0.025431927829579006,0.01764957849795006,0.009104370175580011,0.028619796403010305,0.018119244148321702,0.01890509670555193,0.04189730854648357],[0.0,0.010093629403561004,0.015522906435692943,0.009967413217170417,0.010414650894400093,0.009610019630170602,0.010100019489580435,0.00849832404759427,0.010224055224029142,0.009669093907466909,0.010092263724796057,0.0,0.009972048020955998,0.0,0.00956786039746323,0.023037144166634594,0.009771581599325972,0.0,0.03695635785540544,0.037069944516888706,0.03705386301258201,0.037247620852664046,0.0372296192967495,0.036995132763500714,0.03719100470851046,0.03698699592465253,0.04647552230353062,0.05289141079660704,0.0479148596626383,0.05898044145328178,0.04709750580981195,0.05199763837568527,0.062028566520712945,0.04480809870993544,0.04490153472258107,0.0826119879660345,0.04931656676499083,0.0,0.07162149940850779,0.03394896679886887,0.03666601242899132,0.07654132860468309,0.05723179973207428,0.002925618108391399,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0381515672845674,0.0,0.0592145816818417,0.0,0.0,0.02006713856691596,0.011359378585569966,0.008246297538290759,0.010245503752092813,0.03478266381566684,0.010300947981512364,0.008932402418652716,0.020087291910694253,0.017082170478559984,0.034501304548509644,0.020091244246665363,0.019973581912300857,0.00910855346004869,0.020227074663641695,0.014026492046316714,0.029433589786079486,0.01171240802471495,0.08814235192404223,0.02904089568012472,0.05239046291659968,0.027029026554002394,0.029439897199252395,0.028836027045405544,0.02914376051256186,0.030506182369795975,0.02997989346357689,0.029645642326964216,0.03002492892444601,0.03015920231408437,0.03015799132885547,0.030112419746114387,0.02944355951172062,0.02870384360110544,0.030117919996281283,0.030320496091440708,0.028553803353810223,0.02964851900056606,0.029782642372627365,0.029624779362756766,0.047015960915248525,0.029729988265560524,0.04272728273062881,0.03723757782124295,0.03652801987440897,0.04126450368483207,0.03997243542790255,0.03778558396379776,0.04953575645720527,0.03773041159765747,0.04299936448107228,0.029819541216888023,0.030240238313303767,0.05663299120700657,0.05749606593095289,0.05616581527779042,0.05651430274339923,0.026420126195350672,0.02630448190196971,0.05661774550021279,0.05635982572645134,0.03893507844678501,0.04637176770733725,0.04340426800430696,0.05691281608423413,0.05668954069379542,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05464631662881627,0.0,0.08141342651864006,0.02536139877351209,0.06861418804919471,0.07706052487818363,0.0,0.06406130340613587,0.06273263614904254,0.06745482486747102,0.003907177456287748,0.0019185998209283886,0.003385939684724426,0.0030637128252981962,0.003323710992474563,0.0027159342588330606,0.0032933027070275764,0.0031870953377131548,0.004014230443909727,0.002321350020935283,0.003867294443152607,0.002167925588541878,0.0030455217242197252,0.0033744134191764147,0.0027217632389313156,0.002833707753184054,0.0029610417595310676,0.0027141875939283777,0.0031348825027719446,0.0037124132582560623,0.0034332499923683127,0.005775682504066618,0.0053882886180709666,0.00592580921412247,0.0038614050408685603,0.007530256956985767,0.0053882886180709666,0.007030245275772044,0.0034299455973109206,0.006686333447792392,0.004578683550904469,0.005485343292228747,0.002814515016269493,0.005743304554941024,0.006129843991222145,0.008514073932705892,0.0039461880245149706,0.0036546813857542167,0.00226061564996971,0.008281399116428324,0.005270578568144187,0.005026433335725602,0.0059674801359220295,0.05570098837893972,0.005590731877949644,0.007298427233128932,0.0035277291965235564,0.006766306630677778,0.0065679044080311135,0.02304594288082741,0.03361574803795175,0.0,0.031722472035688586,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.029965618950330345,0.0,0.0,0.0,0.051112184436488683,0.052999649610356095,0.052147543067289935,0.01335741990753986,0.013049997300276457,0.013755188727725604,0.013048726750417364,0.01130163599410105,0.01269900245571411,0.013350785947385242,0.012899407737990157,0.013491099849520788,0.013054865986330206,0.013508966683078223,0.012927459908267042,0.013374585759515722,0.012500966139949497,0.023658253500303015,0.01258499140185752,0.026302016206737607,0.015942715350124398,0.01876276099206524,0.0,0.007776633979880805,0.007130530415062395,0.0075521090295456355,0.016403363820943984,0.004378874793075998,0.004408397121520499,0.004370924086502644,0.004371332260141942,0.004370049156568207,0.004405371648304342,0.05588099490740194,0.07421845585844287,0.03046001915448944,0.06411922564144419,0.05955520341753541,0.041625976268684646,0.04228777058675233,0.0,0.062091873309837634,0.0,0.0,0.10932185215220723,0.10811120873161686,0.11494134908546666,0.03271220840068144,0.03114806195347029,0.03566258168306194,0.032110295293874776,0.024471211819163445,0.0542667739190572,0.030486113725981187,0.03746070549853805,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.022408505333536756,0.0,0.0,0.0,0.0,0.002315042200687866,0.002415448256184114,0.10111401888316975],[0.042797328858508024,0.02403346581257759,0.02464057451276804,0.01186646919641146,0.012398917486121994,0.005720491336803538,0.03607302141837524,0.04552865849002876,0.042602029039263224,0.04028959257390786,0.04205287460353011,0.05001647409457967,0.04748794821186433,0.02452797024494241,0.017086186487153644,0.05485265949559267,0.03489997941959714,0.023569894723585134,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.029505527334750866,0.0,0.0539169859333931,0.025580187096119915,0.0,0.008730371613255575,0.022781119292195944,0.020440791621017362,0.006966051553653881,0.057520185355304225,0.0,0.0,0.0,0.0,0.0,0.0,0.002975073908980732,0.0,0.0,0.0,0.0,0.007998152683888803,0.0,0.0,0.0,0.004617918684616663,0.0,0.011488715225947943,0.002866725333480077,0.0,0.008190028047921377,0.0,0.012387395572675227,0.0,0.0162684291808533,0.005857286073642476,0.0,0.0,0.00901576053479522,0.016362392393177376,0.0,0.036808605959331955,0.00490542046379227,0.04785417653372145,0.0,0.030505163984145406,0.01232241481537949,0.0,0.0,0.043375895712375705,0.0,0.03896412322915781,0.01314055032106951,0.0034859829228725873,0.0061726942600614605,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01087189356960941,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.003313257218934362,0.00344654199165291,0.003609697966256569,0.003933426666645661,0.0036428373301746414,0.0036043848845550663,0.002594670141415161,0.0036976808481601077,0.0033692029849732054,0.0036021673041554494,0.003352077020748887,0.0036574642129611106,0.0035475980752971864,0.003755856169805904,0.0034114584824359285,0.0036100307988589384,0.0025071909873731544,0.009436590548124391,0.0055561235340952685,0.0,0.0038643860820857345,0.0026345804147858403,0.00388077059011276,0.0035969403566509833,0.004863743620758545,0.005660552624122143,0.005748741118256894,0.006427719513746637,0.015013358311758544,0.006811866648688641,0.00570146109780024,0.006038683272513576,0.02450610196996606,0.0,0.0406504858447718,0.01760000236589468,0.005334633099258829,0.02190184200524039,0.0,0.0022841438575123547,0.008062101589301969,0.0,0.0039569658898088835,0.012933566420785051,0.003920764021308965,0.0037943213376415105,0.0047790475695232175,0.0,0.0,0.0,0.0,0.0,0.0,0.0033736040667868283,0.0035251985709024557,0.003231312154406346,0.01119648172790603,0.0,0.004087374967843866,0.030942462867007574,0.03848940112018257,0.024691914381277356,0.0,0.0,0.03848940112018257,0.025109079113261313,0.024500645988515514,0.018573932780251743,0.0,0.04571312441204997,0.020104527633628504,0.0,0.025542095186110145,0.020272460638910996,0.0,0.03915895411142194,0.0,0.02464806198387531,0.02509905302948978,0.03590461138510082,0.024865550554175303,0.008289187580656967,0.01996774273413293,0.030411397641510046,0.025199129763205687,0.0,0.02345779200022015,0.0,0.0025012773494701448,0.012359809877435696,0.0,0.011509748553454869,0.006219101789136644,0.0,0.01160485183580231,0.010349503256205308,0.012662755070424006,0.005506049023217755,0.0315758705308556,0.007182470836255885,0.005945810386940821,0.010291753706714616,0.0,0.011813109830536694,0.0067611564579047705,0.006641840563940281,0.006535055786226772,0.0,0.0,0.0,0.0,0.013454896719043305,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.004994255097534065,0.0,0.0,0.0,0.07875729116600345,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0028925131817734455,0.006311359692547729,0.0,0.0,0.0030826976365376448,0.0,0.0,0.0776891751902374,0.006720183479404295,0.06396313814527657,0.07373445453794576,0.004487950272497692,0.004596759102633103,0.005068174729877106,0.0,0.0,0.0,0.0,0.004855604206159972,0.014909083933396804,0.006049087520930375,0.007432993532505799,0.008574158774217695,0.0,0.008203784413882576,0.0,0.010752982064906397,0.0,0.010694855362875549,0.0047646345035884455,0.0,0.0077098694133560875,0.01081389936033898,0.010699948875300572,0.010798226246342173,0.011732196063922413,0.0,0.0,0.009499496256270442,0.0,0.007117405476234369,0.0,0.008364032355971378,0.0,0.0,0.0,0.003835254484684921,0.007913520779021537,0.0,0.0,0.0,0.007081112658642844],[0.010800007332239401,0.009097353056300474,0.013990741551854122,0.008983594846730199,0.009386688608861262,0.012992215875708174,0.004551556209296366,0.00765950989051946,0.004607452697207807,0.00435736034551245,0.0045480610873910475,0.0,0.004493886089626673,0.0,0.008623479280744164,0.0,0.008807092491047424,0.0,0.009516753351291193,0.009546003426354385,0.009541862225248927,0.009591757444392389,0.00958712180447764,0.009526738405500416,0.00957717803476228,0.009524643061346635,0.007392039974220613,0.00297942778078419,0.007620969930627037,0.008393505258000686,0.0049939785988629935,0.008270345385853443,0.005324393442858723,0.01121816206616511,0.011241554719789187,0.003722894863490417,0.008334159376323789,0.0045353597132042605,0.0032276104089523057,0.0,0.006609389881414807,0.005748869426074593,0.005158282193583173,0.01582109652087247,0.006220866450162225,0.007062615106747316,0.006202203208062637,0.0030185384975542607,0.0027098144958659794,0.0036986790975651945,0.006219607280312638,0.004504601696592824,0.0061837594511541475,0.007969707282351614,0.0059040516699352,0.006119591992710354,0.004036705557767403,0.003308664313863801,0.002646326506937596,0.0034384622936090574,0.003496028162301807,0.0037306973022003913,0.002174403379620883,0.002170274789120141,0.003964681369866285,0.00206677298158558,0.0037745791221931017,0.006251977241595832,0.0041528090713043525,0.01642150658683498,0.0044343000530361444,0.004572706195277556,0.0077513323534771405,0.010238168389325935,0.007432359274718947,0.003078078959373338,0.0034832770950896674,0.0055705251414922725,0.004025371607895932,0.0077591169843122,0.0038490252018899126,0.0062191811454857865,0.007760643652879446,0.007715194230376882,0.004104753768204335,0.007813110859511026,0.004214009490042479,0.006632098011836479,0.007917264445732044,0.004673082062345786,0.004362409702699515,0.004970457043322129,0.0,0.026534076896889303,0.025989810828653315,0.010506867972684086,0.02749511601050192,0.010808309460310193,0.010687805705806885,0.01082454558197462,0.010872953637502214,0.010872517054793149,0.01085608765121771,0.010614951090548927,0.010348269740117932,0.010858070593751684,0.027327757613995664,0.019301582698152964,0.02672210700042393,0.026842991928922772,0.026700710547478707,0.010593830490158999,0.02679553496545606,0.01925497561857019,0.01678104965305129,0.016461288598916733,0.0,0.018013508474935203,0.0,0.0,0.017003144336878842,0.01937758878599474,0.02015718654663711,0.020441566168389245,0.017014372632000088,0.017273668047084335,0.01687401795224584,0.018522234326101304,0.02381236779966597,0.023708138000475814,0.012757344248380256,0.01269922869974318,0.008773012678179848,0.0,0.007824023141688955,0.013989633568383909,0.01277352143791369,0.0025083249267534094,0.002609229111268889,0.0,0.0,0.0,0.0,0.0019643134723200547,0.0,0.0,0.0027270463602144623,0.0,0.0,0.0,0.0,0.0025826688912581885,0.0,0.0018980867569896214,0.003572018972773715,0.004206302811942505,0.0,0.0029255609497810687,0.0019945278284398044,0.0029379649580367267,0.0027230892624553874,0.0,0.0,0.0,0.0,0.011365969618192348,0.0,0.004316331647540135,0.004571628091732146,0.0061841728916131825,0.0036554938372333787,0.005129123205727266,0.013324206884091954,0.004038621903994047,0.011053963439081382,0.0035215254446460554,0.0034584546840173533,0.0030517356550072644,0.0027613137079334875,0.0029956491512339884,0.004895724192447419,0.00593648453875868,0.008617553811031554,0.003618011929852786,0.002092224695732176,0.003485579023697467,0.003907887577444731,0.002744918131835229,0.003041347071979445,0.0024531157357018207,0.005108021873677364,0.00266877663364575,0.0024462878332233914,0.0028254586905750436,0.0033459851507259743,0.003094376270650116,0.007808403812912101,0.007284668670895992,0.010681822446568439,0.0034802709259135665,0.01018049158584035,0.007284668670895992,0.009504503403432327,0.006182796061767908,0.006026369068519424,0.0082535031018591,0.0049439208206722126,0.0076101377695409365,0.010352840818135034,0.011049614115714616,0.010231606942882747,0.007113371068070367,0.006587903229885932,0.010187425092661484,0.011195994307414924,0.007125531183331675,0.0,0.0107569381601805,0.003137694186898044,0.010077814372475003,0.0098670706007991,0.006359060097148341,0.009147672929929355,0.005919629387107415,0.003461871353368277,0.009468048976918197,0.0046785409578729035,0.008577406096130218,0.004356768474284095,0.004708215212076238,0.0033364720606428705,0.0043927677822105824,0.003917582499888855,0.005751857236378403,0.004168393547575324,0.006829924917895001,0.002718770298198353,0.004501318013610115,0.0038957226464388308,0.0034232975777518447,0.004471599379770029,0.00255929077587536,0.0025141263030902905,0.004947410431233848,0.0,0.0,0.0,0.0,0.006790750128383474,0.0,0.0,0.007750794203471867,0.008106320897521946,0.0,0.0,0.0,0.0,0.0,0.0035538502584574346,0.0037809363185328203,0.0,0.004789704621841779,0.007247490509590161,0.0,0.0,0.0,0.0,0.0,0.005919996919229015,0.005959909477066081,0.005909248002979029,0.005909799831200054,0.00590806514602121,0.005955819204344153,0.00875919065183678,0.009556119427163511,0.0,0.010835706551284345,0.007001334468554926,0.0,0.0,0.010693662228706149,0.010175125334318446,0.005380416483825317,0.011164238575934083,0.01019290395644836,0.010440027451104754,0.011510693104757995,0.009827799865107218,0.012477173264698318,0.004591794395376738,0.008268827830506462,0.0036759696757491744,0.007524685305945118,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0017960941343789225,0.0037593622925519298,0.0021106833809704157,0.005918805365741098,0.0033661179795124955,0.004183769715194247,0.0029035066669143407,0.0014977467878863478,0.0036619343987963674,0.01251923687576373,0.013062210646239757,0.005360806667625894]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"nticks\":36,\"title\":{\"text\":\"Summaries\"}},\"yaxis\":{\"nticks\":36,\"title\":{\"text\":\"Knowledge Base Entries\"}},\"font\":{\"size\":18},\"title\":{\"text\":\"Cosine Similarity between Summaries and Knowledge Base Entries\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('7de9e8d5-790f-43c5-b679-d871038e80ff');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'similarity_matrix' is already calculated as shown previously\n",
        "kb_entries_labels = [f\"{knowledge_base[i]}\" for i in range(40, len(knowledge_base))]\n",
        "summaries_labels = [f\"Summary {j+1}\" for j in range(10)]\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Create the heatmap\n",
        "fig = go.Figure(data=go.Heatmap(\n",
        "                   z=similarity_matrix[40:][:10],\n",
        "                   x=summaries_labels,\n",
        "                   y=kb_entries_labels,\n",
        "                   hoverongaps = False,\n",
        "                   colorscale = 'Viridis'))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Cosine Similarity between Summaries and Knowledge Base Entries',\n",
        "    xaxis_nticks=36,\n",
        "    yaxis_nticks=36,\n",
        "    xaxis_title=\"Summaries\",\n",
        "    yaxis_title=\"Knowledge Base Entries\",\n",
        "    font=dict(\n",
        "        size=18  # Adjust the font size here\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fTiew7zt2wu"
      },
      "source": [
        "## Design a classification algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAbemMzew4xg"
      },
      "source": [
        "### Encoded X_train and y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "x1jLs02Uw4xg",
        "outputId": "09d9f912-9780-453e-c7fe-18f31e987609"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <progress\n",
              "            value='544'\n",
              "            max='544',\n",
              "            style='width: 100%'\n",
              "        >\n",
              "            544\n",
              "        </progress>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       id                               fund_name  \\\n",
              "26   0000051931-18-000465                Managed Risk Growth Fund   \n",
              "7    0000051931-18-000151  American Funds College Enrollment Fund   \n",
              "426  0001591556-18-000016    Dreyfus Global Emerging Markets Fund   \n",
              "108  0000940394-18-000852                 Eaton Vance Growth Fund   \n",
              "423  0001580642-18-006021  Anchor Tactical Equity Strategies Fund   \n",
              "\n",
              "    Performance fee? Leverage?  \\\n",
              "26               NaN       Yes   \n",
              "7                NaN       Yes   \n",
              "426              NaN       Yes   \n",
              "108              NaN        No   \n",
              "423              NaN       Yes   \n",
              "\n",
              "                                 Portfolio composition  Concentration  \\\n",
              "26                         Investment grade securities    Diversified   \n",
              "7                          Investment grade securities    Diversified   \n",
              "426  Sub-investment grade securities or emerging ma...    Diversified   \n",
              "108                                    Listed Equities    Diversified   \n",
              "423                        Investment grade securities    Diversified   \n",
              "\n",
              "                                               summary  \n",
              "26   Managed Risk Growth Fund\\n\\nInvestment objecti...  \n",
              "7    American Funds College Enrollment Fund\\n\\nInve...  \n",
              "426  Fund Summary\\n\\nInvestment Objective\\nThe fund...  \n",
              "108  Eaton Vance Growth Fund\\n\\nInvestment Objectiv...  \n",
              "423  FUND SUMMARY - ANCHOR TACTICAL EQUITY STRATEGI...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-817dd435-a923-49a7-8c8c-87e101365e12\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>fund_name</th>\n",
              "      <th>Performance fee?</th>\n",
              "      <th>Leverage?</th>\n",
              "      <th>Portfolio composition</th>\n",
              "      <th>Concentration</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0000051931-18-000465</td>\n",
              "      <td>Managed Risk Growth Fund</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Investment grade securities</td>\n",
              "      <td>Diversified</td>\n",
              "      <td>Managed Risk Growth Fund\\n\\nInvestment objecti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0000051931-18-000151</td>\n",
              "      <td>American Funds College Enrollment Fund</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Investment grade securities</td>\n",
              "      <td>Diversified</td>\n",
              "      <td>American Funds College Enrollment Fund\\n\\nInve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>426</th>\n",
              "      <td>0001591556-18-000016</td>\n",
              "      <td>Dreyfus Global Emerging Markets Fund</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Sub-investment grade securities or emerging ma...</td>\n",
              "      <td>Diversified</td>\n",
              "      <td>Fund Summary\\n\\nInvestment Objective\\nThe fund...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>0000940394-18-000852</td>\n",
              "      <td>Eaton Vance Growth Fund</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>Listed Equities</td>\n",
              "      <td>Diversified</td>\n",
              "      <td>Eaton Vance Growth Fund\\n\\nInvestment Objectiv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>423</th>\n",
              "      <td>0001580642-18-006021</td>\n",
              "      <td>Anchor Tactical Equity Strategies Fund</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Investment grade securities</td>\n",
              "      <td>Diversified</td>\n",
              "      <td>FUND SUMMARY - ANCHOR TACTICAL EQUITY STRATEGI...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-817dd435-a923-49a7-8c8c-87e101365e12')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-817dd435-a923-49a7-8c8c-87e101365e12 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-817dd435-a923-49a7-8c8c-87e101365e12');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e4efd96c-643f-485e-ac2c-f3606cbcf100\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e4efd96c-643f-485e-ac2c-f3606cbcf100')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e4efd96c-643f-485e-ac2c-f3606cbcf100 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_train_new",
              "summary": "{\n  \"name\": \"X_train_new\",\n  \"rows\": 326,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 55,\n        \"samples\": [\n          \"0001193125-18-091654\",\n          \"0001683863-18-000339\",\n          \"0000932471-18-008471\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fund_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 326,\n        \"samples\": [\n          \"Variable Portfolio - BlackRock Global Inflation-Protected Securities Fund\",\n          \"AllianzGI Global Small-Cap Fund\",\n          \"JPMorgan New York Tax Free Bond Fund\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Performance fee?\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Some performance Fees\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Leverage?\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Portfolio composition\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Investment grade securities\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" Concentration\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Concentrated by issuer / sector / jurisdiction\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 325,\n        \"samples\": [\n          \"SUMMARY OF CTIVPSM \\u2013 BLACKROCK GLOBAL INFLATION-PROTECTED SECURITIES FUND\\nInvestment Objective\\nCTIVPSM \\u2013 BlackRock Global Inflation-Protected Securities Fund (the Fund) seeks to provide shareholders with total return that exceeds the rate of inflation over the long term.\\nFees and Expenses of the Fund\\nThis table describes the fees and expenses that you may pay as an investor in the Fund. The table does not reflect any fees or expenses imposed by your Contract or Qualified Plan, which are disclosed in your separate Contract prospectus or Qualified Plan disclosure documents. If the additional fees or expenses were reflected, the expenses set forth below would be higher.\\n    \\nAnnual Fund Operating Expenses (expenses that you pay each year as a percentage of the value of your investment)\\n \\tClass 1\\tClass 2\\tClass 3\\nManagement fees\\t0.51%\\t0.51%\\t0.51%\\nDistribution and/or service (12b-1) fees\\t0.00%\\t0.25%\\t0.13%\\nOther expenses\\t0.20%\\t0.20%\\t0.20%\\nTotal annual Fund operating expenses\\t0.71%\\t0.96%\\t0.84%\\nLess: Fee waivers and/or expense reimbursements(a)\\t(0.10%)\\t(0.10%)\\t(0.10%)\\nTotal annual Fund operating expenses after fee waivers and/or expense reimbursements\\t0.61%\\t0.86%\\t0.74%\\n(a)\\tColumbia Management Investment Advisers, LLC and certain of its affiliates have contractually agreed to waive fees and/or to reimburse expenses (excluding transaction costs and certain other investment related expenses, interest, taxes, acquired fund fees and expenses, and infrequent and/or unusual expenses) through April 30, 2019, unless sooner terminated at the sole discretion of the Fund\\u2019s Board of Trustees. Under this agreement, the Fund\\u2019s net operating expenses, subject to applicable exclusions, will not exceed the annual rates of 0.61% for Class 1, 0.86% for Class 2 and 0.735% for Class 3.\\nExample\\nThe following example is intended to help you compare the cost of investing in the Fund with the cost of investing in other mutual funds. The example illustrates the hypothetical expenses that you would incur over the time periods indicated, and assumes that:\\n\\u25a0\\tyou invest $10,000 in the applicable class of Fund shares for the periods indicated,\\n\\u25a0\\tyour investment has a 5% return each year, and\\n\\u25a0\\tthe Fund\\u2019s total annual operating expenses remain the same as shown in the Annual Fund Operating Expenses table above.\\nThe example does not reflect any fees and expenses that apply to your Contract or Qualified Plan. Inclusion of these charges would increase expenses for all periods shown.\\nSince the waivers and/or reimbursements shown in the Annual Fund Operating Expenses table above expire as indicated in the preceding table, they are only reflected in the 1 year example and the first year of the other examples. Although your actual costs may be higher or lower, based on the assumptions listed above, your costs would be:\\n    \\n \\t1 year\\t3 years\\t5 years\\t10 years\\nClass 1 (whether or not shares are redeemed)\\t$62\\t$217\\t$385\\t$ 873\\nClass 2 (whether or not shares are redeemed)\\t$88\\t$296\\t$521\\t$1,169\\nClass 3 (whether or not shares are redeemed)\\t$76\\t$258\\t$456\\t$1,028\\nPROSPECTUS 2018\\t111\\n \\n\\nTable of Contents\\nCOLUMBIA VARIABLE PORTFOLIO FUNDS\\nSUMMARY OF CTIVPSM \\u2013 BLACKROCK GLOBAL INFLATION-PROTECTED SECURITIES FUND (continued)\\nPortfolio Turnover\\nThe Fund may pay transaction costs, such as commissions, when it buys and sells securities (or \\u201cturns over\\u201d its portfolio). A higher portfolio turnover rate may indicate higher transaction costs. These costs, which are not reflected in annual fund operating expenses or in the example, affect the Fund\\u2019s performance. During the most recent fiscal year, the Fund\\u2019s portfolio turnover rate was 99% of the average value of its portfolio.\\nPrincipal Investment Strategies\\nUnder normal market conditions, the Fund invests at least 80% of its net assets (including the amount of any borrowings for investment purposes) in inflation-protected debt securities. These securities include inflation-indexed bonds of varying maturities issued by the U.S. Government and non-U.S. governments, their agencies or instrumentalities, and U.S. and non-U.S. corporations. The Fund invests only in securities rated investment grade at the time of purchase by a third-party rating agency or, if unrated, deemed by the management team to be of comparable quality. Up to 20% of the Fund\\u2019s net assets may be invested in sectors outside the Fund\\u2019s benchmark index, the Bloomberg Barclays World Government Inflation-Linked Bond Index USD Hedged (the Index). The Fund seeks to maintain an average duration that is within a range of plus or minus 20% of the duration of the Index.\\nUnder normal circumstances, the Fund generally invests at least 40% of its net assets in debt obligations of foreign governments, and companies that (a) maintain their principal place of business or conduct their principal business activities outside the U.S., (b) have their securities traded on non-U.S. exchanges or (c) have been formed under the laws of non-U.S. countries. This 40% minimum investment amount may be reduced to 30% if market conditions for these investments or specific foreign markets are deemed unfavorable. The Fund considers a company to conduct its principal business activities outside the U.S. if it derives at least 50% of its revenue from business outside the U.S. or has at least 50% of its assets outside the U.S. From time to time, the Fund may focus its investments in certain countries or geographic areas, including Europe.\\nThe Fund may invest in privately placed and other securities or instruments that are purchased and sold pursuant to Rule 144A or other exemptions under the Securities Act of 1933, as amended (the 1933 Act), subject to liquidity determinations and certain regulatory restrictions.\\nThe Fund may invest in derivatives, such as forward contracts (including forward foreign currency contracts), futures (including interest rate, other bond, and index futures), options (including options on futures and indices) and swaps (including interest rate swaps and inflation rate swaps). The Fund may enter into derivatives for investment purposes, for risk management (hedging) purposes, to increase flexibility, to produce incremental earnings, and to manage duration, yield curve and interest rate exposure. The Fund\\u2019s use of derivatives creates leverage (market exposure in excess of the Fund\\u2019s assets) in the Fund\\u2019s portfolio.\\nThe management team may hedge any portion of the non-U.S. dollar denominated securities in the Fund to the U.S. dollar.\\nThe Fund\\u2019s investment strategy may involve the frequent trading of portfolio securities.\\nThe Fund is non-diversified, which means that it can invest a greater percentage of its assets in the securities of fewer issuers than can a diversified fund.\\nPrincipal Risks\\nAn investment in the Fund involves risks, including those described below. There is no assurance that the Fund will achieve its investment objective and you may lose money. The value of the Fund\\u2019s holdings may decline, and the Fund\\u2019s net asset value (NAV) and share price may go down. An investment in the Fund is not a bank deposit and is not insured or guaranteed by the Federal Deposit Insurance Corporation or any other government agency.\\nActive Management Risk. Due to its active management, the Fund could underperform its benchmark index and/or other funds with similar investment objectives and/or strategies.\\n112\\tPROSPECTUS 2018\\n \\n\\nTable of Contents\\nCOLUMBIA VARIABLE PORTFOLIO FUNDS\\nSUMMARY OF CTIVPSM \\u2013 BLACKROCK GLOBAL INFLATION-PROTECTED SECURITIES FUND (continued)\\nCounterparty Risk. Counterparty risk is the risk that a counterparty to a transaction in a financial instrument held by the Fund or by a special purpose or structured vehicle invested in by the Fund may become insolvent or otherwise fail to perform its obligations. As a result, the Fund may obtain no or limited recovery of its investment, and any recovery may be significantly delayed.\\nCredit Risk. Credit risk is the risk that the value of debt instruments may decline if the issuer thereof defaults or otherwise becomes unable or unwilling, or is perceived to be unable or unwilling, to honor its financial obligations, such as making payments to the Fund when due. Rating agencies assign credit ratings to certain debt instruments to indicate their credit risk. Unless otherwise provided in the Fund\\u2019s Principal Investment Strategies, investment grade debt instruments are those rated at or above BBB- by Standard and Poor\\u2019s Ratings Services, or equivalently rated by Moody\\u2019s Investors Service, Inc. or Fitch, Inc., or, if unrated, determined by the management team to be of comparable quality. Conversely, below investment grade (commonly called \\u201chigh-yield\\u201d or \\u201cjunk\\u201d) debt instruments are those rated below BBB- by Standard and Poor\\u2019s Ratings Services, or equivalently rated by Moody\\u2019s Investors Service, Inc. or Fitch, Inc., or, if unrated, determined by the management team to be of comparable quality. A rating downgrade by such agencies can negatively impact the value of such instruments. Lower quality or unrated instruments held by the Fund may present increased credit risk as compared to higher-rated instruments. Non-investment grade debt instruments may be subject to greater price fluctuations and are more likely to experience a default than investment grade debt instruments and therefore may expose the Fund to increased credit risk. If the Fund purchases unrated instruments, or if the ratings of instruments held by the Fund are lowered after purchase, the Fund will depend on analysis of credit risk more heavily than usual.\\nDerivatives Risk. Derivatives may involve significant risks. Derivatives are financial instruments with a value in relation to, or derived from, the value of an underlying asset(s) or other reference, such as an index, rate or other economic indicator (each an underlying reference). Derivatives may include those that are privately placed or otherwise exempt from SEC registration, including certain Rule 144A eligible securities. Derivatives could result in Fund losses if the underlying reference does not perform as anticipated. Use of derivatives is a highly specialized activity that can involve investment techniques, risks, and tax planning different from those associated with more traditional investment instruments. The Fund\\u2019s derivatives strategy may not be successful and use of certain derivatives could result in substantial, potentially unlimited, losses to the Fund regardless of the Fund\\u2019s actual investment. A relatively small movement in the price, rate or other economic indicator associated with the underlying reference may result in substantial loss for the Fund. Derivatives may be more volatile than other types of investments. The value of derivatives may be influenced by a variety of factors, including national and international political and economic developments. Potential changes to the regulation of the derivatives markets may make derivatives more costly, may limit the market for derivatives, or may otherwise adversely affect the value or performance of derivatives. Derivatives can increase the Fund\\u2019s risk exposure to underlying references and their attendant risks, such as credit risk, market risk, foreign currency risk and interest rate risk, while exposing the Fund to correlation risk, counterparty risk, hedging risk, leverage risk, liquidity risk, pricing risk and volatility risk.\\nDerivatives Risk \\u2013 Forward Contracts Risk. A forward contract is an over-the-counter derivative transaction between two parties to buy or sell a specified amount of an underlying reference at a specified price (or rate) on a specified date in the future. Forward contracts are negotiated on an individual basis and are not standardized or traded on exchanges. The market for forward contracts is substantially unregulated and can experience lengthy periods of illiquidity, unusually high trading volume and other negative impacts, such as political intervention, which may result in volatility or disruptions in such markets. A relatively small price movement in a forward contract may result in substantial losses to the Fund, exceeding the amount of the margin paid. Forward contracts can increase the Fund\\u2019s risk exposure to underlying references and their attendant risks, such as credit risk, market risk, foreign currency risk and interest rate risk, while also exposing the Fund to correlation risk, counterparty risk, hedging risk, leverage risk, liquidity risk, pricing risk and volatility risk.\\nDerivatives Risk \\u2013 Futures Contracts Risk. A futures contract is an exchange-traded derivative transaction between two parties in which a buyer (holding the \\u201clong\\u201d position) agrees to pay a fixed price (or rate) at a specified future date for delivery of an underlying reference from a seller (holding the \\u201cshort\\u201d position). The seller hopes that the market price on the delivery date is less than the agreed upon price, while the buyer hopes for the contrary. Certain futures contract markets are highly volatile, and futures contracts may be illiquid. Futures exchanges may limit\\nPROSPECTUS 2018\\t113\\n \\n\\nTable of Contents\\nCOLUMBIA VARIABLE PORTFOLIO FUNDS\\nSUMMARY OF CTIVPSM \\u2013 BLACKROCK GLOBAL INFLATION-PROTECTED SECURITIES FUND (continued)\\nfluctuations in futures contract prices by imposing a maximum permissible daily price movement. The Fund may be disadvantaged if it is prohibited from executing a trade outside the daily permissible price movement. At or prior to maturity of a futures contract, the Fund may enter into an offsetting contract and may incur a loss to the extent there has been adverse movement in futures contract prices. The liquidity of the futures markets depends on participants entering into offsetting transactions rather than making or taking delivery. To the extent participants make or take delivery, liquidity in the futures market could be reduced. Because of the low margin deposits normally required in futures trading, it is possible that the Fund may employ a high degree of leverage in the portfolio. As a result, a relatively small price movement in a futures contract may result in substantial losses to the Fund, exceeding the amount of the margin paid. For certain types of futures contracts, losses are potentially unlimited. Futures markets are highly volatile and the use of futures may increase the volatility of the Fund\\u2019s NAV. Futures contracts executed (if any) on foreign exchanges may not provide the same protection as U.S. exchanges. Futures contracts can increase the Fund\\u2019s risk exposure to underlying references and their attendant risks, such as credit risk, market risk, foreign currency risk and interest rate risk, while also exposing the Fund to correlation risk, counterparty risk, hedging risk, leverage risk, liquidity risk, pricing risk and volatility risk.\\nDerivatives Risk \\u2013 Options Risk. Options are derivatives that give the purchaser the option to buy (call) or sell (put) an underlying reference from or to a counterparty at a specified price (the strike price) on or before an expiration date. By investing in options, the Fund is exposed to the risk that it may be required to buy or sell the underlying reference at a disadvantageous price on or before the expiration date. Options may involve economic leverage, which could result in greater volatility in price movement. The Fund's losses could be significant, and are potentially unlimited for certain types of options. Options may be traded on a securities exchange or in the over-the-counter market. At or prior to maturity of an options contract, the Fund may enter into an offsetting contract and may incur a loss to the extent there has been adverse movement in options prices. Options can increase the Fund\\u2019s risk exposure to underlying references and their attendant risks such as credit risk, market risk, foreign currency risk and interest rate risk, while also exposing the Fund to correlation risk, counterparty risk, hedging risk, leverage risk, liquidity risk, pricing risk and volatility risk.\\nDerivatives Risk \\u2013 Swaps Risk. In a typical swap transaction, two parties agree to exchange the return earned on a specified underlying reference for a fixed return or the return from another underlying reference during a specified period of time. Swaps may be difficult to value and may be illiquid. Swaps could result in Fund losses if the underlying asset or reference does not perform as anticipated. Swaps create significant investment leverage such that a relatively small price movement in a swap may result in immediate and substantial losses to the Fund. The Fund may only close out a swap with its particular counterparty, and may only transfer a position with the consent of that counterparty. Certain swaps, such as short swap transactions and total return swaps, have the potential for unlimited losses, regardless of the size of the initial investment. Swaps can increase the Fund\\u2019s risk exposure to underlying references and their attendant risks, such as credit risk, market risk, foreign currency risk and interest rate risk, while also exposing the Fund to correlation risk, counterparty risk, hedging risk, inflation risk, leverage risk, liquidity risk, pricing risk and volatility risk.\\nForeign Securities Risk. Investments in or exposure to foreign securities involve certain risks not associated with investments in or exposure to securities of U.S. companies. Foreign securities subject the Fund to the risks associated with investing in the particular country of an issuer, including political, regulatory, economic, social, diplomatic and other conditions or events (including, for example, military confrontations, war and terrorism), occurring in the country or region, as well as risks associated with less developed custody and settlement practices. Foreign securities may be more volatile and less liquid than securities of U.S. companies, and are subject to the risks associated with potential imposition of economic and other sanctions against a particular foreign country, its nationals or industries or businesses within the country. In addition, foreign governments may impose withholding or other taxes on the Fund\\u2019s income, capital gains or proceeds from the disposition of foreign securities, which could reduce the Fund\\u2019s return on such securities. The performance of the Fund may also be negatively affected by fluctuations in a foreign currency's strength or weakness relative to the U.S. dollar, particularly to the extent the Fund invests a significant percentage of its assets in foreign securities or other assets denominated in currencies other than the U.S. dollar.\\n114\\tPROSPECTUS 2018\\n \\n\\nTable of Contents\\nCOLUMBIA VARIABLE PORTFOLIO FUNDS\\nSUMMARY OF CTIVPSM \\u2013 BLACKROCK GLOBAL INFLATION-PROTECTED SECURITIES FUND (continued)\\nFrequent Trading Risk. The portfolio managers may actively and frequently trade investments in the Fund's portfolio to carry out its investment strategies. Frequent trading can mean higher brokerage and other transaction costs, which could reduce the Fund's return. The trading costs associated with portfolio turnover may adversely affect the Fund\\u2019s performance.\\nGeographic Focus Risk. The Fund may be particularly susceptible to economic, political, regulatory or other events or conditions affecting issuers and countries within the specific geographic regions in which the Fund invests. The Fund\\u2019s NAV may be more volatile than the NAV of a more geographically diversified fund.\\nEurope. The Fund is particularly susceptible to economic, political, regulatory or other events or conditions affecting issuers and countries in Europe. In addition, the private and public sectors\\u2019 debt problems of a single European Union (EU) country can pose significant economic risks to the EU as a whole. As a result, the Fund\\u2019s NAV may be more volatile than the NAV of a more geographically diversified fund. If securities of issuers in Europe fall out of favor, it may cause the Fund to underperform other funds that do not focus their investments in this region of the world. The impact of any partial or complete dissolution of the EU on European economies could be significant, resulting in negative impacts on currency and financial markets generally, such as increased volatility and illiquidity, and potentially lower economic growth in markets in Europe, which may adversely affect the value of your investment in the Fund.\\nInflation-Protected Securities Risk. Inflation-protected debt securities tend to react to changes in real interest rates (i.e., nominal interest rates minus the expected impact of inflation). In general, the price of such securities falls when real interest rates rise, and rises when real interest rates fall. Interest payments on these securities will vary and may be more volatile than interest paid on ordinary bonds. In periods of deflation, the Fund may have no income at all from such investments.\\nInterest Rate Risk. Interest rate risk is the risk of losses attributable to changes in interest rates. In general, if prevailing interest rates rise, the values of debt instruments tend to fall, and if interest rates fall, the values of debt instruments tend to rise. Changes in the value of a debt instrument usually will not affect the amount of income the Fund receives from it but will generally affect the value of your investment in the Fund. Changes in interest rates may also affect the liquidity of the Fund\\u2019s investments in debt instruments. In general, the longer the maturity or duration of a debt instrument, the greater its sensitivity to changes in interest rates. Interest rate declines also may increase prepayments of debt obligations, which, in turn, would increase prepayment risk. Similarly, a period of rising interest rates may negatively impact the Fund\\u2019s performance. Actions by governments and central banking authorities can result in increases in interest rates. Such actions may negatively affect the value of debt instruments held by the Fund, resulting in a negative impact on the Fund's performance and NAV. Any interest rate increases could cause the value of the Fund\\u2019s investments in debt instruments to decrease. Rising interest rates may prompt redemptions from the Fund, which may force the Fund to sell investments at a time when it is not advantageous to do so, which could result in losses.\\nIssuer Risk. An issuer in which the Fund invests or to which it has exposure may perform poorly, and the value of its securities may therefore decline, which would negatively affect the Fund\\u2019s performance. Poor performance may be caused by poor management decisions, competitive pressures, breakthroughs in technology, reliance on suppliers, labor problems or shortages, corporate restructurings, fraudulent disclosures, natural disasters or other events, conditions or factors.\\nLeverage Risk. Leverage occurs when the Fund increases its assets available for investment using borrowings, derivatives, or similar instruments or techniques. Use of leverage can produce volatility and may exaggerate changes in the NAV of Fund shares and in the return on the Fund\\u2019s portfolio, which may increase the risk that the Fund will lose more than it has invested. If the Fund uses leverage, through the purchase of particular instruments such as derivatives, the Fund may experience capital losses that exceed the net assets of the Fund. Leverage can create an interest expense that may lower the Fund's overall returns. Leverage presents the opportunity for increased net income and capital gains, but may also exaggerate the Fund\\u2019s volatility and risk of loss. There can be no guarantee that a leveraging strategy will be successful.\\nPROSPECTUS 2018\\t115\\n \\n\\nTable of Contents\\nCOLUMBIA VARIABLE PORTFOLIO FUNDS\\nSUMMARY OF CTIVPSM \\u2013 BLACKROCK GLOBAL INFLATION-PROTECTED SECURITIES FUND (continued)\\nLiquidity Risk. Liquidity risk is the risk associated with any event, circumstance, or characteristic of an investment or market that negatively impacts the Fund\\u2019s ability to sell, or realize the proceeds from the sale of, an investment at a desirable time or price. Liquidity risk may arise because of, for example, a lack of marketability of the investment, which means that when seeking to sell its portfolio investments, the Fund could find that selling is more difficult than anticipated, especially during times of high market volatility. Decreases in the number of financial institutions, including banks and broker-dealers, willing to make markets (match up sellers and buyers) in the Fund\\u2019s investments or decreases in their capacity or willingness to trade such investments may increase the Fund\\u2019s exposure to this risk. The debt market has experienced considerable growth, and financial institutions making markets in instruments purchased and sold by the Fund (e.g., bond dealers) have been subject to increased regulation. The impact of that growth and regulation on the ability and willingness of financial institutions to engage in trading or \\u201cmaking a market\\u201d in such instruments remains unsettled. Certain types of investments, such as lower-rated securities or those that are purchased and sold in over-the-counter markets, may be especially subject to liquidity risk. Securities or other assets in which the Fund invests may be traded in the over-the-counter market rather than on an exchange and therefore may be more difficult to purchase or sell at a fair price, which may have a negative impact on the Fund\\u2019s performance. Market participants attempting to sell the same or a similar instrument at the same time as the Fund could exacerbate the Fund\\u2019s exposure to liquidity risk. The Fund may have to accept a lower selling price for the holding, sell other liquid or more liquid investments that it might otherwise prefer to hold (thereby increasing the proportion of the Fund\\u2019s investments in less liquid or illiquid securities), or forego another more appealing investment opportunity. Certain investments that were liquid when purchased by the Fund may later become illiquid, particularly in times of overall economic distress. Changing regulatory, market or other conditions or environments (for example, the interest rate or credit environments) may also adversely affect the liquidity and the price of the Fund's investments. Judgment plays a larger role in valuing illiquid or less liquid investments as compared to valuing liquid or more liquid investments. Price volatility may be higher for illiquid or less liquid investments as a result of, for example, the relatively less frequent pricing of such securities (as compared to liquid or more liquid investments). Generally, the less liquid the market at the time the Fund sells a portfolio investment, the greater the risk of loss or decline of value to the Fund. Overall market liquidity and other factors can lead to an increase in redemptions, which may negatively impact Fund performance and NAV, including, for example, if the Fund is forced to sell investments in a down market. Foreign securities can present enhanced liquidity risks, including as a result of less developed custody, settlement or other practices of foreign markets.\\nMarket Risk. Market risk refers to the possibility that the market values of securities or other investments that the Fund holds will fall, sometimes rapidly or unpredictably, or fail to rise. An investment in the Fund could lose money over short or long periods.\\nNon-Diversified Fund Risk. The Fund is non-diversified, which generally means that it will invest a greater percentage of its total assets in the securities of fewer issuers than a \\u201cdiversified\\u201d fund. This increases the risk that a change in the value of any one investment held by the Fund could affect the overall value of the Fund more than it would affect that of a diversified fund holding a greater number of investments. Accordingly, the Fund's value will likely be more volatile than the value of a more diversified fund.\\nPrepayment and Extension Risk. Prepayment and extension risk is the risk that a bond or other security or investment might, in the case of prepayment risk, be called or otherwise converted, prepaid or redeemed before maturity and, in the case of extension risk, that the investment might not be called as expected. In the case of prepayment risk, if the investment is converted, prepaid or redeemed before maturity, the portfolio managers may not be able to invest the proceeds in other investments providing as high a level of income, resulting in a reduced yield to the Fund. In the case of mortgage- or asset-backed securities, as interest rates decrease or spreads narrow, the likelihood of prepayment increases. Conversely, extension risk is the risk that an unexpected rise in interest rates will extend the life of a mortgage- or asset-backed security beyond the prepayment time. If the Fund\\u2019s investments are locked in at a lower interest rate for a longer period of time, the portfolio managers may be unable to capitalize on securities with higher interest rates or wider spreads.\\nReinvestment Risk. Reinvestment risk is the risk that the Fund will not be able to reinvest income or principal at the same return it is currently earning.\\n116\\tPROSPECTUS 2018\\n \\n\\nTable of Contents\\nCOLUMBIA VARIABLE PORTFOLIO FUNDS\\nSUMMARY OF CTIVPSM \\u2013 BLACKROCK GLOBAL INFLATION-PROTECTED SECURITIES FUND (continued)\\nRule 144A and Other Exempted Securities Risk. The Fund may invest in privately placed and other securities or instruments exempt from SEC registration (collectively \\u201cprivate placements\\u201d), subject to liquidity and other regulatory restrictions. In the U.S. market, private placements are typically sold only to qualified institutional buyers, or qualified purchasers, as applicable. An insufficient number of buyers interested in purchasing private placements at a particular time could adversely affect the marketability of such investments and the Fund might be unable to dispose of them promptly or at reasonable prices, subjecting the Fund to liquidity risk. The Fund may invest in private placements determined to be liquid as well as those determined to be illiquid. Even if determined to be liquid, the Fund\\u2019s holdings of private placements may increase the level of Fund illiquidity if eligible buyers are unable or unwilling to purchase them at a particular time. Issuers of Rule 144A eligible securities are required to furnish information to potential investors upon request. However, the required disclosure is much less extensive than that required of public companies and is not publicly available since the offering is not filed with the SEC. Further, issuers of Rule 144A eligible securities can require recipients of the offering information (such as the Fund) to agree contractually to keep the information confidential, which could also adversely affect the Fund\\u2019s ability to dispose of the security.\\nSovereign Debt Risk. A sovereign debtor\\u2019s willingness or ability to repay principal and pay interest in a timely manner may be affected by a variety of factors, including its cash flow situation, the extent of its reserves, the availability of sufficient foreign exchange on the date a payment is due, the relative size of the debt service burden to the economy as a whole, the sovereign debtor\\u2019s policy toward international lenders, and the political constraints to which a sovereign debtor may be subject.\\nU.S. Government Obligations Risk. While U.S. Treasury obligations are backed by the \\u201cfull faith and credit\\u201d of the U.S. Government, such securities are nonetheless subject to credit risk (i.e., the risk that the U.S. Government may be, or be perceived to be, unable or unwilling to honor its financial obligations, such as making payments). Securities issued or guaranteed by federal agencies or authorities and U.S. Government-sponsored instrumentalities or enterprises may or may not be backed by the full faith and credit of the U.S. Government.\\nPerformance Information\\nThe following bar chart and table show you how the Fund has performed in the past, and can help you understand the risks of investing in the Fund. The bar chart shows how the Fund\\u2019s Class 3 share performance has varied for each full calendar year shown. The table below the bar chart compares the Fund\\u2019s returns for the periods shown with a broad measure of market performance.\\nThe performance of one or more share classes shown in the table below begins before the indicated inception date for such share class. The returns shown for each such share class include the returns of the Fund\\u2019s Class 3 shares (adjusted to reflect the higher class-related operating expenses of such classes, where applicable) for periods prior to its inception date. Except for differences in annual returns resulting from differences in expenses (where applicable), the share classes of the Fund would have substantially similar annual returns because all share classes of the Fund invest in the same portfolio of securities.\\nThe returns shown do not reflect any fees and expenses imposed under your Contract or Qualified Plan and would be lower if they did.\\nThe Fund\\u2019s performance prior to October 2012 reflects returns achieved by the Investment Manager according to different principal investment strategies. If the Fund\\u2019s current subadviser and strategies had been in place for the prior periods, results shown may have been different.\\nThe Fund\\u2019s past performance is no guarantee of how the Fund will perform in the future. Updated performance information can be obtained by calling toll-free 800.345.6611.\\n    \\nPROSPECTUS 2018\\t117\\n \\n\\nTable of Contents\\nCOLUMBIA VARIABLE PORTFOLIO FUNDS\\nSUMMARY OF CTIVPSM \\u2013 BLACKROCK GLOBAL INFLATION-PROTECTED SECURITIES FUND (continued)\\nYear by Year Total Return (%)\\nas of December 31 Each Year\\tBest and Worst Quarterly Returns\\nDuring the Period Shown in the Bar Chart\\n\\nBest\\t1st Quarter 2008\\t4.13%\\nWorst\\n2nd Quarter 2013\\t-5.80%\\nAverage Annual Total Returns (for periods ended December 31, 2017)\\n \\tShare Class\\nInception Date\\t1 Year\\t5 Years\\t10 Years\\nClass 1\\t05/03/2010\\t2.66%\\t2.49%\\t3.93%\\nClass 2\\t05/03/2010\\t2.46%\\t2.26%\\t3.72%\\nClass 3\\t09/13/2004\\t2.54%\\t2.38%\\t3.83%\\nBloomberg Barclays World Government Inflation-Linked Bond Index USD Hedged (reflects no deductions for fees, expenses or taxes)\\t \\t3.32%\\t3.02%\\t4.61%\\n  \\nFund Management\\nInvestment Manager: Columbia Management Investment Advisers, LLC\\nSubadviser: BlackRock Financial Management, Inc. (BlackRock)\\nSub-Subadviser: BlackRock International Limited (BIL)\\n    \\nPortfolio Manager\\t \\tTitle\\t \\tRole with Fund\\t \\tManaged Fund Since\\nChristopher Allen, CFA\\t \\tManaging Director of BIL\\t \\tCo-Portfolio Manager\\t \\tMay 2018\\nAkiva Dickstein\\t \\tManaging Director of BlackRock\\t \\tCo-Portfolio Manager\\t \\tMarch 2018\\nPurchase and Sale of Fund Shares\\nThe Fund is available for purchase through Contracts offered by the separate accounts of participating insurance companies or Qualified Plans or by other eligible investors authorized by Columbia Management Investment Distributors, Inc. (the Distributor). Shares of the Fund may not be purchased or sold by individual owners of Contracts or Qualified Plans. If you are a Contract holder or Qualified Plan participant, please refer to your separate Contract prospectus or Qualified Plan disclosure documents for information about minimum investment requirements and how to purchase and redeem shares of the Fund on days the Fund is open for business.\\nTax Information\\nThe Fund normally distributes its net investment income and net realized capital gains, if any, to its shareholders, which are generally the participating insurance companies and Qualified Plans investing in the Fund through separate accounts. These distributions may not be taxable to you as the holder of a Contract or a participant in a Qualified Plan. Please consult the prospectus or other information provided to you by your participating insurance company and/or Qualified Plan regarding the U.S. federal income taxation of your contract, policy and/or plan.\\n118\\tPROSPECTUS 2018\\n \\n\\nTable of Contents\\nCOLUMBIA VARIABLE PORTFOLIO FUNDS\\nSUMMARY OF CTIVPSM \\u2013 BLACKROCK GLOBAL INFLATION-PROTECTED SECURITIES FUND (continued)\\nPayments to Broker-Dealers and Other Financial Intermediaries\\nIf you make allocations to the Fund, the Fund, its Distributor or other related companies may pay participating insurance companies or other financial intermediaries for the allocation (sale) of Fund shares and related services in connection with such allocations to the Fund. These payments may create a conflict of interest by influencing the participating insurance company, other financial intermediary or your salesperson to recommend an allocation to the Fund over another fund or other investment option. Ask your financial advisor or salesperson or visit your financial intermediary\\u2019s website for more information.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Function to get data (Assuming you have this defined)\n",
        "fund_names, summaries = get_data(SUMMARY_PATH)\n",
        "fund_names_in_X_train = X_train['fund_name'].tolist()\n",
        "\n",
        "# Correctly filter summaries where the fund name is in X_test\n",
        "# and ensure alignment between fund names and summaries\n",
        "selected_summaries_in_X_train = []\n",
        "fund_names_with_summaries = []\n",
        "\n",
        "for fund_name, summary in zip(fund_names, summaries):\n",
        "    if fund_name in fund_names_in_X_train:\n",
        "        selected_summaries_in_X_train.append(summary)\n",
        "        fund_names_with_summaries.append(fund_name)\n",
        "\n",
        "# Create DataFrame from extracted summaries\n",
        "df_extraction = pd.DataFrame({\n",
        "    'fund_name': fund_names_with_summaries,\n",
        "    'summary': selected_summaries_in_X_train\n",
        "})\n",
        "\n",
        "original_index = X_train.index\n",
        "X_train_new = X_train.merge(df_extraction, on='fund_name', how='left')\n",
        "X_train_new.index = original_index\n",
        "\n",
        "\n",
        "# Drop rows where the 'summary' is NaN and reset index\n",
        "X_train_new = X_train_new.dropna(subset=['summary'])\n",
        "\n",
        "X_train_new.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-RlCijEw4xg",
        "outputId": "14b4f054-219e-4306-de3b-9c2598527f40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26           Equity Long Only (Low Risk)\n",
              "7      Fixed Income Long Only (Low Risk)\n",
              "426          Equity Long Only (Low Risk)\n",
              "108          Equity Long Only (Low Risk)\n",
              "423         Long Short Funds (High Risk)\n",
              "Name: Ivestment Strategy, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "y_train_new = y_train.reindex(X_train_new.index)\n",
        "\n",
        "y_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "id": "RCXaRmNcw4xg",
        "outputId": "372db2be-23e5-4ee5-f40c-ea395cde8bc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Leverage?  Portfolio composition   Concentration\n",
            "26           1                      0               0\n",
            "7            1                      0               0\n",
            "426          1                      2               0\n",
            "108          0                      1               0\n",
            "423          1                      0               0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Leverage?  Portfolio composition   Concentration  Max Similarity  \\\n",
              "26         1.0                    0.0             0.0        0.089562   \n",
              "7          1.0                    0.0             0.0        0.098075   \n",
              "426        1.0                    2.0             0.0        0.100553   \n",
              "108        0.0                    1.0             0.0        0.097251   \n",
              "423        1.0                    0.0             0.0        0.089518   \n",
              "..         ...                    ...             ...             ...   \n",
              "106        1.0                    1.0             0.0        0.147868   \n",
              "270        0.0                    1.0             0.0        0.088066   \n",
              "348        0.0                    1.0             1.0        0.107280   \n",
              "435        0.0                    1.0             0.0        0.106517   \n",
              "102        0.0                    0.0             0.0        0.106695   \n",
              "\n",
              "     Mean Similarity  \n",
              "26          0.019225  \n",
              "7           0.022875  \n",
              "426         0.022063  \n",
              "108         0.022169  \n",
              "423         0.020525  \n",
              "..               ...  \n",
              "106         0.021592  \n",
              "270         0.018145  \n",
              "348         0.019033  \n",
              "435         0.019398  \n",
              "102         0.022595  \n",
              "\n",
              "[326 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ba8f272-2875-49b9-84a8-23f1cb152714\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Leverage?</th>\n",
              "      <th>Portfolio composition</th>\n",
              "      <th>Concentration</th>\n",
              "      <th>Max Similarity</th>\n",
              "      <th>Mean Similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.089562</td>\n",
              "      <td>0.019225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.098075</td>\n",
              "      <td>0.022875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>426</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.100553</td>\n",
              "      <td>0.022063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.097251</td>\n",
              "      <td>0.022169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>423</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.089518</td>\n",
              "      <td>0.020525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.147868</td>\n",
              "      <td>0.021592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.088066</td>\n",
              "      <td>0.018145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>348</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.107280</td>\n",
              "      <td>0.019033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.106517</td>\n",
              "      <td>0.019398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.106695</td>\n",
              "      <td>0.022595</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>326 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ba8f272-2875-49b9-84a8-23f1cb152714')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8ba8f272-2875-49b9-84a8-23f1cb152714 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8ba8f272-2875-49b9-84a8-23f1cb152714');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6c8b9d38-f09a-45db-ab26-8527042895e2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6c8b9d38-f09a-45db-ab26-8527042895e2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6c8b9d38-f09a-45db-ab26-8527042895e2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_train_final",
              "summary": "{\n  \"name\": \"X_train_final\",\n  \"rows\": 326,\n  \"fields\": [\n    {\n      \"column\": \"Leverage?\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4943570194414875,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Portfolio composition\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7678841445569835,\n        \"min\": 0.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" Concentration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.40470335327607837,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Max Similarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05171950773396436,\n        \"min\": 0.05772239795782152,\n        \"max\": 0.3617669862730344,\n        \"num_unique_values\": 325,\n        \"samples\": [\n          0.28396230115470905,\n          0.08856948627202624\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mean Similarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.003780209680810094,\n        \"min\": 0.009745885098714368,\n        \"max\": 0.030596185643902925,\n        \"num_unique_values\": 325,\n        \"samples\": [\n          0.030596185643902925,\n          0.01769563692834522\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "X_train_new = X_train_new.drop(columns =[\"id\", \"fund_name\", \"summary\", 'Performance fee?'])\n",
        "X_train_new['Leverage?'] = LabelEncoder().fit_transform(X_train_new['Leverage?'])\n",
        "\n",
        "# performance_mapping = {\n",
        "#     \"None\": 0,\n",
        "#     \"Some performance Fees\": 1\n",
        "# }\n",
        "\n",
        "portfolio_composition_mapping = {\n",
        "    \"Investment grade securities\": 0,\n",
        "    \"Listed Equities\": 1,\n",
        "    \"Sub-investment grade securities or emerging markets\": 2\n",
        "}\n",
        "\n",
        "concentration_mapping = {\n",
        "    \"Diversified\": 0,\n",
        "    \"Concentrated by issuer / sector / jurisdiction\": 1\n",
        "}\n",
        "\n",
        "# X_train_new['Performance fee?'] = X_train_new['Performance fee?'].map(performance_mapping)\n",
        "X_train_new['Portfolio composition'] = X_train_new['Portfolio composition'].map(portfolio_composition_mapping)\n",
        "X_train_new[' Concentration'] = X_train_new[' Concentration'].map(concentration_mapping)\n",
        "\n",
        "# Print the first few rows to confirm changes\n",
        "print(X_train_new.head())\n",
        "\n",
        "# Assume 'knowledge_base' is a list of documents/texts you have defined elsewhere\n",
        "all_texts = selected_summaries_in_X_train + knowledge_base\n",
        "\n",
        "# Create a TF-IDF Vectorizer and vectorize all texts\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(all_texts)\n",
        "\n",
        "# Extract TF-IDF vectors for summaries and KB entries\n",
        "tfidf_summaries = tfidf_matrix[:len(selected_summaries_in_X_train)]\n",
        "tfidf_kb_entries = tfidf_matrix[len(selected_summaries_in_X_train):]\n",
        "\n",
        "# Calculate cosine similarity between each summary and each KB entry\n",
        "similarity_matrix = cosine_similarity(tfidf_summaries, tfidf_kb_entries)\n",
        "\n",
        "max_similarity = similarity_matrix.max(axis=1)\n",
        "mean_similarity = similarity_matrix.mean(axis=1)\n",
        "\n",
        "X_train_features = np.column_stack((max_similarity, mean_similarity))\n",
        "\n",
        "X_train_combined = np.hstack((X_train_new.values, X_train_features))\n",
        "\n",
        "X_train_final = pd.DataFrame(X_train_combined, columns=list(X_train_new.columns) + ['Max Similarity', 'Mean Similarity'])\n",
        "\n",
        "X_train_final.index = X_train_new.index\n",
        "\n",
        "X_train_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSp0yVFYw4xh",
        "outputId": "daa532b3-f2d3-4dc8-b28e-1f7c86233407"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26     2\n",
              "7      1\n",
              "426    2\n",
              "108    2\n",
              "423    3\n",
              "Name: Ivestment Strategy, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# Encoded investment strategy\n",
        "investment_strategy_mapping = {\n",
        "    \"Balanced Fund (Low Risk)\": 0,\n",
        "    \"Fixed Income Long Only (Low Risk)\": 1,\n",
        "    \"Equity Long Only (Low Risk)\": 2,\n",
        "    \"Long Short Funds (High Risk)\": 3,\n",
        "    \"Commodities Fund (Low Risk)\": 4\n",
        "}\n",
        "\n",
        "# Apply the mapping to the 'Investment Strategy' column\n",
        "y_train_mapped = y_train.map(investment_strategy_mapping)\n",
        "y_train_mapped.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c45rEMXWw4xh"
      },
      "source": [
        "### Encoded X_val and y_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "NSw3o5WKw4xh",
        "outputId": "3db09862-c24a-4335-8700-8216ce7e9edc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <progress\n",
              "            value='544'\n",
              "            max='544',\n",
              "            style='width: 100%'\n",
              "        >\n",
              "            544\n",
              "        </progress>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       id                                          fund_name  \\\n",
              "56   0000051931-18-001409    American Funds 2060 Target Date Retirement Fund   \n",
              "181  0001193125-18-020442                        Janus Henderson Triton Fund   \n",
              "329  0001379491-18-002694                 Fidelity Advisor Freedom 2020 Fund   \n",
              "271  0001193125-18-227777                             Ivy Global Growth Fund   \n",
              "31   0000051931-18-000465  Portfolio Series - American Funds Global Growt...   \n",
              "\n",
              "    Performance fee? Leverage?  \\\n",
              "56               NaN        No   \n",
              "181              NaN        No   \n",
              "329              NaN       Yes   \n",
              "271              NaN        No   \n",
              "31               NaN        No   \n",
              "\n",
              "                                 Portfolio composition  Concentration  \\\n",
              "56                         Investment grade securities    Diversified   \n",
              "181                                    Listed Equities    Diversified   \n",
              "329  Sub-investment grade securities or emerging ma...    Diversified   \n",
              "271                                    Listed Equities    Diversified   \n",
              "31   Sub-investment grade securities or emerging ma...    Diversified   \n",
              "\n",
              "                                               summary  \n",
              "56   American Funds 2060 Target Date Retirement Fun...  \n",
              "181  Janus Henderson Triton Fund\\n(closed to certai...  \n",
              "329  Fund Summary\\n\\nFund/Class:\\nFidelity Freedom®...  \n",
              "271  Ivy Global Growth Fund\\n\\nObjective\\n\\nTo seek...  \n",
              "31   American Funds Global Growth Portfolio\\n\\nInve...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3fb94d7a-5e64-4420-b5be-44fb9b04840d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>fund_name</th>\n",
              "      <th>Performance fee?</th>\n",
              "      <th>Leverage?</th>\n",
              "      <th>Portfolio composition</th>\n",
              "      <th>Concentration</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>0000051931-18-001409</td>\n",
              "      <td>American Funds 2060 Target Date Retirement Fund</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>Investment grade securities</td>\n",
              "      <td>Diversified</td>\n",
              "      <td>American Funds 2060 Target Date Retirement Fun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>0001193125-18-020442</td>\n",
              "      <td>Janus Henderson Triton Fund</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>Listed Equities</td>\n",
              "      <td>Diversified</td>\n",
              "      <td>Janus Henderson Triton Fund\\n(closed to certai...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>329</th>\n",
              "      <td>0001379491-18-002694</td>\n",
              "      <td>Fidelity Advisor Freedom 2020 Fund</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Sub-investment grade securities or emerging ma...</td>\n",
              "      <td>Diversified</td>\n",
              "      <td>Fund Summary\\n\\nFund/Class:\\nFidelity Freedom®...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>0001193125-18-227777</td>\n",
              "      <td>Ivy Global Growth Fund</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>Listed Equities</td>\n",
              "      <td>Diversified</td>\n",
              "      <td>Ivy Global Growth Fund\\n\\nObjective\\n\\nTo seek...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0000051931-18-000465</td>\n",
              "      <td>Portfolio Series - American Funds Global Growt...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>Sub-investment grade securities or emerging ma...</td>\n",
              "      <td>Diversified</td>\n",
              "      <td>American Funds Global Growth Portfolio\\n\\nInve...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3fb94d7a-5e64-4420-b5be-44fb9b04840d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3fb94d7a-5e64-4420-b5be-44fb9b04840d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3fb94d7a-5e64-4420-b5be-44fb9b04840d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bfa17aa0-4891-4a3b-8a6e-f4d8cd617593\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bfa17aa0-4891-4a3b-8a6e-f4d8cd617593')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bfa17aa0-4891-4a3b-8a6e-f4d8cd617593 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_val_new",
              "summary": "{\n  \"name\": \"X_val_new\",\n  \"rows\": 93,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 42,\n        \"samples\": [\n          \"0001206774-18-001008\",\n          \"0000932471-18-006088\",\n          \"0001193125-18-285341\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fund_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 93,\n        \"samples\": [\n          \"Franklin FTSE China ETF\",\n          \"AllianzGI Income & Growth Fund\",\n          \"Fidelity Managed Retirement 2025 Fund\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Performance fee?\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Some performance Fees\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Leverage?\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Portfolio composition\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Investment grade securities\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" Concentration\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Concentrated by issuer / sector / jurisdiction\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 93,\n        \"samples\": [\n          \"Franklin FTSE China ETF\\n\\nInvestment Goal\\n\\nTo seek to provide investment results that closely correspond, before fees and expenses, to the performance of the FTSE China RIC Capped Index (the FTSE China Capped Index).\\n\\nFees and Expenses of the Fund\\n\\nThe following table describes the fees and expenses that you will incur if you own shares of the Fund. You may also incur usual and customary brokerage commissions when buying or selling shares of the Fund, which are not reflected in the Example that follows.\\n\\n\\nAnnual Fund Operating Expenses\\n\\n(expenses that you pay each year as a percentage of the value of your investment)\\n\\nManagement fees \\t0.19% \\nDistribution and service (12b-1) fees \\tNone \\nOther expenses1 \\tNone \\nTotal annual Fund operating expenses \\t0.19% \\n1. Other expenses are based on estimated amounts for the current fiscal year.\\n\\nExample\\n\\nThis Example is intended to help you compare the cost of investing in the Fund with the cost of investing in other funds. The Example assumes that you invest $10,000 in the Fund for the time periods indicated and then redeem all of your shares at the end of the period. The Example also assumes that your investment has a 5% return each year and that the Fund's operating expenses remain the same. Although your actual costs may be higher or lower, based on these assumptions your costs would be:\\n\\n   \\t1 Year \\t3 Years \\n   \\t$ 19 \\t$ 61 \\nPortfolio Turnover\\n\\nThe Fund pays transaction costs, such as commissions, when it buys and sells securities (or \\\"turns over\\\" its portfolio). A higher portfolio turnover rate may indicate higher transaction costs and may result in higher taxes when Fund shares are held in a taxable account. These costs, which are not reflected in annual Fund operating expenses or in the Example, affect the Fund's performance. During the Fund's first fiscal period (November 2, 2017 to March 31, 2018), the Fund's portfolio turnover rate was 2.71% of the average value of its portfolio.\\n\\nPrincipal Investment Strategies\\n\\nUnder normal market conditions, the Fund invests at least 80% of its assets in the component securities of the FTSE China Capped Index and in depositary receipts representing such securities. The FTSE China Capped Index is a free float-adjusted market capitalization weighted index maintained and calculated by FTSE Russell with a capping methodology applied quarterly to issuer weights so that no single issuer of a component exceeds 25% of the FTSE China Capped Index weight, and all issuers with weights above 5% do not cumulatively exceed 50% of the FTSE China Capped Index\\u2019s weight. The FTSE China Capped Index is based on the FTSE China Index and is designed to measure the performance of Chinese large- and mid-capitalization stocks, as represented by H-Shares (securities of companies incorporated in the People\\u2019s Republic of China (PRC) that are denominated in Hong Kong dollars and listed on the Hong Kong Exchange) and B-Shares (securities of companies incorporated in the PRC and listed for foreign investment on either the Shanghai or Shenzhen stock exchanges). The FTSE China Capped Index also includes certain securities listed outside of the PRC known as N-Shares (issued by companies incorporated in certain foreign jurisdictions, which are controlled, directly or indirectly, by entities, companies or individuals in the PRC, derive substantial revenues or allocate substantial assets in the PRC and are listed on the New York Stock Exchange, NASDAQ or the NYSE MKT), Red-Chips (issued by companies incorporated in certain foreign jurisdictions, which are controlled, directly or indirectly, by entities owned by the national government or local governments in the PRC, derive substantial revenues or allocate substantial assets in the PRC and are listed on the Hong Kong Exchange), P-Chips (issued by companies incorporated in certain foreign jurisdictions, which are controlled, directly or indirectly, by individuals in the PRC, derive substantial revenues or allocate substantial assets in the PRC and are listed on the Hong Kong Exchange) and S-Chips (issued by companies incorporated in certain foreign jurisdictions, which are controlled, directly or indirectly, by entities, companies or individuals in the PRC, derive substantial revenues or allocate substantial assets in the PRC and are listed on the Singapore Exchange). FTSE Russell determines eligible securities for the FTSE China Capped Index based on measures such as the company\\u2019s place of incorporation, quality of investor protection, tax domicile, location of headquarters/factors of production and currency of denomination. As of June 29, 2018, the FTSE China Capped Index was comprised of 262 securities with capitalizations ranging from $89 million to $285.69 billion.\\n\\nThe Fund, using a \\u201cpassive\\u201d or indexing investment approach, seeks investment results that closely correspond, before fees and expenses, to the performance of the FTSE China Capped Index. The investment manager seeks to achieve, over time, a correlation between the Fund\\u2019s performance, before fees and expenses, and that of the FTSE China Capped Index of 0.95 or better. A figure of 1.00 would indicate perfect correlation. The Fund\\u2019s intention is to replicate the component securities of the FTSE China Capped Index as closely as possible (i.e., invest in all of the component securities in their respective weightings in the FTSE China Capped Index). However, under various circumstances, it may not be possible or practicable to replicate the FTSE China Capped Index. In these circumstances, the Fund may use a \\u201crepresentative sampling\\u201d strategy whereby the Fund would invest in what it believes to be a representative sample of the component securities of the FTSE China Capped Index, but may not track the FTSE China Capped Index with the same degree of accuracy as would an investment vehicle replicating the entire FTSE China Capped Index. Under the representative sampling technique, the investment manager will select securities that collectively have an investment profile similar to that of the FTSE China Capped Index, including securities that resemble those included in the FTSE China Capped Index in terms of risk factors, performance attributes and other characteristics, such as market capitalization and industry weightings.\\n\\nThe Fund is a \\\"non-diversified\\\" fund, which means it generally invests a greater proportion of its assets in the securities of one or more issuers and invests overall in a smaller number of issuers than a diversified fund.\\n\\nThe Fund will concentrate its investments (i.e., hold 25% or more of its net assets) in a particular industry or group of industries to approximately the same extent that the FTSE China Capped Index is concentrated. As of June 29, 2018, the FTSE China Capped Index was concentrated in the internet software and services industry.\\n\\nPrincipal Risks\\n\\nYou could lose money by investing in the Fund. Exchange-traded fund (ETF) shares are not deposits or obligations of, or guaranteed or endorsed by, any bank, and are not insured by the Federal Deposit Insurance Corporation, the Federal Reserve Board, or any other agency of the U.S. government. The Fund is subject to the principal risks noted below, any of which may adversely affect the Fund\\u2019s net asset value (NAV), trading price, yield, total return and ability to meet its investment goal.\\n\\nMarket   The market values of securities or other investments owned by the Fund will go up or down, sometimes rapidly or unpredictably. The market value of a security or other investment may be reduced by market activity or other results of supply and demand unrelated to the issuer. This is a basic risk associated with all investments. When there are more sellers than buyers, prices tend to fall. Likewise, when there are more buyers than sellers, prices tend to rise.\\n\\nStock prices tend to go up and down more dramatically than those of debt securities. A slower-growth or recessionary economic environment could have an adverse effect on the prices of the various stocks held by the Fund.\\n\\nForeign Securities (non-U.S.)   Investing in foreign securities typically involves more risks than investing in U.S. securities, and includes risks associated with: (i) internal and external political and economic developments \\u2013 e.g., the political, economic and social policies and structures of some foreign countries may be less stable and more volatile than those in the U.S. or some foreign countries may be subject to trading restrictions or economic sanctions; (ii) trading practices \\u2013 e.g., government supervision and regulation of foreign securities and currency markets, trading systems and brokers may be less than in the U.S.; (iii) availability of information \\u2013 e.g., foreign issuers may not be subject to the same disclosure, accounting and financial reporting standards and practices as U.S. issuers; (iv) limited markets \\u2013 e.g., the securities of certain foreign issuers may be less liquid (harder to sell) and more volatile; and (v) currency exchange rate fluctuations and policies (e.g., fluctuations may negatively affect investments denominated in foreign currencies and any income received or expenses paid by the Fund in that foreign currency). The risks of foreign investments may be greater in developing or emerging market countries.\\n\\nEmerging Market Countries   The Fund\\u2019s investments in emerging market issuers are subject to all of the risks of foreign investing generally, and have additional heightened risks due to a lack of established legal, political, business and social frameworks to support securities markets, including: delays in settling portfolio securities transactions; currency and capital controls; greater sensitivity to interest rate changes; pervasiveness of corruption and crime; currency exchange rate volatility; and inflation, deflation or currency devaluation.\\n\\nGeographic Focus   Because the Fund invests its assets primarily in companies in a specific country and region, the Fund is subject to greater risks of adverse developments in that country, region and/or the surrounding regions than a fund that is more broadly diversified geographically. Political, social or economic disruptions in the country or region, even in countries in which the Fund is not invested, may adversely affect the value of investments held by the Fund.\\n\\nThere are special risks associated with investments in China, including exposure to currency fluctuations, less liquidity, expropriation, confiscatory taxation, nationalization and exchange control regulations (including currency blockage). Inflation and rapid fluctuations in inflation and interest rates have had, and may continue to have, negative effects on the economy and securities markets of China. China is deemed by the investment manager to be an emerging markets country, which means an investment in this country has more heightened risks than general foreign investing due to a lack of established legal, political, business and social frameworks in the country to support securities markets as well as the possibility for more widespread corruption and fraud.\\n\\nDepositary Receipts   Depositary receipts are subject to many of the risks of the underlying securities. For some depositary receipts, the custodian or similar financial institution that holds the issuer's shares in a trust account is located in the issuer's home country. In these cases if the issuer\\u2019s home country does not have developed financial markets, the Fund could be exposed to the credit risk of the custodian or financial institution and greater market risk. In addition, the depository institution may not have physical custody of the underlying securities at all times and may charge fees for various services. The Fund may experience delays in receiving its dividend and interest payments or exercising rights as a shareholder. There may be an increased possibility of untimely responses to certain corporate actions of the issuer in an unsponsored depositary receipt program. Accordingly, there may be less information available regarding issuers of securities underlying unsponsored programs and there may not be a correlation between this information and the market value of the depositary receipts.\\n\\nCalculation Methodology   FTSE Russell relies on various sources of information to assess the criteria of issuers included in the FTSE China Capped Index, including information that may be based on assumptions and estimates. Neither the Fund nor the investment manager can offer assurances that FTSE Russell\\u2019s calculation methodology or sources of information will provide an accurate assessment of included issuers or that the included issuers will provide the Fund with the market exposure it seeks.\\n\\nIndex-Related   There is no assurance that the FTSE China Capped Index will be determined, composed or calculated accurately. While FTSE Russell provides descriptions of what the FTSE China Capped Index is designed to achieve, FTSE Russell does not guarantee the quality, accuracy or completeness of data in respect of its indices, and does not guarantee that the FTSE China Capped Index will be in line with the described index methodology. Gains, losses or costs to the Fund caused by errors in the FTSE China Capped Index may therefore be borne by the Fund and its shareholders.\\n\\nNon-Correlation   There is no guarantee that the Fund will achieve a high degree of correlation to the FTSE China Capped Index and therefore achieve its investment goal. Market disruptions and regulatory restrictions could have an adverse effect on the Fund\\u2019s ability to adjust its exposure to the required levels in order to track the FTSE China Capped Index. In addition, the Fund\\u2019s NAV may deviate from the FTSE China Capped Index if the Fund fair values a portfolio security at a price other than the price used by the FTSE China Capped Index for that security. To the extent that the investment manager uses a representative sampling strategy, the Fund may not track the return of the FTSE China Capped Index as well as it would have if the Fund held all of the securities in the FTSE China Capped Index.\\n\\nTracking Error   Tracking error is the divergence of the Fund\\u2019s performance from that of the FTSE China Capped Index. Tracking error may occur because of differences between the securities held in the Fund\\u2019s portfolio and those included in the FTSE China Capped Index, pricing differences (including differences between a security\\u2019s price at the local market close and the Fund\\u2019s valuation of a security at the time of calculation of the Fund\\u2019s NAV), transaction costs, the Fund\\u2019s holding of cash, differences in timing of the accrual of dividends or interest, tax gains or losses, changes to the FTSE China Capped Index or the need to meet various new or existing regulatory requirements. This risk may be heightened during times of increased market volatility or other unusual market conditions. Tracking error also may result because the Fund incurs fees and expenses, while the FTSE China Capped Index does not.\\n\\nMarket Trading   The Fund faces numerous market trading risks, including the potential lack of an active market for Fund shares, losses from trading in secondary markets, periods of high volatility and disruption in the creation/redemption process of the Fund. Any of these factors, among others, may lead to the Fund\\u2019s shares trading at a premium or discount to NAV. Thus, you may pay more (or less) than NAV when you buy shares of the Fund in the secondary market, and you may receive less (or more) than NAV when you sell those shares in the secondary market. The investment manager cannot predict whether shares will trade above (premium), below (discount) or at NAV.\\n\\nConcentration   To the extent the Fund concentrates in a specific industry, a group of industries, sector or type of investment, the Fund will carry much greater risks of adverse developments and price movements in such industries, sectors or investments than a fund that invests in a wider variety of industries, sectors or investments. There is also the risk that the Fund will perform poorly during a slump in demand for securities of companies in such industries or sectors.\\n\\nThe Fund may focus in the internet software and services industry. Competitive pressures, such as technological developments, fixed-rate pricing and the ability to attract and retain skilled employees, can significantly affect companies in the internet software and services industry. Changing domestic and international demand, research and development costs, availability and price of components and product obsolescence also can affect profitability of companies in this industry.\\n\\nNon-Diversification   Because the Fund is non-diversified, it may be more sensitive to economic, business, political or other changes affecting individual issuers or investments than a diversified fund, which may result in greater fluctuation in the value of the Fund\\u2019s shares and greater risk of loss.\\n\\nMidsize Companies   Securities issued by midsize companies may be more volatile in price than those of larger companies, involve substantial risks and should be considered speculative. Such risks may include greater sensitivity to economic conditions, less certain growth prospects, lack of depth of management and funds for growth and development, and limited or less developed product lines and markets. In addition, midsize companies may be particularly affected by interest rate increases, as they may find it more difficult to borrow money to continue or expand operations, or may have difficulty in repaying any loans.\\n\\nPassive Investment   Unlike many investment companies, the Fund is not actively managed and the investment manager does not attempt to take defensive positions under any market conditions, including declining markets. Therefore, the investment manager would not necessarily buy or sell a security unless that security is added or removed, respectively, from the FTSE China Capped Index, even if that security generally is underperforming.\\n\\nInternational Closed Market Trading   To the extent that the underlying securities held by the Fund trade on an exchange that is closed when the securities exchange on which the Fund shares list and trade is open, there may be market uncertainty about the stale security pricing (i.e., the last quote from its closed foreign market) resulting in premiums or discounts to NAV that may be greater than those experienced by other ETFs.\\n\\nAuthorized Participant Concentration   Only an authorized participant (Authorized Participant) may engage in creation or redemption transactions directly with the Fund. The Fund has a limited number of institutions that act as Authorized Participants. To the extent that these institutions exit the business or are unable to proceed with creation and/or redemption orders with respect to the Fund and no other Authorized Participant is able to step forward to create or redeem Creation Units (as defined below), Fund shares may trade at a discount to NAV and possibly face trading halts and/or delisting. This risk may be more pronounced in volatile markets, potentially where there are significant redemptions in ETFs generally.\\n\\nCash Transactions   Unlike certain ETFs, the Fund expects to generally effect its creations and redemptions partially for cash, rather than for in-kind securities. Therefore, it may be required to sell portfolio securities and subsequently recognize gains on such sales that the Fund might not have recognized if it were to distribute portfolio securities in-kind. As such, investments in Fund shares may be less tax-efficient than an investment in an ETF that distributes portfolio securities entirely in-kind.\\n\\nPerformance\\n\\nBecause the Fund does not have a full calendar year of performance, annual total return information is not available and therefore is not presented. You can obtain updated performance information at libertyshares.com or by calling (800) DIAL BEN/342-5236. The Fund's past performance (before and after taxes) is not necessarily an indication of how the Fund will perform in the future.\\n\\nInvestment Manager\\n\\nFranklin Advisers, Inc. (Advisers)\\n\\nPortfolio Managers\\n\\nDina Ting, CFA   Portfolio Manager of Advisers and lead portfolio manager of the Fund since inception (2017).\\n\\nLouis Hsu, CFA   Portfolio Manager of Advisers and portfolio manager of the Fund since inception (2017).\\n\\nPurchase and Sale of Fund Shares\\n\\nThe Fund is an ETF. Fund shares may only be purchased and sold on a national securities exchange through a broker-dealer. The price of Fund shares is based on market price, and because ETF shares trade at market prices rather than NAV, shares may trade at a price greater than NAV (a premium) or less than NAV (a discount). The Fund issues or redeems shares that have been aggregated into blocks of 400,000 shares or multiples thereof (Creation Units) to Authorized Participants who have entered into agreements with the Fund\\u2019s distributor, Franklin Templeton Distributors, Inc. The Fund will generally issue or redeem Creation Units in return for a basket of securities (and an amount of cash) that the Fund specifies each day.\\n\\nTaxes\\n\\nThe Fund\\u2019s distributions are generally taxable to you as ordinary income, capital gains, or some combination of both, unless you are investing through a tax-deferred arrangement, such as a 401(k) plan or an individual retirement account, in which case your distributions would generally be taxed when withdrawn from the tax-deferred account.\\n\\nPayments to Broker-Dealers and\\nOther Financial Intermediaries\\n\\nIf you purchase shares of the Fund through a broker-dealer or other financial intermediary (such as a bank), Advisers or other related companies may pay the intermediary for the sale of Fund shares and related services. These payments may create a conflict of interest by influencing the broker-dealer or other intermediary and your salesperson to recommend the Fund over another investment. Ask your salesperson or visit your financial intermediary's website for more information.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Function to get data (Assuming you have this defined)\n",
        "fund_names, summaries = get_data(SUMMARY_PATH)\n",
        "fund_names_in_X_val = X_val['fund_name'].tolist()\n",
        "\n",
        "# Correctly filter summaries where the fund name is in X_test\n",
        "# and ensure alignment between fund names and summaries\n",
        "selected_summaries_in_X_val = []\n",
        "fund_names_with_summaries = []\n",
        "\n",
        "for fund_name, summary in zip(fund_names, summaries):\n",
        "    if fund_name in fund_names_in_X_val:\n",
        "        selected_summaries_in_X_val.append(summary)\n",
        "        fund_names_with_summaries.append(fund_name)\n",
        "\n",
        "# Create DataFrame from extracted summaries\n",
        "df_extraction = pd.DataFrame({\n",
        "    'fund_name': fund_names_with_summaries,\n",
        "    'summary': selected_summaries_in_X_val\n",
        "})\n",
        "\n",
        "original_index = X_val.index\n",
        "X_val_new = X_val.merge(df_extraction, on='fund_name', how='left')\n",
        "X_val_new.index = original_index\n",
        "\n",
        "\n",
        "# Drop rows where the 'summary' is NaN and reset index\n",
        "X_val_new = X_val_new.dropna(subset=['summary'])\n",
        "\n",
        "X_val_new.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JFtW0-Kw4xh",
        "outputId": "e5306cb6-7a5c-4278-a909-a9ad2ce2dbd8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56        Balanced Fund (Low Risk)\n",
              "181    Equity Long Only (Low Risk)\n",
              "329       Balanced Fund (Low Risk)\n",
              "271    Equity Long Only (Low Risk)\n",
              "31     Equity Long Only (Low Risk)\n",
              "Name: Ivestment Strategy, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "# Ensure y_test is aligned with X_test_new\n",
        "# Filter y_test using the new index of X_test_new\n",
        "y_val_new = y_val.reindex(X_val_new.index)\n",
        "\n",
        "# Print the cleaned dataframes to confirm that rows have been dropped and indices reset accordingly\n",
        "y_val_new.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WKBZNl3Rw4xh",
        "outputId": "11db57cc-9765-4cff-e460-24182a4b1cd8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Leverage?  Portfolio composition   Concentration  Max Similarity  \\\n",
              "56         0.0                    0.0             0.0        0.085346   \n",
              "181        0.0                    1.0             0.0        0.102477   \n",
              "329        1.0                    2.0             0.0        0.124033   \n",
              "271        0.0                    1.0             0.0        0.069571   \n",
              "31         0.0                    2.0             0.0        0.122207   \n",
              "\n",
              "     Mean Similarity  \n",
              "56          0.021633  \n",
              "181         0.024675  \n",
              "329         0.023591  \n",
              "271         0.015978  \n",
              "31          0.018027  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6f1b4d12-5f2e-4db2-9f68-d447165baabb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Leverage?</th>\n",
              "      <th>Portfolio composition</th>\n",
              "      <th>Concentration</th>\n",
              "      <th>Max Similarity</th>\n",
              "      <th>Mean Similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.085346</td>\n",
              "      <td>0.021633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.102477</td>\n",
              "      <td>0.024675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>329</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.124033</td>\n",
              "      <td>0.023591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.069571</td>\n",
              "      <td>0.015978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.122207</td>\n",
              "      <td>0.018027</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f1b4d12-5f2e-4db2-9f68-d447165baabb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6f1b4d12-5f2e-4db2-9f68-d447165baabb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6f1b4d12-5f2e-4db2-9f68-d447165baabb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d6a84ad7-bc70-4972-a150-a5bc63c39e8f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d6a84ad7-bc70-4972-a150-a5bc63c39e8f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d6a84ad7-bc70-4972-a150-a5bc63c39e8f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_val_final",
              "summary": "{\n  \"name\": \"X_val_final\",\n  \"rows\": 93,\n  \"fields\": [\n    {\n      \"column\": \"Leverage?\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.49423984539688176,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Portfolio composition\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7979637479594567,\n        \"min\": 0.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" Concentration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.33705264882291225,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Max Similarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.044432731085737615,\n        \"min\": 0.06621450726733637,\n        \"max\": 0.30548450444416164,\n        \"num_unique_values\": 93,\n        \"samples\": [\n          0.08844042034299253,\n          0.08697210459557209\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mean Similarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0031347943884802543,\n        \"min\": 0.012180159987788708,\n        \"max\": 0.0253731455952509,\n        \"num_unique_values\": 93,\n        \"samples\": [\n          0.021535357971102783,\n          0.022665601827143743\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "X_val_new = X_val_new.drop(columns =[\"id\", \"fund_name\", \"summary\", 'Performance fee?'])\n",
        "X_val_new['Leverage?'] = LabelEncoder().fit_transform(X_val_new['Leverage?'])\n",
        "\n",
        "# performance_mapping = {\n",
        "#     \"None\": 0,\n",
        "#     \"Some performance Fees\": 1\n",
        "# }\n",
        "\n",
        "portfolio_composition_mapping = {\n",
        "    \"Investment grade securities\": 0,\n",
        "    \"Listed Equities\": 1,\n",
        "    \"Sub-investment grade securities or emerging markets\": 2\n",
        "}\n",
        "\n",
        "concentration_mapping = {\n",
        "    \"Diversified\": 0,\n",
        "    \"Concentrated by issuer / sector / jurisdiction\": 1\n",
        "}\n",
        "\n",
        "# X_val_new['Performance fee?'] = X_val_new['Performance fee?'].map(performance_mapping)\n",
        "X_val_new['Portfolio composition'] = X_val_new['Portfolio composition'].map(portfolio_composition_mapping)\n",
        "X_val_new[' Concentration'] = X_val_new[' Concentration'].map(concentration_mapping)\n",
        "\n",
        "# Assume 'knowledge_base' is a list of documents/texts you have defined elsewhere\n",
        "all_texts = selected_summaries_in_X_val + knowledge_base\n",
        "\n",
        "# Create a TF-IDF Vectorizer and vectorize all texts\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(all_texts)\n",
        "\n",
        "# Extract TF-IDF vectors for summaries and KB entries\n",
        "tfidf_summaries = tfidf_matrix[:len(selected_summaries_in_X_val)]\n",
        "tfidf_kb_entries = tfidf_matrix[len(selected_summaries_in_X_val):]\n",
        "\n",
        "# Calculate cosine similarity between each summary and each KB entry\n",
        "similarity_matrix = cosine_similarity(tfidf_summaries, tfidf_kb_entries)\n",
        "\n",
        "# Feature engineering\n",
        "max_similarity = np.max(similarity_matrix, axis=1)\n",
        "mean_similarity = np.mean(similarity_matrix, axis=1)\n",
        "\n",
        "# Combine features for X_test\n",
        "X_val_features = np.column_stack((max_similarity, mean_similarity))\n",
        "X_val_combined = np.hstack((X_val_new.values, X_val_features))\n",
        "\n",
        "X_val_final = pd.DataFrame(X_val_combined, columns=list(X_val_new.columns) + ['Max Similarity', 'Mean Similarity'])\n",
        "\n",
        "X_val_final.index = X_val_new.index\n",
        "\n",
        "X_val_final.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfET6gw1w4xh",
        "outputId": "0e85dff1-b1d5-49ff-e0f6-8a0672f5eac7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56     0\n",
              "181    2\n",
              "329    0\n",
              "271    2\n",
              "31     2\n",
              "Name: Ivestment Strategy, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "# Encoded investment strategy\n",
        "investment_strategy_mapping = {\n",
        "    \"Balanced Fund (Low Risk)\": 0,\n",
        "    \"Fixed Income Long Only (Low Risk)\": 1,\n",
        "    \"Equity Long Only (Low Risk)\": 2,\n",
        "    \"Long Short Funds (High Risk)\": 3,\n",
        "    \"Commodities Fund (Low Risk)\": 4\n",
        "}\n",
        "\n",
        "# Apply the mapping to the 'Investment Strategy' column\n",
        "y_val_mapped = y_val_new.map(investment_strategy_mapping)\n",
        "y_val_mapped.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qc7vk6WJw4xh"
      },
      "source": [
        "### Encoded X_test and y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "0rUkfIucw4xh",
        "outputId": "87883c5f-c6ee-4bf8-f2e9-39e9d226d670"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <progress\n",
              "            value='544'\n",
              "            max='544',\n",
              "            style='width: 100%'\n",
              "        >\n",
              "            544\n",
              "        </progress>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       id                                    fund_name  \\\n",
              "324  0001379491-18-000929  Fidelity Series Opportunistic Insights Fund   \n",
              "448  0001683863-18-000443                         Growth & Income Fund   \n",
              "298  0001193125-18-285341        Columbia Flexible Capital Income Fund   \n",
              "410  0001379491-18-006486                  Fidelity Emerging Asia Fund   \n",
              "22   0000051931-18-000465                           International Fund   \n",
              "\n",
              "          Performance fee? Leverage?  \\\n",
              "324                    NaN        No   \n",
              "448  Some performance Fees        No   \n",
              "298                    NaN        No   \n",
              "410  Some performance Fees        No   \n",
              "22                     NaN        No   \n",
              "\n",
              "                                 Portfolio composition  Concentration  \\\n",
              "324                                    Listed Equities    Diversified   \n",
              "448                                    Listed Equities    Diversified   \n",
              "298  Sub-investment grade securities or emerging ma...    Diversified   \n",
              "410  Sub-investment grade securities or emerging ma...    Diversified   \n",
              "22   Sub-investment grade securities or emerging ma...    Diversified   \n",
              "\n",
              "                                               summary  \n",
              "324  Fund Summary\\n\\nFund:\\nFidelity® Series Opport...  \n",
              "448  INVESTMENT OBJECTIVE\\nThe USAA Growth & Income...  \n",
              "298  SUMMARY OF THE FUND\\nInvestment Objective\\nCol...  \n",
              "410  Fund Summary\\n\\nFund:\\nFidelity® Emerging Asia...  \n",
              "22   International Fund\\n\\nInvestment objective The...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f252c226-83a3-42ad-abbf-91dc2078911a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>fund_name</th>\n",
              "      <th>Performance fee?</th>\n",
              "      <th>Leverage?</th>\n",
              "      <th>Portfolio composition</th>\n",
              "      <th>Concentration</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>324</th>\n",
              "      <td>0001379491-18-000929</td>\n",
              "      <td>Fidelity Series Opportunistic Insights Fund</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>Listed Equities</td>\n",
              "      <td>Diversified</td>\n",
              "      <td>Fund Summary\\n\\nFund:\\nFidelity® Series Opport...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>0001683863-18-000443</td>\n",
              "      <td>Growth &amp; Income Fund</td>\n",
              "      <td>Some performance Fees</td>\n",
              "      <td>No</td>\n",
              "      <td>Listed Equities</td>\n",
              "      <td>Diversified</td>\n",
              "      <td>INVESTMENT OBJECTIVE\\nThe USAA Growth &amp; Income...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>0001193125-18-285341</td>\n",
              "      <td>Columbia Flexible Capital Income Fund</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>Sub-investment grade securities or emerging ma...</td>\n",
              "      <td>Diversified</td>\n",
              "      <td>SUMMARY OF THE FUND\\nInvestment Objective\\nCol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>410</th>\n",
              "      <td>0001379491-18-006486</td>\n",
              "      <td>Fidelity Emerging Asia Fund</td>\n",
              "      <td>Some performance Fees</td>\n",
              "      <td>No</td>\n",
              "      <td>Sub-investment grade securities or emerging ma...</td>\n",
              "      <td>Diversified</td>\n",
              "      <td>Fund Summary\\n\\nFund:\\nFidelity® Emerging Asia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0000051931-18-000465</td>\n",
              "      <td>International Fund</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>Sub-investment grade securities or emerging ma...</td>\n",
              "      <td>Diversified</td>\n",
              "      <td>International Fund\\n\\nInvestment objective The...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f252c226-83a3-42ad-abbf-91dc2078911a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f252c226-83a3-42ad-abbf-91dc2078911a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f252c226-83a3-42ad-abbf-91dc2078911a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1fa40dd2-7dc3-4083-b4b9-9e80957a98be\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1fa40dd2-7dc3-4083-b4b9-9e80957a98be')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1fa40dd2-7dc3-4083-b4b9-9e80957a98be button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_test_new",
              "summary": "{\n  \"name\": \"X_test_new\",\n  \"rows\": 47,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"0001710607-18-000172\",\n          \"0001144204-18-020502\",\n          \"0001379491-18-001273\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fund_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 47,\n        \"samples\": [\n          \"MFS Georgia Municipal Bond Fund\",\n          \"Growth Fund\",\n          \"Columbia Seligman Communications and Information Fund\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Performance fee?\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Some performance Fees\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Leverage?\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Portfolio composition\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Listed Equities\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" Concentration\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Concentrated by issuer / sector / jurisdiction\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 47,\n        \"samples\": [\n          \"MFS Georgia Municipal Bond Fund\\n\\n \\n\\nSummary of Key Information\\n\\n \\n\\nInvestment Objective\\n\\n \\n\\nThe fund\\u2019s investment objective is to seek total return with an emphasis on income exempt from federal income tax and personal income tax, if any, of Georgia, but also considering capital appreciation.\\n\\n \\n\\nFees and Expenses\\n\\n \\n\\nThis table describes the fees and expenses that you may pay when you buy and hold shares of the fund. Investors may also pay commissions or other fees to their financial intermediaries when they buy and hold shares of the fund, which are not reflected below.\\n\\n \\n\\nYou may qualify for sales charge reductions if, with respect to Class A shares, you and certain members of your family invest, or agree to invest in the future, at least $100,000 in MFS Funds, and, with respect to Class T shares, you invest at least $250,000 in the fund. More information about these and other waivers and reductions is available from your financial intermediary and in \\u201cSales Charges and Waivers and Reductions\\u201d on page 9 and \\u201cAppendix A \\u2013 Waivers and Reductions of Sales Charges\\u201d on page A-1 of the fund\\u2019s prospectus.\\n\\n \\n\\nShareholder Fees (fees paid directly from your investment):\\n\\n \\n\\nShare Class\\n\\n \\n\\nA\\n\\n \\n\\nT\\n\\n \\n\\nB\\n\\n \\n\\nI\\n\\n \\n\\nR6\\n\\n \\n\\nMaximum Sales Charge (Load) Imposed on Purchases (as a percentage of offering price)\\n\\n \\n\\n4.25\\n\\n%\\n\\n2.50\\n\\n%\\n\\nNone\\n\\n \\n\\nNone\\n\\n \\n\\nNone\\n\\n \\n\\nMaximum Deferred Sales Charge (Load) (as a percentage of original purchase price or redemption proceeds, whichever is less)\\n\\n \\n\\n1.00\\n\\n%#\\n\\nNone\\n\\n \\n\\n4.00\\n\\n%\\n\\nNone\\n\\n \\n\\nNone\\n\\n \\n\\n \\n\\nAnnual Fund Operating Expenses (expenses that you pay each year as a percentage of the value of your investment):\\n\\n \\n\\nShare Class\\n\\n \\n\\nA\\n\\n \\n\\nT\\n\\n \\n\\nB\\n\\n \\n\\nI\\n\\n \\n\\nR6\\n\\n \\n\\nManagement Fee\\n\\n \\n\\n0.45\\n\\n%\\n\\n0.45\\n\\n%\\n\\n0.45\\n\\n%\\n\\n0.45\\n\\n%\\n\\n0.45\\n\\n%\\n\\nDistribution and/or Service (12b-1) Fees\\n\\n \\n\\n0.25\\n\\n%\\n\\n0.25\\n\\n%\\n\\n1.00\\n\\n%\\n\\nNone\\n\\n \\n\\nNone\\n\\n \\n\\nOther Expenses\\n\\n \\n\\n0.34\\n\\n%\\n\\n0.34\\n\\n%\\n\\n0.34\\n\\n%\\n\\n0.34\\n\\n%\\n\\n0.28\\n\\n%\\n\\nTotal Annual Fund Operating Expenses\\n\\n \\n\\n1.04\\n\\n%\\n\\n1.04\\n\\n%\\n\\n1.79\\n\\n%\\n\\n0.79\\n\\n%\\n\\n0.73\\n\\n%\\n\\nFee Reductions and/or Expense Reimbursements1\\n\\n \\n\\n(0.14\\n\\n)%\\n\\n(0.14\\n\\n)%\\n\\n(0.14\\n\\n)%\\n\\n(0.14\\n\\n)%\\n\\n(0.13\\n\\n)%\\n\\nTotal Annual Fund Operating Expenses After Fee Reductions and/or Expense Reimbursements\\n\\n \\n\\n0.90\\n\\n%\\n\\n0.90\\n\\n%\\n\\n1.65\\n\\n%\\n\\n0.65\\n\\n%\\n\\n0.60\\n\\n%\\n\\n \\n\\n#                 This contingent deferred sales charge (CDSC) applies to shares purchased without an initial sales charge and redeemed within 18 months of purchase.\\n\\n1                 Massachusetts Financial Services Company has agreed in writing to bear the fund\\u2019s expenses, excluding interest, taxes, extraordinary expenses, brokerage and transaction costs, and investment-related expenses (such as interest and borrowing expenses incurred in connection with the fund\\u2019s investment activity), such that \\u201cTotal Annual Fund Operating Expenses\\u201d do not exceed 0.90% of the class\\u2019 average daily net assets annually for each of Class A and Class T shares, 1.65% of the class\\u2019 average daily net assets annually for Class B shares, 0.65% of the class\\u2019 average daily net assets annually for Class I shares, and 0.60% of the class\\u2019 average daily net assets annually for Class R6 shares. This written agreement will continue until modified by the fund\\u2019s Board of Trustees, but such agreement will continue until at least July 31, 2019.\\n\\n \\n\\n2\\n\\n\\n \\n\\nMFS Georgia Municipal Bond Fund\\n\\n \\n\\nExample\\n\\n \\n\\nThis example is intended to help you compare the cost of investing in the fund with the cost of investing in other mutual funds.\\n\\n \\n\\nThe example assumes that: you invest $10,000 in the fund for the time periods indicated and you redeem your shares at the end of the time periods (unless otherwise indicated); your investment has a 5% return each year; and the fund\\u2019s operating expenses remain the same.\\n\\n \\n\\nAlthough your actual costs will likely be higher or lower, under these assumptions your costs would be:\\n\\n \\n\\n \\n\\n \\n\\n1 YEAR\\n\\n \\n\\n3 YEARS\\n\\n \\n\\n5 YEARS\\n\\n \\n\\n10 YEARS\\n\\n \\n\\nClass A Shares\\n\\n \\n\\n$\\n\\n513\\n\\n \\n\\n$\\n\\n729\\n\\n \\n\\n$\\n\\n962\\n\\n \\n\\n$\\n\\n1,630\\n\\n \\n\\nClass T Shares\\n\\n \\n\\n$\\n\\n340\\n\\n \\n\\n$\\n\\n559\\n\\n \\n\\n$\\n\\n796\\n\\n \\n\\n$\\n\\n1,477\\n\\n \\n\\nClass B Shares assuming\\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nredemption at end of period\\n\\n \\n\\n$\\n\\n568\\n\\n \\n\\n$\\n\\n850\\n\\n \\n\\n$\\n\\n1,157\\n\\n \\n\\n$\\n\\n1,896\\n\\n \\n\\nno redemption at end of period\\n\\n \\n\\n$\\n\\n168\\n\\n \\n\\n$\\n\\n550\\n\\n \\n\\n$\\n\\n957\\n\\n \\n\\n$\\n\\n1,896\\n\\n \\n\\nClass I Shares\\n\\n \\n\\n$\\n\\n66\\n\\n \\n\\n$\\n\\n238\\n\\n \\n\\n$\\n\\n425\\n\\n \\n\\n$\\n\\n965\\n\\n \\n\\nClass R6 Shares\\n\\n \\n\\n$\\n\\n61\\n\\n \\n\\n$\\n\\n220\\n\\n \\n\\n$\\n\\n393\\n\\n \\n\\n$\\n\\n894\\n\\n \\n\\n \\n\\nPortfolio Turnover\\n\\n \\n\\nThe fund pays transaction costs, such as commissions, when it buys and sells securities (or \\u201cturns over\\u201d its portfolio). A higher portfolio turnover rate may indicate higher transaction costs and may result in higher taxes when shares are held in a taxable account. These transaction costs, which are not reflected in \\u201cAnnual Fund Operating Expenses\\u201d or in the \\u201cExample,\\u201d affect the fund\\u2019s performance.  During the most recent fiscal year, the fund\\u2019s portfolio turnover rate was 12% of the average value of its portfolio. \\n\\n \\n\\nPrincipal Investment Strategies\\n\\n \\n\\nThe fund invests, under normal market conditions, at least 80% of its net assets in securities and other investments, the interest on which is exempt from federal income tax and personal income tax, if any, of Georgia. Interest from the fund\\u2019s investments may be subject to the federal alternative minimum tax. MFS (Massachusetts Financial Services Company, the fund\\u2019s investment adviser) may also invest the fund\\u2019s assets in taxable instruments, including municipal instruments of other states.\\n\\n \\n\\nMFS normally invests the fund\\u2019s assets primarily in municipal instruments.\\n\\n \\n\\nMFS may invest 25% or more of the fund\\u2019s assets in municipal instruments that finance similar projects, such as those relating to education, healthcare, housing, utilities, water or sewers. Municipal instruments whose interest is exempt from federal and state personal income tax include instruments issued by U.S. territories and possessions (such as Puerto Rico, Guam, and the U.S. Virgin Islands) and their political subdivisions and public corporations.\\n\\n \\n\\nMFS primarily invests the fund\\u2019s assets in investment grade quality debt instruments, but may also invest in below investment grade quality debt instruments.\\n\\n \\n\\nMFS invests a significant percentage of the fund\\u2019s assets in municipal instruments of Georgia.\\n\\n \\n\\nWhile MFS may use derivatives for any investment purpose, to the extent MFS uses derivatives, MFS expects to use derivatives primarily to increase or decrease exposure to a particular market, segment of the market, or security, to increase or decrease interest rate exposure, or as alternatives to direct investments. Derivatives include futures, forward contracts, options, structured securities, inverse floating rate instruments, and swaps.\\n\\n \\n\\nMFS uses an active bottom-up investment approach to buying and selling investments for the fund. Investments are selected primarily based on fundamental analysis of individual instruments and their issuers. Quantitative models that systematically evaluate instruments may also be considered. In structuring the fund, MFS also considers top-down factors.\\n\\n \\n\\nFor purposes of the fund\\u2019s 80% policy, net assets include the amount of any borrowings for investment purposes.\\n\\n \\n\\nPrincipal Risks\\n\\n \\n\\nAs with any mutual fund, the fund may not achieve its objective and/or you could lose money on your investment in the fund. An investment in the fund is not a bank deposit and is not insured or guaranteed by the Federal Deposit Insurance Corporation or any other governmental agency.\\n\\n \\n\\nThe principal risks of investing in the fund are:\\n\\n \\n\\nDebt Market Risk:  Debt markets can be volatile and can decline significantly in response to, or investor perceptions of, issuer, market, economic, industry, political, regulatory, geopolitical, and other conditions.  These conditions can affect a single instrument, issuer, or borrower, a particular type of instrument, issuer, or borrower, a segment of the debt markets or the debt markets generally. Certain events can have a dramatic adverse effect on debt markets and may lead to periods of high volatility and reduced liquidity in a debt market or segment of a debt market.\\n\\n \\n\\nInterest Rate Risk:  In general, the price of a debt instrument falls when interest rates rise and rises when interest rates fall. Interest rate risk is generally greater for instruments with longer maturities, or that do not pay current interest.\\n\\n \\n\\nCredit Risk:  The price of a debt instrument depends, in part, on the credit quality of the issuer, borrower, counterparty, or other entity responsible for payment, or underlying collateral or assets and the terms of the instrument. The price of a debt instrument can decline in response to changes in the financial condition of the issuer, borrower, counterparty, or other entity, or underlying collateral or assets, or changes in specific or general market, economic, industry, political, regulatory, geopolitical, and other conditions.\\n\\n \\n\\nThe credit quality of, and the ability to pay principal and interest when due by, an issuer of a municipal instrument depends on the credit quality of the entity supporting the municipal instrument, how essential any services supported by the municipal instrument are, the sufficiency of any revenues or taxes that support the municipal instrument, and/or the willingness or ability of the appropriate government entity to approve any appropriations necessary to support the municipal instrument. In addition, the price of a municipal instrument also depends on its credit quality and ability to meet the credit support obligations of any insurer or other entity providing credit support to a municipal instrument.\\n\\n \\n\\nBelow investment grade quality debt instruments (commonly referred to as \\u201chigh yield securities\\u201d or \\u201cjunk bonds\\u201d) can involve a substantially greater risk of default or can already be in default, and their values can decline significantly. Below investment grade quality debt instruments are regarded as having predominantly speculative characteristics. Below investment grade quality debt instruments tend to be more sensitive to adverse news about the issuer, or the market or economy in general, than higher quality debt instruments.\\n\\n \\n\\nFocus Risk:  The fund\\u2019s performance will be closely tied to the economic and political conditions in Georgia, and can be more volatile than the performance of a more geographically diversified\\n\\n \\n\\n3\\n\\n\\n \\n\\nMFS Georgia Municipal Bond Fund\\n\\n \\n\\nfund. In addition, the fund\\u2019s performance can also be tied to the economic and political conditions of other states and U.S. territories and possessions in which the funds are invested. These conditions may include constitutional or statutory limits on an issuer\\u2019s ability to raise revenues or increase taxes, anticipated or actual budget deficits or other financial difficulties, or changes in the credit quality of municipal issuers in the state, other states, or U.S. territories and possessions.\\n\\n \\n\\nMunicipal Risk:  The price of a municipal instrument can be volatile and significantly affected by adverse tax changes or court rulings, legislative or political changes, changes in specific or general market and economic conditions, and the financial condition of municipal issuers and insurers. Because many municipal instruments are issued to finance similar projects, conditions in certain industries can significantly affect the fund and the overall municipal market.\\n\\n \\n\\nPrepayment/Extension Risk:  Instruments subject to prepayment and/or extension can reduce the potential for gain for the instrument\\u2019s holders if the instrument is prepaid and increase the potential for loss if the maturity of the instrument is extended.\\n\\n \\n\\nDerivatives Risk:  Derivatives can be highly volatile and involve risks in addition to the risks of the underlying indicator(s) on which the derivative is based. Gains or losses from derivatives can be substantially greater than the derivatives\\u2019 original cost.  Derivatives can involve leverage.\\n\\n \\n\\nLeveraging Risk:  Leverage involves investment exposure in an amount exceeding the initial investment. Leverage can cause increased volatility by magnifying gains or losses.\\n\\n \\n\\nCounterparty and Third Party Risk:  Transactions involving a counterparty or third party other than the issuer of the instrument are subject to the credit risk of the counterparty or third party, and to the counterparty\\u2019s or third party\\u2019s ability or willingness to perform in accordance with the terms of the transaction.\\n\\n \\n\\nLiquidity Risk:  It may be difficult to value, and it may not be possible to sell, certain investments, types of investments, and/or investments in certain segments of the market, and the fund may have to sell certain of these investments at prices or times that are not advantageous in order to meet redemptions or other cash needs.\\n\\n \\n\\nInvestment Selection Risk:  MFS\\u2019 investment analysis and its selection of investments may not produce the intended results and/or can lead to an investment focus that results in the fund underperforming other funds with similar investment strategies and/or underperforming the markets in which the fund invests.\\n\\n \\n\\nPerformance Information\\n\\n \\n\\nThe bar chart and performance table below are intended to provide some indication of the risks of investing in the fund by showing changes in the fund\\u2019s performance over time and how the fund\\u2019s performance over time compares with that of a broad measure of market performance.\\n\\n \\n\\nThe fund\\u2019s past performance (before and after taxes) does not necessarily indicate how the fund will perform in the future. Updated performance is available online at mfs.com or by calling 1-800-225-2606.\\n\\n \\n\\nClass A Bar Chart.  The bar chart does not take into account any sales charges (loads) that you may be required to pay upon purchase or redemption of the fund\\u2019s shares. If these sales charges were included, they would reduce the returns shown.\\n\\n \\n\\n\\n\\n \\n\\nThe total return for the six-month period ended June 30, 2018, was (0.07)%. During the period(s) shown in the bar chart, the highest quarterly return was 6.91% (for the calendar quarter ended September 30, 2009) and the lowest quarterly return was (5.23)% (for the calendar quarter ended December 31, 2010).\\n\\n \\n\\nPerformance Table.\\n\\n \\n\\nAverage Annual Total Returns\\n\\n(For the Periods Ended December 31, 2017)\\n\\n \\n\\nShare Class\\n\\n \\n\\n1 YEAR\\n\\n \\n\\n5 YEARS\\n\\n \\n\\n10 YEARS\\n\\n \\n\\nReturns Before Taxes\\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nT Shares\\n\\n \\n\\n1.71\\n\\n%\\n\\n1.76\\n\\n%\\n\\n3.64\\n\\n%\\n\\nB Shares\\n\\n \\n\\n(0.46\\n\\n)%\\n\\n1.15\\n\\n%\\n\\n3.27\\n\\n%\\n\\nI Shares\\n\\n \\n\\n4.58\\n\\n%\\n\\n2.53\\n\\n%\\n\\n4.16\\n\\n%\\n\\nR6 Shares\\n\\n \\n\\n4.53\\n\\n%\\n\\n2.52\\n\\n%\\n\\n4.16\\n\\n%\\n\\nA Shares\\n\\n \\n\\n(0.11\\n\\n)%\\n\\n1.39\\n\\n%\\n\\n3.46\\n\\n%\\n\\nReturns After Taxes on Distributions\\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nA Shares\\n\\n \\n\\n(0.12\\n\\n)%\\n\\n1.39\\n\\n%\\n\\n3.41\\n\\n%\\n\\nReturns After Taxes on Distributions and Sale of Fund Shares\\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nA Shares\\n\\n \\n\\n1.26\\n\\n%\\n\\n1.79\\n\\n%\\n\\n3.48\\n\\n%\\n\\nIndex Comparison (Reflects no deduction for fees, expenses, or taxes)\\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nBloomberg Barclays Municipal Bond Index\\n\\n \\n\\n5.45\\n\\n%\\n\\n3.02\\n\\n%\\n\\n4.46\\n\\n%\\n\\n \\n\\nAfter-tax returns are calculated using the historical highest individual federal marginal income tax rates and do not reflect the impact of state and local taxes. Your actual after-tax returns will depend on your own tax situation, and may differ from those shown. The after-tax returns shown are not relevant to investors who hold their shares through tax-advantaged arrangements, such as 401(k) plans or individual retirement accounts. The after-tax returns are shown for only one of the fund\\u2019s classes of shares, and after-tax returns for the fund\\u2019s other classes of shares will vary from the returns shown.\\n\\n \\n\\nInvestment Adviser\\n\\n \\n\\nMFS serves as the investment adviser for the fund.\\n\\n \\n\\n4\\n\\n\\n \\n\\nMFS Georgia Municipal Bond Fund\\n\\n \\n\\nPortfolio Manager(s)\\n\\n \\n\\nPortfolio Manager\\n\\n \\n\\nSince\\n\\n \\n\\nTitle\\n\\nMichael Dawson\\n\\n \\n\\n1999\\n\\n \\n\\nInvestment Officer of MFS\\n\\n \\n\\nPurchase and Sale of Fund Shares\\n\\n \\n\\nYou may purchase and redeem shares of the fund each day the New York Stock Exchange (the \\u201cNYSE\\u201d) is open for trading. You may purchase or redeem shares either by having your financial intermediary process your purchase or redemption, or through MFS Service Center, Inc. (MFSC) by overnight mail (MFSC, c/o DST Asset Manager Solutions, Inc., 30 Dan Road, Canton, MA  02021-2809), by mail ([Fund Name], P.O. Box 55824, Boston, MA 02205-5824), by telephone (1-800-225-2606), or via the Internet at mfs.com (MFS Access).\\n\\n \\n\\nThe fund\\u2019s initial and subsequent investment minimums generally are as follows:\\n\\n \\n\\nClass\\n\\n \\n\\nInitial Minimum\\n\\n \\n\\nSubsequent Minimum\\n\\n \\n\\nClass A, Class T, Class B\\n\\n \\n\\nNone \\u2013 automatic investment plans and certain asset-based fee programs\\n\\n$25 \\u2013 employer-sponsored retirement plans\\n\\n$250 \\u2013 Traditional and Roth IRAs\\n\\n$1,000 \\u2013 other accounts\\n\\n \\n\\n$50 \\u2013 by check and non-systematic written exchange request, and via MFSC telephone representatives\\n\\nNone \\u2013 other purchases\\n\\n \\n\\nClass I, Class R6\\n\\n \\n\\nNone\\n\\n \\n\\nNone\\n\\n \\n\\n \\n\\nAs of the date of this prospectus, Class T shares are not being offered for sale.\\n\\n \\n\\nTaxes\\n\\n \\n\\nThe fund intends to distribute income that is exempt from federal income tax, but may be subject to federal alternative minimum tax.  A portion of the fund\\u2019s distributions may be subject to federal income tax.\\n\\n \\n\\nPayments to Broker/Dealers and Other Financial Intermediaries\\n\\n \\n\\nIf you purchase shares of the fund through a broker/dealer or other financial intermediary (such as a bank), the fund, MFS, and/or MFS\\u2019 affiliates may pay the financial intermediary for the sale of shares of a fund and/or the servicing of shareholder accounts. These payments may create a conflict of interest by influencing your broker/dealer or other financial intermediary and your salesperson to recommend the fund over another investment. Ask your financial intermediary or visit your financial intermediary\\u2019s Web site for more information.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Function to get data (Assuming you have this defined)\n",
        "fund_names, summaries = get_data(SUMMARY_PATH)\n",
        "fund_names_in_X_test = X_test['fund_name'].tolist()\n",
        "\n",
        "# Correctly filter summaries where the fund name is in X_test\n",
        "# and ensure alignment between fund names and summaries\n",
        "selected_summaries_in_X_test = []\n",
        "fund_names_with_summaries = []\n",
        "\n",
        "for fund_name, summary in zip(fund_names, summaries):\n",
        "    if fund_name in fund_names_in_X_test:\n",
        "        selected_summaries_in_X_test.append(summary)\n",
        "        fund_names_with_summaries.append(fund_name)\n",
        "\n",
        "# Create DataFrame from extracted summaries\n",
        "df_extraction = pd.DataFrame({\n",
        "    'fund_name': fund_names_with_summaries,\n",
        "    'summary': selected_summaries_in_X_test\n",
        "})\n",
        "\n",
        "original_index = X_test.index\n",
        "X_test_new = X_test.merge(df_extraction, on='fund_name', how='left')\n",
        "X_test_new.index = original_index\n",
        "\n",
        "\n",
        "# Drop rows where the 'summary' is NaN and reset index\n",
        "X_test_new = X_test_new.dropna(subset=['summary'])\n",
        "\n",
        "X_test_new.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQ4PF6b9w4xh",
        "outputId": "0f7b23cf-368a-42eb-8095-5b051966017a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "324          Equity Long Only (Low Risk)\n",
              "448          Equity Long Only (Low Risk)\n",
              "298    Fixed Income Long Only (Low Risk)\n",
              "410          Equity Long Only (Low Risk)\n",
              "22           Equity Long Only (Low Risk)\n",
              "Name: Ivestment Strategy, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "# Ensure y_test is aligned with X_test_new\n",
        "# Filter y_test using the new index of X_test_new\n",
        "y_test_new = y_test.reindex(X_test_new.index)\n",
        "\n",
        "# Print the cleaned dataframes to confirm that rows have been dropped and indices reset accordingly\n",
        "y_test_new.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zj7OWo0Cw4xh",
        "outputId": "b107bb14-c50a-447e-a3bf-79a8b1fe57e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Leverage?  Portfolio composition   Concentration  Max Similarity  \\\n",
              "324        0.0                    1.0             0.0        0.095795   \n",
              "448        0.0                    1.0             0.0        0.113886   \n",
              "298        0.0                    2.0             0.0        0.121048   \n",
              "410        0.0                    2.0             0.0        0.088594   \n",
              "22         0.0                    2.0             0.0        0.112837   \n",
              "\n",
              "     Mean Similarity  \n",
              "324         0.017673  \n",
              "448         0.016614  \n",
              "298         0.017860  \n",
              "410         0.023219  \n",
              "22          0.021537  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c4d2158-0345-40df-9d7c-e4b34c602887\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Leverage?</th>\n",
              "      <th>Portfolio composition</th>\n",
              "      <th>Concentration</th>\n",
              "      <th>Max Similarity</th>\n",
              "      <th>Mean Similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>324</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.095795</td>\n",
              "      <td>0.017673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.113886</td>\n",
              "      <td>0.016614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.121048</td>\n",
              "      <td>0.017860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>410</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.088594</td>\n",
              "      <td>0.023219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.112837</td>\n",
              "      <td>0.021537</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c4d2158-0345-40df-9d7c-e4b34c602887')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5c4d2158-0345-40df-9d7c-e4b34c602887 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5c4d2158-0345-40df-9d7c-e4b34c602887');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5c5b9ac6-b337-47d5-b3cd-867817372d7b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5c5b9ac6-b337-47d5-b3cd-867817372d7b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5c5b9ac6-b337-47d5-b3cd-867817372d7b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_test_final",
              "summary": "{\n  \"name\": \"X_test_final\",\n  \"rows\": 47,\n  \"fields\": [\n    {\n      \"column\": \"Leverage?\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.48568785444140594,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Portfolio composition\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.765224749775401,\n        \"min\": 0.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" Concentration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.45215078571752676,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Max Similarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03304618648516146,\n        \"min\": 0.06310542753041129,\n        \"max\": 0.26710232784006077,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          0.07394077075709476,\n          0.10113756679314996\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mean Similarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0023981871531365715,\n        \"min\": 0.015297276844295039,\n        \"max\": 0.025234798423533513,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          0.01903013228823859,\n          0.018123203802441156\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "X_test_new = X_test_new.drop(columns =[\"id\", \"fund_name\", \"summary\", 'Performance fee?'])\n",
        "X_test_new['Leverage?'] = LabelEncoder().fit_transform(X_test_new['Leverage?'])\n",
        "\n",
        "# performance_mapping = {\n",
        "#     \"None\": 0,\n",
        "#     \"Some performance Fees\": 1\n",
        "# }\n",
        "\n",
        "portfolio_composition_mapping = {\n",
        "    \"Investment grade securities\": 0,\n",
        "    \"Listed Equities\": 1,\n",
        "    \"Sub-investment grade securities or emerging markets\": 2\n",
        "}\n",
        "\n",
        "concentration_mapping = {\n",
        "    \"Diversified\": 0,\n",
        "    \"Concentrated by issuer / sector / jurisdiction\": 1\n",
        "}\n",
        "\n",
        "# X_test_new['Performance fee?'] = X_test_new['Performance fee?'].map(performance_mapping)\n",
        "X_test_new['Portfolio composition'] = X_test_new['Portfolio composition'].map(portfolio_composition_mapping)\n",
        "X_test_new[' Concentration'] = X_test_new[' Concentration'].map(concentration_mapping)\n",
        "\n",
        "# Assume 'knowledge_base' is a list of documents/texts you have defined elsewhere\n",
        "all_texts = selected_summaries_in_X_test + knowledge_base\n",
        "\n",
        "# Create a TF-IDF Vectorizer and vectorize all texts\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(all_texts)\n",
        "\n",
        "# Extract TF-IDF vectors for summaries and KB entries\n",
        "tfidf_summaries = tfidf_matrix[:len(selected_summaries_in_X_test)]\n",
        "tfidf_kb_entries = tfidf_matrix[len(selected_summaries_in_X_test):]\n",
        "\n",
        "# Calculate cosine similarity between each summary and each KB entry\n",
        "similarity_matrix = cosine_similarity(tfidf_summaries, tfidf_kb_entries)\n",
        "\n",
        "# Feature engineering\n",
        "max_similarity = np.max(similarity_matrix, axis=1)\n",
        "mean_similarity = np.mean(similarity_matrix, axis=1)\n",
        "\n",
        "# Combine features for X_test\n",
        "X_test_features = np.column_stack((max_similarity, mean_similarity))\n",
        "X_test_combined = np.hstack((X_test_new.values, X_test_features))\n",
        "X_test_final = pd.DataFrame(X_test_combined, columns=list(X_test_new.columns) + ['Max Similarity', 'Mean Similarity'])\n",
        "X_test_final.index = X_test_new.index\n",
        "\n",
        "X_test_final.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVScLwTlw4xh",
        "outputId": "1e2c5088-01e0-4700-8162-f1550df895a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "324    2\n",
              "448    2\n",
              "298    1\n",
              "410    2\n",
              "22     2\n",
              "Name: Ivestment Strategy, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "# Encoded investment strategy\n",
        "investment_strategy_mapping = {\n",
        "    \"Balanced Fund (Low Risk)\": 0,\n",
        "    \"Fixed Income Long Only (Low Risk)\": 1,\n",
        "    \"Equity Long Only (Low Risk)\": 2,\n",
        "    \"Long Short Funds (High Risk)\": 3,\n",
        "    \"Commodities Fund (Low Risk)\": 4\n",
        "}\n",
        "\n",
        "# Apply the mapping to the 'Investment Strategy' column\n",
        "y_test_mapped = y_test_new.map(investment_strategy_mapping)\n",
        "y_test_mapped.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest"
      ],
      "metadata": {
        "id": "2nCfFqe-MZk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Training a Random Forest model\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "rf_classifier.fit(X_train_final, y_train_mapped)\n",
        "rf_predictions = rf_classifier.predict(X_val_final)\n",
        "\n",
        "# Evaluating the models\n",
        "print(\"Random Forest Model Accuracy:\", accuracy_score(y_val_mapped, rf_predictions))\n",
        "print(\"\\nRandom Forest Classification Report:\\n\", classification_report(y_val_mapped, rf_predictions))\n"
      ],
      "metadata": {
        "id": "oNO8mObVMZHq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2a74d1e-ba6f-4a48-a188-c16d5d1f0fb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Model Accuracy: 0.6451612903225806\n",
            "\n",
            "Random Forest Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.21      0.18      0.19        17\n",
            "           1       0.54      0.58      0.56        26\n",
            "           2       0.84      0.89      0.87        47\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.65        93\n",
            "   macro avg       0.32      0.33      0.32        93\n",
            "weighted avg       0.61      0.65      0.63        93\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpVS1vwNyYcq"
      },
      "source": [
        "# LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA57Rbe3ycPW",
        "outputId": "576da61f-b2e5-49fe-a421-35a27aad17b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000119 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 225\n",
            "[LightGBM] [Info] Number of data points in the train set: 326, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score -1.659763\n",
            "[LightGBM] [Info] Start training from score -1.320989\n",
            "[LightGBM] [Info] Start training from score -0.616413\n",
            "[LightGBM] [Info] Start training from score -5.786897\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "LightGBM Model Accuracy: 0.6559139784946236\n",
            "\n",
            "LightGBM Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.29      0.28        17\n",
            "           1       0.56      0.54      0.55        26\n",
            "           2       0.86      0.89      0.88        47\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.66        93\n",
            "   macro avg       0.34      0.35      0.34        93\n",
            "weighted avg       0.64      0.66      0.65        93\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Training a LightGBM model\n",
        "lgb_classifier = lgb.LGBMClassifier(random_state=42)\n",
        "lgb_classifier.fit(X_train_final, y_train_mapped)\n",
        "lgb_predictions = lgb_classifier.predict(X_val_final)\n",
        "\n",
        "# Evaluating the models\n",
        "print(\"LightGBM Model Accuracy:\", accuracy_score(y_val_mapped, lgb_predictions))\n",
        "print(\"\\nLightGBM Classification Report:\\n\", classification_report(y_val_mapped, lgb_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMrY0kBEylHZ"
      },
      "source": [
        "# XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5_faHbNw4xh",
        "outputId": "8b384246-18fe-48e5-8674-0ad52f32e80a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Model Accuracy: 0.6774193548387096\n",
            "\n",
            "XGBoost Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.29      0.29        17\n",
            "           1       0.58      0.58      0.58        26\n",
            "           2       0.86      0.91      0.89        47\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.68        93\n",
            "   macro avg       0.35      0.36      0.35        93\n",
            "weighted avg       0.65      0.68      0.66        93\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "# Training an XGBoost model\n",
        "xgb_classifier = xgb.XGBClassifier(random_state=42)\n",
        "xgb_classifier.fit(X_train_final, y_train_mapped)\n",
        "xgb_predictions = xgb_classifier.predict(X_val_final)\n",
        "\n",
        "# Evaluating the models\n",
        "print(\"XGBoost Model Accuracy:\", accuracy_score(y_val_mapped, xgb_predictions))\n",
        "print(\"\\nXGBoost Classification Report:\\n\", classification_report(y_val_mapped, xgb_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3Kob1JiU3kG"
      },
      "source": [
        "# 5. Use validation data to tune your parameters of your classification algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest"
      ],
      "metadata": {
        "id": "6vGSVcamMtPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Define the parameter grid for Random Forest\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
        "    'max_depth': [None, 10, 20, 30],  # Maximum depth of the tree\n",
        "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
        "    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
        "    'bootstrap': [True, False],  # Method of selecting samples for training each tree\n",
        "}\n",
        "\n",
        "# Create the Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Create the RandomizedSearchCV object\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=rf_classifier,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=100,  # number of parameter settings that are sampled\n",
        "    scoring='accuracy',  # can choose different scoring function based on the problem\n",
        "    cv=5,  # number of folds in cross-validation\n",
        "    verbose=1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1  # number of jobs to run in parallel\n",
        ")\n",
        "\n",
        "# Fit the random search model\n",
        "random_search.fit(X_val_final, y_val_mapped)\n",
        "\n",
        "# The best estimator after random search\n",
        "best_rf_classifier = random_search.best_estimator_"
      ],
      "metadata": {
        "id": "8lVZszpeMvZc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ba63648-2c9f-4ac5-e6ad-e31daa60a302"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning:\n",
            "\n",
            "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning:\n",
            "\n",
            "The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning:\n",
            "\n",
            "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZn1laWnw4xi"
      },
      "source": [
        "## LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFZq8nqEfrX-",
        "outputId": "2b1c9676-0711-4cdd-f922-71d4421a2a9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning:\n",
            "\n",
            "The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000087 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 69\n",
            "[LightGBM] [Info] Number of data points in the train set: 93, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score -1.699386\n",
            "[LightGBM] [Info] Start training from score -1.274503\n",
            "[LightGBM] [Info] Start training from score -0.682452\n",
            "[LightGBM] [Info] Start training from score -3.839452\n",
            "[LightGBM] [Info] Start training from score -4.532599\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        }
      ],
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Define the parameter grid\n",
        "param_dist = {\n",
        "    'num_leaves': [31, 41, 51, 61, 71],  # example values\n",
        "    'reg_alpha': [0.1, 0.5, 1.0],  # example values\n",
        "    'reg_lambda': [0.1, 0.5, 1.0],  # example values\n",
        "    'min_split_gain': [0.0, 0.01, 0.1],  # example values\n",
        "    'min_child_weight': [1e-3, 1e-2, 0.1, 1, 10],  # example values\n",
        "    'learning_rate': [0.005, 0.01, 0.1],  # example values\n",
        "    # add other parameters here\n",
        "}\n",
        "\n",
        "# Create the LightGBM classifier\n",
        "lgb_classifier = lgb.LGBMClassifier(random_state=42)\n",
        "\n",
        "# Create the RandomizedSearchCV object\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=lgb_classifier,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=100,  # number of parameter settings that are sampled\n",
        "    scoring='accuracy',  # can choose different scoring function based on the problem\n",
        "    cv=5,  # number of folds in cross-validation\n",
        "    verbose=1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1  # number of jobs to run in parallel\n",
        ")\n",
        "\n",
        "# Fit the random search model\n",
        "random_search.fit(X_val_final, y_val_mapped)\n",
        "\n",
        "# The best estimator after random search\n",
        "best_lgbm_classifier = random_search.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDt1Nf-fw4xi"
      },
      "source": [
        "## XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIb0glDE4PWT",
        "outputId": "675e2b45-aa8c-49ce-8f9c-57a1228b7ff9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning:\n",
            "\n",
            "The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Define the parameter grid to search\n",
        "param_dist = {\n",
        "    'max_depth': [3, 4, 5, 6, 7],  # example range\n",
        "    'min_child_weight': [1, 5, 10],\n",
        "    'gamma': [0.5, 1, 1.5, 2, 5],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "    'learning_rate': [0.01, 0.02, 0.05, 0.1],  # example range\n",
        "    # You can add more parameters here\n",
        "}\n",
        "\n",
        "# Initialize the XGBClassifier\n",
        "xgb_classifier = xgb.XGBClassifier(random_state=42)\n",
        "\n",
        "# Initialize the RandomizedSearchCV object\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=xgb_classifier,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=100,  # number of parameter settings that are sampled\n",
        "    scoring='accuracy',  # can be adjusted based on the problem\n",
        "    cv=3,  # number of folds in cross-validation\n",
        "    verbose=1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1  # number of jobs to run in parallel\n",
        ")\n",
        "\n",
        "# Fit the random search model\n",
        "random_search.fit(X_val_final, y_val_mapped)\n",
        "\n",
        "# Best estimator found by random search\n",
        "best_xgb_classifier = random_search.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b0wyuBA4jEy"
      },
      "source": [
        "# 6. Apply your classification algorithm to predict the investment strategy of each fund in the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bISIogxQw4xi",
        "outputId": "f36bde02-fec2-44aa-9cde-2197c0891f4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Random Forest Model Accuracy: 0.7446808510638298\n",
            "\n",
            "Best Random Forest Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      0.40      0.31         5\n",
            "           1       0.79      0.65      0.71        17\n",
            "           2       0.88      0.92      0.90        24\n",
            "           3       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.74        47\n",
            "   macro avg       0.48      0.49      0.48        47\n",
            "weighted avg       0.76      0.74      0.75        47\n",
            "\n",
            "Best LightGBM Model Accuracy: 0.8085106382978723\n",
            "\n",
            "Best LightGBM Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         5\n",
            "           1       0.71      0.88      0.79        17\n",
            "           2       0.88      0.96      0.92        24\n",
            "           3       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.81        47\n",
            "   macro avg       0.40      0.46      0.43        47\n",
            "weighted avg       0.71      0.81      0.76        47\n",
            "\n",
            "Best XGBoost Model Accuracy: 0.8085106382978723\n",
            "\n",
            "Best XGBoost Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         5\n",
            "           1       0.71      0.88      0.79        17\n",
            "           2       0.88      0.96      0.92        24\n",
            "           3       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.81        47\n",
            "   macro avg       0.40      0.46      0.43        47\n",
            "weighted avg       0.71      0.81      0.76        47\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Random Forest\n",
        "rf_predictions = best_rf_classifier.predict(X_test_final)\n",
        "\n",
        "# Evaluating the model\n",
        "print(\"Best Random Forest Model Accuracy:\", accuracy_score(y_test_mapped, rf_predictions))\n",
        "print(\"\\nBest Random Forest Classification Report:\\n\", classification_report(y_test_mapped, rf_predictions))\n",
        "\n",
        "# LightGBM\n",
        "lgb_predictions = best_lgbm_classifier.predict(X_test_final)\n",
        "\n",
        "# Evaluating the model\n",
        "print(\"Best LightGBM Model Accuracy:\", accuracy_score(y_test_mapped, lgb_predictions))\n",
        "print(\"\\nBest LightGBM Classification Report:\\n\", classification_report(y_test_mapped, lgb_predictions))\n",
        "\n",
        "# XGBoost\n",
        "xgb_predictions = best_xgb_classifier.predict(X_test_final)\n",
        "\n",
        "# Evaluate the best estimator\n",
        "print(\"Best XGBoost Model Accuracy:\", accuracy_score(y_test_mapped, xgb_predictions))\n",
        "print(\"\\nBest XGBoost Classification Report:\\n\", classification_report(y_test_mapped, xgb_predictions))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuAsWJrIw4xi"
      },
      "source": [
        "# 7. Instead of building word embedding ourselves, we can also use pre-trained model (for example, sentence Bert) to extract key sentences of each summary. If you use one of pre-trained models, compare the performance of your classification model in the test set with the model using your own word embedding."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## X_val preprocessing"
      ],
      "metadata": {
        "id": "x4PZiGOPDmYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Function to get data (Assuming you have this defined)\n",
        "fund_names, summaries = get_data(SUMMARY_PATH)\n",
        "fund_names_in_X_val = X_val['fund_name'].tolist()\n",
        "\n",
        "# Correctly filter summaries where the fund name is in X_test\n",
        "# and ensure alignment between fund names and summaries\n",
        "selected_summaries_in_X_val = []\n",
        "fund_names_with_summaries = []\n",
        "\n",
        "for fund_name, summary in zip(fund_names, summaries):\n",
        "    if fund_name in fund_names_in_X_val:\n",
        "        selected_summaries_in_X_val.append(summary)\n",
        "        fund_names_with_summaries.append(fund_name)\n",
        "\n",
        "# Create DataFrame from extracted summaries\n",
        "df_extraction = pd.DataFrame({\n",
        "    'fund_name': fund_names_with_summaries,\n",
        "    'summary': selected_summaries_in_X_val\n",
        "})\n",
        "\n",
        "original_index = X_val.index\n",
        "X_val_new = X_val.merge(df_extraction, on='fund_name', how='left')\n",
        "X_val_new.index = original_index\n",
        "\n",
        "\n",
        "# Drop rows where the 'summary' is NaN and reset index\n",
        "X_val_new = X_val_new.dropna(subset=['summary'])\n",
        "\n",
        "X_val_new.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "CxGS3UK1DTXG",
        "outputId": "7c1ba609-e015-4bb8-876e-93bd61b82afb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <progress\n",
              "            value='544'\n",
              "            max='544',\n",
              "            style='width: 100%'\n",
              "        >\n",
              "            544\n",
              "        </progress>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       id                                          fund_name  \\\n",
              "56   0000051931-18-001409    American Funds 2060 Target Date Retirement Fund   \n",
              "181  0001193125-18-020442                        Janus Henderson Triton Fund   \n",
              "329  0001379491-18-002694                 Fidelity Advisor Freedom 2020 Fund   \n",
              "271  0001193125-18-227777                             Ivy Global Growth Fund   \n",
              "31   0000051931-18-000465  Portfolio Series - American Funds Global Growt...   \n",
              "\n",
              "    Performance fee? Leverage?  \\\n",
              "56               NaN        No   \n",
              "181              NaN        No   \n",
              "329              NaN       Yes   \n",
              "271              NaN        No   \n",
              "31               NaN        No   \n",
              "\n",
              "                                 Portfolio composition  Concentration  \\\n",
              "56                         Investment grade securities    Diversified   \n",
              "181                                    Listed Equities    Diversified   \n",
              "329  Sub-investment grade securities or emerging ma...    Diversified   \n",
              "271                                    Listed Equities    Diversified   \n",
              "31   Sub-investment grade securities or emerging ma...    Diversified   \n",
              "\n",
              "                                               summary  \n",
              "56   American Funds 2060 Target Date Retirement Fun...  \n",
              "181  Janus Henderson Triton Fund\\n(closed to certai...  \n",
              "329  Fund Summary\\n\\nFund/Class:\\nFidelity Freedom®...  \n",
              "271  Ivy Global Growth Fund\\n\\nObjective\\n\\nTo seek...  \n",
              "31   American Funds Global Growth Portfolio\\n\\nInve...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c4dd1de3-2135-42fc-91f2-50fb9155ab33\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>fund_name</th>\n",
              "      <th>Performance fee?</th>\n",
              "      <th>Leverage?</th>\n",
              "      <th>Portfolio composition</th>\n",
              "      <th>Concentration</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>0000051931-18-001409</td>\n",
              "      <td>American Funds 2060 Target Date Retirement Fund</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>Investment grade securities</td>\n",
              "      <td>Diversified</td>\n",
              "      <td>American Funds 2060 Target Date Retirement Fun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>0001193125-18-020442</td>\n",
              "      <td>Janus Henderson Triton Fund</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>Listed Equities</td>\n",
              "      <td>Diversified</td>\n",
              "      <td>Janus Henderson Triton Fund\\n(closed to certai...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>329</th>\n",
              "      <td>0001379491-18-002694</td>\n",
              "      <td>Fidelity Advisor Freedom 2020 Fund</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Sub-investment grade securities or emerging ma...</td>\n",
              "      <td>Diversified</td>\n",
              "      <td>Fund Summary\\n\\nFund/Class:\\nFidelity Freedom®...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>0001193125-18-227777</td>\n",
              "      <td>Ivy Global Growth Fund</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>Listed Equities</td>\n",
              "      <td>Diversified</td>\n",
              "      <td>Ivy Global Growth Fund\\n\\nObjective\\n\\nTo seek...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0000051931-18-000465</td>\n",
              "      <td>Portfolio Series - American Funds Global Growt...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>Sub-investment grade securities or emerging ma...</td>\n",
              "      <td>Diversified</td>\n",
              "      <td>American Funds Global Growth Portfolio\\n\\nInve...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4dd1de3-2135-42fc-91f2-50fb9155ab33')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c4dd1de3-2135-42fc-91f2-50fb9155ab33 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c4dd1de3-2135-42fc-91f2-50fb9155ab33');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b78b5a70-e9ad-4726-b091-4bf88da0818f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b78b5a70-e9ad-4726-b091-4bf88da0818f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b78b5a70-e9ad-4726-b091-4bf88da0818f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_val_new",
              "summary": "{\n  \"name\": \"X_val_new\",\n  \"rows\": 93,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 42,\n        \"samples\": [\n          \"0001206774-18-001008\",\n          \"0000932471-18-006088\",\n          \"0001193125-18-285341\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fund_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 93,\n        \"samples\": [\n          \"Franklin FTSE China ETF\",\n          \"AllianzGI Income & Growth Fund\",\n          \"Fidelity Managed Retirement 2025 Fund\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Performance fee?\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Some performance Fees\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Leverage?\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Portfolio composition\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Investment grade securities\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" Concentration\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Concentrated by issuer / sector / jurisdiction\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 93,\n        \"samples\": [\n          \"Franklin FTSE China ETF\\n\\nInvestment Goal\\n\\nTo seek to provide investment results that closely correspond, before fees and expenses, to the performance of the FTSE China RIC Capped Index (the FTSE China Capped Index).\\n\\nFees and Expenses of the Fund\\n\\nThe following table describes the fees and expenses that you will incur if you own shares of the Fund. You may also incur usual and customary brokerage commissions when buying or selling shares of the Fund, which are not reflected in the Example that follows.\\n\\n\\nAnnual Fund Operating Expenses\\n\\n(expenses that you pay each year as a percentage of the value of your investment)\\n\\nManagement fees \\t0.19% \\nDistribution and service (12b-1) fees \\tNone \\nOther expenses1 \\tNone \\nTotal annual Fund operating expenses \\t0.19% \\n1. Other expenses are based on estimated amounts for the current fiscal year.\\n\\nExample\\n\\nThis Example is intended to help you compare the cost of investing in the Fund with the cost of investing in other funds. The Example assumes that you invest $10,000 in the Fund for the time periods indicated and then redeem all of your shares at the end of the period. The Example also assumes that your investment has a 5% return each year and that the Fund's operating expenses remain the same. Although your actual costs may be higher or lower, based on these assumptions your costs would be:\\n\\n   \\t1 Year \\t3 Years \\n   \\t$ 19 \\t$ 61 \\nPortfolio Turnover\\n\\nThe Fund pays transaction costs, such as commissions, when it buys and sells securities (or \\\"turns over\\\" its portfolio). A higher portfolio turnover rate may indicate higher transaction costs and may result in higher taxes when Fund shares are held in a taxable account. These costs, which are not reflected in annual Fund operating expenses or in the Example, affect the Fund's performance. During the Fund's first fiscal period (November 2, 2017 to March 31, 2018), the Fund's portfolio turnover rate was 2.71% of the average value of its portfolio.\\n\\nPrincipal Investment Strategies\\n\\nUnder normal market conditions, the Fund invests at least 80% of its assets in the component securities of the FTSE China Capped Index and in depositary receipts representing such securities. The FTSE China Capped Index is a free float-adjusted market capitalization weighted index maintained and calculated by FTSE Russell with a capping methodology applied quarterly to issuer weights so that no single issuer of a component exceeds 25% of the FTSE China Capped Index weight, and all issuers with weights above 5% do not cumulatively exceed 50% of the FTSE China Capped Index\\u2019s weight. The FTSE China Capped Index is based on the FTSE China Index and is designed to measure the performance of Chinese large- and mid-capitalization stocks, as represented by H-Shares (securities of companies incorporated in the People\\u2019s Republic of China (PRC) that are denominated in Hong Kong dollars and listed on the Hong Kong Exchange) and B-Shares (securities of companies incorporated in the PRC and listed for foreign investment on either the Shanghai or Shenzhen stock exchanges). The FTSE China Capped Index also includes certain securities listed outside of the PRC known as N-Shares (issued by companies incorporated in certain foreign jurisdictions, which are controlled, directly or indirectly, by entities, companies or individuals in the PRC, derive substantial revenues or allocate substantial assets in the PRC and are listed on the New York Stock Exchange, NASDAQ or the NYSE MKT), Red-Chips (issued by companies incorporated in certain foreign jurisdictions, which are controlled, directly or indirectly, by entities owned by the national government or local governments in the PRC, derive substantial revenues or allocate substantial assets in the PRC and are listed on the Hong Kong Exchange), P-Chips (issued by companies incorporated in certain foreign jurisdictions, which are controlled, directly or indirectly, by individuals in the PRC, derive substantial revenues or allocate substantial assets in the PRC and are listed on the Hong Kong Exchange) and S-Chips (issued by companies incorporated in certain foreign jurisdictions, which are controlled, directly or indirectly, by entities, companies or individuals in the PRC, derive substantial revenues or allocate substantial assets in the PRC and are listed on the Singapore Exchange). FTSE Russell determines eligible securities for the FTSE China Capped Index based on measures such as the company\\u2019s place of incorporation, quality of investor protection, tax domicile, location of headquarters/factors of production and currency of denomination. As of June 29, 2018, the FTSE China Capped Index was comprised of 262 securities with capitalizations ranging from $89 million to $285.69 billion.\\n\\nThe Fund, using a \\u201cpassive\\u201d or indexing investment approach, seeks investment results that closely correspond, before fees and expenses, to the performance of the FTSE China Capped Index. The investment manager seeks to achieve, over time, a correlation between the Fund\\u2019s performance, before fees and expenses, and that of the FTSE China Capped Index of 0.95 or better. A figure of 1.00 would indicate perfect correlation. The Fund\\u2019s intention is to replicate the component securities of the FTSE China Capped Index as closely as possible (i.e., invest in all of the component securities in their respective weightings in the FTSE China Capped Index). However, under various circumstances, it may not be possible or practicable to replicate the FTSE China Capped Index. In these circumstances, the Fund may use a \\u201crepresentative sampling\\u201d strategy whereby the Fund would invest in what it believes to be a representative sample of the component securities of the FTSE China Capped Index, but may not track the FTSE China Capped Index with the same degree of accuracy as would an investment vehicle replicating the entire FTSE China Capped Index. Under the representative sampling technique, the investment manager will select securities that collectively have an investment profile similar to that of the FTSE China Capped Index, including securities that resemble those included in the FTSE China Capped Index in terms of risk factors, performance attributes and other characteristics, such as market capitalization and industry weightings.\\n\\nThe Fund is a \\\"non-diversified\\\" fund, which means it generally invests a greater proportion of its assets in the securities of one or more issuers and invests overall in a smaller number of issuers than a diversified fund.\\n\\nThe Fund will concentrate its investments (i.e., hold 25% or more of its net assets) in a particular industry or group of industries to approximately the same extent that the FTSE China Capped Index is concentrated. As of June 29, 2018, the FTSE China Capped Index was concentrated in the internet software and services industry.\\n\\nPrincipal Risks\\n\\nYou could lose money by investing in the Fund. Exchange-traded fund (ETF) shares are not deposits or obligations of, or guaranteed or endorsed by, any bank, and are not insured by the Federal Deposit Insurance Corporation, the Federal Reserve Board, or any other agency of the U.S. government. The Fund is subject to the principal risks noted below, any of which may adversely affect the Fund\\u2019s net asset value (NAV), trading price, yield, total return and ability to meet its investment goal.\\n\\nMarket   The market values of securities or other investments owned by the Fund will go up or down, sometimes rapidly or unpredictably. The market value of a security or other investment may be reduced by market activity or other results of supply and demand unrelated to the issuer. This is a basic risk associated with all investments. When there are more sellers than buyers, prices tend to fall. Likewise, when there are more buyers than sellers, prices tend to rise.\\n\\nStock prices tend to go up and down more dramatically than those of debt securities. A slower-growth or recessionary economic environment could have an adverse effect on the prices of the various stocks held by the Fund.\\n\\nForeign Securities (non-U.S.)   Investing in foreign securities typically involves more risks than investing in U.S. securities, and includes risks associated with: (i) internal and external political and economic developments \\u2013 e.g., the political, economic and social policies and structures of some foreign countries may be less stable and more volatile than those in the U.S. or some foreign countries may be subject to trading restrictions or economic sanctions; (ii) trading practices \\u2013 e.g., government supervision and regulation of foreign securities and currency markets, trading systems and brokers may be less than in the U.S.; (iii) availability of information \\u2013 e.g., foreign issuers may not be subject to the same disclosure, accounting and financial reporting standards and practices as U.S. issuers; (iv) limited markets \\u2013 e.g., the securities of certain foreign issuers may be less liquid (harder to sell) and more volatile; and (v) currency exchange rate fluctuations and policies (e.g., fluctuations may negatively affect investments denominated in foreign currencies and any income received or expenses paid by the Fund in that foreign currency). The risks of foreign investments may be greater in developing or emerging market countries.\\n\\nEmerging Market Countries   The Fund\\u2019s investments in emerging market issuers are subject to all of the risks of foreign investing generally, and have additional heightened risks due to a lack of established legal, political, business and social frameworks to support securities markets, including: delays in settling portfolio securities transactions; currency and capital controls; greater sensitivity to interest rate changes; pervasiveness of corruption and crime; currency exchange rate volatility; and inflation, deflation or currency devaluation.\\n\\nGeographic Focus   Because the Fund invests its assets primarily in companies in a specific country and region, the Fund is subject to greater risks of adverse developments in that country, region and/or the surrounding regions than a fund that is more broadly diversified geographically. Political, social or economic disruptions in the country or region, even in countries in which the Fund is not invested, may adversely affect the value of investments held by the Fund.\\n\\nThere are special risks associated with investments in China, including exposure to currency fluctuations, less liquidity, expropriation, confiscatory taxation, nationalization and exchange control regulations (including currency blockage). Inflation and rapid fluctuations in inflation and interest rates have had, and may continue to have, negative effects on the economy and securities markets of China. China is deemed by the investment manager to be an emerging markets country, which means an investment in this country has more heightened risks than general foreign investing due to a lack of established legal, political, business and social frameworks in the country to support securities markets as well as the possibility for more widespread corruption and fraud.\\n\\nDepositary Receipts   Depositary receipts are subject to many of the risks of the underlying securities. For some depositary receipts, the custodian or similar financial institution that holds the issuer's shares in a trust account is located in the issuer's home country. In these cases if the issuer\\u2019s home country does not have developed financial markets, the Fund could be exposed to the credit risk of the custodian or financial institution and greater market risk. In addition, the depository institution may not have physical custody of the underlying securities at all times and may charge fees for various services. The Fund may experience delays in receiving its dividend and interest payments or exercising rights as a shareholder. There may be an increased possibility of untimely responses to certain corporate actions of the issuer in an unsponsored depositary receipt program. Accordingly, there may be less information available regarding issuers of securities underlying unsponsored programs and there may not be a correlation between this information and the market value of the depositary receipts.\\n\\nCalculation Methodology   FTSE Russell relies on various sources of information to assess the criteria of issuers included in the FTSE China Capped Index, including information that may be based on assumptions and estimates. Neither the Fund nor the investment manager can offer assurances that FTSE Russell\\u2019s calculation methodology or sources of information will provide an accurate assessment of included issuers or that the included issuers will provide the Fund with the market exposure it seeks.\\n\\nIndex-Related   There is no assurance that the FTSE China Capped Index will be determined, composed or calculated accurately. While FTSE Russell provides descriptions of what the FTSE China Capped Index is designed to achieve, FTSE Russell does not guarantee the quality, accuracy or completeness of data in respect of its indices, and does not guarantee that the FTSE China Capped Index will be in line with the described index methodology. Gains, losses or costs to the Fund caused by errors in the FTSE China Capped Index may therefore be borne by the Fund and its shareholders.\\n\\nNon-Correlation   There is no guarantee that the Fund will achieve a high degree of correlation to the FTSE China Capped Index and therefore achieve its investment goal. Market disruptions and regulatory restrictions could have an adverse effect on the Fund\\u2019s ability to adjust its exposure to the required levels in order to track the FTSE China Capped Index. In addition, the Fund\\u2019s NAV may deviate from the FTSE China Capped Index if the Fund fair values a portfolio security at a price other than the price used by the FTSE China Capped Index for that security. To the extent that the investment manager uses a representative sampling strategy, the Fund may not track the return of the FTSE China Capped Index as well as it would have if the Fund held all of the securities in the FTSE China Capped Index.\\n\\nTracking Error   Tracking error is the divergence of the Fund\\u2019s performance from that of the FTSE China Capped Index. Tracking error may occur because of differences between the securities held in the Fund\\u2019s portfolio and those included in the FTSE China Capped Index, pricing differences (including differences between a security\\u2019s price at the local market close and the Fund\\u2019s valuation of a security at the time of calculation of the Fund\\u2019s NAV), transaction costs, the Fund\\u2019s holding of cash, differences in timing of the accrual of dividends or interest, tax gains or losses, changes to the FTSE China Capped Index or the need to meet various new or existing regulatory requirements. This risk may be heightened during times of increased market volatility or other unusual market conditions. Tracking error also may result because the Fund incurs fees and expenses, while the FTSE China Capped Index does not.\\n\\nMarket Trading   The Fund faces numerous market trading risks, including the potential lack of an active market for Fund shares, losses from trading in secondary markets, periods of high volatility and disruption in the creation/redemption process of the Fund. Any of these factors, among others, may lead to the Fund\\u2019s shares trading at a premium or discount to NAV. Thus, you may pay more (or less) than NAV when you buy shares of the Fund in the secondary market, and you may receive less (or more) than NAV when you sell those shares in the secondary market. The investment manager cannot predict whether shares will trade above (premium), below (discount) or at NAV.\\n\\nConcentration   To the extent the Fund concentrates in a specific industry, a group of industries, sector or type of investment, the Fund will carry much greater risks of adverse developments and price movements in such industries, sectors or investments than a fund that invests in a wider variety of industries, sectors or investments. There is also the risk that the Fund will perform poorly during a slump in demand for securities of companies in such industries or sectors.\\n\\nThe Fund may focus in the internet software and services industry. Competitive pressures, such as technological developments, fixed-rate pricing and the ability to attract and retain skilled employees, can significantly affect companies in the internet software and services industry. Changing domestic and international demand, research and development costs, availability and price of components and product obsolescence also can affect profitability of companies in this industry.\\n\\nNon-Diversification   Because the Fund is non-diversified, it may be more sensitive to economic, business, political or other changes affecting individual issuers or investments than a diversified fund, which may result in greater fluctuation in the value of the Fund\\u2019s shares and greater risk of loss.\\n\\nMidsize Companies   Securities issued by midsize companies may be more volatile in price than those of larger companies, involve substantial risks and should be considered speculative. Such risks may include greater sensitivity to economic conditions, less certain growth prospects, lack of depth of management and funds for growth and development, and limited or less developed product lines and markets. In addition, midsize companies may be particularly affected by interest rate increases, as they may find it more difficult to borrow money to continue or expand operations, or may have difficulty in repaying any loans.\\n\\nPassive Investment   Unlike many investment companies, the Fund is not actively managed and the investment manager does not attempt to take defensive positions under any market conditions, including declining markets. Therefore, the investment manager would not necessarily buy or sell a security unless that security is added or removed, respectively, from the FTSE China Capped Index, even if that security generally is underperforming.\\n\\nInternational Closed Market Trading   To the extent that the underlying securities held by the Fund trade on an exchange that is closed when the securities exchange on which the Fund shares list and trade is open, there may be market uncertainty about the stale security pricing (i.e., the last quote from its closed foreign market) resulting in premiums or discounts to NAV that may be greater than those experienced by other ETFs.\\n\\nAuthorized Participant Concentration   Only an authorized participant (Authorized Participant) may engage in creation or redemption transactions directly with the Fund. The Fund has a limited number of institutions that act as Authorized Participants. To the extent that these institutions exit the business or are unable to proceed with creation and/or redemption orders with respect to the Fund and no other Authorized Participant is able to step forward to create or redeem Creation Units (as defined below), Fund shares may trade at a discount to NAV and possibly face trading halts and/or delisting. This risk may be more pronounced in volatile markets, potentially where there are significant redemptions in ETFs generally.\\n\\nCash Transactions   Unlike certain ETFs, the Fund expects to generally effect its creations and redemptions partially for cash, rather than for in-kind securities. Therefore, it may be required to sell portfolio securities and subsequently recognize gains on such sales that the Fund might not have recognized if it were to distribute portfolio securities in-kind. As such, investments in Fund shares may be less tax-efficient than an investment in an ETF that distributes portfolio securities entirely in-kind.\\n\\nPerformance\\n\\nBecause the Fund does not have a full calendar year of performance, annual total return information is not available and therefore is not presented. You can obtain updated performance information at libertyshares.com or by calling (800) DIAL BEN/342-5236. The Fund's past performance (before and after taxes) is not necessarily an indication of how the Fund will perform in the future.\\n\\nInvestment Manager\\n\\nFranklin Advisers, Inc. (Advisers)\\n\\nPortfolio Managers\\n\\nDina Ting, CFA   Portfolio Manager of Advisers and lead portfolio manager of the Fund since inception (2017).\\n\\nLouis Hsu, CFA   Portfolio Manager of Advisers and portfolio manager of the Fund since inception (2017).\\n\\nPurchase and Sale of Fund Shares\\n\\nThe Fund is an ETF. Fund shares may only be purchased and sold on a national securities exchange through a broker-dealer. The price of Fund shares is based on market price, and because ETF shares trade at market prices rather than NAV, shares may trade at a price greater than NAV (a premium) or less than NAV (a discount). The Fund issues or redeems shares that have been aggregated into blocks of 400,000 shares or multiples thereof (Creation Units) to Authorized Participants who have entered into agreements with the Fund\\u2019s distributor, Franklin Templeton Distributors, Inc. The Fund will generally issue or redeem Creation Units in return for a basket of securities (and an amount of cash) that the Fund specifies each day.\\n\\nTaxes\\n\\nThe Fund\\u2019s distributions are generally taxable to you as ordinary income, capital gains, or some combination of both, unless you are investing through a tax-deferred arrangement, such as a 401(k) plan or an individual retirement account, in which case your distributions would generally be taxed when withdrawn from the tax-deferred account.\\n\\nPayments to Broker-Dealers and\\nOther Financial Intermediaries\\n\\nIf you purchase shares of the Fund through a broker-dealer or other financial intermediary (such as a bank), Advisers or other related companies may pay the intermediary for the sale of Fund shares and related services. These payments may create a conflict of interest by influencing the broker-dealer or other intermediary and your salesperson to recommend the Fund over another investment. Ask your salesperson or visit your financial intermediary's website for more information.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "X_val_final_bert_v0 = copy.deepcopy(X_val_final)\n",
        "X_val_final_bert_v0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "lgFtBmMvD453",
        "outputId": "0d15b037-b314-4cb0-f121-7727b568ccb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Leverage?  Portfolio composition   Concentration  Max Similarity  \\\n",
              "56         0.0                    0.0             0.0        0.085346   \n",
              "181        0.0                    1.0             0.0        0.102477   \n",
              "329        1.0                    2.0             0.0        0.124033   \n",
              "271        0.0                    1.0             0.0        0.069571   \n",
              "31         0.0                    2.0             0.0        0.122207   \n",
              "..         ...                    ...             ...             ...   \n",
              "438        1.0                    2.0             0.0        0.080380   \n",
              "17         0.0                    2.0             0.0        0.090054   \n",
              "427        1.0                    2.0             0.0        0.106521   \n",
              "195        1.0                    2.0             0.0        0.086601   \n",
              "57         1.0                    1.0             0.0        0.123167   \n",
              "\n",
              "     Mean Similarity  \n",
              "56          0.021633  \n",
              "181         0.024675  \n",
              "329         0.023591  \n",
              "271         0.015978  \n",
              "31          0.018027  \n",
              "..               ...  \n",
              "438         0.017300  \n",
              "17          0.018571  \n",
              "427         0.020521  \n",
              "195         0.019685  \n",
              "57          0.020228  \n",
              "\n",
              "[93 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-996266b4-ca03-4da3-896d-68e1619b3595\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Leverage?</th>\n",
              "      <th>Portfolio composition</th>\n",
              "      <th>Concentration</th>\n",
              "      <th>Max Similarity</th>\n",
              "      <th>Mean Similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.085346</td>\n",
              "      <td>0.021633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.102477</td>\n",
              "      <td>0.024675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>329</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.124033</td>\n",
              "      <td>0.023591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.069571</td>\n",
              "      <td>0.015978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.122207</td>\n",
              "      <td>0.018027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.080380</td>\n",
              "      <td>0.017300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.090054</td>\n",
              "      <td>0.018571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>427</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.106521</td>\n",
              "      <td>0.020521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.086601</td>\n",
              "      <td>0.019685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.123167</td>\n",
              "      <td>0.020228</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>93 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-996266b4-ca03-4da3-896d-68e1619b3595')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-996266b4-ca03-4da3-896d-68e1619b3595 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-996266b4-ca03-4da3-896d-68e1619b3595');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-78a6a97e-0c03-4e15-bdfe-f735f441da83\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-78a6a97e-0c03-4e15-bdfe-f735f441da83')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-78a6a97e-0c03-4e15-bdfe-f735f441da83 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_val_final_bert_v0",
              "summary": "{\n  \"name\": \"X_val_final_bert_v0\",\n  \"rows\": 93,\n  \"fields\": [\n    {\n      \"column\": \"Leverage?\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.49423984539688176,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Portfolio composition\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7979637479594567,\n        \"min\": 0.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" Concentration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.33705264882291225,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Max Similarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.044432731085737615,\n        \"min\": 0.06621450726733637,\n        \"max\": 0.30548450444416164,\n        \"num_unique_values\": 93,\n        \"samples\": [\n          0.08844042034299253,\n          0.08697210459557209\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mean Similarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0031347943884802543,\n        \"min\": 0.012180159987788708,\n        \"max\": 0.0253731455952509,\n        \"num_unique_values\": 93,\n        \"samples\": [\n          0.021535357971102783,\n          0.022665601827143743\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_val_final_bert_v0['summary'] = X_val_new['summary']\n",
        "X_val_final_bert_v0 = X_val_final_bert_v0.drop(columns= [\"Max Similarity\", \"Mean Similarity\"])\n",
        "X_val_final_bert_v0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ZzfxTRxpD-f-",
        "outputId": "a2d2a41a-0b8b-4728-a53f-c8180cc4b3b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Leverage?  Portfolio composition   Concentration  \\\n",
              "56         0.0                    0.0             0.0   \n",
              "181        0.0                    1.0             0.0   \n",
              "329        1.0                    2.0             0.0   \n",
              "271        0.0                    1.0             0.0   \n",
              "31         0.0                    2.0             0.0   \n",
              "..         ...                    ...             ...   \n",
              "438        1.0                    2.0             0.0   \n",
              "17         0.0                    2.0             0.0   \n",
              "427        1.0                    2.0             0.0   \n",
              "195        1.0                    2.0             0.0   \n",
              "57         1.0                    1.0             0.0   \n",
              "\n",
              "                                               summary  \n",
              "56   American Funds 2060 Target Date Retirement Fun...  \n",
              "181  Janus Henderson Triton Fund\\n(closed to certai...  \n",
              "329  Fund Summary\\n\\nFund/Class:\\nFidelity Freedom®...  \n",
              "271  Ivy Global Growth Fund\\n\\nObjective\\n\\nTo seek...  \n",
              "31   American Funds Global Growth Portfolio\\n\\nInve...  \n",
              "..                                                 ...  \n",
              "438  INVESTMENT OBJECTIVE\\nThe USAA Cornerstone Mod...  \n",
              "17   Global Growth and Income Fund\\n\\nInvestment ob...  \n",
              "427  Fund Summary\\n\\nInvestment Objective\\nThe fund...  \n",
              "195  SUMMARY OF COLUMBIA VP – GLOBAL BOND FUND\\nInv...  \n",
              "57   Fund Summary\\n\\nInvestment Objective\\nThe fund...  \n",
              "\n",
              "[93 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3eaa3824-d14b-4cb7-8222-26f9fb75ddab\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Leverage?</th>\n",
              "      <th>Portfolio composition</th>\n",
              "      <th>Concentration</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>American Funds 2060 Target Date Retirement Fun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Janus Henderson Triton Fund\\n(closed to certai...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>329</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Fund Summary\\n\\nFund/Class:\\nFidelity Freedom®...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Ivy Global Growth Fund\\n\\nObjective\\n\\nTo seek...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>American Funds Global Growth Portfolio\\n\\nInve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>INVESTMENT OBJECTIVE\\nThe USAA Cornerstone Mod...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Global Growth and Income Fund\\n\\nInvestment ob...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>427</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Fund Summary\\n\\nInvestment Objective\\nThe fund...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>SUMMARY OF COLUMBIA VP – GLOBAL BOND FUND\\nInv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Fund Summary\\n\\nInvestment Objective\\nThe fund...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>93 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3eaa3824-d14b-4cb7-8222-26f9fb75ddab')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3eaa3824-d14b-4cb7-8222-26f9fb75ddab button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3eaa3824-d14b-4cb7-8222-26f9fb75ddab');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0efec5cb-3712-4724-9161-7349ef1396bb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0efec5cb-3712-4724-9161-7349ef1396bb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0efec5cb-3712-4724-9161-7349ef1396bb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_val_final_bert_v0",
              "summary": "{\n  \"name\": \"X_val_final_bert_v0\",\n  \"rows\": 93,\n  \"fields\": [\n    {\n      \"column\": \"Leverage?\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.49423984539688176,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Portfolio composition\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7979637479594567,\n        \"min\": 0.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" Concentration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.33705264882291225,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 93,\n        \"samples\": [\n          \"Franklin FTSE China ETF\\n\\nInvestment Goal\\n\\nTo seek to provide investment results that closely correspond, before fees and expenses, to the performance of the FTSE China RIC Capped Index (the FTSE China Capped Index).\\n\\nFees and Expenses of the Fund\\n\\nThe following table describes the fees and expenses that you will incur if you own shares of the Fund. You may also incur usual and customary brokerage commissions when buying or selling shares of the Fund, which are not reflected in the Example that follows.\\n\\n\\nAnnual Fund Operating Expenses\\n\\n(expenses that you pay each year as a percentage of the value of your investment)\\n\\nManagement fees \\t0.19% \\nDistribution and service (12b-1) fees \\tNone \\nOther expenses1 \\tNone \\nTotal annual Fund operating expenses \\t0.19% \\n1. Other expenses are based on estimated amounts for the current fiscal year.\\n\\nExample\\n\\nThis Example is intended to help you compare the cost of investing in the Fund with the cost of investing in other funds. The Example assumes that you invest $10,000 in the Fund for the time periods indicated and then redeem all of your shares at the end of the period. The Example also assumes that your investment has a 5% return each year and that the Fund's operating expenses remain the same. Although your actual costs may be higher or lower, based on these assumptions your costs would be:\\n\\n   \\t1 Year \\t3 Years \\n   \\t$ 19 \\t$ 61 \\nPortfolio Turnover\\n\\nThe Fund pays transaction costs, such as commissions, when it buys and sells securities (or \\\"turns over\\\" its portfolio). A higher portfolio turnover rate may indicate higher transaction costs and may result in higher taxes when Fund shares are held in a taxable account. These costs, which are not reflected in annual Fund operating expenses or in the Example, affect the Fund's performance. During the Fund's first fiscal period (November 2, 2017 to March 31, 2018), the Fund's portfolio turnover rate was 2.71% of the average value of its portfolio.\\n\\nPrincipal Investment Strategies\\n\\nUnder normal market conditions, the Fund invests at least 80% of its assets in the component securities of the FTSE China Capped Index and in depositary receipts representing such securities. The FTSE China Capped Index is a free float-adjusted market capitalization weighted index maintained and calculated by FTSE Russell with a capping methodology applied quarterly to issuer weights so that no single issuer of a component exceeds 25% of the FTSE China Capped Index weight, and all issuers with weights above 5% do not cumulatively exceed 50% of the FTSE China Capped Index\\u2019s weight. The FTSE China Capped Index is based on the FTSE China Index and is designed to measure the performance of Chinese large- and mid-capitalization stocks, as represented by H-Shares (securities of companies incorporated in the People\\u2019s Republic of China (PRC) that are denominated in Hong Kong dollars and listed on the Hong Kong Exchange) and B-Shares (securities of companies incorporated in the PRC and listed for foreign investment on either the Shanghai or Shenzhen stock exchanges). The FTSE China Capped Index also includes certain securities listed outside of the PRC known as N-Shares (issued by companies incorporated in certain foreign jurisdictions, which are controlled, directly or indirectly, by entities, companies or individuals in the PRC, derive substantial revenues or allocate substantial assets in the PRC and are listed on the New York Stock Exchange, NASDAQ or the NYSE MKT), Red-Chips (issued by companies incorporated in certain foreign jurisdictions, which are controlled, directly or indirectly, by entities owned by the national government or local governments in the PRC, derive substantial revenues or allocate substantial assets in the PRC and are listed on the Hong Kong Exchange), P-Chips (issued by companies incorporated in certain foreign jurisdictions, which are controlled, directly or indirectly, by individuals in the PRC, derive substantial revenues or allocate substantial assets in the PRC and are listed on the Hong Kong Exchange) and S-Chips (issued by companies incorporated in certain foreign jurisdictions, which are controlled, directly or indirectly, by entities, companies or individuals in the PRC, derive substantial revenues or allocate substantial assets in the PRC and are listed on the Singapore Exchange). FTSE Russell determines eligible securities for the FTSE China Capped Index based on measures such as the company\\u2019s place of incorporation, quality of investor protection, tax domicile, location of headquarters/factors of production and currency of denomination. As of June 29, 2018, the FTSE China Capped Index was comprised of 262 securities with capitalizations ranging from $89 million to $285.69 billion.\\n\\nThe Fund, using a \\u201cpassive\\u201d or indexing investment approach, seeks investment results that closely correspond, before fees and expenses, to the performance of the FTSE China Capped Index. The investment manager seeks to achieve, over time, a correlation between the Fund\\u2019s performance, before fees and expenses, and that of the FTSE China Capped Index of 0.95 or better. A figure of 1.00 would indicate perfect correlation. The Fund\\u2019s intention is to replicate the component securities of the FTSE China Capped Index as closely as possible (i.e., invest in all of the component securities in their respective weightings in the FTSE China Capped Index). However, under various circumstances, it may not be possible or practicable to replicate the FTSE China Capped Index. In these circumstances, the Fund may use a \\u201crepresentative sampling\\u201d strategy whereby the Fund would invest in what it believes to be a representative sample of the component securities of the FTSE China Capped Index, but may not track the FTSE China Capped Index with the same degree of accuracy as would an investment vehicle replicating the entire FTSE China Capped Index. Under the representative sampling technique, the investment manager will select securities that collectively have an investment profile similar to that of the FTSE China Capped Index, including securities that resemble those included in the FTSE China Capped Index in terms of risk factors, performance attributes and other characteristics, such as market capitalization and industry weightings.\\n\\nThe Fund is a \\\"non-diversified\\\" fund, which means it generally invests a greater proportion of its assets in the securities of one or more issuers and invests overall in a smaller number of issuers than a diversified fund.\\n\\nThe Fund will concentrate its investments (i.e., hold 25% or more of its net assets) in a particular industry or group of industries to approximately the same extent that the FTSE China Capped Index is concentrated. As of June 29, 2018, the FTSE China Capped Index was concentrated in the internet software and services industry.\\n\\nPrincipal Risks\\n\\nYou could lose money by investing in the Fund. Exchange-traded fund (ETF) shares are not deposits or obligations of, or guaranteed or endorsed by, any bank, and are not insured by the Federal Deposit Insurance Corporation, the Federal Reserve Board, or any other agency of the U.S. government. The Fund is subject to the principal risks noted below, any of which may adversely affect the Fund\\u2019s net asset value (NAV), trading price, yield, total return and ability to meet its investment goal.\\n\\nMarket   The market values of securities or other investments owned by the Fund will go up or down, sometimes rapidly or unpredictably. The market value of a security or other investment may be reduced by market activity or other results of supply and demand unrelated to the issuer. This is a basic risk associated with all investments. When there are more sellers than buyers, prices tend to fall. Likewise, when there are more buyers than sellers, prices tend to rise.\\n\\nStock prices tend to go up and down more dramatically than those of debt securities. A slower-growth or recessionary economic environment could have an adverse effect on the prices of the various stocks held by the Fund.\\n\\nForeign Securities (non-U.S.)   Investing in foreign securities typically involves more risks than investing in U.S. securities, and includes risks associated with: (i) internal and external political and economic developments \\u2013 e.g., the political, economic and social policies and structures of some foreign countries may be less stable and more volatile than those in the U.S. or some foreign countries may be subject to trading restrictions or economic sanctions; (ii) trading practices \\u2013 e.g., government supervision and regulation of foreign securities and currency markets, trading systems and brokers may be less than in the U.S.; (iii) availability of information \\u2013 e.g., foreign issuers may not be subject to the same disclosure, accounting and financial reporting standards and practices as U.S. issuers; (iv) limited markets \\u2013 e.g., the securities of certain foreign issuers may be less liquid (harder to sell) and more volatile; and (v) currency exchange rate fluctuations and policies (e.g., fluctuations may negatively affect investments denominated in foreign currencies and any income received or expenses paid by the Fund in that foreign currency). The risks of foreign investments may be greater in developing or emerging market countries.\\n\\nEmerging Market Countries   The Fund\\u2019s investments in emerging market issuers are subject to all of the risks of foreign investing generally, and have additional heightened risks due to a lack of established legal, political, business and social frameworks to support securities markets, including: delays in settling portfolio securities transactions; currency and capital controls; greater sensitivity to interest rate changes; pervasiveness of corruption and crime; currency exchange rate volatility; and inflation, deflation or currency devaluation.\\n\\nGeographic Focus   Because the Fund invests its assets primarily in companies in a specific country and region, the Fund is subject to greater risks of adverse developments in that country, region and/or the surrounding regions than a fund that is more broadly diversified geographically. Political, social or economic disruptions in the country or region, even in countries in which the Fund is not invested, may adversely affect the value of investments held by the Fund.\\n\\nThere are special risks associated with investments in China, including exposure to currency fluctuations, less liquidity, expropriation, confiscatory taxation, nationalization and exchange control regulations (including currency blockage). Inflation and rapid fluctuations in inflation and interest rates have had, and may continue to have, negative effects on the economy and securities markets of China. China is deemed by the investment manager to be an emerging markets country, which means an investment in this country has more heightened risks than general foreign investing due to a lack of established legal, political, business and social frameworks in the country to support securities markets as well as the possibility for more widespread corruption and fraud.\\n\\nDepositary Receipts   Depositary receipts are subject to many of the risks of the underlying securities. For some depositary receipts, the custodian or similar financial institution that holds the issuer's shares in a trust account is located in the issuer's home country. In these cases if the issuer\\u2019s home country does not have developed financial markets, the Fund could be exposed to the credit risk of the custodian or financial institution and greater market risk. In addition, the depository institution may not have physical custody of the underlying securities at all times and may charge fees for various services. The Fund may experience delays in receiving its dividend and interest payments or exercising rights as a shareholder. There may be an increased possibility of untimely responses to certain corporate actions of the issuer in an unsponsored depositary receipt program. Accordingly, there may be less information available regarding issuers of securities underlying unsponsored programs and there may not be a correlation between this information and the market value of the depositary receipts.\\n\\nCalculation Methodology   FTSE Russell relies on various sources of information to assess the criteria of issuers included in the FTSE China Capped Index, including information that may be based on assumptions and estimates. Neither the Fund nor the investment manager can offer assurances that FTSE Russell\\u2019s calculation methodology or sources of information will provide an accurate assessment of included issuers or that the included issuers will provide the Fund with the market exposure it seeks.\\n\\nIndex-Related   There is no assurance that the FTSE China Capped Index will be determined, composed or calculated accurately. While FTSE Russell provides descriptions of what the FTSE China Capped Index is designed to achieve, FTSE Russell does not guarantee the quality, accuracy or completeness of data in respect of its indices, and does not guarantee that the FTSE China Capped Index will be in line with the described index methodology. Gains, losses or costs to the Fund caused by errors in the FTSE China Capped Index may therefore be borne by the Fund and its shareholders.\\n\\nNon-Correlation   There is no guarantee that the Fund will achieve a high degree of correlation to the FTSE China Capped Index and therefore achieve its investment goal. Market disruptions and regulatory restrictions could have an adverse effect on the Fund\\u2019s ability to adjust its exposure to the required levels in order to track the FTSE China Capped Index. In addition, the Fund\\u2019s NAV may deviate from the FTSE China Capped Index if the Fund fair values a portfolio security at a price other than the price used by the FTSE China Capped Index for that security. To the extent that the investment manager uses a representative sampling strategy, the Fund may not track the return of the FTSE China Capped Index as well as it would have if the Fund held all of the securities in the FTSE China Capped Index.\\n\\nTracking Error   Tracking error is the divergence of the Fund\\u2019s performance from that of the FTSE China Capped Index. Tracking error may occur because of differences between the securities held in the Fund\\u2019s portfolio and those included in the FTSE China Capped Index, pricing differences (including differences between a security\\u2019s price at the local market close and the Fund\\u2019s valuation of a security at the time of calculation of the Fund\\u2019s NAV), transaction costs, the Fund\\u2019s holding of cash, differences in timing of the accrual of dividends or interest, tax gains or losses, changes to the FTSE China Capped Index or the need to meet various new or existing regulatory requirements. This risk may be heightened during times of increased market volatility or other unusual market conditions. Tracking error also may result because the Fund incurs fees and expenses, while the FTSE China Capped Index does not.\\n\\nMarket Trading   The Fund faces numerous market trading risks, including the potential lack of an active market for Fund shares, losses from trading in secondary markets, periods of high volatility and disruption in the creation/redemption process of the Fund. Any of these factors, among others, may lead to the Fund\\u2019s shares trading at a premium or discount to NAV. Thus, you may pay more (or less) than NAV when you buy shares of the Fund in the secondary market, and you may receive less (or more) than NAV when you sell those shares in the secondary market. The investment manager cannot predict whether shares will trade above (premium), below (discount) or at NAV.\\n\\nConcentration   To the extent the Fund concentrates in a specific industry, a group of industries, sector or type of investment, the Fund will carry much greater risks of adverse developments and price movements in such industries, sectors or investments than a fund that invests in a wider variety of industries, sectors or investments. There is also the risk that the Fund will perform poorly during a slump in demand for securities of companies in such industries or sectors.\\n\\nThe Fund may focus in the internet software and services industry. Competitive pressures, such as technological developments, fixed-rate pricing and the ability to attract and retain skilled employees, can significantly affect companies in the internet software and services industry. Changing domestic and international demand, research and development costs, availability and price of components and product obsolescence also can affect profitability of companies in this industry.\\n\\nNon-Diversification   Because the Fund is non-diversified, it may be more sensitive to economic, business, political or other changes affecting individual issuers or investments than a diversified fund, which may result in greater fluctuation in the value of the Fund\\u2019s shares and greater risk of loss.\\n\\nMidsize Companies   Securities issued by midsize companies may be more volatile in price than those of larger companies, involve substantial risks and should be considered speculative. Such risks may include greater sensitivity to economic conditions, less certain growth prospects, lack of depth of management and funds for growth and development, and limited or less developed product lines and markets. In addition, midsize companies may be particularly affected by interest rate increases, as they may find it more difficult to borrow money to continue or expand operations, or may have difficulty in repaying any loans.\\n\\nPassive Investment   Unlike many investment companies, the Fund is not actively managed and the investment manager does not attempt to take defensive positions under any market conditions, including declining markets. Therefore, the investment manager would not necessarily buy or sell a security unless that security is added or removed, respectively, from the FTSE China Capped Index, even if that security generally is underperforming.\\n\\nInternational Closed Market Trading   To the extent that the underlying securities held by the Fund trade on an exchange that is closed when the securities exchange on which the Fund shares list and trade is open, there may be market uncertainty about the stale security pricing (i.e., the last quote from its closed foreign market) resulting in premiums or discounts to NAV that may be greater than those experienced by other ETFs.\\n\\nAuthorized Participant Concentration   Only an authorized participant (Authorized Participant) may engage in creation or redemption transactions directly with the Fund. The Fund has a limited number of institutions that act as Authorized Participants. To the extent that these institutions exit the business or are unable to proceed with creation and/or redemption orders with respect to the Fund and no other Authorized Participant is able to step forward to create or redeem Creation Units (as defined below), Fund shares may trade at a discount to NAV and possibly face trading halts and/or delisting. This risk may be more pronounced in volatile markets, potentially where there are significant redemptions in ETFs generally.\\n\\nCash Transactions   Unlike certain ETFs, the Fund expects to generally effect its creations and redemptions partially for cash, rather than for in-kind securities. Therefore, it may be required to sell portfolio securities and subsequently recognize gains on such sales that the Fund might not have recognized if it were to distribute portfolio securities in-kind. As such, investments in Fund shares may be less tax-efficient than an investment in an ETF that distributes portfolio securities entirely in-kind.\\n\\nPerformance\\n\\nBecause the Fund does not have a full calendar year of performance, annual total return information is not available and therefore is not presented. You can obtain updated performance information at libertyshares.com or by calling (800) DIAL BEN/342-5236. The Fund's past performance (before and after taxes) is not necessarily an indication of how the Fund will perform in the future.\\n\\nInvestment Manager\\n\\nFranklin Advisers, Inc. (Advisers)\\n\\nPortfolio Managers\\n\\nDina Ting, CFA   Portfolio Manager of Advisers and lead portfolio manager of the Fund since inception (2017).\\n\\nLouis Hsu, CFA   Portfolio Manager of Advisers and portfolio manager of the Fund since inception (2017).\\n\\nPurchase and Sale of Fund Shares\\n\\nThe Fund is an ETF. Fund shares may only be purchased and sold on a national securities exchange through a broker-dealer. The price of Fund shares is based on market price, and because ETF shares trade at market prices rather than NAV, shares may trade at a price greater than NAV (a premium) or less than NAV (a discount). The Fund issues or redeems shares that have been aggregated into blocks of 400,000 shares or multiples thereof (Creation Units) to Authorized Participants who have entered into agreements with the Fund\\u2019s distributor, Franklin Templeton Distributors, Inc. The Fund will generally issue or redeem Creation Units in return for a basket of securities (and an amount of cash) that the Fund specifies each day.\\n\\nTaxes\\n\\nThe Fund\\u2019s distributions are generally taxable to you as ordinary income, capital gains, or some combination of both, unless you are investing through a tax-deferred arrangement, such as a 401(k) plan or an individual retirement account, in which case your distributions would generally be taxed when withdrawn from the tax-deferred account.\\n\\nPayments to Broker-Dealers and\\nOther Financial Intermediaries\\n\\nIf you purchase shares of the Fund through a broker-dealer or other financial intermediary (such as a bank), Advisers or other related companies may pay the intermediary for the sale of Fund shares and related services. These payments may create a conflict of interest by influencing the broker-dealer or other intermediary and your salesperson to recommend the Fund over another investment. Ask your salesperson or visit your financial intermediary's website for more information.\",\n          \"Investment Objective\\n\\nThe Fund seeks total return comprised of current income, current gains and capital appreciation.\\n \\n\\n \\n\\nFees and Expenses of the Fund\\n\\nThe tables below describe the fees and expenses that you may pay if you buy and hold shares of the Fund. You may qualify for sales charge discounts if you and your family invest, or agree to invest in the future, at least $50,000 in Class A shares of eligible funds that are part of the family of mutual funds sponsored by Allianz. More information about these and other discounts is available in the \\u201cClasses of Shares\\u201d section beginning on page 98 of the Fund\\u2019s prospectus or from your financial advisor. In addition, if you purchase shares through a specific intermediary, you may be subject to different sales charges including reductions in or waivers of such charges. More information about these intermediary-specific sales charge variations is available in Appendix A to the Fund\\u2019s prospectus (\\u201cIntermediary Sales Charge Discounts and Waivers\\u201d).\\n \\n\\nShareholder Fees (fees paid directly from your investment)\\n\\n \\n\\nShare Class\\t \\t\\nMaximum Sales Charge (Load) Imposed\\n\\non Purchases (as a percentage of offering price)\\n\\n \\t\\nMaximum Contingent Deferred Sales Charge (CDSC) (Load)\\n\\n(as a percentage of the lower of original purchase price or  NAV)(1)\\n\\nClass A\\t \\t5.50%\\t \\t1%\\nClass C\\t \\tNone\\t \\t1%\\nClass T\\t \\t2.50%\\t \\tNone\\nClass R\\t \\tNone\\t \\tNone\\nInstitutional\\t \\tNone\\t \\tNone\\nClass R6\\t \\tNone\\t \\tNone\\nClass P\\t \\tNone\\t \\tNone\\n \\n\\nAnnual Fund Operating Expenses (expenses that you pay each year as a percentage of the value of your investment)\\n\\n \\n\\nShare Class\\t \\t\\nManagement\\n\\nFees\\n\\n \\t\\nDistribution\\n\\nand/or Service\\n\\n(12b-1) Fees\\n\\n \\t\\nOther\\n\\nExpenses\\n\\n \\t\\nTotal Annual\\n\\nFund Operating\\n\\nExpenses\\n\\nClass A\\t \\t1.03%\\t \\t0.25%\\t \\t[    ]%\\t \\t[    ]%\\nClass C\\t \\t1.03\\t \\t1.00\\t \\t[    ]\\t \\t[    ]\\nClass T\\t \\t1.03\\t \\t0.25\\t \\t[    ]\\t \\t[    ]\\nClass R\\t \\t1.03\\t \\t0.50\\t \\t[    ]\\t \\t[    ]\\nInstitutional\\t \\t0.93\\t \\tNone\\t \\t[    ]\\t \\t[    ]\\nClass R6\\t \\t[    ]\\t \\tNone\\t \\t[    ]\\t \\t[    ]\\nClass P\\t \\t1.03\\t \\tNone\\t \\t[    ]\\t \\t[    ]\\n \\t(1)\\t \\t\\nFor Class A shares, the CDSC is imposed only in certain circumstances where shares are purchased without a front-end sales charge at the time of purchase. For Class C shares, the CDSC is imposed only on shares redeemed in the first year.\\n\\n \\n\\nExamples.  The Examples are intended to help you compare the cost of investing in shares of the Fund with the costs of investing in other mutual funds. The Examples assume that you invest $10,000 in the noted class of shares for the time periods indicated, your investment has a 5% return each year, and the Fund\\u2019s operating expenses remain the same. Although your actual costs may be higher or lower, the Examples show what your costs would be based on these assumptions.\\n\\n \\n\\n \\t \\tExample:  Assuming you redeem your shares at the end of each period\\t \\t \\tExample:  Assuming you do not redeem your shares\\t \\nShare Class\\t \\t1 Year\\t \\t \\t3 Years\\t \\t \\t5 Years\\t \\t \\t10 Years\\t \\t \\t1 Year\\t \\t \\t3 Years\\t \\t \\t5 Years\\t \\t \\t10 Years\\t \\nClass A\\t \\t$\\t[    \\t] \\t \\t$\\t[    \\t] \\t \\t$\\t[    \\t] \\t \\t$\\t[    \\t] \\t \\t$\\t[    \\t] \\t \\t$\\t[    \\t] \\t \\t$\\t[    \\t] \\t \\t$\\t[    \\t] \\nClass C\\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\nClass T\\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\nClass R\\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\nInstitutional\\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\nClass R6\\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\nClass P\\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\n \\n\\nPortfolio Turnover.  The Fund pays transaction costs, such as commissions, when it buys and sells securities (or \\u201cturns over\\u201d its portfolio). The Fund\\u2019s portfolio turnover rate for the fiscal year ended June 30, 2018 was [    ]% of the average value of its portfolio. High levels of portfolio turnover may indicate higher transaction costs and may result in higher taxes for you if your Fund shares are held in a taxable account. These costs, which are not reflected in Total Annual Fund Operating Expenses or in the Examples above, can adversely affect the Fund\\u2019s investment performance.\\n\\n \\n\\n \\n\\nPrincipal Investment Strategies\\n\\nThe Fund seeks to achieve its objective by investing primarily in a combination of common stocks and other equity securities, debt securities and convertible securities. The allocation of the Fund\\u2019s investments across asset classes will\\n\\n \\n\\n22\\t \\tAllianz Funds\\nTable of Contents\\nAllianzGI Income & Growth Fund (continued)\\n\\n \\n\\n \\t\\nvary substantially from time to time. The Fund\\u2019s investments in each asset class are based upon the portfolio managers\\u2019 assessment of economic conditions and market factors, including equity price levels, interest rate levels and their anticipated direction. The portfolio managers will select common stocks by utilizing a fundamental, bottom-up research process which facilitates the early identification of issuers demonstrating the ability to improve their fundamental characteristics. It is expected that a substantial portion of the Fund\\u2019s investments in debt securities and convertible securities will be rated below investment grade or unrated and determined to be of similar quality (\\u201chigh-yield securities\\u201d or \\u201cjunk bonds\\u201d). The Fund may invest in issuers of any market capitalization (with a focus on $3 billion and above) and may invest a portion of its assets in non-U.S. securities (including emerging market securities). The Fund also may employ a strategy of writing (selling) call options on the common stocks it holds; such strategy is intended to enhance Fund distributions and reduce overall portfolio risk, though there is no assurance that it will succeed. In addition to equity securities (such as preferred stocks and warrants), the Fund may invest a significant portion of its assets in private placement securities (including Rule 144A securities) and may utilize foreign currency exchange contracts, options, stock index futures contracts and other derivative instruments.\\n\\n \\n\\n \\n\\nPrincipal Risks\\n\\nThe principal risks of investing in the Fund, which could adversely affect its net asset value, yield and total return, are (in alphabetical order after the first seven risks):\\n \\n\\n \\tMarket Risk:  The Fund will be affected by factors influencing the U.S. or global economies and securities markets or relevant industries or sectors within them.\\n \\n\\n \\tIssuer Risk:  The Fund will be affected by factors specific to the issuers of securities and other instruments in which the Fund invests, including actual or perceived changes in the financial condition or business prospects of such issuers.\\n \\n\\n \\tHigh Yield Risk:  High-yield or junk bonds are subject to greater levels of credit and liquidity risk, may be speculative and may decline in value due to increases in interest rates or an issuer\\u2019s deterioration or default.\\n \\n\\n \\tEquity Securities Risk:  Equity securities may react more strongly to changes in an issuer\\u2019s financial condition or prospects than other securities of the same issuer.\\n \\n\\n \\tFixed Income Risk:  Fixed income (debt) securities are subject to greater levels of credit and liquidity risk, may be speculative and may decline in value due to changes in interest rates or an issuer\\u2019s or counterparty\\u2019s deterioration or default.\\n \\n\\n \\tSmaller Company Risk:  Securities issued by smaller companies may be more volatile and present increased liquidity risk relative to securities issued by larger companies.\\n \\n\\n \\tDerivatives Risk:  Derivative instruments are complex, have different characteristics than their underlying assets and are subject to additional risks, including leverage, liquidity and valuation.\\n \\n\\n \\tConvertible Securities Risk:  Convertible securities are subject to greater levels of credit and liquidity risk, may be speculative and may decline in value due to increases in interest rates or an issuer\\u2019s deterioration or default.\\n \\n\\n \\tCredit and Counterparty Risk:  An issuer or counterparty may default on obligations.\\n \\n\\n \\tCurrency Risk:  The values of non-U.S. securities may fluctuate with currency exchange rates and exposure to non-U.S. currencies may subject the Fund to the risk that those currencies will decline in value relative to the U.S. dollar.\\n \\n\\n \\tEmerging Markets Risk:  Non-U.S. investment risk may be particularly high to the extent that the Fund invests in emerging market securities. These securities may present market, credit, currency, liquidity, legal, political, technical and other risks different from, or greater than, the risks of investing in developed countries.\\n \\n\\n \\tFocused Investment Risk:  Focusing on a limited number of issuers, sectors, industries or geographic regions increases risk and volatility.\\n \\n\\n \\tInterest Rate Risk:  Fixed income securities may decline in value because of increases in interest rates.\\n \\n\\n \\tLeveraging Risk:  Instruments and transactions that constitute leverage magnify gains or losses and increase volatility.\\n \\n\\n \\tLiquidity Risk:  The lack of an active market for investments may cause delay in disposition or force a sale below fair value.\\n \\n\\n \\tManagement Risk:  The Fund will be affected by the allocation determinations, investment decisions and techniques of the Fund\\u2019s management.\\n \\n\\n \\tNon-U.S. Investment Risk:  Non-U.S. securities markets and issuers may be more volatile, smaller, less liquid, less transparent and subject to less oversight, particularly in emerging markets.\\n \\n\\n \\tTurnover Risk:  High levels of portfolio turnover increase transaction costs and taxes and may lower investment performance.\\n \\n\\nProspectus\\t \\t \\t23\\t \\nTable of Contents\\nAllianzGI Income & Growth Fund (continued)\\n\\n \\n\\nPlease see \\u201cSummary of Principal Risks\\u201d in the Fund\\u2019s prospectus for a more detailed description of the Fund\\u2019s risks. It is possible to lose money on an investment in the Fund. An investment in the Fund is not a deposit of a bank and is not insured or guaranteed by the Federal Deposit Insurance Corporation or any other government agency.\\n\\n \\n\\n \\n\\nPerformance Information\\n\\nThe performance information below provides some indication of the risks of investing in the Fund by showing changes in its total return from year to year and by comparing the Fund\\u2019s average annual total returns with those of two broad-based market indexes and a performance average of similar mutual funds. The bar chart and the information to its right show performance of the Fund\\u2019s Class A shares, but do not reflect the impact of sales charges (loads). If they did, returns would be lower than those shown. Other share classes would have different performance due to the different expenses they bear. Performance in the Average Annual Total Returns table reflects the impact of sales charges. For periods prior to the inception date of a share class, performance information shown for such class may be based on the performance of an older class of shares that dates back to the Fund\\u2019s inception, as adjusted to reflect fees and expenses paid by the newer class. These adjustments generally result in estimated performance results for the newer class that are different from the actual results of the predecessor class, due to differing levels of fees and expenses paid. Details regarding the calculation of the Fund\\u2019s class-by-class performance, including a discussion of any performance adjustments, are provided under \\u201cAdditional Performance Information\\u201d in the Fund\\u2019s prospectus and SAI. Past performance, before and after taxes, is not necessarily predictive of future performance. Visit us.allianzgi.com for more current performance information.\\n \\n\\nCalendar Year Total Returns \\u2014 Class A\\n\\nLOGO\\n\\nMore Recent Return Information\\t \\n1/1/18\\u20136/30/18\\t \\t \\t[    ]%\\t \\n[Highest and Lowest Quarter Returns]\\t \\n(for periods shown in the bar chart)\\t \\nHighest 04/01/2009\\u201306/30/2009\\t \\t \\t18.45%\\t \\nLowest 10/01/2008\\u201312/31/2008\\t \\t \\t-20.58%\\t \\n \\nAverage Annual Total Returns (for periods ended 12/31/17)\\n\\n \\n\\n  \\t \\t1 Year\\t \\t \\t5 Years\\t \\t \\t10 Year\\t \\t \\tFund Inception\\n(2/28/07)\\t \\nClass A \\u2014 Before Taxes\\n\\n \\t \\t7.21\\t% \\t \\t \\t7.39\\t% \\t \\t \\t6.10\\t% \\t \\t \\t6.48\\t% \\nClass A \\u2014 After Taxes on Distributions\\n\\n \\t \\t3.28\\t% \\t \\t \\t3.47\\t% \\t \\t \\t2.36\\t% \\t \\t \\t2.79\\t% \\nClass A \\u2014After Taxes on Distributions and Sale of Fund Shares\\n\\n \\t \\t3.96\\t% \\t \\t \\t3.81\\t% \\t \\t \\t2.91\\t% \\t \\t \\t3.27\\t% \\nClass C \\u2014 Before Taxes\\n\\n \\t \\t11.63\\t% \\t \\t \\t7.80\\t% \\t \\t \\t5.91\\t% \\t \\t \\t6.24\\t% \\nClass R \\u2014 Before Taxes\\n\\n \\t \\t13.17\\t% \\t \\t \\t8.33\\t% \\t \\t \\t6.44\\t% \\t \\t \\t6.78\\t% \\nInstitutional Class \\u2014 Before Taxes\\n\\n \\t \\t13.87\\t% \\t \\t \\t8.98\\t% \\t \\t \\t7.08\\t% \\t \\t \\t7.42\\t% \\nClass R6 \\u2014 Before Taxes\\n\\n \\t \\t\\u2014\\t \\t \\t \\t\\u2014\\t \\t \\t \\t\\u2014\\t \\t \\t \\t\\u2014\\t \\nClass P \\u2014 Before Taxes\\n\\n \\t \\t13.79\\t% \\t \\t \\t8.88\\t% \\t \\t \\t6.98\\t% \\t \\t \\t7.32\\t% \\nClass T \\u2014 Before Taxes\\n\\n \\t \\t10.62\\t% \\t \\t \\t8.07\\t% \\t \\t \\t6.43\\t% \\t \\t \\t6.79\\t% \\nBloomberg Barclays U.S. Aggregate Bond Index (reflects no deduction for fees, expenses or taxes)\\n\\n \\t \\t3.54\\t% \\t \\t \\t2.10\\t% \\t \\t \\t4.01\\t% \\t \\t \\t4.19\\t% \\nS&P 500 Index (reflects no deduction for fees, expenses or taxes)\\n\\n \\t \\t21.83\\t% \\t \\t \\t15.79\\t% \\t \\t \\t8.50\\t% \\t \\t \\t8.39\\t% \\nLipper Flexible Portfolio Funds Average\\n\\n \\t \\t12.73\\t% \\t \\t \\t6.18\\t% \\t \\t \\t4.43\\t% \\t \\t \\t4.91\\t% \\n \\n\\nAfter-tax returns are estimated using the highest historical individual federal marginal income tax rates and do not reflect the impact of state and local taxes. Actual after-tax returns depend on an investor\\u2019s tax situation and may differ from those shown. After-tax returns are not relevant to investors who hold Fund shares through tax-advantaged arrangements such as 401(k) plans or individual retirement accounts. In some cases the return after taxes may exceed the return before taxes due to an assumed tax benefit from any losses on a sale of Fund shares at the end of the measurement period. After-tax returns are for Class A shares only. After-tax returns for other share classes will vary.\\n\\n \\n\\n24\\t \\tAllianz Funds\\nTable of Contents\\nAllianzGI Income & Growth Fund (continued)\\n\\n \\n\\n \\n\\nManagement of the Fund \\n\\nInvestment Adviser and Administrator  Allianz Global Investors U.S. LLC (\\u201cAllianzGI U.S.\\u201d)\\n \\n\\nPortfolio Managers\\n\\nDouglas G. Forsyth, CFA, portfolio manager, managing director and CIO US Income & Growth Strategies, has managed the Fund since 2007.\\n\\n \\n\\nMichael E. Yee, portfolio manager and managing director, has managed the Fund since 2007.\\n\\n \\n\\nJustin Kass, CFA, portfolio manager and managing director, has managed the Fund since 2007.\\n\\n \\n\\nPurchase and Sale of Fund Shares\\n\\nYou may purchase or sell (redeem) shares of the Fund on any business day through a broker, dealer, or other financial intermediary (for Class T shares, such intermediary must have an agreement with the Distributor to sell Class T shares), or directly from the Fund\\u2019s transfer agent by mail (Allianz Global Investors Distributors LLC, P.O. Box 8050, Boston, MA 02266-8050) for Class A, Class C and Class R shares, or directly from the Fund\\u2019s transfer agent by mail (Allianz Institutional Funds, P.O. Box 219968, Kansas City, MO 64121-9968) for Institutional Class, Class R6 and Class P shares, or as further described in the Fund\\u2019s prospectus and SAI. Additionally, certain direct shareholders may be able to purchase or redeem shares of the Fund online by visiting our website, us.allianzgi.com, clicking on the \\u201cAccount Access\\u201d link at the top of that webpage, and following instructions. Some restrictions may apply. To avoid delays in a purchase or redemption, please call 1-800-988-8380 for Class A, Class C, Class T and Class R shares and 1-800-498-5413 for Institutional Class, Class R6 and Class P shares with any questions about the requirements before submitting a request. Generally, purchase and redemption orders for Fund shares are processed at the net asset value (NAV) next calculated after an order is received by the distributor or an authorized intermediary. NAVs are determined only on days when the New York Stock Exchange is open for regular trading. For Class A, Class C and Class T shares, the minimum initial investment in the Fund is $1,000 and the minimum subsequent investment is $50. For Class R shares, specified benefit plans may establish various minimum investment and account size requirements; ask your plan administrator for more information. For Institutional Class and Class P shares, the minimum initial investment in the Fund is $1 million and no minimum is needed to add to an existing account, though minimums may be modified for certain financial intermediaries that aggregate trades on behalf of investors. For Class R6 shares, there is no minimum initial investment and no minimum is needed to add to an existing account for specified benefit plans and other eligible investors.\\n \\n\\nTax Information\\n\\nThe Fund\\u2019s distributions are generally taxable to you as ordinary income or capital gains, unless you are investing through a tax-advantaged arrangement, such as a 401(k) plan or an individual retirement account.\\n \\n\\nPayments to Broker-Dealers and Other Financial Intermediaries\\n\\nIf you purchase shares of the Fund through a broker-dealer or other financial intermediary (such as a bank), the Fund, its distributor, its investment adviser or their affiliates may pay the intermediary for the sale of Fund shares and related services. These payments may create a conflict of interest by influencing the broker-dealer or intermediary and your salesperson to recommend the Fund over another investment. Ask your salesperson or visit your financial intermediary\\u2019s Web site for more information.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## X_test preprocessing"
      ],
      "metadata": {
        "id": "LAdxOl3_Dig5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "S_AXxAPRw4xi",
        "outputId": "e8b85005-0933-4772-d377-bf809a63b139"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <progress\n",
              "            value='544'\n",
              "            max='544',\n",
              "            style='width: 100%'\n",
              "        >\n",
              "            544\n",
              "        </progress>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       id                                    fund_name  \\\n",
              "324  0001379491-18-000929  Fidelity Series Opportunistic Insights Fund   \n",
              "448  0001683863-18-000443                         Growth & Income Fund   \n",
              "298  0001193125-18-285341        Columbia Flexible Capital Income Fund   \n",
              "410  0001379491-18-006486                  Fidelity Emerging Asia Fund   \n",
              "22   0000051931-18-000465                           International Fund   \n",
              "\n",
              "          Performance fee? Leverage?  \\\n",
              "324                    NaN        No   \n",
              "448  Some performance Fees        No   \n",
              "298                    NaN        No   \n",
              "410  Some performance Fees        No   \n",
              "22                     NaN        No   \n",
              "\n",
              "                                 Portfolio composition  Concentration  \\\n",
              "324                                    Listed Equities    Diversified   \n",
              "448                                    Listed Equities    Diversified   \n",
              "298  Sub-investment grade securities or emerging ma...    Diversified   \n",
              "410  Sub-investment grade securities or emerging ma...    Diversified   \n",
              "22   Sub-investment grade securities or emerging ma...    Diversified   \n",
              "\n",
              "                                               summary  \n",
              "324  Fund Summary\\n\\nFund:\\nFidelity® Series Opport...  \n",
              "448  INVESTMENT OBJECTIVE\\nThe USAA Growth & Income...  \n",
              "298  SUMMARY OF THE FUND\\nInvestment Objective\\nCol...  \n",
              "410  Fund Summary\\n\\nFund:\\nFidelity® Emerging Asia...  \n",
              "22   International Fund\\n\\nInvestment objective The...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-273e53e3-f0e4-41d0-b3b6-4ce73f41a528\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>fund_name</th>\n",
              "      <th>Performance fee?</th>\n",
              "      <th>Leverage?</th>\n",
              "      <th>Portfolio composition</th>\n",
              "      <th>Concentration</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>324</th>\n",
              "      <td>0001379491-18-000929</td>\n",
              "      <td>Fidelity Series Opportunistic Insights Fund</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>Listed Equities</td>\n",
              "      <td>Diversified</td>\n",
              "      <td>Fund Summary\\n\\nFund:\\nFidelity® Series Opport...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>0001683863-18-000443</td>\n",
              "      <td>Growth &amp; Income Fund</td>\n",
              "      <td>Some performance Fees</td>\n",
              "      <td>No</td>\n",
              "      <td>Listed Equities</td>\n",
              "      <td>Diversified</td>\n",
              "      <td>INVESTMENT OBJECTIVE\\nThe USAA Growth &amp; Income...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>0001193125-18-285341</td>\n",
              "      <td>Columbia Flexible Capital Income Fund</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>Sub-investment grade securities or emerging ma...</td>\n",
              "      <td>Diversified</td>\n",
              "      <td>SUMMARY OF THE FUND\\nInvestment Objective\\nCol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>410</th>\n",
              "      <td>0001379491-18-006486</td>\n",
              "      <td>Fidelity Emerging Asia Fund</td>\n",
              "      <td>Some performance Fees</td>\n",
              "      <td>No</td>\n",
              "      <td>Sub-investment grade securities or emerging ma...</td>\n",
              "      <td>Diversified</td>\n",
              "      <td>Fund Summary\\n\\nFund:\\nFidelity® Emerging Asia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0000051931-18-000465</td>\n",
              "      <td>International Fund</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>Sub-investment grade securities or emerging ma...</td>\n",
              "      <td>Diversified</td>\n",
              "      <td>International Fund\\n\\nInvestment objective The...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-273e53e3-f0e4-41d0-b3b6-4ce73f41a528')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-273e53e3-f0e4-41d0-b3b6-4ce73f41a528 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-273e53e3-f0e4-41d0-b3b6-4ce73f41a528');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5cfbe054-c4cc-49ad-8ae0-2f2fd78182e9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5cfbe054-c4cc-49ad-8ae0-2f2fd78182e9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5cfbe054-c4cc-49ad-8ae0-2f2fd78182e9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_test_new",
              "summary": "{\n  \"name\": \"X_test_new\",\n  \"rows\": 47,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"0001710607-18-000172\",\n          \"0001144204-18-020502\",\n          \"0001379491-18-001273\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fund_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 47,\n        \"samples\": [\n          \"MFS Georgia Municipal Bond Fund\",\n          \"Growth Fund\",\n          \"Columbia Seligman Communications and Information Fund\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Performance fee?\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Some performance Fees\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Leverage?\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Portfolio composition\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Listed Equities\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" Concentration\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Concentrated by issuer / sector / jurisdiction\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 47,\n        \"samples\": [\n          \"MFS Georgia Municipal Bond Fund\\n\\n \\n\\nSummary of Key Information\\n\\n \\n\\nInvestment Objective\\n\\n \\n\\nThe fund\\u2019s investment objective is to seek total return with an emphasis on income exempt from federal income tax and personal income tax, if any, of Georgia, but also considering capital appreciation.\\n\\n \\n\\nFees and Expenses\\n\\n \\n\\nThis table describes the fees and expenses that you may pay when you buy and hold shares of the fund. Investors may also pay commissions or other fees to their financial intermediaries when they buy and hold shares of the fund, which are not reflected below.\\n\\n \\n\\nYou may qualify for sales charge reductions if, with respect to Class A shares, you and certain members of your family invest, or agree to invest in the future, at least $100,000 in MFS Funds, and, with respect to Class T shares, you invest at least $250,000 in the fund. More information about these and other waivers and reductions is available from your financial intermediary and in \\u201cSales Charges and Waivers and Reductions\\u201d on page 9 and \\u201cAppendix A \\u2013 Waivers and Reductions of Sales Charges\\u201d on page A-1 of the fund\\u2019s prospectus.\\n\\n \\n\\nShareholder Fees (fees paid directly from your investment):\\n\\n \\n\\nShare Class\\n\\n \\n\\nA\\n\\n \\n\\nT\\n\\n \\n\\nB\\n\\n \\n\\nI\\n\\n \\n\\nR6\\n\\n \\n\\nMaximum Sales Charge (Load) Imposed on Purchases (as a percentage of offering price)\\n\\n \\n\\n4.25\\n\\n%\\n\\n2.50\\n\\n%\\n\\nNone\\n\\n \\n\\nNone\\n\\n \\n\\nNone\\n\\n \\n\\nMaximum Deferred Sales Charge (Load) (as a percentage of original purchase price or redemption proceeds, whichever is less)\\n\\n \\n\\n1.00\\n\\n%#\\n\\nNone\\n\\n \\n\\n4.00\\n\\n%\\n\\nNone\\n\\n \\n\\nNone\\n\\n \\n\\n \\n\\nAnnual Fund Operating Expenses (expenses that you pay each year as a percentage of the value of your investment):\\n\\n \\n\\nShare Class\\n\\n \\n\\nA\\n\\n \\n\\nT\\n\\n \\n\\nB\\n\\n \\n\\nI\\n\\n \\n\\nR6\\n\\n \\n\\nManagement Fee\\n\\n \\n\\n0.45\\n\\n%\\n\\n0.45\\n\\n%\\n\\n0.45\\n\\n%\\n\\n0.45\\n\\n%\\n\\n0.45\\n\\n%\\n\\nDistribution and/or Service (12b-1) Fees\\n\\n \\n\\n0.25\\n\\n%\\n\\n0.25\\n\\n%\\n\\n1.00\\n\\n%\\n\\nNone\\n\\n \\n\\nNone\\n\\n \\n\\nOther Expenses\\n\\n \\n\\n0.34\\n\\n%\\n\\n0.34\\n\\n%\\n\\n0.34\\n\\n%\\n\\n0.34\\n\\n%\\n\\n0.28\\n\\n%\\n\\nTotal Annual Fund Operating Expenses\\n\\n \\n\\n1.04\\n\\n%\\n\\n1.04\\n\\n%\\n\\n1.79\\n\\n%\\n\\n0.79\\n\\n%\\n\\n0.73\\n\\n%\\n\\nFee Reductions and/or Expense Reimbursements1\\n\\n \\n\\n(0.14\\n\\n)%\\n\\n(0.14\\n\\n)%\\n\\n(0.14\\n\\n)%\\n\\n(0.14\\n\\n)%\\n\\n(0.13\\n\\n)%\\n\\nTotal Annual Fund Operating Expenses After Fee Reductions and/or Expense Reimbursements\\n\\n \\n\\n0.90\\n\\n%\\n\\n0.90\\n\\n%\\n\\n1.65\\n\\n%\\n\\n0.65\\n\\n%\\n\\n0.60\\n\\n%\\n\\n \\n\\n#                 This contingent deferred sales charge (CDSC) applies to shares purchased without an initial sales charge and redeemed within 18 months of purchase.\\n\\n1                 Massachusetts Financial Services Company has agreed in writing to bear the fund\\u2019s expenses, excluding interest, taxes, extraordinary expenses, brokerage and transaction costs, and investment-related expenses (such as interest and borrowing expenses incurred in connection with the fund\\u2019s investment activity), such that \\u201cTotal Annual Fund Operating Expenses\\u201d do not exceed 0.90% of the class\\u2019 average daily net assets annually for each of Class A and Class T shares, 1.65% of the class\\u2019 average daily net assets annually for Class B shares, 0.65% of the class\\u2019 average daily net assets annually for Class I shares, and 0.60% of the class\\u2019 average daily net assets annually for Class R6 shares. This written agreement will continue until modified by the fund\\u2019s Board of Trustees, but such agreement will continue until at least July 31, 2019.\\n\\n \\n\\n2\\n\\n\\n \\n\\nMFS Georgia Municipal Bond Fund\\n\\n \\n\\nExample\\n\\n \\n\\nThis example is intended to help you compare the cost of investing in the fund with the cost of investing in other mutual funds.\\n\\n \\n\\nThe example assumes that: you invest $10,000 in the fund for the time periods indicated and you redeem your shares at the end of the time periods (unless otherwise indicated); your investment has a 5% return each year; and the fund\\u2019s operating expenses remain the same.\\n\\n \\n\\nAlthough your actual costs will likely be higher or lower, under these assumptions your costs would be:\\n\\n \\n\\n \\n\\n \\n\\n1 YEAR\\n\\n \\n\\n3 YEARS\\n\\n \\n\\n5 YEARS\\n\\n \\n\\n10 YEARS\\n\\n \\n\\nClass A Shares\\n\\n \\n\\n$\\n\\n513\\n\\n \\n\\n$\\n\\n729\\n\\n \\n\\n$\\n\\n962\\n\\n \\n\\n$\\n\\n1,630\\n\\n \\n\\nClass T Shares\\n\\n \\n\\n$\\n\\n340\\n\\n \\n\\n$\\n\\n559\\n\\n \\n\\n$\\n\\n796\\n\\n \\n\\n$\\n\\n1,477\\n\\n \\n\\nClass B Shares assuming\\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nredemption at end of period\\n\\n \\n\\n$\\n\\n568\\n\\n \\n\\n$\\n\\n850\\n\\n \\n\\n$\\n\\n1,157\\n\\n \\n\\n$\\n\\n1,896\\n\\n \\n\\nno redemption at end of period\\n\\n \\n\\n$\\n\\n168\\n\\n \\n\\n$\\n\\n550\\n\\n \\n\\n$\\n\\n957\\n\\n \\n\\n$\\n\\n1,896\\n\\n \\n\\nClass I Shares\\n\\n \\n\\n$\\n\\n66\\n\\n \\n\\n$\\n\\n238\\n\\n \\n\\n$\\n\\n425\\n\\n \\n\\n$\\n\\n965\\n\\n \\n\\nClass R6 Shares\\n\\n \\n\\n$\\n\\n61\\n\\n \\n\\n$\\n\\n220\\n\\n \\n\\n$\\n\\n393\\n\\n \\n\\n$\\n\\n894\\n\\n \\n\\n \\n\\nPortfolio Turnover\\n\\n \\n\\nThe fund pays transaction costs, such as commissions, when it buys and sells securities (or \\u201cturns over\\u201d its portfolio). A higher portfolio turnover rate may indicate higher transaction costs and may result in higher taxes when shares are held in a taxable account. These transaction costs, which are not reflected in \\u201cAnnual Fund Operating Expenses\\u201d or in the \\u201cExample,\\u201d affect the fund\\u2019s performance.  During the most recent fiscal year, the fund\\u2019s portfolio turnover rate was 12% of the average value of its portfolio. \\n\\n \\n\\nPrincipal Investment Strategies\\n\\n \\n\\nThe fund invests, under normal market conditions, at least 80% of its net assets in securities and other investments, the interest on which is exempt from federal income tax and personal income tax, if any, of Georgia. Interest from the fund\\u2019s investments may be subject to the federal alternative minimum tax. MFS (Massachusetts Financial Services Company, the fund\\u2019s investment adviser) may also invest the fund\\u2019s assets in taxable instruments, including municipal instruments of other states.\\n\\n \\n\\nMFS normally invests the fund\\u2019s assets primarily in municipal instruments.\\n\\n \\n\\nMFS may invest 25% or more of the fund\\u2019s assets in municipal instruments that finance similar projects, such as those relating to education, healthcare, housing, utilities, water or sewers. Municipal instruments whose interest is exempt from federal and state personal income tax include instruments issued by U.S. territories and possessions (such as Puerto Rico, Guam, and the U.S. Virgin Islands) and their political subdivisions and public corporations.\\n\\n \\n\\nMFS primarily invests the fund\\u2019s assets in investment grade quality debt instruments, but may also invest in below investment grade quality debt instruments.\\n\\n \\n\\nMFS invests a significant percentage of the fund\\u2019s assets in municipal instruments of Georgia.\\n\\n \\n\\nWhile MFS may use derivatives for any investment purpose, to the extent MFS uses derivatives, MFS expects to use derivatives primarily to increase or decrease exposure to a particular market, segment of the market, or security, to increase or decrease interest rate exposure, or as alternatives to direct investments. Derivatives include futures, forward contracts, options, structured securities, inverse floating rate instruments, and swaps.\\n\\n \\n\\nMFS uses an active bottom-up investment approach to buying and selling investments for the fund. Investments are selected primarily based on fundamental analysis of individual instruments and their issuers. Quantitative models that systematically evaluate instruments may also be considered. In structuring the fund, MFS also considers top-down factors.\\n\\n \\n\\nFor purposes of the fund\\u2019s 80% policy, net assets include the amount of any borrowings for investment purposes.\\n\\n \\n\\nPrincipal Risks\\n\\n \\n\\nAs with any mutual fund, the fund may not achieve its objective and/or you could lose money on your investment in the fund. An investment in the fund is not a bank deposit and is not insured or guaranteed by the Federal Deposit Insurance Corporation or any other governmental agency.\\n\\n \\n\\nThe principal risks of investing in the fund are:\\n\\n \\n\\nDebt Market Risk:  Debt markets can be volatile and can decline significantly in response to, or investor perceptions of, issuer, market, economic, industry, political, regulatory, geopolitical, and other conditions.  These conditions can affect a single instrument, issuer, or borrower, a particular type of instrument, issuer, or borrower, a segment of the debt markets or the debt markets generally. Certain events can have a dramatic adverse effect on debt markets and may lead to periods of high volatility and reduced liquidity in a debt market or segment of a debt market.\\n\\n \\n\\nInterest Rate Risk:  In general, the price of a debt instrument falls when interest rates rise and rises when interest rates fall. Interest rate risk is generally greater for instruments with longer maturities, or that do not pay current interest.\\n\\n \\n\\nCredit Risk:  The price of a debt instrument depends, in part, on the credit quality of the issuer, borrower, counterparty, or other entity responsible for payment, or underlying collateral or assets and the terms of the instrument. The price of a debt instrument can decline in response to changes in the financial condition of the issuer, borrower, counterparty, or other entity, or underlying collateral or assets, or changes in specific or general market, economic, industry, political, regulatory, geopolitical, and other conditions.\\n\\n \\n\\nThe credit quality of, and the ability to pay principal and interest when due by, an issuer of a municipal instrument depends on the credit quality of the entity supporting the municipal instrument, how essential any services supported by the municipal instrument are, the sufficiency of any revenues or taxes that support the municipal instrument, and/or the willingness or ability of the appropriate government entity to approve any appropriations necessary to support the municipal instrument. In addition, the price of a municipal instrument also depends on its credit quality and ability to meet the credit support obligations of any insurer or other entity providing credit support to a municipal instrument.\\n\\n \\n\\nBelow investment grade quality debt instruments (commonly referred to as \\u201chigh yield securities\\u201d or \\u201cjunk bonds\\u201d) can involve a substantially greater risk of default or can already be in default, and their values can decline significantly. Below investment grade quality debt instruments are regarded as having predominantly speculative characteristics. Below investment grade quality debt instruments tend to be more sensitive to adverse news about the issuer, or the market or economy in general, than higher quality debt instruments.\\n\\n \\n\\nFocus Risk:  The fund\\u2019s performance will be closely tied to the economic and political conditions in Georgia, and can be more volatile than the performance of a more geographically diversified\\n\\n \\n\\n3\\n\\n\\n \\n\\nMFS Georgia Municipal Bond Fund\\n\\n \\n\\nfund. In addition, the fund\\u2019s performance can also be tied to the economic and political conditions of other states and U.S. territories and possessions in which the funds are invested. These conditions may include constitutional or statutory limits on an issuer\\u2019s ability to raise revenues or increase taxes, anticipated or actual budget deficits or other financial difficulties, or changes in the credit quality of municipal issuers in the state, other states, or U.S. territories and possessions.\\n\\n \\n\\nMunicipal Risk:  The price of a municipal instrument can be volatile and significantly affected by adverse tax changes or court rulings, legislative or political changes, changes in specific or general market and economic conditions, and the financial condition of municipal issuers and insurers. Because many municipal instruments are issued to finance similar projects, conditions in certain industries can significantly affect the fund and the overall municipal market.\\n\\n \\n\\nPrepayment/Extension Risk:  Instruments subject to prepayment and/or extension can reduce the potential for gain for the instrument\\u2019s holders if the instrument is prepaid and increase the potential for loss if the maturity of the instrument is extended.\\n\\n \\n\\nDerivatives Risk:  Derivatives can be highly volatile and involve risks in addition to the risks of the underlying indicator(s) on which the derivative is based. Gains or losses from derivatives can be substantially greater than the derivatives\\u2019 original cost.  Derivatives can involve leverage.\\n\\n \\n\\nLeveraging Risk:  Leverage involves investment exposure in an amount exceeding the initial investment. Leverage can cause increased volatility by magnifying gains or losses.\\n\\n \\n\\nCounterparty and Third Party Risk:  Transactions involving a counterparty or third party other than the issuer of the instrument are subject to the credit risk of the counterparty or third party, and to the counterparty\\u2019s or third party\\u2019s ability or willingness to perform in accordance with the terms of the transaction.\\n\\n \\n\\nLiquidity Risk:  It may be difficult to value, and it may not be possible to sell, certain investments, types of investments, and/or investments in certain segments of the market, and the fund may have to sell certain of these investments at prices or times that are not advantageous in order to meet redemptions or other cash needs.\\n\\n \\n\\nInvestment Selection Risk:  MFS\\u2019 investment analysis and its selection of investments may not produce the intended results and/or can lead to an investment focus that results in the fund underperforming other funds with similar investment strategies and/or underperforming the markets in which the fund invests.\\n\\n \\n\\nPerformance Information\\n\\n \\n\\nThe bar chart and performance table below are intended to provide some indication of the risks of investing in the fund by showing changes in the fund\\u2019s performance over time and how the fund\\u2019s performance over time compares with that of a broad measure of market performance.\\n\\n \\n\\nThe fund\\u2019s past performance (before and after taxes) does not necessarily indicate how the fund will perform in the future. Updated performance is available online at mfs.com or by calling 1-800-225-2606.\\n\\n \\n\\nClass A Bar Chart.  The bar chart does not take into account any sales charges (loads) that you may be required to pay upon purchase or redemption of the fund\\u2019s shares. If these sales charges were included, they would reduce the returns shown.\\n\\n \\n\\n\\n\\n \\n\\nThe total return for the six-month period ended June 30, 2018, was (0.07)%. During the period(s) shown in the bar chart, the highest quarterly return was 6.91% (for the calendar quarter ended September 30, 2009) and the lowest quarterly return was (5.23)% (for the calendar quarter ended December 31, 2010).\\n\\n \\n\\nPerformance Table.\\n\\n \\n\\nAverage Annual Total Returns\\n\\n(For the Periods Ended December 31, 2017)\\n\\n \\n\\nShare Class\\n\\n \\n\\n1 YEAR\\n\\n \\n\\n5 YEARS\\n\\n \\n\\n10 YEARS\\n\\n \\n\\nReturns Before Taxes\\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nT Shares\\n\\n \\n\\n1.71\\n\\n%\\n\\n1.76\\n\\n%\\n\\n3.64\\n\\n%\\n\\nB Shares\\n\\n \\n\\n(0.46\\n\\n)%\\n\\n1.15\\n\\n%\\n\\n3.27\\n\\n%\\n\\nI Shares\\n\\n \\n\\n4.58\\n\\n%\\n\\n2.53\\n\\n%\\n\\n4.16\\n\\n%\\n\\nR6 Shares\\n\\n \\n\\n4.53\\n\\n%\\n\\n2.52\\n\\n%\\n\\n4.16\\n\\n%\\n\\nA Shares\\n\\n \\n\\n(0.11\\n\\n)%\\n\\n1.39\\n\\n%\\n\\n3.46\\n\\n%\\n\\nReturns After Taxes on Distributions\\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nA Shares\\n\\n \\n\\n(0.12\\n\\n)%\\n\\n1.39\\n\\n%\\n\\n3.41\\n\\n%\\n\\nReturns After Taxes on Distributions and Sale of Fund Shares\\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nA Shares\\n\\n \\n\\n1.26\\n\\n%\\n\\n1.79\\n\\n%\\n\\n3.48\\n\\n%\\n\\nIndex Comparison (Reflects no deduction for fees, expenses, or taxes)\\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nBloomberg Barclays Municipal Bond Index\\n\\n \\n\\n5.45\\n\\n%\\n\\n3.02\\n\\n%\\n\\n4.46\\n\\n%\\n\\n \\n\\nAfter-tax returns are calculated using the historical highest individual federal marginal income tax rates and do not reflect the impact of state and local taxes. Your actual after-tax returns will depend on your own tax situation, and may differ from those shown. The after-tax returns shown are not relevant to investors who hold their shares through tax-advantaged arrangements, such as 401(k) plans or individual retirement accounts. The after-tax returns are shown for only one of the fund\\u2019s classes of shares, and after-tax returns for the fund\\u2019s other classes of shares will vary from the returns shown.\\n\\n \\n\\nInvestment Adviser\\n\\n \\n\\nMFS serves as the investment adviser for the fund.\\n\\n \\n\\n4\\n\\n\\n \\n\\nMFS Georgia Municipal Bond Fund\\n\\n \\n\\nPortfolio Manager(s)\\n\\n \\n\\nPortfolio Manager\\n\\n \\n\\nSince\\n\\n \\n\\nTitle\\n\\nMichael Dawson\\n\\n \\n\\n1999\\n\\n \\n\\nInvestment Officer of MFS\\n\\n \\n\\nPurchase and Sale of Fund Shares\\n\\n \\n\\nYou may purchase and redeem shares of the fund each day the New York Stock Exchange (the \\u201cNYSE\\u201d) is open for trading. You may purchase or redeem shares either by having your financial intermediary process your purchase or redemption, or through MFS Service Center, Inc. (MFSC) by overnight mail (MFSC, c/o DST Asset Manager Solutions, Inc., 30 Dan Road, Canton, MA  02021-2809), by mail ([Fund Name], P.O. Box 55824, Boston, MA 02205-5824), by telephone (1-800-225-2606), or via the Internet at mfs.com (MFS Access).\\n\\n \\n\\nThe fund\\u2019s initial and subsequent investment minimums generally are as follows:\\n\\n \\n\\nClass\\n\\n \\n\\nInitial Minimum\\n\\n \\n\\nSubsequent Minimum\\n\\n \\n\\nClass A, Class T, Class B\\n\\n \\n\\nNone \\u2013 automatic investment plans and certain asset-based fee programs\\n\\n$25 \\u2013 employer-sponsored retirement plans\\n\\n$250 \\u2013 Traditional and Roth IRAs\\n\\n$1,000 \\u2013 other accounts\\n\\n \\n\\n$50 \\u2013 by check and non-systematic written exchange request, and via MFSC telephone representatives\\n\\nNone \\u2013 other purchases\\n\\n \\n\\nClass I, Class R6\\n\\n \\n\\nNone\\n\\n \\n\\nNone\\n\\n \\n\\n \\n\\nAs of the date of this prospectus, Class T shares are not being offered for sale.\\n\\n \\n\\nTaxes\\n\\n \\n\\nThe fund intends to distribute income that is exempt from federal income tax, but may be subject to federal alternative minimum tax.  A portion of the fund\\u2019s distributions may be subject to federal income tax.\\n\\n \\n\\nPayments to Broker/Dealers and Other Financial Intermediaries\\n\\n \\n\\nIf you purchase shares of the fund through a broker/dealer or other financial intermediary (such as a bank), the fund, MFS, and/or MFS\\u2019 affiliates may pay the financial intermediary for the sale of shares of a fund and/or the servicing of shareholder accounts. These payments may create a conflict of interest by influencing your broker/dealer or other financial intermediary and your salesperson to recommend the fund over another investment. Ask your financial intermediary or visit your financial intermediary\\u2019s Web site for more information.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Function to get data (Assuming you have this defined)\n",
        "fund_names, summaries = get_data(SUMMARY_PATH)\n",
        "fund_names_in_X_test = X_test['fund_name'].tolist()\n",
        "\n",
        "# Correctly filter summaries where the fund name is in X_test\n",
        "# and ensure alignment between fund names and summaries\n",
        "selected_summaries_in_X_test = []\n",
        "fund_names_with_summaries = []\n",
        "\n",
        "for fund_name, summary in zip(fund_names, summaries):\n",
        "    if fund_name in fund_names_in_X_test:\n",
        "        selected_summaries_in_X_test.append(summary)\n",
        "        fund_names_with_summaries.append(fund_name)\n",
        "\n",
        "# Create DataFrame from extracted summaries\n",
        "df_extraction = pd.DataFrame({\n",
        "    'fund_name': fund_names_with_summaries,\n",
        "    'summary': selected_summaries_in_X_test\n",
        "})\n",
        "\n",
        "original_index = X_test.index\n",
        "X_test_new = X_test.merge(df_extraction, on='fund_name', how='left')\n",
        "X_test_new.index = original_index\n",
        "\n",
        "\n",
        "# Drop rows where the 'summary' is NaN and reset index\n",
        "X_test_new = X_test_new.dropna(subset=['summary'])\n",
        "\n",
        "X_test_new.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "X_test_final_bert_v0 = copy.deepcopy(X_test_final)\n",
        "X_test_final_bert_v0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cxSPFDrR9J4h",
        "outputId": "dd18d109-a807-46d7-8ae5-b969f87ca2dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Leverage?  Portfolio composition   Concentration  Max Similarity  \\\n",
              "324        0.0                    1.0             0.0        0.095795   \n",
              "448        0.0                    1.0             0.0        0.113886   \n",
              "298        0.0                    2.0             0.0        0.121048   \n",
              "410        0.0                    2.0             0.0        0.088594   \n",
              "22         0.0                    2.0             0.0        0.112837   \n",
              "234        1.0                    0.0             0.0        0.117292   \n",
              "398        0.0                    0.0             0.0        0.110279   \n",
              "238        1.0                    0.0             0.0        0.124509   \n",
              "60         0.0                    1.0             0.0        0.113346   \n",
              "464        1.0                    2.0             0.0        0.119668   \n",
              "325        0.0                    1.0             0.0        0.095687   \n",
              "239        1.0                    1.0             0.0        0.138812   \n",
              "76         0.0                    2.0             1.0        0.096468   \n",
              "24         1.0                    0.0             0.0        0.116521   \n",
              "84         0.0                    1.0             1.0        0.105821   \n",
              "157        0.0                    1.0             0.0        0.119726   \n",
              "311        0.0                    0.0             1.0        0.117924   \n",
              "297        1.0                    1.0             0.0        0.085781   \n",
              "73         0.0                    2.0             1.0        0.102072   \n",
              "168        1.0                    1.0             0.0        0.115835   \n",
              "124        0.0                    1.0             0.0        0.145813   \n",
              "382        0.0                    0.0             0.0        0.145812   \n",
              "176        1.0                    1.0             0.0        0.103540   \n",
              "86         1.0                    0.0             0.0        0.172895   \n",
              "322        0.0                    1.0             0.0        0.166213   \n",
              "72         0.0                    2.0             1.0        0.063105   \n",
              "302        0.0                    1.0             1.0        0.079268   \n",
              "132        1.0                    0.0             1.0        0.073941   \n",
              "140        1.0                    0.0             1.0        0.267102   \n",
              "137        1.0                    0.0             1.0        0.111175   \n",
              "380        0.0                    0.0             0.0        0.091762   \n",
              "424        1.0                    0.0             0.0        0.106551   \n",
              "77         0.0                    0.0             1.0        0.097175   \n",
              "79         1.0                    0.0             0.0        0.104286   \n",
              "185        1.0                    0.0             1.0        0.106184   \n",
              "280        0.0                    1.0             0.0        0.149728   \n",
              "321        0.0                    1.0             0.0        0.184918   \n",
              "25         1.0                    0.0             0.0        0.134114   \n",
              "400        0.0                    0.0             0.0        0.134065   \n",
              "19         0.0                    1.0             0.0        0.101138   \n",
              "55         0.0                    0.0             0.0        0.116074   \n",
              "78         0.0                    0.0             1.0        0.110761   \n",
              "30         0.0                    2.0             0.0        0.077758   \n",
              "101        0.0                    0.0             0.0        0.107120   \n",
              "75         0.0                    2.0             1.0        0.105292   \n",
              "192        1.0                    1.0             0.0        0.103636   \n",
              "116        0.0                    0.0             0.0        0.108588   \n",
              "\n",
              "     Mean Similarity  \n",
              "324         0.017673  \n",
              "448         0.016614  \n",
              "298         0.017860  \n",
              "410         0.023219  \n",
              "22          0.021537  \n",
              "234         0.018681  \n",
              "398         0.020864  \n",
              "238         0.020973  \n",
              "60          0.021788  \n",
              "464         0.020821  \n",
              "325         0.017820  \n",
              "239         0.021762  \n",
              "76          0.020091  \n",
              "24          0.024863  \n",
              "84          0.022690  \n",
              "157         0.020859  \n",
              "311         0.024465  \n",
              "297         0.018526  \n",
              "73          0.017862  \n",
              "168         0.023314  \n",
              "124         0.025235  \n",
              "382         0.025235  \n",
              "176         0.022747  \n",
              "86          0.020240  \n",
              "322         0.020498  \n",
              "72          0.015297  \n",
              "302         0.020482  \n",
              "132         0.019030  \n",
              "140         0.022799  \n",
              "137         0.020149  \n",
              "380         0.017940  \n",
              "424         0.018827  \n",
              "77          0.019151  \n",
              "79          0.017773  \n",
              "185         0.018762  \n",
              "280         0.021491  \n",
              "321         0.021968  \n",
              "25          0.023624  \n",
              "400         0.023653  \n",
              "19          0.018123  \n",
              "55          0.018222  \n",
              "78          0.019798  \n",
              "30          0.020199  \n",
              "101         0.019056  \n",
              "75          0.017781  \n",
              "192         0.021942  \n",
              "116         0.019383  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-033d6718-d527-4c71-ae93-54a4d852e932\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Leverage?</th>\n",
              "      <th>Portfolio composition</th>\n",
              "      <th>Concentration</th>\n",
              "      <th>Max Similarity</th>\n",
              "      <th>Mean Similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>324</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.095795</td>\n",
              "      <td>0.017673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.113886</td>\n",
              "      <td>0.016614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.121048</td>\n",
              "      <td>0.017860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>410</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.088594</td>\n",
              "      <td>0.023219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.112837</td>\n",
              "      <td>0.021537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.117292</td>\n",
              "      <td>0.018681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.110279</td>\n",
              "      <td>0.020864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>238</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.124509</td>\n",
              "      <td>0.020973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.113346</td>\n",
              "      <td>0.021788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>464</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.119668</td>\n",
              "      <td>0.020821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>325</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.095687</td>\n",
              "      <td>0.017820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.138812</td>\n",
              "      <td>0.021762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.096468</td>\n",
              "      <td>0.020091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.116521</td>\n",
              "      <td>0.024863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.105821</td>\n",
              "      <td>0.022690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.119726</td>\n",
              "      <td>0.020859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.117924</td>\n",
              "      <td>0.024465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.085781</td>\n",
              "      <td>0.018526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.102072</td>\n",
              "      <td>0.017862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.115835</td>\n",
              "      <td>0.023314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.145813</td>\n",
              "      <td>0.025235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>382</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.145812</td>\n",
              "      <td>0.025235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.103540</td>\n",
              "      <td>0.022747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.172895</td>\n",
              "      <td>0.020240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>322</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166213</td>\n",
              "      <td>0.020498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.063105</td>\n",
              "      <td>0.015297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.079268</td>\n",
              "      <td>0.020482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.073941</td>\n",
              "      <td>0.019030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.267102</td>\n",
              "      <td>0.022799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.111175</td>\n",
              "      <td>0.020149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>380</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.091762</td>\n",
              "      <td>0.017940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>424</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.106551</td>\n",
              "      <td>0.018827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.097175</td>\n",
              "      <td>0.019151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.104286</td>\n",
              "      <td>0.017773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>185</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.106184</td>\n",
              "      <td>0.018762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>280</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.149728</td>\n",
              "      <td>0.021491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.184918</td>\n",
              "      <td>0.021968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.134114</td>\n",
              "      <td>0.023624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.134065</td>\n",
              "      <td>0.023653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.101138</td>\n",
              "      <td>0.018123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.116074</td>\n",
              "      <td>0.018222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.110761</td>\n",
              "      <td>0.019798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.077758</td>\n",
              "      <td>0.020199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.107120</td>\n",
              "      <td>0.019056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.105292</td>\n",
              "      <td>0.017781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.103636</td>\n",
              "      <td>0.021942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.108588</td>\n",
              "      <td>0.019383</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-033d6718-d527-4c71-ae93-54a4d852e932')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-033d6718-d527-4c71-ae93-54a4d852e932 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-033d6718-d527-4c71-ae93-54a4d852e932');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fd420e74-3cf1-4a19-b3dd-1324e297d774\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fd420e74-3cf1-4a19-b3dd-1324e297d774')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fd420e74-3cf1-4a19-b3dd-1324e297d774 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_test_final_bert_v0",
              "summary": "{\n  \"name\": \"X_test_final_bert_v0\",\n  \"rows\": 47,\n  \"fields\": [\n    {\n      \"column\": \"Leverage?\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.48568785444140594,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Portfolio composition\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.765224749775401,\n        \"min\": 0.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" Concentration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.45215078571752676,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Max Similarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03304618648516146,\n        \"min\": 0.06310542753041129,\n        \"max\": 0.26710232784006077,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          0.07394077075709476,\n          0.10113756679314996\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mean Similarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0023981871531365715,\n        \"min\": 0.015297276844295039,\n        \"max\": 0.025234798423533513,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          0.01903013228823859,\n          0.018123203802441156\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qoXcGCUSw4xi",
        "outputId": "8bce7fd0-1a5e-4b40-8e94-8d22d4cb0963"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Leverage?  Portfolio composition   Concentration  \\\n",
              "324        0.0                    1.0             0.0   \n",
              "448        0.0                    1.0             0.0   \n",
              "298        0.0                    2.0             0.0   \n",
              "410        0.0                    2.0             0.0   \n",
              "22         0.0                    2.0             0.0   \n",
              "234        1.0                    0.0             0.0   \n",
              "398        0.0                    0.0             0.0   \n",
              "238        1.0                    0.0             0.0   \n",
              "60         0.0                    1.0             0.0   \n",
              "464        1.0                    2.0             0.0   \n",
              "325        0.0                    1.0             0.0   \n",
              "239        1.0                    1.0             0.0   \n",
              "76         0.0                    2.0             1.0   \n",
              "24         1.0                    0.0             0.0   \n",
              "84         0.0                    1.0             1.0   \n",
              "157        0.0                    1.0             0.0   \n",
              "311        0.0                    0.0             1.0   \n",
              "297        1.0                    1.0             0.0   \n",
              "73         0.0                    2.0             1.0   \n",
              "168        1.0                    1.0             0.0   \n",
              "124        0.0                    1.0             0.0   \n",
              "382        0.0                    0.0             0.0   \n",
              "176        1.0                    1.0             0.0   \n",
              "86         1.0                    0.0             0.0   \n",
              "322        0.0                    1.0             0.0   \n",
              "72         0.0                    2.0             1.0   \n",
              "302        0.0                    1.0             1.0   \n",
              "132        1.0                    0.0             1.0   \n",
              "140        1.0                    0.0             1.0   \n",
              "137        1.0                    0.0             1.0   \n",
              "380        0.0                    0.0             0.0   \n",
              "424        1.0                    0.0             0.0   \n",
              "77         0.0                    0.0             1.0   \n",
              "79         1.0                    0.0             0.0   \n",
              "185        1.0                    0.0             1.0   \n",
              "280        0.0                    1.0             0.0   \n",
              "321        0.0                    1.0             0.0   \n",
              "25         1.0                    0.0             0.0   \n",
              "400        0.0                    0.0             0.0   \n",
              "19         0.0                    1.0             0.0   \n",
              "55         0.0                    0.0             0.0   \n",
              "78         0.0                    0.0             1.0   \n",
              "30         0.0                    2.0             0.0   \n",
              "101        0.0                    0.0             0.0   \n",
              "75         0.0                    2.0             1.0   \n",
              "192        1.0                    1.0             0.0   \n",
              "116        0.0                    0.0             0.0   \n",
              "\n",
              "                                               summary  \n",
              "324  Fund Summary\\n\\nFund:\\nFidelity® Series Opport...  \n",
              "448  INVESTMENT OBJECTIVE\\nThe USAA Growth & Income...  \n",
              "298  SUMMARY OF THE FUND\\nInvestment Objective\\nCol...  \n",
              "410  Fund Summary\\n\\nFund:\\nFidelity® Emerging Asia...  \n",
              "22   International Fund\\n\\nInvestment objective The...  \n",
              "234  PIMCO REALPATH® 2035 Fund\\n\\n\\n\\n\\nInvestment ...  \n",
              "398  Franklin Payout 2019 Fund\\n\\nInvestment Goal\\n...  \n",
              "238  PIMCO REALPATH® 2055 Fund\\n\\n\\n\\n\\nInvestment ...  \n",
              "60   Fund Summary\\nInvestment Objective\\nThe fund s...  \n",
              "464  Fund Summary\\nInvestment Objective\\nThe fund s...  \n",
              "325  Fund Summary\\n\\nFund:\\nFidelity Advisor® Serie...  \n",
              "239  SUMMARY OF THE FUND\\nInvestment Objective\\nCol...  \n",
              "76   Fund Summary\\nInvestment Objective\\nThe fund s...  \n",
              "24   Managed Risk Asset Allocation Fund\\n\\nInvestme...  \n",
              "84   Fund Summary\\n\\nInvestment Objective\\n\\nThe Fu...  \n",
              "157  MainStay VP MacKay Mid Cap Core Portfolio\\n\\n(...  \n",
              "311  PIMCO Gurtin California Municipal Intermediate...  \n",
              "297  SUMMARY OF THE FUND\\nInvestment Objective\\nCol...  \n",
              "73   SUMMARY\\n\\nInvestment Objective\\n\\nThe fund se...  \n",
              "168  Janus Henderson Global Equity Income Fund\\nTic...  \n",
              "124  Summary of Key Information\\n\\n \\n\\nInvestment ...  \n",
              "382  Fund Summary\\n\\nFund/Class:\\nFidelity® Municip...  \n",
              "176  Janus Henderson International Opportunities Fu...  \n",
              "86   Vanguard Short-Term Investment-Grade Fund\\n\\nI...  \n",
              "322  Fund Summary\\n\\nFund:\\nFidelity® Contrafund® K...  \n",
              "72   nvestment Objective\\n\\nThe fund seeks long-ter...  \n",
              "302  SUMMARY OF THE FUND\\nInvestment Objective\\nCol...  \n",
              "132  MFS Georgia Municipal Bond Fund\\n\\n \\n\\nSummar...  \n",
              "140  MFS South Carolina Municipal Bond Fund\\n\\n \\n\\...  \n",
              "137  MFS New York Municipal Bond Fund\\n\\n \\n\\nSumma...  \n",
              "380  Fund Summary\\n\\nFund/Class:\\nFidelity® Municip...  \n",
              "424  FUND SUMMARY - ANCHOR TACTICAL MUNICIPAL STRAT...  \n",
              "77   Fund Summary\\nInvestment Objective \\nThe fund ...  \n",
              "79   Vanguard GNMA Fund\\n\\nInvestment Objective\\n\\n...  \n",
              "185  Investment objective\\n\\nThe fund seeks to prov...  \n",
              "280  Ivy Mid Cap Income Opportunities Fund\\n\\nObjec...  \n",
              "321  Fund Summary\\n\\nFund/Class:\\nFidelity® Contraf...  \n",
              "25   Managed Risk Blue Chip Income and Growth Fund\\...  \n",
              "400  Franklin Payout 2021 Fund\\n\\nInvestment Goal\\n...  \n",
              "19   Growth Fund\\n\\nInvestment objective The fund’s...  \n",
              "55   American Funds 2055 Target Date Retirement Fun...  \n",
              "78   Fund Summary\\nInvestment Objective \\nThe fund ...  \n",
              "30   New World Fund\\n\\nInvestment objective The fun...  \n",
              "101  Vanguard Russell 2000 Index Fund\\n\\nInvestment...  \n",
              "75   Investment Objective\\n\\nThe fund seeks long-te...  \n",
              "192  SUMMARY OF COLUMBIA VP – DISCIPLINED CORE FUND...  \n",
              "116  Eaton Vance TABS Intermediate-Term Municipal B...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-76a14b36-5206-4b9e-b685-5d966d557ad4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Leverage?</th>\n",
              "      <th>Portfolio composition</th>\n",
              "      <th>Concentration</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>324</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Fund Summary\\n\\nFund:\\nFidelity® Series Opport...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>INVESTMENT OBJECTIVE\\nThe USAA Growth &amp; Income...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>SUMMARY OF THE FUND\\nInvestment Objective\\nCol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>410</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Fund Summary\\n\\nFund:\\nFidelity® Emerging Asia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>International Fund\\n\\nInvestment objective The...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>PIMCO REALPATH® 2035 Fund\\n\\n\\n\\n\\nInvestment ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Franklin Payout 2019 Fund\\n\\nInvestment Goal\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>238</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>PIMCO REALPATH® 2055 Fund\\n\\n\\n\\n\\nInvestment ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Fund Summary\\nInvestment Objective\\nThe fund s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>464</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Fund Summary\\nInvestment Objective\\nThe fund s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>325</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Fund Summary\\n\\nFund:\\nFidelity Advisor® Serie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>SUMMARY OF THE FUND\\nInvestment Objective\\nCol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Fund Summary\\nInvestment Objective\\nThe fund s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Managed Risk Asset Allocation Fund\\n\\nInvestme...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Fund Summary\\n\\nInvestment Objective\\n\\nThe Fu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>MainStay VP MacKay Mid Cap Core Portfolio\\n\\n(...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>PIMCO Gurtin California Municipal Intermediate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>SUMMARY OF THE FUND\\nInvestment Objective\\nCol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>SUMMARY\\n\\nInvestment Objective\\n\\nThe fund se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Janus Henderson Global Equity Income Fund\\nTic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Summary of Key Information\\n\\n \\n\\nInvestment ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>382</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Fund Summary\\n\\nFund/Class:\\nFidelity® Municip...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Janus Henderson International Opportunities Fu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Vanguard Short-Term Investment-Grade Fund\\n\\nI...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>322</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Fund Summary\\n\\nFund:\\nFidelity® Contrafund® K...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>nvestment Objective\\n\\nThe fund seeks long-ter...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>SUMMARY OF THE FUND\\nInvestment Objective\\nCol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>MFS Georgia Municipal Bond Fund\\n\\n \\n\\nSummar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>MFS South Carolina Municipal Bond Fund\\n\\n \\n\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>MFS New York Municipal Bond Fund\\n\\n \\n\\nSumma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>380</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Fund Summary\\n\\nFund/Class:\\nFidelity® Municip...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>424</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>FUND SUMMARY - ANCHOR TACTICAL MUNICIPAL STRAT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Fund Summary\\nInvestment Objective \\nThe fund ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Vanguard GNMA Fund\\n\\nInvestment Objective\\n\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>185</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Investment objective\\n\\nThe fund seeks to prov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>280</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Ivy Mid Cap Income Opportunities Fund\\n\\nObjec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Fund Summary\\n\\nFund/Class:\\nFidelity® Contraf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Managed Risk Blue Chip Income and Growth Fund\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Franklin Payout 2021 Fund\\n\\nInvestment Goal\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Growth Fund\\n\\nInvestment objective The fund’s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>American Funds 2055 Target Date Retirement Fun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Fund Summary\\nInvestment Objective \\nThe fund ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>New World Fund\\n\\nInvestment objective The fun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Vanguard Russell 2000 Index Fund\\n\\nInvestment...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Investment Objective\\n\\nThe fund seeks long-te...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>SUMMARY OF COLUMBIA VP – DISCIPLINED CORE FUND...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Eaton Vance TABS Intermediate-Term Municipal B...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76a14b36-5206-4b9e-b685-5d966d557ad4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-76a14b36-5206-4b9e-b685-5d966d557ad4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-76a14b36-5206-4b9e-b685-5d966d557ad4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8e53530f-1e72-4949-9872-77fb2b360a6a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8e53530f-1e72-4949-9872-77fb2b360a6a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8e53530f-1e72-4949-9872-77fb2b360a6a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_test_final_bert_v0",
              "summary": "{\n  \"name\": \"X_test_final_bert_v0\",\n  \"rows\": 47,\n  \"fields\": [\n    {\n      \"column\": \"Leverage?\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.48568785444140594,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Portfolio composition\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.765224749775401,\n        \"min\": 0.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" Concentration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.45215078571752676,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 47,\n        \"samples\": [\n          \"MFS Georgia Municipal Bond Fund\\n\\n \\n\\nSummary of Key Information\\n\\n \\n\\nInvestment Objective\\n\\n \\n\\nThe fund\\u2019s investment objective is to seek total return with an emphasis on income exempt from federal income tax and personal income tax, if any, of Georgia, but also considering capital appreciation.\\n\\n \\n\\nFees and Expenses\\n\\n \\n\\nThis table describes the fees and expenses that you may pay when you buy and hold shares of the fund. Investors may also pay commissions or other fees to their financial intermediaries when they buy and hold shares of the fund, which are not reflected below.\\n\\n \\n\\nYou may qualify for sales charge reductions if, with respect to Class A shares, you and certain members of your family invest, or agree to invest in the future, at least $100,000 in MFS Funds, and, with respect to Class T shares, you invest at least $250,000 in the fund. More information about these and other waivers and reductions is available from your financial intermediary and in \\u201cSales Charges and Waivers and Reductions\\u201d on page 9 and \\u201cAppendix A \\u2013 Waivers and Reductions of Sales Charges\\u201d on page A-1 of the fund\\u2019s prospectus.\\n\\n \\n\\nShareholder Fees (fees paid directly from your investment):\\n\\n \\n\\nShare Class\\n\\n \\n\\nA\\n\\n \\n\\nT\\n\\n \\n\\nB\\n\\n \\n\\nI\\n\\n \\n\\nR6\\n\\n \\n\\nMaximum Sales Charge (Load) Imposed on Purchases (as a percentage of offering price)\\n\\n \\n\\n4.25\\n\\n%\\n\\n2.50\\n\\n%\\n\\nNone\\n\\n \\n\\nNone\\n\\n \\n\\nNone\\n\\n \\n\\nMaximum Deferred Sales Charge (Load) (as a percentage of original purchase price or redemption proceeds, whichever is less)\\n\\n \\n\\n1.00\\n\\n%#\\n\\nNone\\n\\n \\n\\n4.00\\n\\n%\\n\\nNone\\n\\n \\n\\nNone\\n\\n \\n\\n \\n\\nAnnual Fund Operating Expenses (expenses that you pay each year as a percentage of the value of your investment):\\n\\n \\n\\nShare Class\\n\\n \\n\\nA\\n\\n \\n\\nT\\n\\n \\n\\nB\\n\\n \\n\\nI\\n\\n \\n\\nR6\\n\\n \\n\\nManagement Fee\\n\\n \\n\\n0.45\\n\\n%\\n\\n0.45\\n\\n%\\n\\n0.45\\n\\n%\\n\\n0.45\\n\\n%\\n\\n0.45\\n\\n%\\n\\nDistribution and/or Service (12b-1) Fees\\n\\n \\n\\n0.25\\n\\n%\\n\\n0.25\\n\\n%\\n\\n1.00\\n\\n%\\n\\nNone\\n\\n \\n\\nNone\\n\\n \\n\\nOther Expenses\\n\\n \\n\\n0.34\\n\\n%\\n\\n0.34\\n\\n%\\n\\n0.34\\n\\n%\\n\\n0.34\\n\\n%\\n\\n0.28\\n\\n%\\n\\nTotal Annual Fund Operating Expenses\\n\\n \\n\\n1.04\\n\\n%\\n\\n1.04\\n\\n%\\n\\n1.79\\n\\n%\\n\\n0.79\\n\\n%\\n\\n0.73\\n\\n%\\n\\nFee Reductions and/or Expense Reimbursements1\\n\\n \\n\\n(0.14\\n\\n)%\\n\\n(0.14\\n\\n)%\\n\\n(0.14\\n\\n)%\\n\\n(0.14\\n\\n)%\\n\\n(0.13\\n\\n)%\\n\\nTotal Annual Fund Operating Expenses After Fee Reductions and/or Expense Reimbursements\\n\\n \\n\\n0.90\\n\\n%\\n\\n0.90\\n\\n%\\n\\n1.65\\n\\n%\\n\\n0.65\\n\\n%\\n\\n0.60\\n\\n%\\n\\n \\n\\n#                 This contingent deferred sales charge (CDSC) applies to shares purchased without an initial sales charge and redeemed within 18 months of purchase.\\n\\n1                 Massachusetts Financial Services Company has agreed in writing to bear the fund\\u2019s expenses, excluding interest, taxes, extraordinary expenses, brokerage and transaction costs, and investment-related expenses (such as interest and borrowing expenses incurred in connection with the fund\\u2019s investment activity), such that \\u201cTotal Annual Fund Operating Expenses\\u201d do not exceed 0.90% of the class\\u2019 average daily net assets annually for each of Class A and Class T shares, 1.65% of the class\\u2019 average daily net assets annually for Class B shares, 0.65% of the class\\u2019 average daily net assets annually for Class I shares, and 0.60% of the class\\u2019 average daily net assets annually for Class R6 shares. This written agreement will continue until modified by the fund\\u2019s Board of Trustees, but such agreement will continue until at least July 31, 2019.\\n\\n \\n\\n2\\n\\n\\n \\n\\nMFS Georgia Municipal Bond Fund\\n\\n \\n\\nExample\\n\\n \\n\\nThis example is intended to help you compare the cost of investing in the fund with the cost of investing in other mutual funds.\\n\\n \\n\\nThe example assumes that: you invest $10,000 in the fund for the time periods indicated and you redeem your shares at the end of the time periods (unless otherwise indicated); your investment has a 5% return each year; and the fund\\u2019s operating expenses remain the same.\\n\\n \\n\\nAlthough your actual costs will likely be higher or lower, under these assumptions your costs would be:\\n\\n \\n\\n \\n\\n \\n\\n1 YEAR\\n\\n \\n\\n3 YEARS\\n\\n \\n\\n5 YEARS\\n\\n \\n\\n10 YEARS\\n\\n \\n\\nClass A Shares\\n\\n \\n\\n$\\n\\n513\\n\\n \\n\\n$\\n\\n729\\n\\n \\n\\n$\\n\\n962\\n\\n \\n\\n$\\n\\n1,630\\n\\n \\n\\nClass T Shares\\n\\n \\n\\n$\\n\\n340\\n\\n \\n\\n$\\n\\n559\\n\\n \\n\\n$\\n\\n796\\n\\n \\n\\n$\\n\\n1,477\\n\\n \\n\\nClass B Shares assuming\\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nredemption at end of period\\n\\n \\n\\n$\\n\\n568\\n\\n \\n\\n$\\n\\n850\\n\\n \\n\\n$\\n\\n1,157\\n\\n \\n\\n$\\n\\n1,896\\n\\n \\n\\nno redemption at end of period\\n\\n \\n\\n$\\n\\n168\\n\\n \\n\\n$\\n\\n550\\n\\n \\n\\n$\\n\\n957\\n\\n \\n\\n$\\n\\n1,896\\n\\n \\n\\nClass I Shares\\n\\n \\n\\n$\\n\\n66\\n\\n \\n\\n$\\n\\n238\\n\\n \\n\\n$\\n\\n425\\n\\n \\n\\n$\\n\\n965\\n\\n \\n\\nClass R6 Shares\\n\\n \\n\\n$\\n\\n61\\n\\n \\n\\n$\\n\\n220\\n\\n \\n\\n$\\n\\n393\\n\\n \\n\\n$\\n\\n894\\n\\n \\n\\n \\n\\nPortfolio Turnover\\n\\n \\n\\nThe fund pays transaction costs, such as commissions, when it buys and sells securities (or \\u201cturns over\\u201d its portfolio). A higher portfolio turnover rate may indicate higher transaction costs and may result in higher taxes when shares are held in a taxable account. These transaction costs, which are not reflected in \\u201cAnnual Fund Operating Expenses\\u201d or in the \\u201cExample,\\u201d affect the fund\\u2019s performance.  During the most recent fiscal year, the fund\\u2019s portfolio turnover rate was 12% of the average value of its portfolio. \\n\\n \\n\\nPrincipal Investment Strategies\\n\\n \\n\\nThe fund invests, under normal market conditions, at least 80% of its net assets in securities and other investments, the interest on which is exempt from federal income tax and personal income tax, if any, of Georgia. Interest from the fund\\u2019s investments may be subject to the federal alternative minimum tax. MFS (Massachusetts Financial Services Company, the fund\\u2019s investment adviser) may also invest the fund\\u2019s assets in taxable instruments, including municipal instruments of other states.\\n\\n \\n\\nMFS normally invests the fund\\u2019s assets primarily in municipal instruments.\\n\\n \\n\\nMFS may invest 25% or more of the fund\\u2019s assets in municipal instruments that finance similar projects, such as those relating to education, healthcare, housing, utilities, water or sewers. Municipal instruments whose interest is exempt from federal and state personal income tax include instruments issued by U.S. territories and possessions (such as Puerto Rico, Guam, and the U.S. Virgin Islands) and their political subdivisions and public corporations.\\n\\n \\n\\nMFS primarily invests the fund\\u2019s assets in investment grade quality debt instruments, but may also invest in below investment grade quality debt instruments.\\n\\n \\n\\nMFS invests a significant percentage of the fund\\u2019s assets in municipal instruments of Georgia.\\n\\n \\n\\nWhile MFS may use derivatives for any investment purpose, to the extent MFS uses derivatives, MFS expects to use derivatives primarily to increase or decrease exposure to a particular market, segment of the market, or security, to increase or decrease interest rate exposure, or as alternatives to direct investments. Derivatives include futures, forward contracts, options, structured securities, inverse floating rate instruments, and swaps.\\n\\n \\n\\nMFS uses an active bottom-up investment approach to buying and selling investments for the fund. Investments are selected primarily based on fundamental analysis of individual instruments and their issuers. Quantitative models that systematically evaluate instruments may also be considered. In structuring the fund, MFS also considers top-down factors.\\n\\n \\n\\nFor purposes of the fund\\u2019s 80% policy, net assets include the amount of any borrowings for investment purposes.\\n\\n \\n\\nPrincipal Risks\\n\\n \\n\\nAs with any mutual fund, the fund may not achieve its objective and/or you could lose money on your investment in the fund. An investment in the fund is not a bank deposit and is not insured or guaranteed by the Federal Deposit Insurance Corporation or any other governmental agency.\\n\\n \\n\\nThe principal risks of investing in the fund are:\\n\\n \\n\\nDebt Market Risk:  Debt markets can be volatile and can decline significantly in response to, or investor perceptions of, issuer, market, economic, industry, political, regulatory, geopolitical, and other conditions.  These conditions can affect a single instrument, issuer, or borrower, a particular type of instrument, issuer, or borrower, a segment of the debt markets or the debt markets generally. Certain events can have a dramatic adverse effect on debt markets and may lead to periods of high volatility and reduced liquidity in a debt market or segment of a debt market.\\n\\n \\n\\nInterest Rate Risk:  In general, the price of a debt instrument falls when interest rates rise and rises when interest rates fall. Interest rate risk is generally greater for instruments with longer maturities, or that do not pay current interest.\\n\\n \\n\\nCredit Risk:  The price of a debt instrument depends, in part, on the credit quality of the issuer, borrower, counterparty, or other entity responsible for payment, or underlying collateral or assets and the terms of the instrument. The price of a debt instrument can decline in response to changes in the financial condition of the issuer, borrower, counterparty, or other entity, or underlying collateral or assets, or changes in specific or general market, economic, industry, political, regulatory, geopolitical, and other conditions.\\n\\n \\n\\nThe credit quality of, and the ability to pay principal and interest when due by, an issuer of a municipal instrument depends on the credit quality of the entity supporting the municipal instrument, how essential any services supported by the municipal instrument are, the sufficiency of any revenues or taxes that support the municipal instrument, and/or the willingness or ability of the appropriate government entity to approve any appropriations necessary to support the municipal instrument. In addition, the price of a municipal instrument also depends on its credit quality and ability to meet the credit support obligations of any insurer or other entity providing credit support to a municipal instrument.\\n\\n \\n\\nBelow investment grade quality debt instruments (commonly referred to as \\u201chigh yield securities\\u201d or \\u201cjunk bonds\\u201d) can involve a substantially greater risk of default or can already be in default, and their values can decline significantly. Below investment grade quality debt instruments are regarded as having predominantly speculative characteristics. Below investment grade quality debt instruments tend to be more sensitive to adverse news about the issuer, or the market or economy in general, than higher quality debt instruments.\\n\\n \\n\\nFocus Risk:  The fund\\u2019s performance will be closely tied to the economic and political conditions in Georgia, and can be more volatile than the performance of a more geographically diversified\\n\\n \\n\\n3\\n\\n\\n \\n\\nMFS Georgia Municipal Bond Fund\\n\\n \\n\\nfund. In addition, the fund\\u2019s performance can also be tied to the economic and political conditions of other states and U.S. territories and possessions in which the funds are invested. These conditions may include constitutional or statutory limits on an issuer\\u2019s ability to raise revenues or increase taxes, anticipated or actual budget deficits or other financial difficulties, or changes in the credit quality of municipal issuers in the state, other states, or U.S. territories and possessions.\\n\\n \\n\\nMunicipal Risk:  The price of a municipal instrument can be volatile and significantly affected by adverse tax changes or court rulings, legislative or political changes, changes in specific or general market and economic conditions, and the financial condition of municipal issuers and insurers. Because many municipal instruments are issued to finance similar projects, conditions in certain industries can significantly affect the fund and the overall municipal market.\\n\\n \\n\\nPrepayment/Extension Risk:  Instruments subject to prepayment and/or extension can reduce the potential for gain for the instrument\\u2019s holders if the instrument is prepaid and increase the potential for loss if the maturity of the instrument is extended.\\n\\n \\n\\nDerivatives Risk:  Derivatives can be highly volatile and involve risks in addition to the risks of the underlying indicator(s) on which the derivative is based. Gains or losses from derivatives can be substantially greater than the derivatives\\u2019 original cost.  Derivatives can involve leverage.\\n\\n \\n\\nLeveraging Risk:  Leverage involves investment exposure in an amount exceeding the initial investment. Leverage can cause increased volatility by magnifying gains or losses.\\n\\n \\n\\nCounterparty and Third Party Risk:  Transactions involving a counterparty or third party other than the issuer of the instrument are subject to the credit risk of the counterparty or third party, and to the counterparty\\u2019s or third party\\u2019s ability or willingness to perform in accordance with the terms of the transaction.\\n\\n \\n\\nLiquidity Risk:  It may be difficult to value, and it may not be possible to sell, certain investments, types of investments, and/or investments in certain segments of the market, and the fund may have to sell certain of these investments at prices or times that are not advantageous in order to meet redemptions or other cash needs.\\n\\n \\n\\nInvestment Selection Risk:  MFS\\u2019 investment analysis and its selection of investments may not produce the intended results and/or can lead to an investment focus that results in the fund underperforming other funds with similar investment strategies and/or underperforming the markets in which the fund invests.\\n\\n \\n\\nPerformance Information\\n\\n \\n\\nThe bar chart and performance table below are intended to provide some indication of the risks of investing in the fund by showing changes in the fund\\u2019s performance over time and how the fund\\u2019s performance over time compares with that of a broad measure of market performance.\\n\\n \\n\\nThe fund\\u2019s past performance (before and after taxes) does not necessarily indicate how the fund will perform in the future. Updated performance is available online at mfs.com or by calling 1-800-225-2606.\\n\\n \\n\\nClass A Bar Chart.  The bar chart does not take into account any sales charges (loads) that you may be required to pay upon purchase or redemption of the fund\\u2019s shares. If these sales charges were included, they would reduce the returns shown.\\n\\n \\n\\n\\n\\n \\n\\nThe total return for the six-month period ended June 30, 2018, was (0.07)%. During the period(s) shown in the bar chart, the highest quarterly return was 6.91% (for the calendar quarter ended September 30, 2009) and the lowest quarterly return was (5.23)% (for the calendar quarter ended December 31, 2010).\\n\\n \\n\\nPerformance Table.\\n\\n \\n\\nAverage Annual Total Returns\\n\\n(For the Periods Ended December 31, 2017)\\n\\n \\n\\nShare Class\\n\\n \\n\\n1 YEAR\\n\\n \\n\\n5 YEARS\\n\\n \\n\\n10 YEARS\\n\\n \\n\\nReturns Before Taxes\\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nT Shares\\n\\n \\n\\n1.71\\n\\n%\\n\\n1.76\\n\\n%\\n\\n3.64\\n\\n%\\n\\nB Shares\\n\\n \\n\\n(0.46\\n\\n)%\\n\\n1.15\\n\\n%\\n\\n3.27\\n\\n%\\n\\nI Shares\\n\\n \\n\\n4.58\\n\\n%\\n\\n2.53\\n\\n%\\n\\n4.16\\n\\n%\\n\\nR6 Shares\\n\\n \\n\\n4.53\\n\\n%\\n\\n2.52\\n\\n%\\n\\n4.16\\n\\n%\\n\\nA Shares\\n\\n \\n\\n(0.11\\n\\n)%\\n\\n1.39\\n\\n%\\n\\n3.46\\n\\n%\\n\\nReturns After Taxes on Distributions\\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nA Shares\\n\\n \\n\\n(0.12\\n\\n)%\\n\\n1.39\\n\\n%\\n\\n3.41\\n\\n%\\n\\nReturns After Taxes on Distributions and Sale of Fund Shares\\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nA Shares\\n\\n \\n\\n1.26\\n\\n%\\n\\n1.79\\n\\n%\\n\\n3.48\\n\\n%\\n\\nIndex Comparison (Reflects no deduction for fees, expenses, or taxes)\\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nBloomberg Barclays Municipal Bond Index\\n\\n \\n\\n5.45\\n\\n%\\n\\n3.02\\n\\n%\\n\\n4.46\\n\\n%\\n\\n \\n\\nAfter-tax returns are calculated using the historical highest individual federal marginal income tax rates and do not reflect the impact of state and local taxes. Your actual after-tax returns will depend on your own tax situation, and may differ from those shown. The after-tax returns shown are not relevant to investors who hold their shares through tax-advantaged arrangements, such as 401(k) plans or individual retirement accounts. The after-tax returns are shown for only one of the fund\\u2019s classes of shares, and after-tax returns for the fund\\u2019s other classes of shares will vary from the returns shown.\\n\\n \\n\\nInvestment Adviser\\n\\n \\n\\nMFS serves as the investment adviser for the fund.\\n\\n \\n\\n4\\n\\n\\n \\n\\nMFS Georgia Municipal Bond Fund\\n\\n \\n\\nPortfolio Manager(s)\\n\\n \\n\\nPortfolio Manager\\n\\n \\n\\nSince\\n\\n \\n\\nTitle\\n\\nMichael Dawson\\n\\n \\n\\n1999\\n\\n \\n\\nInvestment Officer of MFS\\n\\n \\n\\nPurchase and Sale of Fund Shares\\n\\n \\n\\nYou may purchase and redeem shares of the fund each day the New York Stock Exchange (the \\u201cNYSE\\u201d) is open for trading. You may purchase or redeem shares either by having your financial intermediary process your purchase or redemption, or through MFS Service Center, Inc. (MFSC) by overnight mail (MFSC, c/o DST Asset Manager Solutions, Inc., 30 Dan Road, Canton, MA  02021-2809), by mail ([Fund Name], P.O. Box 55824, Boston, MA 02205-5824), by telephone (1-800-225-2606), or via the Internet at mfs.com (MFS Access).\\n\\n \\n\\nThe fund\\u2019s initial and subsequent investment minimums generally are as follows:\\n\\n \\n\\nClass\\n\\n \\n\\nInitial Minimum\\n\\n \\n\\nSubsequent Minimum\\n\\n \\n\\nClass A, Class T, Class B\\n\\n \\n\\nNone \\u2013 automatic investment plans and certain asset-based fee programs\\n\\n$25 \\u2013 employer-sponsored retirement plans\\n\\n$250 \\u2013 Traditional and Roth IRAs\\n\\n$1,000 \\u2013 other accounts\\n\\n \\n\\n$50 \\u2013 by check and non-systematic written exchange request, and via MFSC telephone representatives\\n\\nNone \\u2013 other purchases\\n\\n \\n\\nClass I, Class R6\\n\\n \\n\\nNone\\n\\n \\n\\nNone\\n\\n \\n\\n \\n\\nAs of the date of this prospectus, Class T shares are not being offered for sale.\\n\\n \\n\\nTaxes\\n\\n \\n\\nThe fund intends to distribute income that is exempt from federal income tax, but may be subject to federal alternative minimum tax.  A portion of the fund\\u2019s distributions may be subject to federal income tax.\\n\\n \\n\\nPayments to Broker/Dealers and Other Financial Intermediaries\\n\\n \\n\\nIf you purchase shares of the fund through a broker/dealer or other financial intermediary (such as a bank), the fund, MFS, and/or MFS\\u2019 affiliates may pay the financial intermediary for the sale of shares of a fund and/or the servicing of shareholder accounts. These payments may create a conflict of interest by influencing your broker/dealer or other financial intermediary and your salesperson to recommend the fund over another investment. Ask your financial intermediary or visit your financial intermediary\\u2019s Web site for more information.\",\n          \"Growth Fund\\n\\nInvestment objective The fund\\u2019s investment objective is to provide growth of capital.\\n\\nFees and expenses of the fund This table describes the fees and expenses that you may pay if you buy and hold an interest in Class 1 shares of the fund. It does not reflect insurance contract fees and expenses. If insurance contract fees and expenses were reflected, expenses shown would be higher.\\n\\n \\t \\nAnnual fund operating expenses (expenses that you pay each year as a percentage of the value of your investment)\\tClass 1\\nManagement fee\\t0.33%\\nOther expenses\\t0.02\\nTotal annual fund operating expenses\\t0.35\\nExample This example is intended to help you compare the cost of investing in Class 1 shares of the fund with the cost of investing in other mutual funds.\\n\\nThe example assumes that you invest $10,000 in the fund for the time periods indicated and then redeem all of your shares at the end of those periods. The example also assumes that your investment has a 5% return each year and that the fund\\u2019s operating expenses remain the same. The example does not reflect insurance contract expenses. If insurance contract expenses were reflected, expenses shown would be higher. Although your actual costs may be higher or lower, based on these assumptions your costs would be:\\n\\n \\t \\t \\t \\t \\n \\t1 year\\t3 years\\t5 years\\t10 years\\nClass 1\\t$36\\t$113\\t$197\\t$443\\nPortfolio turnover The fund pays transaction costs, such as commissions, when it buys and sells securities (or \\u201cturns over\\u201d its portfolio). A higher portfolio turnover rate may indicate higher transaction costs. These costs, which are not reflected in annual fund operating expenses or in the example, affect the fund\\u2019s investment results. During the most recent fiscal year, the fund\\u2019s portfolio turnover rate was 24% of the average value of its portfolio.\\n\\nPrincipal investment strategies The fund invests primarily in common stocks and seeks to invest in companies that appear to offer superior opportunities for growth of capital. The fund may invest up to 25% of its assets in common stocks and other securities of issuers domiciled outside the United States.\\n\\nThe investment adviser uses a system of multiple portfolio managers in managing the fund\\u2019s assets. Under this approach, the portfolio of the fund is divided into segments managed by individual managers who decide how their respective segments will be invested.\\n\\nThe fund relies on the professional judgment of its investment adviser to make decisions about the fund\\u2019s portfolio investments. The basic investment philosophy of the investment adviser is to seek to invest in attractively valued companies that, in its opinion, represent good, long-term investment opportunities. The investment adviser believes that an important way to accomplish this is through fundamental analysis, which may include meeting with company executives and employees, suppliers, customers and competitors. Securities may be sold when the investment adviser believes that they no longer represent relatively attractive investment opportunities.\\n\\n7     American Funds Insurance Series / Prospectus\\n\\n\\n \\n \\n \\n\\nPrincipal risks\\n\\nThis section describes the principal risks associated with the fund\\u2019s principal investment strategies. You may lose money by investing in the fund. The likelihood of loss may be greater if you invest for a shorter period of time. Investors in the fund should have a long-term perspective and be able to tolerate potentially sharp declines in value.\\n\\nMarket conditions \\u2014 The prices of, and the income generated by, the common stocks and other securities held by the fund may decline \\u2013 sometimes rapidly or unpredictably \\u2013 due to various factors, including events or conditions affecting the general economy or particular industries; overall market changes; local, regional or global political, social or economic instability; governmental or governmental agency responses to economic conditions; and currency exchange rate, interest rate and commodity price fluctuations.\\n\\nIssuer risks \\u2014 The prices of, and the income generated by, securities held by the fund may decline in response to various factors directly related to the issuers of such securities, including reduced demand for an issuer\\u2019s goods or services, poor management performance and strategic initiatives such as mergers, acquisitions or dispositions and the market response to any such initiatives.\\n\\nInvesting in growth-oriented stocks \\u2014 Growth-oriented common stocks and other equity-type securities (such as preferred stocks, convertible preferred stocks and convertible bonds) may involve larger price swings and greater potential for loss than other types of investments. These risks may be even greater in the case of smaller capitalization stocks.\\n\\nInvesting outside the United States \\u2014 Securities of issuers domiciled outside the United States, or with significant operations or revenues outside the United States, may lose value because of adverse political, social, economic or market developments (including social instability, regional conflicts, terrorism and war) in the countries or regions in which the issuers operate or generate revenue. These securities may also lose value due to changes in foreign currency exchange rates against the U.S. dollar and/or currencies of other countries. Issuers of these securities may be more susceptible to actions of foreign governments, such as the imposition of price controls or punitive taxes, that could adversely impact the value of these securities. Securities markets in certain countries may be more volatile and/or less liquid than those in the United States. Investments outside the United States may also be subject to different accounting practices and different regulatory, legal and reporting standards and practices, and may be more difficult to value, than those in the United States. In addition, the value of investments outside the United States may be reduced by foreign taxes, including foreign withholding taxes on interest and dividends. Further, there may be increased risks of delayed settlement of securities purchased or sold by the fund. The risks of investing outside the United States may be heightened in connection with investments in emerging markets.\\n\\nManagement \\u2014 The investment adviser to the fund actively manages the fund\\u2019s investments. Consequently, the fund is subject to the risk that the methods and analyses employed by the investment adviser in this process may not produce the desired results. This could cause the fund to lose value or its investment results to lag relevant benchmarks or other funds with similar objectives.\\n\\nYour investment in the fund is not a bank deposit and is not insured or guaranteed by the Federal Deposit Insurance Corporation or any other governmental agency, entity or person. You should consider how this fund fits into your overall investment program.\\n\\nAmerican Funds Insurance Series / Prospectus     8\\n\\n\\n \\n \\n \\n\\nInvestment results The following bar chart shows how the investment results of the Class 1 shares of the fund have varied from year to year, and the following table shows how the fund\\u2019s average annual total returns for various periods compare with a broad measure of securities market results and other applicable measures of market results. This information provides some indication of the risks of investing in the fund. The Lipper Growth Funds Index and the Lipper Capital Appreciation Funds Index include mutual funds that disclose investment objectives and/or strategies reasonably comparable to those of the fund. Past investment results (before and after taxes) are not predictive of future investment results. Figures shown reflect fees and expenses associated with an investment in the fund, but do not reflect insurance contract fees and expenses. If insurance contract fees and expenses were included, results would have been lower. Updated information on the fund\\u2019s investment results can be obtained by visiting americanfunds.com/afis.\\n\\n\\n\\n \\n\\n \\t \\t \\t \\t \\nAverage annual total returns For the periods ended December 31, 2017:\\t1 year\\t5 years\\t10 years\\tLifetime\\nFund (inception date \\u2014 2/8/84)\\t28.62%\\t16.50%\\t8.56%\\t12.83%\\nS&P 500 Index (reflects no deduction for sales charges, account fees, expenses or U.S. federal income taxes)\\t21.83\\t15.79\\t8.50\\t11.41\\nLipper Growth Funds Index (reflects no deduction for sales charges, account fees or U.S. federal income taxes)\\t27.51\\t15.93\\t8.02\\t9.81\\nLipper Capital Appreciation Funds Index (reflects no deduction for sales charges, account fees or U.S. federal income taxes)\\t23.60\\t14.22\\t7.48\\t9.77\\nManagement\\n\\nInvestment adviser Capital Research and Management CompanySM\\nPortfolio managers The individuals primarily responsible for the portfolio management of the fund are:\\n\\n \\t \\t \\nPortfolio manager/\\nSeries title (if applicable)\\tPortfolio manager\\nexperience in this fund\\tPrimary title\\nwith investment adviser\\nMark L. Casey\\t1 year\\tPartner \\u2013 Capital World Investors\\nMichael T. Kerr\\t13 years\\tPartner \\u2013 Capital World Investors\\nAndraz Razen\\t5 years\\tPartner \\u2013 Capital World Investors\\nMartin Romo\\t2 years\\tPartner \\u2013 Capital World Investors\\nAlan J. Wilson\\t4 years\\tPartner \\u2013 Capital World Investors\\n \\n \\nTax information See your variable insurance contract prospectus for information regarding the federal income tax treatment of your variable insurance contract and related distributions.\\n\\nPayments to broker-dealers and other financial intermediaries If you purchase shares of the fund through a broker-dealer or other financial intermediary (such as an insurance company), the fund and the fund\\u2019s distributor or its affiliates may pay the intermediary for the sale of fund shares and related services. These payments may create a conflict of interest by influencing the broker-dealer or other intermediary and your individual financial advisor to recommend the fund over another investment. Ask your individual financial advisor or visit your financial intermediary\\u2019s website for more information. The fund is not sold directly to the general public but instead is offered as an underlying investment option for variable insurance contracts. In addition to payments described above, the fund and its related companies may make payments to the sponsoring insurance company (or its affiliates) for distribution and/or other services. These payments may be a factor that the insurance company considers in including the fund as an underlying investment option in the variable insurance contract. The prospectus (or other offering document) for your variable insurance contract may contain additional information about these payments.GROWTH FUND\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "X_test_final_bert_v0['summary'] = X_test_new['summary']\n",
        "X_test_final_bert_v0 = X_test_final_bert_v0.drop(columns= [\"Max Similarity\", \"Mean Similarity\"])\n",
        "X_test_final_bert_v0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_val_final_bert_v0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "_r2uZ3SwXap7",
        "outputId": "918c9ca1-cd4e-4d8e-8ac0-c4c2079178db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Leverage?  Portfolio composition   Concentration  \\\n",
              "56         0.0                    0.0             0.0   \n",
              "181        0.0                    1.0             0.0   \n",
              "329        1.0                    2.0             0.0   \n",
              "271        0.0                    1.0             0.0   \n",
              "31         0.0                    2.0             0.0   \n",
              "..         ...                    ...             ...   \n",
              "438        1.0                    2.0             0.0   \n",
              "17         0.0                    2.0             0.0   \n",
              "427        1.0                    2.0             0.0   \n",
              "195        1.0                    2.0             0.0   \n",
              "57         1.0                    1.0             0.0   \n",
              "\n",
              "                                               summary  \n",
              "56   American Funds 2060 Target Date Retirement Fun...  \n",
              "181  Janus Henderson Triton Fund\\n(closed to certai...  \n",
              "329  Fund Summary\\n\\nFund/Class:\\nFidelity Freedom®...  \n",
              "271  Ivy Global Growth Fund\\n\\nObjective\\n\\nTo seek...  \n",
              "31   American Funds Global Growth Portfolio\\n\\nInve...  \n",
              "..                                                 ...  \n",
              "438  INVESTMENT OBJECTIVE\\nThe USAA Cornerstone Mod...  \n",
              "17   Global Growth and Income Fund\\n\\nInvestment ob...  \n",
              "427  Fund Summary\\n\\nInvestment Objective\\nThe fund...  \n",
              "195  SUMMARY OF COLUMBIA VP – GLOBAL BOND FUND\\nInv...  \n",
              "57   Fund Summary\\n\\nInvestment Objective\\nThe fund...  \n",
              "\n",
              "[93 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-899f137e-b365-4907-9bb9-4d83d5e8f752\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Leverage?</th>\n",
              "      <th>Portfolio composition</th>\n",
              "      <th>Concentration</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>American Funds 2060 Target Date Retirement Fun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Janus Henderson Triton Fund\\n(closed to certai...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>329</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Fund Summary\\n\\nFund/Class:\\nFidelity Freedom®...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Ivy Global Growth Fund\\n\\nObjective\\n\\nTo seek...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>American Funds Global Growth Portfolio\\n\\nInve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>INVESTMENT OBJECTIVE\\nThe USAA Cornerstone Mod...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Global Growth and Income Fund\\n\\nInvestment ob...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>427</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Fund Summary\\n\\nInvestment Objective\\nThe fund...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>SUMMARY OF COLUMBIA VP – GLOBAL BOND FUND\\nInv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Fund Summary\\n\\nInvestment Objective\\nThe fund...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>93 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-899f137e-b365-4907-9bb9-4d83d5e8f752')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-899f137e-b365-4907-9bb9-4d83d5e8f752 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-899f137e-b365-4907-9bb9-4d83d5e8f752');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0293da48-5621-44ea-8e6b-77a5f3f48a54\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0293da48-5621-44ea-8e6b-77a5f3f48a54')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0293da48-5621-44ea-8e6b-77a5f3f48a54 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_val_final_bert_v0",
              "summary": "{\n  \"name\": \"X_val_final_bert_v0\",\n  \"rows\": 93,\n  \"fields\": [\n    {\n      \"column\": \"Leverage?\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.49423984539688176,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Portfolio composition\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7979637479594567,\n        \"min\": 0.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" Concentration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.33705264882291225,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 93,\n        \"samples\": [\n          \"Franklin FTSE China ETF\\n\\nInvestment Goal\\n\\nTo seek to provide investment results that closely correspond, before fees and expenses, to the performance of the FTSE China RIC Capped Index (the FTSE China Capped Index).\\n\\nFees and Expenses of the Fund\\n\\nThe following table describes the fees and expenses that you will incur if you own shares of the Fund. You may also incur usual and customary brokerage commissions when buying or selling shares of the Fund, which are not reflected in the Example that follows.\\n\\n\\nAnnual Fund Operating Expenses\\n\\n(expenses that you pay each year as a percentage of the value of your investment)\\n\\nManagement fees \\t0.19% \\nDistribution and service (12b-1) fees \\tNone \\nOther expenses1 \\tNone \\nTotal annual Fund operating expenses \\t0.19% \\n1. Other expenses are based on estimated amounts for the current fiscal year.\\n\\nExample\\n\\nThis Example is intended to help you compare the cost of investing in the Fund with the cost of investing in other funds. The Example assumes that you invest $10,000 in the Fund for the time periods indicated and then redeem all of your shares at the end of the period. The Example also assumes that your investment has a 5% return each year and that the Fund's operating expenses remain the same. Although your actual costs may be higher or lower, based on these assumptions your costs would be:\\n\\n   \\t1 Year \\t3 Years \\n   \\t$ 19 \\t$ 61 \\nPortfolio Turnover\\n\\nThe Fund pays transaction costs, such as commissions, when it buys and sells securities (or \\\"turns over\\\" its portfolio). A higher portfolio turnover rate may indicate higher transaction costs and may result in higher taxes when Fund shares are held in a taxable account. These costs, which are not reflected in annual Fund operating expenses or in the Example, affect the Fund's performance. During the Fund's first fiscal period (November 2, 2017 to March 31, 2018), the Fund's portfolio turnover rate was 2.71% of the average value of its portfolio.\\n\\nPrincipal Investment Strategies\\n\\nUnder normal market conditions, the Fund invests at least 80% of its assets in the component securities of the FTSE China Capped Index and in depositary receipts representing such securities. The FTSE China Capped Index is a free float-adjusted market capitalization weighted index maintained and calculated by FTSE Russell with a capping methodology applied quarterly to issuer weights so that no single issuer of a component exceeds 25% of the FTSE China Capped Index weight, and all issuers with weights above 5% do not cumulatively exceed 50% of the FTSE China Capped Index\\u2019s weight. The FTSE China Capped Index is based on the FTSE China Index and is designed to measure the performance of Chinese large- and mid-capitalization stocks, as represented by H-Shares (securities of companies incorporated in the People\\u2019s Republic of China (PRC) that are denominated in Hong Kong dollars and listed on the Hong Kong Exchange) and B-Shares (securities of companies incorporated in the PRC and listed for foreign investment on either the Shanghai or Shenzhen stock exchanges). The FTSE China Capped Index also includes certain securities listed outside of the PRC known as N-Shares (issued by companies incorporated in certain foreign jurisdictions, which are controlled, directly or indirectly, by entities, companies or individuals in the PRC, derive substantial revenues or allocate substantial assets in the PRC and are listed on the New York Stock Exchange, NASDAQ or the NYSE MKT), Red-Chips (issued by companies incorporated in certain foreign jurisdictions, which are controlled, directly or indirectly, by entities owned by the national government or local governments in the PRC, derive substantial revenues or allocate substantial assets in the PRC and are listed on the Hong Kong Exchange), P-Chips (issued by companies incorporated in certain foreign jurisdictions, which are controlled, directly or indirectly, by individuals in the PRC, derive substantial revenues or allocate substantial assets in the PRC and are listed on the Hong Kong Exchange) and S-Chips (issued by companies incorporated in certain foreign jurisdictions, which are controlled, directly or indirectly, by entities, companies or individuals in the PRC, derive substantial revenues or allocate substantial assets in the PRC and are listed on the Singapore Exchange). FTSE Russell determines eligible securities for the FTSE China Capped Index based on measures such as the company\\u2019s place of incorporation, quality of investor protection, tax domicile, location of headquarters/factors of production and currency of denomination. As of June 29, 2018, the FTSE China Capped Index was comprised of 262 securities with capitalizations ranging from $89 million to $285.69 billion.\\n\\nThe Fund, using a \\u201cpassive\\u201d or indexing investment approach, seeks investment results that closely correspond, before fees and expenses, to the performance of the FTSE China Capped Index. The investment manager seeks to achieve, over time, a correlation between the Fund\\u2019s performance, before fees and expenses, and that of the FTSE China Capped Index of 0.95 or better. A figure of 1.00 would indicate perfect correlation. The Fund\\u2019s intention is to replicate the component securities of the FTSE China Capped Index as closely as possible (i.e., invest in all of the component securities in their respective weightings in the FTSE China Capped Index). However, under various circumstances, it may not be possible or practicable to replicate the FTSE China Capped Index. In these circumstances, the Fund may use a \\u201crepresentative sampling\\u201d strategy whereby the Fund would invest in what it believes to be a representative sample of the component securities of the FTSE China Capped Index, but may not track the FTSE China Capped Index with the same degree of accuracy as would an investment vehicle replicating the entire FTSE China Capped Index. Under the representative sampling technique, the investment manager will select securities that collectively have an investment profile similar to that of the FTSE China Capped Index, including securities that resemble those included in the FTSE China Capped Index in terms of risk factors, performance attributes and other characteristics, such as market capitalization and industry weightings.\\n\\nThe Fund is a \\\"non-diversified\\\" fund, which means it generally invests a greater proportion of its assets in the securities of one or more issuers and invests overall in a smaller number of issuers than a diversified fund.\\n\\nThe Fund will concentrate its investments (i.e., hold 25% or more of its net assets) in a particular industry or group of industries to approximately the same extent that the FTSE China Capped Index is concentrated. As of June 29, 2018, the FTSE China Capped Index was concentrated in the internet software and services industry.\\n\\nPrincipal Risks\\n\\nYou could lose money by investing in the Fund. Exchange-traded fund (ETF) shares are not deposits or obligations of, or guaranteed or endorsed by, any bank, and are not insured by the Federal Deposit Insurance Corporation, the Federal Reserve Board, or any other agency of the U.S. government. The Fund is subject to the principal risks noted below, any of which may adversely affect the Fund\\u2019s net asset value (NAV), trading price, yield, total return and ability to meet its investment goal.\\n\\nMarket   The market values of securities or other investments owned by the Fund will go up or down, sometimes rapidly or unpredictably. The market value of a security or other investment may be reduced by market activity or other results of supply and demand unrelated to the issuer. This is a basic risk associated with all investments. When there are more sellers than buyers, prices tend to fall. Likewise, when there are more buyers than sellers, prices tend to rise.\\n\\nStock prices tend to go up and down more dramatically than those of debt securities. A slower-growth or recessionary economic environment could have an adverse effect on the prices of the various stocks held by the Fund.\\n\\nForeign Securities (non-U.S.)   Investing in foreign securities typically involves more risks than investing in U.S. securities, and includes risks associated with: (i) internal and external political and economic developments \\u2013 e.g., the political, economic and social policies and structures of some foreign countries may be less stable and more volatile than those in the U.S. or some foreign countries may be subject to trading restrictions or economic sanctions; (ii) trading practices \\u2013 e.g., government supervision and regulation of foreign securities and currency markets, trading systems and brokers may be less than in the U.S.; (iii) availability of information \\u2013 e.g., foreign issuers may not be subject to the same disclosure, accounting and financial reporting standards and practices as U.S. issuers; (iv) limited markets \\u2013 e.g., the securities of certain foreign issuers may be less liquid (harder to sell) and more volatile; and (v) currency exchange rate fluctuations and policies (e.g., fluctuations may negatively affect investments denominated in foreign currencies and any income received or expenses paid by the Fund in that foreign currency). The risks of foreign investments may be greater in developing or emerging market countries.\\n\\nEmerging Market Countries   The Fund\\u2019s investments in emerging market issuers are subject to all of the risks of foreign investing generally, and have additional heightened risks due to a lack of established legal, political, business and social frameworks to support securities markets, including: delays in settling portfolio securities transactions; currency and capital controls; greater sensitivity to interest rate changes; pervasiveness of corruption and crime; currency exchange rate volatility; and inflation, deflation or currency devaluation.\\n\\nGeographic Focus   Because the Fund invests its assets primarily in companies in a specific country and region, the Fund is subject to greater risks of adverse developments in that country, region and/or the surrounding regions than a fund that is more broadly diversified geographically. Political, social or economic disruptions in the country or region, even in countries in which the Fund is not invested, may adversely affect the value of investments held by the Fund.\\n\\nThere are special risks associated with investments in China, including exposure to currency fluctuations, less liquidity, expropriation, confiscatory taxation, nationalization and exchange control regulations (including currency blockage). Inflation and rapid fluctuations in inflation and interest rates have had, and may continue to have, negative effects on the economy and securities markets of China. China is deemed by the investment manager to be an emerging markets country, which means an investment in this country has more heightened risks than general foreign investing due to a lack of established legal, political, business and social frameworks in the country to support securities markets as well as the possibility for more widespread corruption and fraud.\\n\\nDepositary Receipts   Depositary receipts are subject to many of the risks of the underlying securities. For some depositary receipts, the custodian or similar financial institution that holds the issuer's shares in a trust account is located in the issuer's home country. In these cases if the issuer\\u2019s home country does not have developed financial markets, the Fund could be exposed to the credit risk of the custodian or financial institution and greater market risk. In addition, the depository institution may not have physical custody of the underlying securities at all times and may charge fees for various services. The Fund may experience delays in receiving its dividend and interest payments or exercising rights as a shareholder. There may be an increased possibility of untimely responses to certain corporate actions of the issuer in an unsponsored depositary receipt program. Accordingly, there may be less information available regarding issuers of securities underlying unsponsored programs and there may not be a correlation between this information and the market value of the depositary receipts.\\n\\nCalculation Methodology   FTSE Russell relies on various sources of information to assess the criteria of issuers included in the FTSE China Capped Index, including information that may be based on assumptions and estimates. Neither the Fund nor the investment manager can offer assurances that FTSE Russell\\u2019s calculation methodology or sources of information will provide an accurate assessment of included issuers or that the included issuers will provide the Fund with the market exposure it seeks.\\n\\nIndex-Related   There is no assurance that the FTSE China Capped Index will be determined, composed or calculated accurately. While FTSE Russell provides descriptions of what the FTSE China Capped Index is designed to achieve, FTSE Russell does not guarantee the quality, accuracy or completeness of data in respect of its indices, and does not guarantee that the FTSE China Capped Index will be in line with the described index methodology. Gains, losses or costs to the Fund caused by errors in the FTSE China Capped Index may therefore be borne by the Fund and its shareholders.\\n\\nNon-Correlation   There is no guarantee that the Fund will achieve a high degree of correlation to the FTSE China Capped Index and therefore achieve its investment goal. Market disruptions and regulatory restrictions could have an adverse effect on the Fund\\u2019s ability to adjust its exposure to the required levels in order to track the FTSE China Capped Index. In addition, the Fund\\u2019s NAV may deviate from the FTSE China Capped Index if the Fund fair values a portfolio security at a price other than the price used by the FTSE China Capped Index for that security. To the extent that the investment manager uses a representative sampling strategy, the Fund may not track the return of the FTSE China Capped Index as well as it would have if the Fund held all of the securities in the FTSE China Capped Index.\\n\\nTracking Error   Tracking error is the divergence of the Fund\\u2019s performance from that of the FTSE China Capped Index. Tracking error may occur because of differences between the securities held in the Fund\\u2019s portfolio and those included in the FTSE China Capped Index, pricing differences (including differences between a security\\u2019s price at the local market close and the Fund\\u2019s valuation of a security at the time of calculation of the Fund\\u2019s NAV), transaction costs, the Fund\\u2019s holding of cash, differences in timing of the accrual of dividends or interest, tax gains or losses, changes to the FTSE China Capped Index or the need to meet various new or existing regulatory requirements. This risk may be heightened during times of increased market volatility or other unusual market conditions. Tracking error also may result because the Fund incurs fees and expenses, while the FTSE China Capped Index does not.\\n\\nMarket Trading   The Fund faces numerous market trading risks, including the potential lack of an active market for Fund shares, losses from trading in secondary markets, periods of high volatility and disruption in the creation/redemption process of the Fund. Any of these factors, among others, may lead to the Fund\\u2019s shares trading at a premium or discount to NAV. Thus, you may pay more (or less) than NAV when you buy shares of the Fund in the secondary market, and you may receive less (or more) than NAV when you sell those shares in the secondary market. The investment manager cannot predict whether shares will trade above (premium), below (discount) or at NAV.\\n\\nConcentration   To the extent the Fund concentrates in a specific industry, a group of industries, sector or type of investment, the Fund will carry much greater risks of adverse developments and price movements in such industries, sectors or investments than a fund that invests in a wider variety of industries, sectors or investments. There is also the risk that the Fund will perform poorly during a slump in demand for securities of companies in such industries or sectors.\\n\\nThe Fund may focus in the internet software and services industry. Competitive pressures, such as technological developments, fixed-rate pricing and the ability to attract and retain skilled employees, can significantly affect companies in the internet software and services industry. Changing domestic and international demand, research and development costs, availability and price of components and product obsolescence also can affect profitability of companies in this industry.\\n\\nNon-Diversification   Because the Fund is non-diversified, it may be more sensitive to economic, business, political or other changes affecting individual issuers or investments than a diversified fund, which may result in greater fluctuation in the value of the Fund\\u2019s shares and greater risk of loss.\\n\\nMidsize Companies   Securities issued by midsize companies may be more volatile in price than those of larger companies, involve substantial risks and should be considered speculative. Such risks may include greater sensitivity to economic conditions, less certain growth prospects, lack of depth of management and funds for growth and development, and limited or less developed product lines and markets. In addition, midsize companies may be particularly affected by interest rate increases, as they may find it more difficult to borrow money to continue or expand operations, or may have difficulty in repaying any loans.\\n\\nPassive Investment   Unlike many investment companies, the Fund is not actively managed and the investment manager does not attempt to take defensive positions under any market conditions, including declining markets. Therefore, the investment manager would not necessarily buy or sell a security unless that security is added or removed, respectively, from the FTSE China Capped Index, even if that security generally is underperforming.\\n\\nInternational Closed Market Trading   To the extent that the underlying securities held by the Fund trade on an exchange that is closed when the securities exchange on which the Fund shares list and trade is open, there may be market uncertainty about the stale security pricing (i.e., the last quote from its closed foreign market) resulting in premiums or discounts to NAV that may be greater than those experienced by other ETFs.\\n\\nAuthorized Participant Concentration   Only an authorized participant (Authorized Participant) may engage in creation or redemption transactions directly with the Fund. The Fund has a limited number of institutions that act as Authorized Participants. To the extent that these institutions exit the business or are unable to proceed with creation and/or redemption orders with respect to the Fund and no other Authorized Participant is able to step forward to create or redeem Creation Units (as defined below), Fund shares may trade at a discount to NAV and possibly face trading halts and/or delisting. This risk may be more pronounced in volatile markets, potentially where there are significant redemptions in ETFs generally.\\n\\nCash Transactions   Unlike certain ETFs, the Fund expects to generally effect its creations and redemptions partially for cash, rather than for in-kind securities. Therefore, it may be required to sell portfolio securities and subsequently recognize gains on such sales that the Fund might not have recognized if it were to distribute portfolio securities in-kind. As such, investments in Fund shares may be less tax-efficient than an investment in an ETF that distributes portfolio securities entirely in-kind.\\n\\nPerformance\\n\\nBecause the Fund does not have a full calendar year of performance, annual total return information is not available and therefore is not presented. You can obtain updated performance information at libertyshares.com or by calling (800) DIAL BEN/342-5236. The Fund's past performance (before and after taxes) is not necessarily an indication of how the Fund will perform in the future.\\n\\nInvestment Manager\\n\\nFranklin Advisers, Inc. (Advisers)\\n\\nPortfolio Managers\\n\\nDina Ting, CFA   Portfolio Manager of Advisers and lead portfolio manager of the Fund since inception (2017).\\n\\nLouis Hsu, CFA   Portfolio Manager of Advisers and portfolio manager of the Fund since inception (2017).\\n\\nPurchase and Sale of Fund Shares\\n\\nThe Fund is an ETF. Fund shares may only be purchased and sold on a national securities exchange through a broker-dealer. The price of Fund shares is based on market price, and because ETF shares trade at market prices rather than NAV, shares may trade at a price greater than NAV (a premium) or less than NAV (a discount). The Fund issues or redeems shares that have been aggregated into blocks of 400,000 shares or multiples thereof (Creation Units) to Authorized Participants who have entered into agreements with the Fund\\u2019s distributor, Franklin Templeton Distributors, Inc. The Fund will generally issue or redeem Creation Units in return for a basket of securities (and an amount of cash) that the Fund specifies each day.\\n\\nTaxes\\n\\nThe Fund\\u2019s distributions are generally taxable to you as ordinary income, capital gains, or some combination of both, unless you are investing through a tax-deferred arrangement, such as a 401(k) plan or an individual retirement account, in which case your distributions would generally be taxed when withdrawn from the tax-deferred account.\\n\\nPayments to Broker-Dealers and\\nOther Financial Intermediaries\\n\\nIf you purchase shares of the Fund through a broker-dealer or other financial intermediary (such as a bank), Advisers or other related companies may pay the intermediary for the sale of Fund shares and related services. These payments may create a conflict of interest by influencing the broker-dealer or other intermediary and your salesperson to recommend the Fund over another investment. Ask your salesperson or visit your financial intermediary's website for more information.\",\n          \"Investment Objective\\n\\nThe Fund seeks total return comprised of current income, current gains and capital appreciation.\\n \\n\\n \\n\\nFees and Expenses of the Fund\\n\\nThe tables below describe the fees and expenses that you may pay if you buy and hold shares of the Fund. You may qualify for sales charge discounts if you and your family invest, or agree to invest in the future, at least $50,000 in Class A shares of eligible funds that are part of the family of mutual funds sponsored by Allianz. More information about these and other discounts is available in the \\u201cClasses of Shares\\u201d section beginning on page 98 of the Fund\\u2019s prospectus or from your financial advisor. In addition, if you purchase shares through a specific intermediary, you may be subject to different sales charges including reductions in or waivers of such charges. More information about these intermediary-specific sales charge variations is available in Appendix A to the Fund\\u2019s prospectus (\\u201cIntermediary Sales Charge Discounts and Waivers\\u201d).\\n \\n\\nShareholder Fees (fees paid directly from your investment)\\n\\n \\n\\nShare Class\\t \\t\\nMaximum Sales Charge (Load) Imposed\\n\\non Purchases (as a percentage of offering price)\\n\\n \\t\\nMaximum Contingent Deferred Sales Charge (CDSC) (Load)\\n\\n(as a percentage of the lower of original purchase price or  NAV)(1)\\n\\nClass A\\t \\t5.50%\\t \\t1%\\nClass C\\t \\tNone\\t \\t1%\\nClass T\\t \\t2.50%\\t \\tNone\\nClass R\\t \\tNone\\t \\tNone\\nInstitutional\\t \\tNone\\t \\tNone\\nClass R6\\t \\tNone\\t \\tNone\\nClass P\\t \\tNone\\t \\tNone\\n \\n\\nAnnual Fund Operating Expenses (expenses that you pay each year as a percentage of the value of your investment)\\n\\n \\n\\nShare Class\\t \\t\\nManagement\\n\\nFees\\n\\n \\t\\nDistribution\\n\\nand/or Service\\n\\n(12b-1) Fees\\n\\n \\t\\nOther\\n\\nExpenses\\n\\n \\t\\nTotal Annual\\n\\nFund Operating\\n\\nExpenses\\n\\nClass A\\t \\t1.03%\\t \\t0.25%\\t \\t[    ]%\\t \\t[    ]%\\nClass C\\t \\t1.03\\t \\t1.00\\t \\t[    ]\\t \\t[    ]\\nClass T\\t \\t1.03\\t \\t0.25\\t \\t[    ]\\t \\t[    ]\\nClass R\\t \\t1.03\\t \\t0.50\\t \\t[    ]\\t \\t[    ]\\nInstitutional\\t \\t0.93\\t \\tNone\\t \\t[    ]\\t \\t[    ]\\nClass R6\\t \\t[    ]\\t \\tNone\\t \\t[    ]\\t \\t[    ]\\nClass P\\t \\t1.03\\t \\tNone\\t \\t[    ]\\t \\t[    ]\\n \\t(1)\\t \\t\\nFor Class A shares, the CDSC is imposed only in certain circumstances where shares are purchased without a front-end sales charge at the time of purchase. For Class C shares, the CDSC is imposed only on shares redeemed in the first year.\\n\\n \\n\\nExamples.  The Examples are intended to help you compare the cost of investing in shares of the Fund with the costs of investing in other mutual funds. The Examples assume that you invest $10,000 in the noted class of shares for the time periods indicated, your investment has a 5% return each year, and the Fund\\u2019s operating expenses remain the same. Although your actual costs may be higher or lower, the Examples show what your costs would be based on these assumptions.\\n\\n \\n\\n \\t \\tExample:  Assuming you redeem your shares at the end of each period\\t \\t \\tExample:  Assuming you do not redeem your shares\\t \\nShare Class\\t \\t1 Year\\t \\t \\t3 Years\\t \\t \\t5 Years\\t \\t \\t10 Years\\t \\t \\t1 Year\\t \\t \\t3 Years\\t \\t \\t5 Years\\t \\t \\t10 Years\\t \\nClass A\\t \\t$\\t[    \\t] \\t \\t$\\t[    \\t] \\t \\t$\\t[    \\t] \\t \\t$\\t[    \\t] \\t \\t$\\t[    \\t] \\t \\t$\\t[    \\t] \\t \\t$\\t[    \\t] \\t \\t$\\t[    \\t] \\nClass C\\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\nClass T\\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\nClass R\\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\nInstitutional\\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\nClass R6\\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\nClass P\\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\t \\t \\t[    \\t] \\n \\n\\nPortfolio Turnover.  The Fund pays transaction costs, such as commissions, when it buys and sells securities (or \\u201cturns over\\u201d its portfolio). The Fund\\u2019s portfolio turnover rate for the fiscal year ended June 30, 2018 was [    ]% of the average value of its portfolio. High levels of portfolio turnover may indicate higher transaction costs and may result in higher taxes for you if your Fund shares are held in a taxable account. These costs, which are not reflected in Total Annual Fund Operating Expenses or in the Examples above, can adversely affect the Fund\\u2019s investment performance.\\n\\n \\n\\n \\n\\nPrincipal Investment Strategies\\n\\nThe Fund seeks to achieve its objective by investing primarily in a combination of common stocks and other equity securities, debt securities and convertible securities. The allocation of the Fund\\u2019s investments across asset classes will\\n\\n \\n\\n22\\t \\tAllianz Funds\\nTable of Contents\\nAllianzGI Income & Growth Fund (continued)\\n\\n \\n\\n \\t\\nvary substantially from time to time. The Fund\\u2019s investments in each asset class are based upon the portfolio managers\\u2019 assessment of economic conditions and market factors, including equity price levels, interest rate levels and their anticipated direction. The portfolio managers will select common stocks by utilizing a fundamental, bottom-up research process which facilitates the early identification of issuers demonstrating the ability to improve their fundamental characteristics. It is expected that a substantial portion of the Fund\\u2019s investments in debt securities and convertible securities will be rated below investment grade or unrated and determined to be of similar quality (\\u201chigh-yield securities\\u201d or \\u201cjunk bonds\\u201d). The Fund may invest in issuers of any market capitalization (with a focus on $3 billion and above) and may invest a portion of its assets in non-U.S. securities (including emerging market securities). The Fund also may employ a strategy of writing (selling) call options on the common stocks it holds; such strategy is intended to enhance Fund distributions and reduce overall portfolio risk, though there is no assurance that it will succeed. In addition to equity securities (such as preferred stocks and warrants), the Fund may invest a significant portion of its assets in private placement securities (including Rule 144A securities) and may utilize foreign currency exchange contracts, options, stock index futures contracts and other derivative instruments.\\n\\n \\n\\n \\n\\nPrincipal Risks\\n\\nThe principal risks of investing in the Fund, which could adversely affect its net asset value, yield and total return, are (in alphabetical order after the first seven risks):\\n \\n\\n \\tMarket Risk:  The Fund will be affected by factors influencing the U.S. or global economies and securities markets or relevant industries or sectors within them.\\n \\n\\n \\tIssuer Risk:  The Fund will be affected by factors specific to the issuers of securities and other instruments in which the Fund invests, including actual or perceived changes in the financial condition or business prospects of such issuers.\\n \\n\\n \\tHigh Yield Risk:  High-yield or junk bonds are subject to greater levels of credit and liquidity risk, may be speculative and may decline in value due to increases in interest rates or an issuer\\u2019s deterioration or default.\\n \\n\\n \\tEquity Securities Risk:  Equity securities may react more strongly to changes in an issuer\\u2019s financial condition or prospects than other securities of the same issuer.\\n \\n\\n \\tFixed Income Risk:  Fixed income (debt) securities are subject to greater levels of credit and liquidity risk, may be speculative and may decline in value due to changes in interest rates or an issuer\\u2019s or counterparty\\u2019s deterioration or default.\\n \\n\\n \\tSmaller Company Risk:  Securities issued by smaller companies may be more volatile and present increased liquidity risk relative to securities issued by larger companies.\\n \\n\\n \\tDerivatives Risk:  Derivative instruments are complex, have different characteristics than their underlying assets and are subject to additional risks, including leverage, liquidity and valuation.\\n \\n\\n \\tConvertible Securities Risk:  Convertible securities are subject to greater levels of credit and liquidity risk, may be speculative and may decline in value due to increases in interest rates or an issuer\\u2019s deterioration or default.\\n \\n\\n \\tCredit and Counterparty Risk:  An issuer or counterparty may default on obligations.\\n \\n\\n \\tCurrency Risk:  The values of non-U.S. securities may fluctuate with currency exchange rates and exposure to non-U.S. currencies may subject the Fund to the risk that those currencies will decline in value relative to the U.S. dollar.\\n \\n\\n \\tEmerging Markets Risk:  Non-U.S. investment risk may be particularly high to the extent that the Fund invests in emerging market securities. These securities may present market, credit, currency, liquidity, legal, political, technical and other risks different from, or greater than, the risks of investing in developed countries.\\n \\n\\n \\tFocused Investment Risk:  Focusing on a limited number of issuers, sectors, industries or geographic regions increases risk and volatility.\\n \\n\\n \\tInterest Rate Risk:  Fixed income securities may decline in value because of increases in interest rates.\\n \\n\\n \\tLeveraging Risk:  Instruments and transactions that constitute leverage magnify gains or losses and increase volatility.\\n \\n\\n \\tLiquidity Risk:  The lack of an active market for investments may cause delay in disposition or force a sale below fair value.\\n \\n\\n \\tManagement Risk:  The Fund will be affected by the allocation determinations, investment decisions and techniques of the Fund\\u2019s management.\\n \\n\\n \\tNon-U.S. Investment Risk:  Non-U.S. securities markets and issuers may be more volatile, smaller, less liquid, less transparent and subject to less oversight, particularly in emerging markets.\\n \\n\\n \\tTurnover Risk:  High levels of portfolio turnover increase transaction costs and taxes and may lower investment performance.\\n \\n\\nProspectus\\t \\t \\t23\\t \\nTable of Contents\\nAllianzGI Income & Growth Fund (continued)\\n\\n \\n\\nPlease see \\u201cSummary of Principal Risks\\u201d in the Fund\\u2019s prospectus for a more detailed description of the Fund\\u2019s risks. It is possible to lose money on an investment in the Fund. An investment in the Fund is not a deposit of a bank and is not insured or guaranteed by the Federal Deposit Insurance Corporation or any other government agency.\\n\\n \\n\\n \\n\\nPerformance Information\\n\\nThe performance information below provides some indication of the risks of investing in the Fund by showing changes in its total return from year to year and by comparing the Fund\\u2019s average annual total returns with those of two broad-based market indexes and a performance average of similar mutual funds. The bar chart and the information to its right show performance of the Fund\\u2019s Class A shares, but do not reflect the impact of sales charges (loads). If they did, returns would be lower than those shown. Other share classes would have different performance due to the different expenses they bear. Performance in the Average Annual Total Returns table reflects the impact of sales charges. For periods prior to the inception date of a share class, performance information shown for such class may be based on the performance of an older class of shares that dates back to the Fund\\u2019s inception, as adjusted to reflect fees and expenses paid by the newer class. These adjustments generally result in estimated performance results for the newer class that are different from the actual results of the predecessor class, due to differing levels of fees and expenses paid. Details regarding the calculation of the Fund\\u2019s class-by-class performance, including a discussion of any performance adjustments, are provided under \\u201cAdditional Performance Information\\u201d in the Fund\\u2019s prospectus and SAI. Past performance, before and after taxes, is not necessarily predictive of future performance. Visit us.allianzgi.com for more current performance information.\\n \\n\\nCalendar Year Total Returns \\u2014 Class A\\n\\nLOGO\\n\\nMore Recent Return Information\\t \\n1/1/18\\u20136/30/18\\t \\t \\t[    ]%\\t \\n[Highest and Lowest Quarter Returns]\\t \\n(for periods shown in the bar chart)\\t \\nHighest 04/01/2009\\u201306/30/2009\\t \\t \\t18.45%\\t \\nLowest 10/01/2008\\u201312/31/2008\\t \\t \\t-20.58%\\t \\n \\nAverage Annual Total Returns (for periods ended 12/31/17)\\n\\n \\n\\n  \\t \\t1 Year\\t \\t \\t5 Years\\t \\t \\t10 Year\\t \\t \\tFund Inception\\n(2/28/07)\\t \\nClass A \\u2014 Before Taxes\\n\\n \\t \\t7.21\\t% \\t \\t \\t7.39\\t% \\t \\t \\t6.10\\t% \\t \\t \\t6.48\\t% \\nClass A \\u2014 After Taxes on Distributions\\n\\n \\t \\t3.28\\t% \\t \\t \\t3.47\\t% \\t \\t \\t2.36\\t% \\t \\t \\t2.79\\t% \\nClass A \\u2014After Taxes on Distributions and Sale of Fund Shares\\n\\n \\t \\t3.96\\t% \\t \\t \\t3.81\\t% \\t \\t \\t2.91\\t% \\t \\t \\t3.27\\t% \\nClass C \\u2014 Before Taxes\\n\\n \\t \\t11.63\\t% \\t \\t \\t7.80\\t% \\t \\t \\t5.91\\t% \\t \\t \\t6.24\\t% \\nClass R \\u2014 Before Taxes\\n\\n \\t \\t13.17\\t% \\t \\t \\t8.33\\t% \\t \\t \\t6.44\\t% \\t \\t \\t6.78\\t% \\nInstitutional Class \\u2014 Before Taxes\\n\\n \\t \\t13.87\\t% \\t \\t \\t8.98\\t% \\t \\t \\t7.08\\t% \\t \\t \\t7.42\\t% \\nClass R6 \\u2014 Before Taxes\\n\\n \\t \\t\\u2014\\t \\t \\t \\t\\u2014\\t \\t \\t \\t\\u2014\\t \\t \\t \\t\\u2014\\t \\nClass P \\u2014 Before Taxes\\n\\n \\t \\t13.79\\t% \\t \\t \\t8.88\\t% \\t \\t \\t6.98\\t% \\t \\t \\t7.32\\t% \\nClass T \\u2014 Before Taxes\\n\\n \\t \\t10.62\\t% \\t \\t \\t8.07\\t% \\t \\t \\t6.43\\t% \\t \\t \\t6.79\\t% \\nBloomberg Barclays U.S. Aggregate Bond Index (reflects no deduction for fees, expenses or taxes)\\n\\n \\t \\t3.54\\t% \\t \\t \\t2.10\\t% \\t \\t \\t4.01\\t% \\t \\t \\t4.19\\t% \\nS&P 500 Index (reflects no deduction for fees, expenses or taxes)\\n\\n \\t \\t21.83\\t% \\t \\t \\t15.79\\t% \\t \\t \\t8.50\\t% \\t \\t \\t8.39\\t% \\nLipper Flexible Portfolio Funds Average\\n\\n \\t \\t12.73\\t% \\t \\t \\t6.18\\t% \\t \\t \\t4.43\\t% \\t \\t \\t4.91\\t% \\n \\n\\nAfter-tax returns are estimated using the highest historical individual federal marginal income tax rates and do not reflect the impact of state and local taxes. Actual after-tax returns depend on an investor\\u2019s tax situation and may differ from those shown. After-tax returns are not relevant to investors who hold Fund shares through tax-advantaged arrangements such as 401(k) plans or individual retirement accounts. In some cases the return after taxes may exceed the return before taxes due to an assumed tax benefit from any losses on a sale of Fund shares at the end of the measurement period. After-tax returns are for Class A shares only. After-tax returns for other share classes will vary.\\n\\n \\n\\n24\\t \\tAllianz Funds\\nTable of Contents\\nAllianzGI Income & Growth Fund (continued)\\n\\n \\n\\n \\n\\nManagement of the Fund \\n\\nInvestment Adviser and Administrator  Allianz Global Investors U.S. LLC (\\u201cAllianzGI U.S.\\u201d)\\n \\n\\nPortfolio Managers\\n\\nDouglas G. Forsyth, CFA, portfolio manager, managing director and CIO US Income & Growth Strategies, has managed the Fund since 2007.\\n\\n \\n\\nMichael E. Yee, portfolio manager and managing director, has managed the Fund since 2007.\\n\\n \\n\\nJustin Kass, CFA, portfolio manager and managing director, has managed the Fund since 2007.\\n\\n \\n\\nPurchase and Sale of Fund Shares\\n\\nYou may purchase or sell (redeem) shares of the Fund on any business day through a broker, dealer, or other financial intermediary (for Class T shares, such intermediary must have an agreement with the Distributor to sell Class T shares), or directly from the Fund\\u2019s transfer agent by mail (Allianz Global Investors Distributors LLC, P.O. Box 8050, Boston, MA 02266-8050) for Class A, Class C and Class R shares, or directly from the Fund\\u2019s transfer agent by mail (Allianz Institutional Funds, P.O. Box 219968, Kansas City, MO 64121-9968) for Institutional Class, Class R6 and Class P shares, or as further described in the Fund\\u2019s prospectus and SAI. Additionally, certain direct shareholders may be able to purchase or redeem shares of the Fund online by visiting our website, us.allianzgi.com, clicking on the \\u201cAccount Access\\u201d link at the top of that webpage, and following instructions. Some restrictions may apply. To avoid delays in a purchase or redemption, please call 1-800-988-8380 for Class A, Class C, Class T and Class R shares and 1-800-498-5413 for Institutional Class, Class R6 and Class P shares with any questions about the requirements before submitting a request. Generally, purchase and redemption orders for Fund shares are processed at the net asset value (NAV) next calculated after an order is received by the distributor or an authorized intermediary. NAVs are determined only on days when the New York Stock Exchange is open for regular trading. For Class A, Class C and Class T shares, the minimum initial investment in the Fund is $1,000 and the minimum subsequent investment is $50. For Class R shares, specified benefit plans may establish various minimum investment and account size requirements; ask your plan administrator for more information. For Institutional Class and Class P shares, the minimum initial investment in the Fund is $1 million and no minimum is needed to add to an existing account, though minimums may be modified for certain financial intermediaries that aggregate trades on behalf of investors. For Class R6 shares, there is no minimum initial investment and no minimum is needed to add to an existing account for specified benefit plans and other eligible investors.\\n \\n\\nTax Information\\n\\nThe Fund\\u2019s distributions are generally taxable to you as ordinary income or capital gains, unless you are investing through a tax-advantaged arrangement, such as a 401(k) plan or an individual retirement account.\\n \\n\\nPayments to Broker-Dealers and Other Financial Intermediaries\\n\\nIf you purchase shares of the Fund through a broker-dealer or other financial intermediary (such as a bank), the Fund, its distributor, its investment adviser or their affiliates may pay the intermediary for the sale of Fund shares and related services. These payments may create a conflict of interest by influencing the broker-dealer or intermediary and your salesperson to recommend the Fund over another investment. Ask your salesperson or visit your financial intermediary\\u2019s Web site for more information.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentence BERT"
      ],
      "metadata": {
        "id": "q2ehI8VD_ZPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def get_bert_embeddings(texts):\n",
        "    # Tokenize and pad texts\n",
        "    encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "    # Get embeddings\n",
        "    with torch.no_grad():\n",
        "        model_output = model(**encoded_input)\n",
        "\n",
        "    # Mean pool the token embeddings to get the text representation\n",
        "    embeddings = model_output.last_hidden_state.mean(dim=1)\n",
        "    return embeddings.numpy()\n",
        "\n",
        "# Apply the function to the summaries and knowledge base texts\n",
        "summaries_list = X_val_final_bert_v0['summary'].astype(str).tolist()\n",
        "bert_summaries = get_bert_embeddings(summaries_list)\n",
        "print(\"success\")\n",
        "bert_kb_entries = get_bert_embeddings(knowledge_base)\n",
        "\n",
        "similarity_matrix = cosine_similarity(bert_summaries, bert_kb_entries)\n",
        "\n",
        "# Feature engineering\n",
        "max_similarity = np.max(similarity_matrix, axis=1)\n",
        "mean_similarity = np.mean(similarity_matrix, axis=1)\n",
        "\n",
        "# Combine features for X_test\n",
        "X_val_features = np.column_stack((max_similarity, mean_similarity))\n",
        "X_val_combined = np.hstack((X_val_final_bert_v0.values, X_val_features))\n",
        "X_val_final_bert_v1 = pd.DataFrame(X_val_combined, columns=list(X_val_final_bert_v0.columns) + ['Max Similarity', 'Mean Similarity'])\n",
        "X_val_final_bert_v1.index = X_val_final_bert_v0.index\n",
        "X_val_final_bert_v1 = X_val_final_bert_v1.drop(columns = 'summary')\n",
        "X_val_final_bert_v1.head()\n",
        "print(X_val_final_bert_v1)\n",
        "\n",
        "\n",
        "# Apply the function to the summaries and knowledge base texts\n",
        "summaries_list = X_test_final_bert_v0['summary'].astype(str).tolist()\n",
        "bert_summaries = get_bert_embeddings(summaries_list)\n",
        "bert_kb_entries = get_bert_embeddings(knowledge_base)\n",
        "\n",
        "similarity_matrix = cosine_similarity(bert_summaries, bert_kb_entries)\n",
        "\n",
        "# Feature engineering\n",
        "max_similarity = np.max(similarity_matrix, axis=1)\n",
        "mean_similarity = np.mean(similarity_matrix, axis=1)\n",
        "\n",
        "# Combine features for X_test\n",
        "X_test_features = np.column_stack((max_similarity, mean_similarity))\n",
        "X_test_combined = np.hstack((X_test_final_bert_v0.values, X_test_features))\n",
        "X_test_final_bert_v1 = pd.DataFrame(X_test_combined, columns=list(X_test_final_bert_v0.columns) + ['Max Similarity', 'Mean Similarity'])\n",
        "X_test_final_bert_v1.index = X_test_final_bert_v0.index\n",
        "X_test_final_bert_v1 = X_test_final_bert_v1.drop(columns = 'summary')\n",
        "X_test_final_bert_v1.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "id": "VRFNFMtj63B4",
        "outputId": "3c9028b6-ce87-430a-b39b-f74660a66bd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning:\n",
            "\n",
            "\n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "success\n",
            "    Leverage? Portfolio composition  Concentration Max Similarity  \\\n",
            "56        0.0                   0.0            0.0       0.517075   \n",
            "181       0.0                   1.0            0.0       0.505877   \n",
            "329       1.0                   2.0            0.0       0.495611   \n",
            "271       0.0                   1.0            0.0       0.509351   \n",
            "31        0.0                   2.0            0.0       0.528082   \n",
            "..        ...                   ...            ...            ...   \n",
            "438       1.0                   2.0            0.0       0.522941   \n",
            "17        0.0                   2.0            0.0        0.49072   \n",
            "427       1.0                   2.0            0.0       0.542177   \n",
            "195       1.0                   2.0            0.0       0.520733   \n",
            "57        1.0                   1.0            0.0        0.51173   \n",
            "\n",
            "    Mean Similarity  \n",
            "56          0.32213  \n",
            "181        0.321849  \n",
            "329        0.321709  \n",
            "271        0.300371  \n",
            "31         0.300714  \n",
            "..              ...  \n",
            "438         0.30832  \n",
            "17         0.314474  \n",
            "427        0.330219  \n",
            "195        0.301487  \n",
            "57         0.325383  \n",
            "\n",
            "[93 rows x 5 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Leverage? Portfolio composition  Concentration Max Similarity  \\\n",
              "324       0.0                   1.0            0.0       0.488102   \n",
              "448       0.0                   1.0            0.0       0.525775   \n",
              "298       0.0                   2.0            0.0       0.519184   \n",
              "410       0.0                   2.0            0.0       0.477807   \n",
              "22        0.0                   2.0            0.0       0.490794   \n",
              "\n",
              "    Mean Similarity  \n",
              "324        0.328051  \n",
              "448        0.296721  \n",
              "298        0.325215  \n",
              "410        0.315914  \n",
              "22         0.314899  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-657e2adb-08ba-46a0-8c0e-1f5d583a8e6d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Leverage?</th>\n",
              "      <th>Portfolio composition</th>\n",
              "      <th>Concentration</th>\n",
              "      <th>Max Similarity</th>\n",
              "      <th>Mean Similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>324</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.488102</td>\n",
              "      <td>0.328051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.525775</td>\n",
              "      <td>0.296721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.519184</td>\n",
              "      <td>0.325215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>410</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.477807</td>\n",
              "      <td>0.315914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.490794</td>\n",
              "      <td>0.314899</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-657e2adb-08ba-46a0-8c0e-1f5d583a8e6d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-657e2adb-08ba-46a0-8c0e-1f5d583a8e6d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-657e2adb-08ba-46a0-8c0e-1f5d583a8e6d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-86ddd405-b8a5-4ecf-8b70-906129ac5c78\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-86ddd405-b8a5-4ecf-8b70-906129ac5c78')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-86ddd405-b8a5-4ecf-8b70-906129ac5c78 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_test_final_bert_v1",
              "repr_error": "0"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_convert = ['Leverage?', 'Portfolio composition', ' Concentration', 'Max Similarity', 'Mean Similarity']\n",
        "for col in columns_to_convert:\n",
        "    X_val_final_bert_v1[col] = pd.to_numeric(X_val_final_bert_v1[col], errors='coerce')\n",
        "\n",
        "print(X_val_final_bert_v1.dtypes)\n",
        "\n",
        "columns_to_convert = ['Leverage?', 'Portfolio composition', ' Concentration', 'Max Similarity', 'Mean Similarity']\n",
        "for col in columns_to_convert:\n",
        "    X_test_final_bert_v1[col] = pd.to_numeric(X_test_final_bert_v1[col], errors='coerce')\n",
        "\n",
        "print(X_test_final_bert_v1.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3icCi97-8t_",
        "outputId": "df3c947d-5304-4467-f5a1-8203234259e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Leverage?                float64\n",
            "Portfolio composition    float64\n",
            " Concentration           float64\n",
            "Max Similarity           float64\n",
            "Mean Similarity          float64\n",
            "dtype: object\n",
            "Leverage?                float64\n",
            "Portfolio composition    float64\n",
            " Concentration           float64\n",
            "Max Similarity           float64\n",
            "Mean Similarity          float64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlchIcjpw4xi",
        "outputId": "991ac094-dc75-4e9a-a297-2c9efee160cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning:\n",
            "\n",
            "The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning:\n",
            "\n",
            "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Random Forest Model Accuracy: 0.7659574468085106\n",
            "\n",
            "Best Random Forest Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.40      0.40         5\n",
            "           1       0.79      0.65      0.71        17\n",
            "           2       0.85      0.96      0.90        24\n",
            "           3       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.77        47\n",
            "   macro avg       0.51      0.50      0.50        47\n",
            "weighted avg       0.76      0.77      0.76        47\n",
            "\n",
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning:\n",
            "\n",
            "The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000087 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 69\n",
            "[LightGBM] [Info] Number of data points in the train set: 93, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score -1.699386\n",
            "[LightGBM] [Info] Start training from score -1.274503\n",
            "[LightGBM] [Info] Start training from score -0.682452\n",
            "[LightGBM] [Info] Start training from score -3.839452\n",
            "[LightGBM] [Info] Start training from score -4.532599\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Best LightGBM Model Accuracy: 0.8085106382978723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning:\n",
            "\n",
            "The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best LightGBM Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         5\n",
            "           1       0.71      0.88      0.79        17\n",
            "           2       0.88      0.96      0.92        24\n",
            "           3       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.81        47\n",
            "   macro avg       0.40      0.46      0.43        47\n",
            "weighted avg       0.71      0.81      0.76        47\n",
            "\n",
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
            "Best XGBoost Model Accuracy: 0.723404255319149\n",
            "\n",
            "Best XGBoost Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         5\n",
            "           1       0.65      0.65      0.65        17\n",
            "           2       0.85      0.96      0.90        24\n",
            "           3       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.72        47\n",
            "   macro avg       0.37      0.40      0.39        47\n",
            "weighted avg       0.67      0.72      0.69        47\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Define the parameter grid for Random Forest\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
        "    'max_depth': [None, 10, 20, 30],  # Maximum depth of the tree\n",
        "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
        "    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
        "    'bootstrap': [True, False],  # Method of selecting samples for training each tree\n",
        "}\n",
        "\n",
        "# Create the Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Create the RandomizedSearchCV object\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=rf_classifier,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=100,  # number of parameter settings that are sampled\n",
        "    scoring='accuracy',  # can choose different scoring function based on the problem\n",
        "    cv=5,  # number of folds in cross-validation\n",
        "    verbose=1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1  # number of jobs to run in parallel\n",
        ")\n",
        "\n",
        "# Fit the random search model\n",
        "random_search.fit(X_val_final_bert_v1, y_val_mapped)\n",
        "\n",
        "# The best estimator after random search\n",
        "best_rf_classifier = random_search.best_estimator_\n",
        "\n",
        "# Random Forest\n",
        "rf_predictions = best_rf_classifier.predict(X_test_final_bert_v1)\n",
        "\n",
        "# Evaluating the model\n",
        "print(\"Best Random Forest Model Accuracy:\", accuracy_score(y_test_mapped, rf_predictions))\n",
        "print(\"\\nBest Random Forest Classification Report:\\n\", classification_report(y_test_mapped, rf_predictions))\n",
        "\n",
        "# Define the parameter grid\n",
        "param_dist = {\n",
        "    'num_leaves': [31, 41, 51, 61, 71],  # example values\n",
        "    'reg_alpha': [0.1, 0.5, 1.0],  # example values\n",
        "    'reg_lambda': [0.1, 0.5, 1.0],  # example values\n",
        "    'min_split_gain': [0.0, 0.01, 0.1],  # example values\n",
        "    'min_child_weight': [1e-3, 1e-2, 0.1, 1, 10],  # example values\n",
        "    'learning_rate': [0.005, 0.01, 0.1],  # example values\n",
        "    # add other parameters here\n",
        "}\n",
        "\n",
        "# Create the LightGBM classifier\n",
        "lgb_classifier = lgb.LGBMClassifier(random_state=42)\n",
        "\n",
        "# Create the RandomizedSearchCV object\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=lgb_classifier,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=100,  # number of parameter settings that are sampled\n",
        "    scoring='accuracy',  # can choose different scoring function based on the problem\n",
        "    cv=5,  # number of folds in cross-validation\n",
        "    verbose=1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1  # number of jobs to run in parallel\n",
        ")\n",
        "\n",
        "# Fit the random search model\n",
        "random_search.fit(X_val_final_bert_v1, y_val_mapped)\n",
        "\n",
        "# The best estimator after random search\n",
        "best_lgbm_classifier = random_search.best_estimator_\n",
        "\n",
        "# LightGBM\n",
        "lgb_predictions = best_lgbm_classifier.predict(X_test_final_bert_v1)\n",
        "\n",
        "# Evaluating the model\n",
        "print(\"Best LightGBM Model Accuracy:\", accuracy_score(y_test_mapped, lgb_predictions))\n",
        "print(\"\\nBest LightGBM Classification Report:\\n\", classification_report(y_test_mapped, lgb_predictions))\n",
        "\n",
        "\n",
        "# Define the parameter grid to search\n",
        "param_dist = {\n",
        "    'max_depth': [3, 4, 5, 6, 7],  # example range\n",
        "    'min_child_weight': [1, 5, 10],\n",
        "    'gamma': [0.5, 1, 1.5, 2, 5],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "    'learning_rate': [0.01, 0.02, 0.05, 0.1],  # example range\n",
        "    # You can add more parameters here\n",
        "}\n",
        "\n",
        "# Initialize the XGBClassifier\n",
        "xgb_classifier = xgb.XGBClassifier(random_state=42)\n",
        "\n",
        "# Initialize the RandomizedSearchCV object\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=xgb_classifier,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=100,  # number of parameter settings that are sampled\n",
        "    scoring='accuracy',  # can be adjusted based on the problem\n",
        "    cv=3,  # number of folds in cross-validation\n",
        "    verbose=1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1  # number of jobs to run in parallel\n",
        ")\n",
        "\n",
        "# Fit the random search model\n",
        "random_search.fit(X_val_final_bert_v1, y_val_mapped)\n",
        "\n",
        "# Best estimator found by random search\n",
        "best_xgb_classifier = random_search.best_estimator_\n",
        "\n",
        "# XGBoost\n",
        "xgb_predictions = best_xgb_classifier.predict(X_test_final_bert_v1)\n",
        "\n",
        "# Evaluate the best estimator\n",
        "print(\"Best XGBoost Model Accuracy:\", accuracy_score(y_test_mapped, xgb_predictions))\n",
        "print(\"\\nBest XGBoost Classification Report:\\n\", classification_report(y_test_mapped, xgb_predictions))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLvWi2-Iw4xi"
      },
      "source": [
        "## RoBERTa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "id": "aOf8rShWw4xi",
        "outputId": "2165b5e5-ac74-454b-b7e1-ae5574faa411"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Leverage? Portfolio composition  Concentration Max Similarity  \\\n",
            "56        0.0                   0.0            0.0       0.986513   \n",
            "181       0.0                   1.0            0.0       0.988428   \n",
            "329       1.0                   2.0            0.0        0.98548   \n",
            "271       0.0                   1.0            0.0       0.987444   \n",
            "31        0.0                   2.0            0.0       0.985036   \n",
            "..        ...                   ...            ...            ...   \n",
            "438       1.0                   2.0            0.0       0.985197   \n",
            "17        0.0                   2.0            0.0        0.98382   \n",
            "427       1.0                   2.0            0.0       0.990438   \n",
            "195       1.0                   2.0            0.0       0.987441   \n",
            "57        1.0                   1.0            0.0       0.989053   \n",
            "\n",
            "    Mean Similarity  \n",
            "56         0.984571  \n",
            "181        0.986504  \n",
            "329        0.983212  \n",
            "271        0.985633  \n",
            "31         0.982575  \n",
            "..              ...  \n",
            "438        0.982293  \n",
            "17         0.981602  \n",
            "427         0.98863  \n",
            "195        0.985371  \n",
            "57         0.987118  \n",
            "\n",
            "[93 rows x 5 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Leverage? Portfolio composition  Concentration Max Similarity  \\\n",
              "324       0.0                   1.0            0.0       0.985401   \n",
              "448       0.0                   1.0            0.0        0.98614   \n",
              "298       0.0                   2.0            0.0       0.985934   \n",
              "410       0.0                   2.0            0.0       0.985516   \n",
              "22        0.0                   2.0            0.0       0.984667   \n",
              "\n",
              "    Mean Similarity  \n",
              "324         0.98326  \n",
              "448        0.983537  \n",
              "298        0.983902  \n",
              "410         0.98336  \n",
              "22          0.98248  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-027676f2-e97f-4464-b801-1f26c7cfd5df\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Leverage?</th>\n",
              "      <th>Portfolio composition</th>\n",
              "      <th>Concentration</th>\n",
              "      <th>Max Similarity</th>\n",
              "      <th>Mean Similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>324</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.985401</td>\n",
              "      <td>0.98326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.98614</td>\n",
              "      <td>0.983537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.985934</td>\n",
              "      <td>0.983902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>410</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.985516</td>\n",
              "      <td>0.98336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.984667</td>\n",
              "      <td>0.98248</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-027676f2-e97f-4464-b801-1f26c7cfd5df')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-027676f2-e97f-4464-b801-1f26c7cfd5df button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-027676f2-e97f-4464-b801-1f26c7cfd5df');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-737df0a0-ef91-435f-adc1-8f918cdd1d71\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-737df0a0-ef91-435f-adc1-8f918cdd1d71')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-737df0a0-ef91-435f-adc1-8f918cdd1d71 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_test_final_bert_v2",
              "repr_error": "0"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import RobertaModel, RobertaTokenizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load pre-trained RoBERTa model and tokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
        "model = RobertaModel.from_pretrained('roberta-large')\n",
        "\n",
        "def get_bert_embeddings(texts):\n",
        "    # Tokenize and pad texts\n",
        "    encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "    # Get embeddings\n",
        "    with torch.no_grad():\n",
        "        model_output = model(**encoded_input)\n",
        "\n",
        "    # Mean pool the token embeddings to get the text representation\n",
        "    embeddings = model_output.last_hidden_state.mean(dim=1)\n",
        "    return embeddings.numpy()\n",
        "\n",
        "# Apply the function to the summaries and knowledge base texts\n",
        "summaries_list = X_val_final_bert_v0['summary'].astype(str).tolist()\n",
        "bert_summaries = get_bert_embeddings(summaries_list)\n",
        "bert_kb_entries = get_bert_embeddings(knowledge_base)\n",
        "\n",
        "similarity_matrix = cosine_similarity(bert_summaries, bert_kb_entries)\n",
        "\n",
        "# Feature engineering\n",
        "max_similarity = np.max(similarity_matrix, axis=1)\n",
        "mean_similarity = np.mean(similarity_matrix, axis=1)\n",
        "\n",
        "# Combine features for X_test\n",
        "X_val_features = np.column_stack((max_similarity, mean_similarity))\n",
        "X_val_combined = np.hstack((X_val_final_bert_v0.values, X_val_features))\n",
        "X_val_final_bert_v2 = pd.DataFrame(X_val_combined, columns=list(X_val_final_bert_v0.columns) + ['Max Similarity', 'Mean Similarity'])\n",
        "X_val_final_bert_v2.index = X_val_final_bert_v0.index\n",
        "X_val_final_bert_v2 = X_val_final_bert_v2.drop(columns = 'summary')\n",
        "X_val_final_bert_v2.head()\n",
        "print(X_val_final_bert_v2)\n",
        "\n",
        "# Apply the function to the summaries and knowledge base texts\n",
        "summaries_list = X_test_final_bert_v0['summary'].astype(str).tolist()\n",
        "bert_summaries = get_bert_embeddings(summaries_list)\n",
        "bert_kb_entries = get_bert_embeddings(knowledge_base)\n",
        "\n",
        "similarity_matrix = cosine_similarity(bert_summaries, bert_kb_entries)\n",
        "\n",
        "# Feature engineering\n",
        "max_similarity = np.max(similarity_matrix, axis=1)\n",
        "mean_similarity = np.mean(similarity_matrix, axis=1)\n",
        "\n",
        "# Combine features for X_test\n",
        "X_test_features = np.column_stack((max_similarity, mean_similarity))\n",
        "X_test_combined = np.hstack((X_test_final_bert_v0.values, X_test_features))\n",
        "X_test_final_bert_v2 = pd.DataFrame(X_test_combined, columns=list(X_test_final_bert_v0.columns) + ['Max Similarity', 'Mean Similarity'])\n",
        "X_test_final_bert_v2.index = X_test_final_bert_v0.index\n",
        "X_test_final_bert_v2 = X_test_final_bert_v2.drop(columns = 'summary')\n",
        "X_test_final_bert_v2.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_convert = ['Leverage?', 'Portfolio composition', ' Concentration', 'Max Similarity', 'Mean Similarity']\n",
        "for col in columns_to_convert:\n",
        "    X_val_final_bert_v2[col] = pd.to_numeric(X_val_final_bert_v2[col], errors='coerce')\n",
        "\n",
        "print(X_val_final_bert_v2.dtypes)\n",
        "\n",
        "columns_to_convert = ['Leverage?', 'Portfolio composition', ' Concentration', 'Max Similarity', 'Mean Similarity']\n",
        "for col in columns_to_convert:\n",
        "    X_test_final_bert_v2[col] = pd.to_numeric(X_test_final_bert_v2[col], errors='coerce')\n",
        "\n",
        "print(X_test_final_bert_v2.dtypes)"
      ],
      "metadata": {
        "id": "2yDkLIJrCP1T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62e6c964-9bd3-4942-fd9f-de1e744ff1b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Leverage?                float64\n",
            "Portfolio composition    float64\n",
            " Concentration           float64\n",
            "Max Similarity           float64\n",
            "Mean Similarity          float64\n",
            "dtype: object\n",
            "Leverage?                float64\n",
            "Portfolio composition    float64\n",
            " Concentration           float64\n",
            "Max Similarity           float64\n",
            "Mean Similarity          float64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5q0_IIfw4xj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "579ecb6d-a627-450c-fa7c-c7e03a395d4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning:\n",
            "\n",
            "The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning:\n",
            "\n",
            "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Random Forest Model Accuracy: 0.8085106382978723\n",
            "\n",
            "Best Random Forest Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.40      0.50         5\n",
            "           1       0.87      0.76      0.81        17\n",
            "           2       0.82      0.96      0.88        24\n",
            "           3       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.81        47\n",
            "   macro avg       0.59      0.53      0.55        47\n",
            "weighted avg       0.80      0.81      0.80        47\n",
            "\n",
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning:\n",
            "\n",
            "The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000062 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 69\n",
            "[LightGBM] [Info] Number of data points in the train set: 93, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score -1.699386\n",
            "[LightGBM] [Info] Start training from score -1.274503\n",
            "[LightGBM] [Info] Start training from score -0.682452\n",
            "[LightGBM] [Info] Start training from score -3.839452\n",
            "[LightGBM] [Info] Start training from score -4.532599\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Best LightGBM Model Accuracy: 0.7872340425531915\n",
            "\n",
            "Best LightGBM Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.40      0.40         5\n",
            "           1       0.76      0.76      0.76        17\n",
            "           2       0.88      0.92      0.90        24\n",
            "           3       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.79        47\n",
            "   macro avg       0.51      0.52      0.52        47\n",
            "weighted avg       0.77      0.79      0.78        47\n",
            "\n",
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning:\n",
            "\n",
            "The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best XGBoost Model Accuracy: 0.7659574468085106\n",
            "\n",
            "Best XGBoost Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.40      0.33         5\n",
            "           1       0.79      0.65      0.71        17\n",
            "           2       0.88      0.96      0.92        24\n",
            "           3       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.77        47\n",
            "   macro avg       0.49      0.50      0.49        47\n",
            "weighted avg       0.77      0.77      0.76        47\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Define the parameter grid for Random Forest\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
        "    'max_depth': [None, 10, 20, 30],  # Maximum depth of the tree\n",
        "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
        "    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
        "    'bootstrap': [True, False],  # Method of selecting samples for training each tree\n",
        "}\n",
        "\n",
        "# Create the Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Create the RandomizedSearchCV object\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=rf_classifier,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=100,  # number of parameter settings that are sampled\n",
        "    scoring='accuracy',  # can choose different scoring function based on the problem\n",
        "    cv=5,  # number of folds in cross-validation\n",
        "    verbose=1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1  # number of jobs to run in parallel\n",
        ")\n",
        "\n",
        "# Fit the random search model\n",
        "random_search.fit(X_val_final_bert_v2, y_val_mapped)\n",
        "\n",
        "# The best estimator after random search\n",
        "best_rf_classifier = random_search.best_estimator_\n",
        "\n",
        "# Random Forest\n",
        "rf_predictions = best_rf_classifier.predict(X_test_final_bert_v2)\n",
        "\n",
        "# Evaluating the model\n",
        "print(\"Best Random Forest Model Accuracy:\", accuracy_score(y_test_mapped, rf_predictions))\n",
        "print(\"\\nBest Random Forest Classification Report:\\n\", classification_report(y_test_mapped, rf_predictions))\n",
        "\n",
        "# Define the parameter grid\n",
        "param_dist = {\n",
        "    'num_leaves': [31, 41, 51, 61, 71],  # example values\n",
        "    'reg_alpha': [0.1, 0.5, 1.0],  # example values\n",
        "    'reg_lambda': [0.1, 0.5, 1.0],  # example values\n",
        "    'min_split_gain': [0.0, 0.01, 0.1],  # example values\n",
        "    'min_child_weight': [1e-3, 1e-2, 0.1, 1, 10],  # example values\n",
        "    'learning_rate': [0.005, 0.01, 0.1],  # example values\n",
        "    # add other parameters here\n",
        "}\n",
        "\n",
        "# Create the LightGBM classifier\n",
        "lgb_classifier = lgb.LGBMClassifier(random_state=42)\n",
        "\n",
        "# Create the RandomizedSearchCV object\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=lgb_classifier,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=100,  # number of parameter settings that are sampled\n",
        "    scoring='accuracy',  # can choose different scoring function based on the problem\n",
        "    cv=5,  # number of folds in cross-validation\n",
        "    verbose=1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1  # number of jobs to run in parallel\n",
        ")\n",
        "\n",
        "# Fit the random search model\n",
        "random_search.fit(X_val_final_bert_v2, y_val_mapped)\n",
        "\n",
        "# The best estimator after random search\n",
        "best_lgbm_classifier = random_search.best_estimator_\n",
        "\n",
        "# LightGBM\n",
        "lgb_predictions = best_lgbm_classifier.predict(X_test_final_bert_v2)\n",
        "\n",
        "# Evaluating the model\n",
        "print(\"Best LightGBM Model Accuracy:\", accuracy_score(y_test_mapped, lgb_predictions))\n",
        "print(\"\\nBest LightGBM Classification Report:\\n\", classification_report(y_test_mapped, lgb_predictions))\n",
        "\n",
        "\n",
        "# Define the parameter grid to search\n",
        "param_dist = {\n",
        "    'max_depth': [3, 4, 5, 6, 7],  # example range\n",
        "    'min_child_weight': [1, 5, 10],\n",
        "    'gamma': [0.5, 1, 1.5, 2, 5],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "    'learning_rate': [0.01, 0.02, 0.05, 0.1],  # example range\n",
        "    # You can add more parameters here\n",
        "}\n",
        "\n",
        "# Initialize the XGBClassifier\n",
        "xgb_classifier = xgb.XGBClassifier(random_state=42)\n",
        "\n",
        "# Initialize the RandomizedSearchCV object\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=xgb_classifier,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=100,  # number of parameter settings that are sampled\n",
        "    scoring='accuracy',  # can be adjusted based on the problem\n",
        "    cv=3,  # number of folds in cross-validation\n",
        "    verbose=1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1  # number of jobs to run in parallel\n",
        ")\n",
        "\n",
        "# Fit the random search model\n",
        "random_search.fit(X_val_final_bert_v2, y_val_mapped)\n",
        "\n",
        "# Best estimator found by random search\n",
        "best_xgb_classifier = random_search.best_estimator_\n",
        "\n",
        "# XGBoost\n",
        "xgb_predictions = best_xgb_classifier.predict(X_test_final_bert_v2)\n",
        "\n",
        "# Evaluate the best estimator\n",
        "print(\"Best XGBoost Model Accuracy:\", accuracy_score(y_test_mapped, xgb_predictions))\n",
        "print(\"\\nBest XGBoost Classification Report:\\n\", classification_report(y_test_mapped, xgb_predictions))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}